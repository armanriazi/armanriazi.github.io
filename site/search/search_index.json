{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"I prefer to create a knowledge base for myself and then share it. The philosophy of creating this page is to solve this issue. Video Guide-Website Through to my experiences. Main Menu","title":"Index"},{"location":"about/","tags":["about","me","i","armanriazi","riazi","experience","skills","career","recuit"],"text":"About Me \u00b6 Arman Riazi knows how to move your business, developing on Blockchain 4.0. Getting Luxary services that you can afford. I'm ArmanRiazi. I work with companies to realize the benefits and business outcomes of Blockchain and ITIL. I want to kind of give you a menu of every type of investment and solutions on the Blockchain. I learned the hard way over the years and I try to make it really simplistic on the website. It took me ages to learn the programming and found knowledge of IT. I have been working on the Blockchain ecosystem as a CryptoTrader and Blockchain developer for about 2 years. I've always influence by dr.Ravenwood. His works are so creative. I am sure he will impressive much more in the future. Following the table is my recent experiences \ud83d\ude0b by access to archive before 2020 you can click on it. Resume \u00b6 Blockchain Experience \u00b6 Exprt: Experience Prd: Period Desc: Description Priority: My Interest priority for keep in continue Exprt Prd Priority Desc CryptoTrading 1 Y Experience losts liquid because of trading crypto in 2021 \ud83e\udd15 - Archived Cryptocurrency Solidity 2 M It seems to me that there would be better languages for developing so in the near furure we need to low-level lang for improve performance hardware resources IBM HyperLedger 1 M HyperLedger is suited for organizations especially. Hyperledger has got good community and uses cloud-native tools but I think it is not a real decentralized blockchain framework for scalability and giving governance so I used to decide a little bit work on it Rust-Lang 7 M Fantastic, complex language for decentralized/distributed Substrate 2 M Awsome work of \ud83d\ude4fDr.Gavin and parity.io community Polkadot & Kusuma 1 M Crowdloan, tokenization\ud83d\udcb2, parachain and parathreads Blockchain research 1 Y It is always included in my routine activity during a day About 8-month trading, 2 months solidity, 4 months rust-lang, 2 months substrate, 2 months research on Polkadot ecosystem, 6 month scholar research on blockchain. There is not exactly the time to estimate spend time since developing and learning would go with each other. In my opinion, developers who had a kind of skills like Frontend, Backend, or Database have been forced into the Blockchain ecosystem because of the charm of the subject and the rapid growth and evolution of the Technology. I wonder to let you know I am big on Substrate and WASM Substrate, WASM to apply for mixing experiences and technologies that lead to #Defi2.0 & #Web3.0 . It is the only chance I get to find out what's been going on in the technology world and catch up with the current affairs. I worked for companies that were B2B or B2C. Therefore, I have developed projects based on the skills mentioned in the resume, which did not need to be introduced on the personal website because the material and intellectual rights of the works must be preserved. I have worked for 5 domestic companies in the field of support, development and consulting, and when I decided to work internationally(or decentralized), I spent a lot of time learning again and more(because there are high inflation and economics pressure in the country and I estimated in the future will be harder but my top priority always have been gaining more experiance in different places). You can see the prototypes of the works done on GitHub. Proof of Knowledge \u00b6 Knowledgement-Tags Hands-On Experience With Blockchain Developing. Knowledge Of Blockchain Structure. Experienced With Software Development Lifecycle. Experienced With Cloud-Computing And DevOps/ Link CloudNative Tools. Expert In Modern Programming Languages. Have Technical Conscience To Define The Right Blockchain Solutions. Understand Decentralized Ledgers and Configure Full/Master Node. Technical Knowledge of Standards and Ecosystems. Cryptocurrency #trading and using financial services. Graduated M.Sc [[master]] In The Field Of Information Technology. Birthday: 11/11/1989 In Addition Expertise with various blockchain platforms between permissioned vs. public chains. Enthusiastic building solutions on blockchain protocols (e.g. Polkadot, Kusama, NEAR, Solana). Trade Experience with layer 2 protocols. Knowledge of some of the consensus mechanism technical knowledge like (x)POS, POW. Knowledge of Digital Assets, Smart Contract Oracles, Inter-operability, private/permissioned blockchains and sustainability. Knowledge of Ethereum development tools (i.e. Hardhat, OpenZeppelin). Experience in delivering cloud-native architectures and solutions (e.g. Azure, IBM, Rancher). Experience with writing/debugging and deploying Smart Contracts. Experience with platform security, scalability, and reliability. Understanding of the blockchain vendor landscape. Understanding of how to layer blockchain network with cloud application and client UI through API streams. Demonstrates strong value for diversity and ability to team and collaborate effectively. Substantial experience developing and delivering executive level presentations. Comfortable working in a virtual environment and managing a virtual team. Flexibility/adaptability - comfortable working with ambiguity and continually evolving priorities. Willingness to travel as required. 5+ years technology consulting experience. Over 10 years of experience in designing, developing, deploying, analyzing, and implementing [[Cloud]]-native, web, and software engineers. Expertise in the architecture of #Microservices and distributed systems, and modifying related application code. Capable of learning new programming languages and technologies. Good communication, problem-solving, documentation, and analytical. Capable of learning new skills and concepts quickly. Maintain effective relationships with others. General features including Research, Creative, Analyze, Self-Developing. Highly organized, motivated, confident. Favourites \u00b6 Cosmology books. Read fundamental blockchain whitepapers. and new taxonomy articles. Personal interests Footbal, Running, Body-Building, Motorcycles and Reading Books. Live Concert and Music Video-Magazine Call Me-Preferred Channels \u00b6 Contact Me Support Me/Sponsership \u00b6 MetaMask(MultiNet): 0xde5D732a5AB44832E1c69b18be30834639F44A2c","title":"About"},{"location":"about/#about-me","text":"Arman Riazi knows how to move your business, developing on Blockchain 4.0. Getting Luxary services that you can afford. I'm ArmanRiazi. I work with companies to realize the benefits and business outcomes of Blockchain and ITIL. I want to kind of give you a menu of every type of investment and solutions on the Blockchain. I learned the hard way over the years and I try to make it really simplistic on the website. It took me ages to learn the programming and found knowledge of IT. I have been working on the Blockchain ecosystem as a CryptoTrader and Blockchain developer for about 2 years. I've always influence by dr.Ravenwood. His works are so creative. I am sure he will impressive much more in the future. Following the table is my recent experiences \ud83d\ude0b by access to archive before 2020 you can click on it.","title":"About Me"},{"location":"about/#resume","text":"","title":"Resume"},{"location":"about/#blockchain-experience","text":"Exprt: Experience Prd: Period Desc: Description Priority: My Interest priority for keep in continue Exprt Prd Priority Desc CryptoTrading 1 Y Experience losts liquid because of trading crypto in 2021 \ud83e\udd15 - Archived Cryptocurrency Solidity 2 M It seems to me that there would be better languages for developing so in the near furure we need to low-level lang for improve performance hardware resources IBM HyperLedger 1 M HyperLedger is suited for organizations especially. Hyperledger has got good community and uses cloud-native tools but I think it is not a real decentralized blockchain framework for scalability and giving governance so I used to decide a little bit work on it Rust-Lang 7 M Fantastic, complex language for decentralized/distributed Substrate 2 M Awsome work of \ud83d\ude4fDr.Gavin and parity.io community Polkadot & Kusuma 1 M Crowdloan, tokenization\ud83d\udcb2, parachain and parathreads Blockchain research 1 Y It is always included in my routine activity during a day About 8-month trading, 2 months solidity, 4 months rust-lang, 2 months substrate, 2 months research on Polkadot ecosystem, 6 month scholar research on blockchain. There is not exactly the time to estimate spend time since developing and learning would go with each other. In my opinion, developers who had a kind of skills like Frontend, Backend, or Database have been forced into the Blockchain ecosystem because of the charm of the subject and the rapid growth and evolution of the Technology. I wonder to let you know I am big on Substrate and WASM Substrate, WASM to apply for mixing experiences and technologies that lead to #Defi2.0 & #Web3.0 . It is the only chance I get to find out what's been going on in the technology world and catch up with the current affairs. I worked for companies that were B2B or B2C. Therefore, I have developed projects based on the skills mentioned in the resume, which did not need to be introduced on the personal website because the material and intellectual rights of the works must be preserved. I have worked for 5 domestic companies in the field of support, development and consulting, and when I decided to work internationally(or decentralized), I spent a lot of time learning again and more(because there are high inflation and economics pressure in the country and I estimated in the future will be harder but my top priority always have been gaining more experiance in different places). You can see the prototypes of the works done on GitHub.","title":"Blockchain Experience"},{"location":"about/#proof-of-knowledge","text":"Knowledgement-Tags Hands-On Experience With Blockchain Developing. Knowledge Of Blockchain Structure. Experienced With Software Development Lifecycle. Experienced With Cloud-Computing And DevOps/ Link CloudNative Tools. Expert In Modern Programming Languages. Have Technical Conscience To Define The Right Blockchain Solutions. Understand Decentralized Ledgers and Configure Full/Master Node. Technical Knowledge of Standards and Ecosystems. Cryptocurrency #trading and using financial services. Graduated M.Sc [[master]] In The Field Of Information Technology. Birthday: 11/11/1989 In Addition Expertise with various blockchain platforms between permissioned vs. public chains. Enthusiastic building solutions on blockchain protocols (e.g. Polkadot, Kusama, NEAR, Solana). Trade Experience with layer 2 protocols. Knowledge of some of the consensus mechanism technical knowledge like (x)POS, POW. Knowledge of Digital Assets, Smart Contract Oracles, Inter-operability, private/permissioned blockchains and sustainability. Knowledge of Ethereum development tools (i.e. Hardhat, OpenZeppelin). Experience in delivering cloud-native architectures and solutions (e.g. Azure, IBM, Rancher). Experience with writing/debugging and deploying Smart Contracts. Experience with platform security, scalability, and reliability. Understanding of the blockchain vendor landscape. Understanding of how to layer blockchain network with cloud application and client UI through API streams. Demonstrates strong value for diversity and ability to team and collaborate effectively. Substantial experience developing and delivering executive level presentations. Comfortable working in a virtual environment and managing a virtual team. Flexibility/adaptability - comfortable working with ambiguity and continually evolving priorities. Willingness to travel as required. 5+ years technology consulting experience. Over 10 years of experience in designing, developing, deploying, analyzing, and implementing [[Cloud]]-native, web, and software engineers. Expertise in the architecture of #Microservices and distributed systems, and modifying related application code. Capable of learning new programming languages and technologies. Good communication, problem-solving, documentation, and analytical. Capable of learning new skills and concepts quickly. Maintain effective relationships with others. General features including Research, Creative, Analyze, Self-Developing. Highly organized, motivated, confident.","title":"Proof of Knowledge"},{"location":"about/#favourites","text":"Cosmology books. Read fundamental blockchain whitepapers. and new taxonomy articles. Personal interests Footbal, Running, Body-Building, Motorcycles and Reading Books. Live Concert and Music Video-Magazine","title":"Favourites"},{"location":"about/#call-me-preferred-channels","text":"Contact Me","title":"Call Me-Preferred Channels"},{"location":"about/#support-mesponsership","text":"MetaMask(MultiNet): 0xde5D732a5AB44832E1c69b18be30834639F44A2c","title":"Support Me/Sponsership"},{"location":"fun/","text":"Entertainment \u00b6 3D-360-Images 3D-360-Videos Music-Video Magazine","title":"Entertainment"},{"location":"fun/#entertainment","text":"3D-360-Images 3D-360-Videos Music-Video Magazine","title":"Entertainment"},{"location":"links/","text":"Links Papers On Blockchain Personal WebSite(Archived) Personal WebSite(Archived) Email addresses Links \u00b6 Youtube Channel Blockchain Youtube Channel-Archived Papers On Blockchain \u00b6 Read.Cash Medium Ecency Repo-Doc-Blockchain Github Gitlab Aparat Channel Linux foundation Linkedin ResearchGate Dev.to Stackoverflow CodeGrepper Linktr.ee Personal WebSite(Archived) \u00b6 Arazhit Aramisit ArmanRiazi Personal WebSite(Archived) \u00b6 ArmanRiazi-Doc Email addresses \u00b6 *Job Developer Scholar *** Skype ID *** armanriazi","title":"Links"},{"location":"links/#links","text":"Youtube Channel Blockchain Youtube Channel-Archived","title":"Links"},{"location":"links/#papers-on-blockchain","text":"Read.Cash Medium Ecency Repo-Doc-Blockchain Github Gitlab Aparat Channel Linux foundation Linkedin ResearchGate Dev.to Stackoverflow CodeGrepper Linktr.ee","title":"Papers On Blockchain"},{"location":"links/#personal-websitearchived","text":"Arazhit Aramisit ArmanRiazi","title":"Personal WebSite(Archived)"},{"location":"links/#personal-websitearchived_1","text":"ArmanRiazi-Doc","title":"Personal WebSite(Archived)"},{"location":"links/#email-addresses","text":"*Job Developer Scholar *** Skype ID *** armanriazi","title":"Email addresses"},{"location":"social/","tags":["about","social","contact","connect","me","i","armanriazi","riazi","career","recuit"],"text":"Contact Me \u00b6 [To Set Schedule Meeting] armanriyazi.github.io@gmail.com Users.Rust-Lang Discord Matrix.to Disqus . I am here \u00b6 Skype: armanriazi (Video Call) Telegram: @arman_riazi (Instant Message, Call) Instagram: arman_soc_riazi(Instant Message, Call) Twitter: arman_soc_riazi(Message, Shared links) Channel: Blockchain-Aramisit, Discord ID: armanriyazi.github.io#5111 I recommend signing up channels to keep in connect. Support Me \u00b6 MetaMask(MultiNet): 0xde5D732a5AB44832E1c69b18be30834639F44A2c","title":"Reach Me"},{"location":"social/#contact-me","text":"[To Set Schedule Meeting] armanriyazi.github.io@gmail.com Users.Rust-Lang Discord Matrix.to Disqus .","title":"Contact Me"},{"location":"social/#i-am-here","text":"Skype: armanriazi (Video Call) Telegram: @arman_riazi (Instant Message, Call) Instagram: arman_soc_riazi(Instant Message, Call) Twitter: arman_soc_riazi(Message, Shared links) Channel: Blockchain-Aramisit, Discord ID: armanriyazi.github.io#5111 I recommend signing up channels to keep in connect.","title":"I am here"},{"location":"social/#support-me","text":"MetaMask(MultiNet): 0xde5D732a5AB44832E1c69b18be30834639F44A2c","title":"Support Me"},{"location":"tags/","text":"Tags \u00b6 If you want to get Updated-graph image, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ Graph) If you want to get Updated-mind-mapping image, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ MindMapping) If you want to get Commands(Ubuntu, Devops, Blockchain CLIs) in a compact, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ Commands) Following is a list of relevant tags: about \u00b6 About Me Reach Me api \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api armanriazi \u00b6 About Me Reach Me Master Thesis--Arman Riazi build \u00b6 Ocw runtime caas \u00b6 Rancher Master Thesis--Arman Riazi career \u00b6 About Me Reach Me cicd \u00b6 CICD Kubernetes armanriazi-movies-reactjs armanriazi-vidly-api cloud \u00b6 Cloud Virualization armanriazi-movies-reactjs armanriazi-vidly-api Master Thesis--Arman Riazi codebase \u00b6 Programming compile \u00b6 Libc rust connect \u00b6 Reach Me contact \u00b6 Reach Me container \u00b6 Docker Rancher Master Thesis--Arman Riazi corda \u00b6 Corda-R3 couchdb \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api crowdloan \u00b6 Crowdloan research intro cryprocurrency \u00b6 Cryptocurrency Balance Sheets (Archived) devops \u00b6 Hyperledger CICD Cloud DevOps Docker Elastic-Search Kubernetes Rancher Virualization armanriazi-movies-reactjs armanriazi-vidly-api Master Thesis--Arman Riazi docker \u00b6 Docker elastic \u00b6 Elastic-Search esxi \u00b6 Virualization ethereum_ecosystem \u00b6 Solidity Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract ewasm \u00b6 ParaState WASM experience \u00b6 About Me expressjs \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api faucet \u00b6 Arman Riazi github \u00b6 Substrate Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract armanriazi-movies-reactjs armanriazi-vidly-api Programming Master Thesis--Arman Riazi hyperledger \u00b6 Hyperledger i \u00b6 About Me Reach Me ibm \u00b6 Hyperledger armanriazi-movies-reactjs armanriazi-vidly-api iot \u00b6 Secondstate research intro java \u00b6 Corda-R3 Master Thesis--Arman Riazi kovan \u00b6 Arman Riazi kubernetes \u00b6 Kubernetes Rancher kusama \u00b6 Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro libc \u00b6 Libc rust llvm \u00b6 Ewasm research intro magazine \u00b6 Magazine master \u00b6 Master Thesis--Arman Riazi me \u00b6 About Me Reach Me music \u00b6 Music Videos node \u00b6 Substrate setup research intro nodejs \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api ocw \u00b6 Ocw runtime parastate \u00b6 Parastate research intro polkadot \u00b6 Polka research intro Substrate framework research intro polkadot_ecosystem \u00b6 ParaState Polkadot Substrate Parastate research intro Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro Ewasm research intro pos \u00b6 Parastate research intro programming \u00b6 Programming project \u00b6 ParaState Polkadot Substrate rancher \u00b6 Rancher reactjs \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api recuit \u00b6 About Me Reach Me research \u00b6 ParaState Polkadot restapi \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api riazi \u00b6 About Me Reach Me rpc \u00b6 Substrate setup research intro runtime \u00b6 Ocw runtime rust \u00b6 Substrate setup research intro Programming sample \u00b6 ParaState Polkadot Substrate Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract armanriazi-movies-reactjs armanriazi-vidly-api science \u00b6 Master Thesis--Arman Riazi search \u00b6 Elastic-Search secondstate \u00b6 Secondstate research intro simulation \u00b6 Corda-R3 skills \u00b6 About Me smartcontract \u00b6 Solidity Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract social \u00b6 Reach Me substrate \u00b6 ParaState Polkadot Substrate Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro Ewasm research intro trade \u00b6 Cryptocurrency Balance Sheets (Archived) university \u00b6 Master Thesis--Arman Riazi virtualization \u00b6 Virualization Master Thesis--Arman Riazi vsphere \u00b6 Virualization wasm \u00b6 SecondState WASM Ewasm research intro webassembly \u00b6 Ewasm research intro whitepapaer \u00b6 Polka research intro","title":"Tags"},{"location":"tags/#tags","text":"If you want to get Updated-graph image, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ Graph) If you want to get Updated-mind-mapping image, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ MindMapping) If you want to get Commands(Ubuntu, Devops, Blockchain CLIs) in a compact, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ Commands) Following is a list of relevant tags:","title":"Tags"},{"location":"tags/#about","text":"About Me Reach Me","title":"about"},{"location":"tags/#api","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"api"},{"location":"tags/#armanriazi","text":"About Me Reach Me Master Thesis--Arman Riazi","title":"armanriazi"},{"location":"tags/#build","text":"Ocw runtime","title":"build"},{"location":"tags/#caas","text":"Rancher Master Thesis--Arman Riazi","title":"caas"},{"location":"tags/#career","text":"About Me Reach Me","title":"career"},{"location":"tags/#cicd","text":"CICD Kubernetes armanriazi-movies-reactjs armanriazi-vidly-api","title":"cicd"},{"location":"tags/#cloud","text":"Cloud Virualization armanriazi-movies-reactjs armanriazi-vidly-api Master Thesis--Arman Riazi","title":"cloud"},{"location":"tags/#codebase","text":"Programming","title":"codebase"},{"location":"tags/#compile","text":"Libc rust","title":"compile"},{"location":"tags/#connect","text":"Reach Me","title":"connect"},{"location":"tags/#contact","text":"Reach Me","title":"contact"},{"location":"tags/#container","text":"Docker Rancher Master Thesis--Arman Riazi","title":"container"},{"location":"tags/#corda","text":"Corda-R3","title":"corda"},{"location":"tags/#couchdb","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"couchdb"},{"location":"tags/#crowdloan","text":"Crowdloan research intro","title":"crowdloan"},{"location":"tags/#cryprocurrency","text":"Cryptocurrency Balance Sheets (Archived)","title":"cryprocurrency"},{"location":"tags/#devops","text":"Hyperledger CICD Cloud DevOps Docker Elastic-Search Kubernetes Rancher Virualization armanriazi-movies-reactjs armanriazi-vidly-api Master Thesis--Arman Riazi","title":"devops"},{"location":"tags/#docker","text":"Docker","title":"docker"},{"location":"tags/#elastic","text":"Elastic-Search","title":"elastic"},{"location":"tags/#esxi","text":"Virualization","title":"esxi"},{"location":"tags/#ethereum_ecosystem","text":"Solidity Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract","title":"ethereum_ecosystem"},{"location":"tags/#ewasm","text":"ParaState WASM","title":"ewasm"},{"location":"tags/#experience","text":"About Me","title":"experience"},{"location":"tags/#expressjs","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"expressjs"},{"location":"tags/#faucet","text":"Arman Riazi","title":"faucet"},{"location":"tags/#github","text":"Substrate Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract armanriazi-movies-reactjs armanriazi-vidly-api Programming Master Thesis--Arman Riazi","title":"github"},{"location":"tags/#hyperledger","text":"Hyperledger","title":"hyperledger"},{"location":"tags/#i","text":"About Me Reach Me","title":"i"},{"location":"tags/#ibm","text":"Hyperledger armanriazi-movies-reactjs armanriazi-vidly-api","title":"ibm"},{"location":"tags/#iot","text":"Secondstate research intro","title":"iot"},{"location":"tags/#java","text":"Corda-R3 Master Thesis--Arman Riazi","title":"java"},{"location":"tags/#kovan","text":"Arman Riazi","title":"kovan"},{"location":"tags/#kubernetes","text":"Kubernetes Rancher","title":"kubernetes"},{"location":"tags/#kusama","text":"Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro","title":"kusama"},{"location":"tags/#libc","text":"Libc rust","title":"libc"},{"location":"tags/#llvm","text":"Ewasm research intro","title":"llvm"},{"location":"tags/#magazine","text":"Magazine","title":"magazine"},{"location":"tags/#master","text":"Master Thesis--Arman Riazi","title":"master"},{"location":"tags/#me","text":"About Me Reach Me","title":"me"},{"location":"tags/#music","text":"Music Videos","title":"music"},{"location":"tags/#node","text":"Substrate setup research intro","title":"node"},{"location":"tags/#nodejs","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"nodejs"},{"location":"tags/#ocw","text":"Ocw runtime","title":"ocw"},{"location":"tags/#parastate","text":"Parastate research intro","title":"parastate"},{"location":"tags/#polkadot","text":"Polka research intro Substrate framework research intro","title":"polkadot"},{"location":"tags/#polkadot_ecosystem","text":"ParaState Polkadot Substrate Parastate research intro Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro Ewasm research intro","title":"polkadot_ecosystem"},{"location":"tags/#pos","text":"Parastate research intro","title":"pos"},{"location":"tags/#programming","text":"Programming","title":"programming"},{"location":"tags/#project","text":"ParaState Polkadot Substrate","title":"project"},{"location":"tags/#rancher","text":"Rancher","title":"rancher"},{"location":"tags/#reactjs","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"reactjs"},{"location":"tags/#recuit","text":"About Me Reach Me","title":"recuit"},{"location":"tags/#research","text":"ParaState Polkadot","title":"research"},{"location":"tags/#restapi","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"restapi"},{"location":"tags/#riazi","text":"About Me Reach Me","title":"riazi"},{"location":"tags/#rpc","text":"Substrate setup research intro","title":"rpc"},{"location":"tags/#runtime","text":"Ocw runtime","title":"runtime"},{"location":"tags/#rust","text":"Substrate setup research intro Programming","title":"rust"},{"location":"tags/#sample","text":"ParaState Polkadot Substrate Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract armanriazi-movies-reactjs armanriazi-vidly-api","title":"sample"},{"location":"tags/#science","text":"Master Thesis--Arman Riazi","title":"science"},{"location":"tags/#search","text":"Elastic-Search","title":"search"},{"location":"tags/#secondstate","text":"Secondstate research intro","title":"secondstate"},{"location":"tags/#simulation","text":"Corda-R3","title":"simulation"},{"location":"tags/#skills","text":"About Me","title":"skills"},{"location":"tags/#smartcontract","text":"Solidity Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract","title":"smartcontract"},{"location":"tags/#social","text":"Reach Me","title":"social"},{"location":"tags/#substrate","text":"ParaState Polkadot Substrate Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro Ewasm research intro","title":"substrate"},{"location":"tags/#trade","text":"Cryptocurrency Balance Sheets (Archived)","title":"trade"},{"location":"tags/#university","text":"Master Thesis--Arman Riazi","title":"university"},{"location":"tags/#virtualization","text":"Virualization Master Thesis--Arman Riazi","title":"virtualization"},{"location":"tags/#vsphere","text":"Virualization","title":"vsphere"},{"location":"tags/#wasm","text":"SecondState WASM Ewasm research intro","title":"wasm"},{"location":"tags/#webassembly","text":"Ewasm research intro","title":"webassembly"},{"location":"tags/#whitepapaer","text":"Polka research intro","title":"whitepapaer"},{"location":"todo/","text":"okay so I want to set a few expectations I wasn't I wasn't sort of expecting to stand at the front and give any sort of talks so not very much is is is ready in that regard it's really meant to be a workshop for kind of rough coding I wanted to get some people whoever brought their laptop sort of up to speed maybe get substrate downloaded and built and sort of take take people through maybe deploying deploying a new chain maybe writing some modules Sergei here is going to sort of give some give a demonstration of how to deploy a smart contract on our smart contract based substrate base smart contract chain so yeah don't expect too much hand holding on this what else yeah I figured actually I would put it to the audience what it is that you would prefer to see and do do like remember that you know if you say ah we'd like to see a new substrate module being done or I'd like to see how you develop the UI or how I would see something else it is gonna be me sort of bashing away on a keyboard for 85% at the time and if you don't have a keyboard to bash away with in-concert then it's it's going to be pretty boring but feel free to to ask me to demonstrate or sort of educate on what substrate does and how it works and I'll try and use my now freshly compiled substrate code base to help help explain any so any any requests no requests yep Adrian I certainly car would be my greatest pleasure to you to walk through and anything beyond walking through JavaScript's sorry walking through substrate models in JavaScript yeah sure okay sure yep that's gonna be a month or two before we we've already done over that but yeah you can expect that in the new year it's good that Rob's not here otherwise you might meet cringing right now sure yeah okay I guess there's a few things there to be working on okay let's start with the the last question because that's the one I can remember the easiest so if we if we had to depart the code base is this can you actually read that or should i zoom in a bit better or some more yeah okay cause like the more i zoom the less the less easier for me it's gonna be boring it can also make more space are a horizontal space yeah okay cool yeah so a you TXO model it's an interesting sort of one and one that we have just about begun prototyping in parity we've got a team of like two or three people working on it basically the bitcoin style you UTXO model \u00b6 is kind of an interesting hybrid between the stripped/stricked all full nodes must validate everything and and base their validation they the things that they validate sort of they put a state route/root a storage route if you like state route into each block header and that means that like clients when they come along they can actually in principle validate everything all of the state transition logic of every block based purely upon the state route of the last block right so if you trust that the header of the last block is something or other then you can check that state route and you can come you can be provided with a proof that all of the transactions on the current block where executed correctly and therefore that the state route on the current block is is correct and polka dot very much uses this model it's the model that the power chains are based around and it basically means that validators by having just like client logic can actually validate every power chain equally I'm bitcoins a little different in principle if you trust the previous blocks header you can still be provided with a proof that the current block is valid but the proof is potentially all of the Bitcoin blockchain and therefore not super concise this it's this is the case because Bitcoin doesn't keep a track of the current state at every block and place that in the header as a cryptographic hash rather when you want to so make some transaction on Bitcoin and prove that it's a valid transaction you use unspent transaction outputs and those are outputs that it is expected that nodes will record in their database but if you want the actual proof that those outputs are valid you have to go all the way back to the block where they were they were the outputs from a spend in order to be sure that that they're legit and obviously you have to see the entire chain between now and then in order to be sure that they weren't spent already so it's it's much harder to do a you TXO model in literally the same vein as Bitcoin because this kind of light client sort of model doesn't doesn't quite extend to the conciseness theorems does that said if you instead store the unspent transaction outputs in a murkily structure in the same way that aetherium stores its contract state then you are able to basically get a hash of that structure every block and you can you can provide concise proofs that a particular transaction is valid because you can see the you can demonstrate that those and spent transaction outputs appear in this localized structure and that's how we would implement a u TXO style chain within the para chain model and probably how we would implement it in substrate and that's actually going forward how its we built in principle though as I said that you could introduce a raw database into substrate and actually mimic bitcoins model but it would preclude turning it into a para chain without adding some additional layers of indirection and likely are not likely enough trust which we're not so keen on introducing programmatically speaking you'd introduce a UT EXO's at if we go into the code base so I mentioned before like substrate has three levels of kind of you can dive into substrate of three levels so you can dive into at the core which is right there oh and this is if you use substrate you use substrate core and it's got all of the things that you would expect to see in a in a block chain if we look at the modules or the crates as Arista falls them then we you know you can see things like the consensus and the finality and the keystore and the networking and the our PCs and so forth it would likely be implemented as a outside of the SRM L so the SRM L is here because the SRM L is rather designed around a an account and an index model similar to aetherium in principle you could nonetheless create some additional SRM l modules that kind of introduce you to EXO's I mean in principle as modules of turing-complete they've got entry point functions that can be arbitrary bodies and they've got they can they can do basically anything with storage that they want so there's no reason that you couldn't implement it that way but it'd probably be a bit more efficient and make a bit more sense if you implement it as its own runtime and to do it as its own runtime you would basically just use the underlying abstractions in core that were used in order to pass in order to allow things like the execute block function to be to be implemented and for it to be called into by the the rest of the client and and work with that directly and you define your own block format and your own transaction format and in general build the execute block function and that's in Bitcoin from from scratch where as I say parity is is pushing forward with its with a you TXO chain mostly so partly to make sure that the model that we have is actually general it's it's a good sort of sanity check and partly because we actually want to introduce a payment based system that's that's a sorry a payment system that's based around you TX owes and potentially that has some sort of ZK snark functionality in as well and we're doing that with the by reusing as much of the PBGC block parity Bitcoin and code bases become cool I'm not going to start implementing one here am i okay maybe laters cool what were the other three questions theorem compatibility yeah so how does the RPC RPC and JavaScript work this is a yeah this is an interesting question so substrates meant to be pretty generic and if we go to the RBC module it's split into four four sub sub modules author chain state and system author is to do with block authoring and it contains have a look what it contains submit extrinsic there's a couple formats you can submit them in and a Ana pub/sub to let you watch what's happening with those extrinsic s-- so if you actually want to inter inter oh if you want to communicate with substrate through the AH feces then these are the RPC is you're going to use and it's basically like here's an extrinsic it's already signed it's already done and dusted just submit it broadcast it whatever and let me know how it goes and you from this you'll get back various messages I think I know they were on the have a look maybe I've got some messages yeah I don't you'll get various messages to tell you that it's been validated that it's been broadcast that or that it's about to be broadcast that it's been broadcast and that it's been finalized or if it doesn't get finalized if something else gets finalized in its place and that it's now been dumped then you'll be again told that it's been okay so back to substrate 101 yes right to make to make substrate be as general as possible we didn't want to introduce data into the block header that may not be in every block chain that substrate that need not be in every block chain that substrate is gonna cater for rather we want to make the header strictly the information that is required for substrate and the rest of the rest of the information that might otherwise go into a header in normal block chains for example the timestamp instead is provided under a separate model that's outside of the header called the extrinsic and extrinsic just mean that it's like data that is extrinsic to the block chain so it's not it's not intrinsic to the chain it's not like part of its state or anything like that it's not a previous transaction or anything that it can draw upon directly but rather it's just data from the external world is extrinsic to the chain and so data from the external world is provided in this set of of snippets of pieces and each piece is called extra and extrinsic and it's just short for a piece of extra piece of data extrinsic to the chain so right so specifically the transactions that are coming in coming in from the external world they are indeed extrinsic so most block chains possibly all require there they're sort of transactions to be signed like they have a particular signature scheme and if they're not signed or if the signatures wrong then they'll never be considered they won't even make it into the system substrates a bit different so substrate says extrinsic scan there are perfectly valid extrinsic s-- that are not signed they're extrinsic the only thing special about them is that they're a bit of data and they come with some way of determining their length upfront so you you know you can pass them around on the network without worrying how long they are other than that they're they're just arbitrary bits of data they may be signed they may include a signature they may include a multi-sig they may not it doesn't really matter some pieces of data for example the timestamp so there's literal okay I can think of very easy Taric ways how you might possibly argue that a timestamp could be signed and that would make it valid like maybe if the the what's at the atoll the guys are on the atomic clocks like maybe signed it with one of the keys but still someone could steal the keys and then the signature it doesn't make it specifically valid nothing can make a timestamp specifically valid right it's a piece of data from the external world and the only thing that means a time star is correct as if we all agree that it's correct what time is it right now well I can say well it's 38 minutes past 6:00 in the evening but it's if your watch says that it's 37 minutes past 6:00 then you know there is no way how without like finding a shared Authority there's no way how we can argue that one is more correct than another and certainly signing it isn't going to help all three authors just an arbitrary name that we call when we say author we just mean block author so this is a block authoring API this is an a this is an RPC that you use when you want to interact with the bit of substrate that is authoring blocks and this is actually incorrectly named it's very good that you brought it up it shouldn't be called extrinsic s-- or at least it's it's it's a little over general to call the extrinsic the only extrinsic that you can submit using this API are specifically signed extrinsic because it's coming from the RPC and therefore you have no other way other than looking for a signature to know that it's anything that's really sensible unsigned extrinsic switch for what it's worth we call inherence because they are we treat them as being inherently valid are are generated within substrate so extrinsic s-- is information that come from the outside of substrate and inherent are our extrinsic that come from within substrate and sorry transactions really come from the outside inherent come from with them they're both forms of extrinsic because they're both forms of data that can be introduced to the blockchain and that might make some sense to the runtime now if you don't if you don't sign some data then it's like well you know how does that how does that possibly work you know data's not signed then it could be anything right and the way that it works is the validators so the guys that basically say that this block is valid are the ones that get to be opinionated over whether this data is sensible or not and that's actually how this works in other blockchains as well so if you look to aetherium if the time stamp is actually just an opinion right a validator when they validate an aetherium block have an opinion over whether this time stamp is sensible or not and if it's not sensible they ignore the block they unilaterally decide to ignore the block and in in that sense substrate is equivalent in its treatment of inherent if a is up to a validator when they're proposing the block to put in sensible inherence and if they don't put in sensible inherence if there's inherent in correct or incorrect in the opinion of the other validators then their block will be considered useless and won't get any further attention so it's up to them to put in sensible values for the inherent extrinsic that are required by the block and this basically means that we can do all sorts of interesting stuff aside from time stamps I mean time stamps are the first use but we can do things like for example with para chained candidates for the polkadot relay chain there are that's another form of inherence why because which candidates you choose in order to in order to to be to be therefore finalizing is necessarily an opinion right it's different validators might choose different para chained candidate blocks to be finalized for that particular relay chain block there's no way of deterministic elite oozing the correct set of these guys it's just whichever ones happen to come come by you but if you put forward blocks that the other validators on the relay chain think are invalid perhaps pick they don't have the Associated data because there's no data availability for them or just perhaps because they're empty perhaps because they they just haven't seen them before whatever reason it is if they don't think that your opinion is is a good one over the selection of these blocks and they're free to ignore you in reality you know they'd have to be quite malevolent before they do ignore valid blocks because they get paid basically for passing these things but by and large it's up to the validators to self-police the content of the inherent transactions the the sorry the inherent extrinsic s-- for the transaction extrinsic s-- there they are per se valid or invalid like you can check whether a transaction is valid by virtue of does it have a good signature and whatever account has signed it does it have enough funds at this point in order to pay for the the cost for it to be placed on chain and if those two answers are yes then it's all good and that's the difference between the two so this is the RPC for how you can submit them unlike aetherium we don't provide any account management stuff in here so what you can't do is provide is try and get it to sign in and to sign a transaction all of the signing happens external to the node so the node is minimal we do very well noticed the keystore package is there specifically for for block authors so far the validator nodes just stored their their block authoring keys so basically when you when you set up a node as a validator node which so I got away without doing this on the on the demo that I gave earlier by using the - - dev option which is shorthand for - - chain equals dev - - validator \u00b6 key Alice but I could have typed those in and it would have done the same thing and so when you pass it the key it will it will use that it will basically put that key into the the key store and then if it notices a key in the keystore is one of the validators and it's set to being a validator it will actually start signing what and and join in with the consensus so that's the key store is really just there for the for managing validators keys for consensus yeah I can see yeah so there'll be some shims or middleware in order to manage some of this some of these are pcs to make to make it compatible now I'll go into I'll go because this is kind of an interesting exploration I think so there are a few other modules chain does pretty much what you'd expect it to do it's it's about blocks and headers it lets you get transactions and as I have been chatting to a meal over the last few weeks and months the the point of a substrate node isn't to provide a generic sort of very generalized database for every all of your uses that you might have I mean etherium was kind of pushing in that direction we provided all sorts of lookups that we didn't really have to substrate keeps it minimal it's it's got a fairly you know that's one of its Maxim's of design and one of the ways that we keep it so one of the ways that this sort of minimal RPC comes out is the fact that you can't look up specific transaction hashes you can I think maybe get oh yes so you can get a block and the block will come with a bunch of extrinsic sand in those extrinsic will be the transactions and that's that's basically if you want to index if you want to have a you know get so get a transaction by its hash you're gonna have to go to a chain Explorer or a party service provider or whatever to get that now you can verify that that that's the case just by getting the block and transaction index and then going back to your node and using this RPC to get that block and then lookup that index in the extrinsic and you'll find your transaction or not but we're not going to do that indexing for you because it's too much work it's it's better done on a dedicated software yeah sure i-i'm sure or are all of the author and other extrinsic s-- you mean the entire chains worth if the blocks not created yet then you can't look it up at all when it's when the blocks being executed no no no so either the block has has made its way into the database it's finalized then it's good or you can't you can't read it at all during what sorry execution of the block or well when a block executes I can show you that that that code but basically there's an execute block function and it gets given you get given a bunch of bytes and it's up to you to execute those bytes so at the lowest level so at core a core level yes SR ml it's a lot easier but that that's full of a lot of opinionation that isn't necessarily indicative of your chain that you're writing on substrate yeah yeah you just get given a bunch of bytes and that's your block and it's up to you to interpret the look of the block as you as you desire okay let me let me go through the are pcs and I'll come back to you so yeah we can get header block block hash and there's also a runtime version that should actually be in state but it was a very late edition Thank You Tomic Thank You Tomic we have system which just gives you a bunch of information about the system just the name version and the chain that's basically just the the current running node for example we also have the JavaScript implementation of much of substrate and that will return different things from from these are PCs finally as the state this is the most interesting thing so again back in if we if we think about what you can query of a block of a blockchain state in other block chains usually it's like account balances whether an output is is spent or not how much is sitting there potentially some state of a contract you might even be able to make a call into a contract and have it execute we're a bit lower level with substrate as as might be imagined from the fact this is a library with a framework with which you build block chains but there are things that you can get from the current state of the chain are storage so we have at the moment this RPC reflects a single storage database so basically we have a merkel Merkel tree there is of arbitrary size keys and Val in pairs right so the tree itself stores basically any key value any set of key value pairs and the root is stored as the state root and that goes into every block as you change the storage as we change these keys and values then you can that that will obviously change the state and you can make it's very handy for building pair of chains because you can make very clear like client proofs that one particular block with one state given these transactions that executed or these extrinsic sigh should say that executed left another particular block with another particular State that's nothing nothing no really not really any different to how etherium works the main difference is that of generalization and with our road map that allow where we want to build multiple different cryptographic databases so if we if we think of the Merc alized key value storage that we have here as a one example of a cryptographic database then we want to actually extend this to other cryptographic databases and also add a a means of having many of them at the same time so if you're familiar with how aetherium works there is a every smart contract actually has its own sort of cryptographic database where it stores its key value pairs it's storage if you like and and then there's one sort of big one that all of these other the by virtue of them having state routes all of these other databases hang off substrate only has one but it's one very general one and in principle though that can now be expanded to have as many as as is desired and they can even be of different types and they can be dynamically added and removed in the similar way to that you would dynamically add and remove them in a theory and when smart contracts go in and out of existence we also have metadata which is a wonderful wonderful RPC that I will spend some time talking about when I address one of the other questions which was the color JavaScript sort of magically works and finally we have a pub sub for storage so you can subscribe to particular storage items and you can get notifications when those storage items change so if you understand how storage works and that's one of the other magical things about metadata that's what it kind of provides that's what it partly provides then you can basically keep an eye on that storage and just be notified when that entry changes yeah so Sergei can go into how smart contracts so this this little symposium will be will be split so I'll answer whatever sort of more general questions about substrate and then Sergey is going to do a little sort of walkthrough of deploying a smart contracting because explain some of the technicals behind the smart contracts and we can go into the events and and smart contract storage there this is specifically for substrate chains as a whole and this will be very likely look like the final RPC an API for para chains so with smart contract so we have a smart contract module and that exists as a module within substrates SR ml so you can basically make a substrate chain that can can manage smart contracts as well as do a bunch of other things like have governance and all the rest of it so we we kind of see smart contracts as a piece of functionality that you can answer your chain or not add to your chain as you see fit the on your use case some use cases that require a generalized sort of smart contract environment some a very sort of specific fixed-function chains and if their specific fixed function chains then like for example a plasma chain a plasma chain doesn't require a smart contract modules and these smart contracts in there right it's a fixed function chain that would that basically manages all of the other chains hanging off it and what to do if those chains want to do an early termination or or settle on the upper layer so I don't imagine all chains to have smart contracts from finality in fact I suspect many chain even perhaps a majority of chains won't have smart contract functionality there'll be they'll settle for having fixed function fixed pipe fixed block processing functionality that's upgradeable we like up readability cool so that's that's basically the our pcs now the interesting thing is how these interact with the JavaScript environment so we're developing because we like to give people Choice we're developing multiple JavaScript API is to interact with substrate and substrate modules now these api's are primarily geared towards interacting with the substrate runtime module library the SRM l so they are fairly their highest level right there are lower level components like for example you can use these pub subs with promises I believe at the JavaScript level but if you want to but we make it easy for you to use to build applications based around custom modules that you code in the SRM so you got a taste of that although it might have sort of flown past you a little bit in the demo because that was trying to get it all finished and more or less on time but I don't know if you noticed but when I wrote that that little sort of toy the I was able to interact with the toy in the browser as soon as the chain had been upgraded I actually in the console got like an object that that let me do it in like that was specific to them the code that I'd literally just written in rusty now I that wasn't a trick I didn't have anything up my sleeves it was it was literally that cool what happened was the runtime got upgraded although I didn't code any new JavaScript stuff what the the code that I wrote and annoyingly I can't really I don't have know let me see if I can find that code should be in substrate node template and if I remember correctly I might even have to I do okay so so if we go back to the substrate node template so this is this is the sort of demo node that I that I forked and started coding and I have this demo module and if you remember I did something like this I said I did post sender and then decoded this this little address and then also for the call it's calls demo dot set payment and that just worked despite me not actually having changed anything in the JavaScript I didn't even reload the page I think I certainly shouldn't have had to what happened was when I coded this module with play and set payment and when I coded this storage with the two entries here payment and pot part of this macro generates some metadata about what these functions are and what these storage items are and this includes the types this metadata is compiled into a sort of blob and then amalgamated with all the other metadata from all the other modules by virtue of this macro here construct runtime that you might have remembered I put the demo line in this then gets passed to through this macro which implements the api's into as a something that can be called into from the client so we have here one specific trait that we can implement called metadata as a metadata trait if we implement it it means that metadata RPC will work and what it will do is it will check to make sure it's actually implemented call into it which means dispatching into the newly compiled runtime that's been compiled into webassembly and interpreting this metadata and all this this this function does is it grabs the metadata from the runtime and that was caught that was built from this constructor and time and that was built from all of the individual modules which are each are built from their declarations of what they're stripped their storage are and what their what their module is that in terms of their function entry points and this gets passed into the JavaScript and as part of the substrate JavaScript libraries we have a couple of libraries that you can choose to use one is based on observables one is based on the bomb's framework that I did last year and these libraries will in interpret this metadata blob and turn into real JavaScript utility objects that reflect and [Music] and will dispatch to and utilize all of the all of the module specific stuff so if we go to the way they put it no just live demo yeah so if we go to demo then it will actually interpret will basically make Marshall all the arguments and dispatch it through the transaction dispatch system into yeah and similarly if we query what the pot is it will work out where this runtime given this this module stores the pot in its storage and then go into storage and check that using these storage are PCs and if you part of bonds is the fact that it's reactive so if you tie that into a reactive component if you remember at the end of the demo I very quickly did a little label that that tracked the pot going up and down what it's doing there is it's setting up a pub sub with the thing that it figured out all on its own with the storage location for pot and track the value it knew what the type was because it looked that to see that this pot type is T balanced and decoded it into a balanced type and then put that into a label formatted it correctly and put it on the screen and it did all of that without me really having to do anything other than implement it right here in rust so the idea with this is to make it not just painless but actually fun to code modules and the U is four modules what was one of the other that was another question mempool yes this is an interesting one so we rewrote the meant well Tomek I should say rewrote the mempool recently we call it the transaction pool same thing we wanted something that was general but also easy to use and it took a little bit of thought but what we came up with was a a pool that basically allows runtimes to specify dependency graphs arbitrary dependency graphs of transactions easily we wanted something that would work equally well between UT EXO model and a account and index model so basically a transaction pool that was equally viable to be used for something like Bitcoin and aetherium with the idea being that if we made something general enough for both of them it would probably be pretty general sufficiently at least for doing interesting other chains in the future so the way it basically works is the runtime gets queried and I can show you where this comes in the runtime gets queried through this validate transaction as part of a transaction Q trait so this is a trait that you have to implement in order for this transaction queue to work transaction pool actually just references the executive here so the executive is like a sort of overarching SRM L module that looks after just executing a block in general in particular it runs through each of the extrinsic and dispatches them off into the module that is expecting to that the extrinsic is sort of trying to call into all extrinsic in the SRM L framework have a they they may or may not have a sender they may or may not have a signature they may or may not have an index they may or may not have an error we actually allow we actually force or not force we actually facilitate extrinsic soar transactions to limit the number of blocks that they're valid for inherit right so you can make an extrinsic the transaction I should say that is valid for the 16 blocks between a thousand and twenty four and a thousand and forty right and it after a block a thousand and forty it's just no longer valid it can never possibly be make its way into a block chain this is needed for a bunch of other things particularly for having dust collection which I can go into after after I've talked about this if that's of interesting the transaction the way that the validate transaction thing works the important thing I want to show you is the inputs and the output so the inputs are the transaction fair enough the outputs are the trend is this transaction validity object let's see if I can find where this is defined this is basically a means of we see so we can see it's got like three potential states invalid valid or unknown l invalid oh no no and a pretty obvious what they mean valid so for a valid transaction we have a bunch of we have four sort of fields that we have to define priority so how what's this transactions priority amongst peers for which everything else is the same right so assuming this that everything else is is all other things being equal which one should we favor to put into a block for in aetherium style chain this would basically be what's the gas price if the gas price is higher then we just favorite more we also have requires and provide so requires is and we have this vector of transaction tags transaction tags are just Veck vu8 so in rust lack of UI it's basically just an arbitrary bunch of bytes right it's just a by the string yeah and these tanks they're therefore entirely up to the it's entirely up to the runtime how it what tags it uses it can tag them by hashes it could tighten them by integers it really doesn't matter could tag it by account IDs it could you know concatenate a bunch of these things and that could be the tag they're entirely arbitrary all that a transaction list transaction validity function has to state is what does it what tags does it require and what tanks does it provide now we can imagine for a for an aetherium style chain it would require the tags that requires are all of the tags actually let's start with the tax that it provides tags that provides our one tag that's formed by the concatenation of the account ID the sender ID and the current index the index of the transaction right the nonce yeah so you pop those two together that's your tag right that's just an identifier for the the thing that this transaction provides what it allows us to do is to then state what other transactions require in those terms so suppose you have a my transaction is sent from me my account dev and it's got an index of 10 right so for that to work in the etherium model there has to be a sent by me one with index 0 1 with index yeah and that would make 10 to be the next valid transaction so what it requires is all of those tags now that's a bit unwieldy for when we get into the thousands of or tens of thousands of transactions coming from a single account so what we say is only requires the tags that have not yet made their way onto the chain yeah and if if we get into the silly numbers like hundreds then we just say either unknown or invalid and we just say look this this transaction is just way ahead of schedule send it back sometime future and that that actually is more or less the way that the etherium the the parity etherium transaction queue sort of worked just not in these terms now if you're on a UT EXO chain then it's actually quite a bit easier because a UT EXO model like basically you've got what the tags are they're tags are just transaction output hashes yeah so your tags are it requires these unspent transactions or unspent transaction outputs so those transactions that are providing those outputs are specifically the things that are required and it provides well it provides its own hash its transaction hash so you can very quickly build a very easily build a dependency graph from aut EXO chain that fits the Maps quite fairly well on to this and we also have a longevity so longevity is basically it's valid now but for how many blocks will it continue to be valid in the future 4-bit Connor and aetherium that's infinity basically transactions don't become invalid just because time has passed but for for our substrate chains we have this notion as I said before of errors and the ability to inherently make a make a an extrinsic or a transaction in they're inherently invalid merely after the passing of time specifically blocks and that's what this sort of lets the transaction so yeah that's pretty much how transactions work in substrate this is more for the SR ml it is meant to be general so in theory it can be used perfectly easily from the core from if you want to build like your own from scratch substrate chain in principle this can be used fine but you're also free to write your own like there's there's nothing you can you can plug in your own cue if you want to write your own cue if you have something that this model can't can't manage to embed the nice thing about this though is that it goes to the runtime for all of its rules which means if you want to update your transaction formats and you want to introduce all sorts of new and crazy interesting stuff as long as you can put it in terms of priority requires provides and longevity then you can implement whatever it is that you want and when you upgrade the chain all of the full nodes all of the authoring nodes will all automatically use your new transaction semantics and they'll the transaction queues will function accordingly yep the only you can't modify so can you modify a transaction in the that's in the queue so what you can do is you can if a transaction has made its way into the queue because it said hey it's valid and you want another transaction to be able to to beat that one to it you know if the to a mutually one can you can make it mutually exclusive by by simply giving it the same tag but higher priority that will that will get the transaction kids are sort of boot it out the transaction queue only feeds transactions into the block if you just want a transaction to just become invalid before it's been finalized or before it's been before it makes its way into a block you can do that just as easily by having a sort of you know if in the execute block function if one of the transactions is this transaction then invalid block right and what will happen is the the unlucky guy who's using this transaction queue to to make a block will will find that adding this transaction makes their block invalid and and it's kind of bad form to do it that way you should try and like make it as much of a part of the queue as possible but if for whatever reason you can't do that then yeah you can make it invalid just by virtue of changing the runtime I get in the office Tomic can probably offer a little bit more insight into this basically priority is the is the first thing that it will select on and beyond that so for the transactions that have not yet become valid then basically it's just randomly choose randomly discarding one's not that random is is particularly great but it also minimizes any potential issues regarding censorship so if you've got like tons of nodes on the network and you really try to prevent some particular transaction from getting through and you're doing that just by spamming transaction out onto the transactions out onto the network we minimize the the worst case by by choosing transactions at random to discard because it's likely that eventually one node will eventually will mine that that that transaction that ultimately if lots and lots of people want to transact at the same time then there will be congestion so it's it's really just the case of randomly choosing transactions that come through I mean in principle priority here is that's precisely what priority is for times of congestion the runtime can basically state which transactions should be favored above which others but if if priority isn't enough or for whatever reason maybe everyone's got the same gas price I don't know whatever or you don't introduce any particularly compelling priority prioritization mechanism then random is is the best we can do cool Oh what was the what was the thing after transaction I've forgotten no is there something else to discuss yep okay anything before smart contracts yeah ah yeah okay yeah I can go into that so so the runtime encodes a lot a lot about what what the blockchain does how it works it doesn't encode everything in the substrate model because we don't want some things to be to be special what we could do is literally just put a rest executable on the chain and when that changes you have to kind of download the new one and run it but we don't like that there are I think I may well need to be corrected here but I think there are there is a certain other project that's trying to do governance and upgrade ability and that's more or less the model that it takes so it sort of basically puts its executable on the chain and it's up to the nodes to kind of download the new executable and run that I don't like that model I prefer to be a little bit more conservative about the specific component that can be upgraded and when we accept that part of the logic doesn't sit on chain for example the peer-to-peer networking library I don't think it's sensible to put that logic on the chain and there's even questions about putting consensus logic on the chain it could be that if consensus logic is on the chain then you have this kind of monoculture almost monocultural strategy for the consensus and that may lead to attack vectors by virtue of knowing that all of the nodes use the same strategy so if we're happy with not putting all of our logic onto the chain then the question is given that we need to have the same data structures ostensibly on the chain like in the runtime that's upgradeable and off the chain in the sort of general node itself how do we how do we manage the fact that sometimes those structures will be those data structures like transactions for example could be changed over the course of a chains life how do we how do we like manage the fact that these transactions have to then be sent they have to be stored in a transaction queue and they have to be sent over the network there have there has to be some way of handling these things right so we need some sort of object and that's where these opaque objects come in we need to a block needs to have some characteristics and there has to be some object that we can call a block but we don't need to go into the specific meaning of a block beyond basic the basic semantics of here's how to read a block number here's how to read the parent hash and these these very basic types or what we call the opaque types and they are the fundamental types of a block chain that don't change from Genesis onwards the in principle they're basically fixed now you say oh well hold on the extrinsic format is fixed and the block format is fixed and you know then surely you can't upgrade and it's like well actually it that's the reason that they are opaque is because most of the data that they contain is not stored in terms of specific fields like the the real meaning but rather it's just a blob a generic blob and it's only the bits of the data that we actually need to know for example we need to know the length of the transaction yep the extrinsic we you know because if we're going to send it around we need to how long it is and so what we do is we if we're going to concatenate it together into a block then we need to know how long each particular piece of the concatenation is so we we say write the one bit of a transaction of an extrinsic transactions format is going to be the length at the prefixed length but everything beyond that we're going to leave undefined as to its meaning we're just going to tell you how to decode and encode it you decode it by reading the length and then reading that many other bytes I'm not going to tell you what those bytes mean but that's how you decoded it and you encode it by seeing how long it is and then putting the length at the beginning and then following up with the other things by avoiding defining this stuff we can then define it in the runtime and then as runtimes upgrade we're not left with incompatible data structures that for handling these things in the client now it's important that so this isn't something that we do with every type it's just the fundamental cut types that clients do tend to have to be able to handle basically because we need to pass these types around the network or because we have to interpret them for the consensus algorithm so block headers one type extrinsic one of the type and I think hashes may be although hashes are paint data anyway I think it's basically just those two types yeah yeah although again signatures are opaque data anyway specific so you've got two types of signatures that float around in substrate you have to consent there are signatures on the consensus side and signatures on the signed on the transaction side so signatures on the transaction side they don't need to be the same and the runtime entirely interprets those I can well imagine extra substrate chains that don't have any signing any cryptographic signing on them at all that they're they're just you know the validators choose which things come along they you know from maybe some trusted corporate centralized database and they're just funneling this data in and it's going into the chain and just being recorded and maybe there's some state transitions that happen on the chain but basically it's that that's there's no need for signatures the consensus side yes there are signatures but I guess the consensus algorithm to define their own cryptography anyway I mentioned what sorry yeah so I I kind of spent a while describing that but I mean I can I guess I can probably if I can launch a node do I have one already oh yeah sure okay so yeah I have a node running okay so this is I think the demo node I'm gonna upgrade it okay so yeah okay so is that too small I guess that's way too small right how do i is that still too small it's too big okay so this is template node V - which I think means the demo is in but I can I can check this by so I mentioned there was the run time object fun time okay so the run time has a bunch of these are the various modules in the run time right so balances consensus core demo that's the one I just coded earlier today system timestamp upgrade key and version these as I mentioned come from the metadata so I can I can show you the code I mean it's it's I don't know how interesting is if we go into the double-oh-seven if we go into the double-oh-seven library and then the double-oh-seven substrate and then the bonds this is where they get created let me see if I can make this a bit bigger okay can you read that just about yeah I need a I need the drum player okay so these are these are the sort of easy ones that just they're just sort of hard-coded height header head fash name version and chain I mean you saw the RPC end of these we have this node service that just ensures there's a single WebSockets connection to the node so it's like a singleton and then we can I assure a request and these these are these are single shot requests some of these like head there subscriptions so there they use the pub sub functionality we have runtime version so I can eat I can I can give you a lighter quick and runtime I think it was in the core and then console log and that's what comes back very simple got the api's this this exactly represents this structure in rust that is in runtime template yeah so this this represents exactly this structure if I change this structure and upgrade the upgrade the chain then this will automatically update if I run this this thing again it will it will give me the new values yeah and it's the meta it's actually it's not the metadata that encodes that I think but that is that is fetched in this from the runtime in the same way that the metadata is fetched so the meta metadata is built automatically per module in the runtime amalgamated together by virtue of a couple of macros and then pass the line into the JavaScript and in the JavaScript we have a so we actually have a serialization library very very lightweight basically just memory representation serialization library and we have the opposite in JavaScript so we can serialize and deserialize in rest and we have the same thing in JavaScript and we can kind of a bit like a bit like JSON or whatever except binary and sort of designed to be very fast and very minimal lightweight yeah that's yeah the you mean these modules yeah so these are indeed there is a web pack running somewhere yeah yeah so got like MPM sitting around in the background updating are checking for changes and packing it all together ok so there's there's two things going on so the first is the these module these UI components those you have to code independently so they don't come from rust they're not automatically made you actually if you want to add a new a new module you have to sort of get get yeah typing fingers out and and and go into wherever it was that I went into now here we go yeah where is it now here so this is the yeah this is the UI and this isn't special at all this is just standard reacts semantic UI with web pack and NPM packing things in there looking out and watching it and packing it in the background so there's nothing I don't I don't so if I if I add any module then I have to press controller yeah but what happens I didn't press control I just now to get sorry if I do a blockchain upgrade I don't I don't have to press ctrl R now because the metadata automatically gets updated in the background so that doesn't come from the thing I was mentioning earlier with the hard-coded things so the bonds these bonds here the version bond and the the name chain the hi header hash these are all hard-coded they don't change their fundamental are PCs that substrate provides but the other things the things like if I go to run time and like I don't know balances if I want to get the balance of an account or accounts do I have let's decode an account let's decode this account so I want to get the balance of this guy then I can decode that into an account ID and give it to balance and then print the output and it's going to tell me that this guy doesn't have any money I think yeah balanced zero and then if I if I gave this guy some money so let's send some funds to him or her it's a hex address I'm not sure if they have gender do I have any Alice has got some I guess Alice is a girl and I'm going to send I don't know if I send a thousand units that's going through sent and then if I go back to balance is then we go now it's got a thousand yeah so this stuff when we go into specific run time modules they're not built they're not they don't come in by virtue of this code this code builds them programmatically from the metadata is has a pub/sub relationship with the with the node itself so as the nodes runtime gets upgraded this finds out about the upgrade grabs the metadata and rebuilds all of those objects and data structures and letters now interact with with the new runtime in a organic fashion but if we want to add UI components then we have to go in and do them ourselves and press controller the real a chain what what does it use so polka-dot uses power to codec polka-dot uses basically all of substrate like there's not much in substrate smart contracts is the only thing it doesn't use and yeah other than that it looks pretty similar to our basic substrate node so it's got all of the sort of functionality in apart from a smart contract but it does have an extra module that's specific to polka dot called para chains module so I haven't I'm not like it's been a little while since I looked at the para Chains module but that's something that will become pretty important over the next POC so PRC 3 was dedicated mainly to our new consensus algorithm that would be the final our algorithm for polka dot shaft or grandpa I don't know you know I mean I do know obviously shaft but some people don't not everyone agrees yeah sure so shaft is a actually is al here so al al invented shaft at the time it was called afge Al's finality gadget but we're kind of renaming it and basically it's a progressive adaptive progressive finality consensus algorithm designed specifically for polkadots use case and the idea is that it's a it adapts to network situations and validator pluralities if you have lots of validators sorry if you have few validators and a really good network then shaft will finalize as quickly as instant an instant finality algorithm like tender mint or rhododendron which is our sort of take on pbft for the blockchain but even if you have slower Network and lots of validators it will finalize as fast as it can behind the scenes and the way it does that is by having a transitive relationship over the blocks so the way that pbft derived algorithms work in general is you have a candidate block so every every block number that you want to finalize every block that you want to finalize there is a candidate right it's not yet finalized so it's just one of many and then you put it to a bunch of vault authorities or validators that the participants in this consensus game and they will each if it's a pbft based thing they'll do a a pre commit to basically say this is the one that we think should win and then if they see enough other pre-commit they'll they'll move on to a commit and there were rules about how you whether you can change from a pre given that you've pre committed on one thing whether you can change your you know what what you're allowed to commit to and if you've committed on one thing whether you're allowed to switch that commitment and these rules basically guarantee that assuming no more than two thirds plus one Byzantine nodes or Byzantine participants in the game that you will always come to an agreement on what it is that on a particular candidate now this is fine it's a perfectly reasonable way to go but the problem is that block it's not optimal because block chains have relationships blocks have relationships between each of them so blocks that are all of the same number so they're all at the same level they're just can different candidates for the same potential slot don't have much of a relationship beyond being mutually exclusive but blocks that appear before so parents or ancestor blocks have a very very strong relationship right cryptographic relationship we store their hash which means as an implication that if you voted for block I don't know that that 68 references by virtue of its parent hash you're you've also voted for that right you've also voted for 66 or Genesis block assuming that the network conditions are such that you are not going to be able to afford to finalize every block then a vote for 68 should definitely imply a vote for 64 67 and so forth but for that 67 yep so if there's two folks if there's a fork and what it's made its way to block deep okay maybe asn't made yeah actually you could have in principle have made it's way too much deep just at the production stage then it's important that any vote not allowed to do under this transitive model is both commit to 68 on one fork and to the 67 on the other fork and that that's one of the things that now becomes illegal but because that's illegal it what it means is that we can interpret a vote for 68 as a vote for all of the blocks that haven't yet been finalized on that on that fork and if suppose we suppose where that last the most recently finalized block is terrible network conditions the most recent recent finalized block is like say block 50 yeah so we're running 18 blocks in advance of the of the most recent sort of had agreed on head of the chain then if we've seen let's suppose we have 10 validators and they're basically just validate they're just voting for the blocks that they see we can only get out one vote per block and it's our vote so actually that's not I've got 20 validators and we can only get out one vote per block what would happen is that under Undershaft these votes we would always be running at the actually no because we only need \u2154 so it'd be the 13 th or 14 th most recent vote vote because we can accept all of the votes that are that are were on blocks after let's say where were 50 so suppose we're trying to finalize like I don't know 53 yeah all of the votes on that fork after 53 so every validator is like doing one vote per block so one of them is voted on 54 one of them is voted on 55 one voted on 56 all the way up to 67 or 68 where every were then it's likely that every new block \u2154 plus 1 will have voted on one more than the last block in total access account ensures every new block that's being produced that validator will be voting on that new block which will imply they voted on all of the blocks up until that new block which will imply you've got one more vote assuming a constant cycling of validators one more vote on that chain in general and so because that chains been brought forward by a block because everyone's voting on that chain then the the the the most recent block to be finalized will probably be a bit further along as a network conditions improve we can get invalidated can get more messages out then that will catch up naturally because the greater number of votes will be recent and and therefore again transitive relationships being what they are you'll be able to basically form a consensus that two thirds plus one validators agree that in fact 62 is the most recent shared block that they can all finalize it's a pain to spot when a validator has behaved badly basically because the rules are transitive sorry yeah rules are transitive and so you have to enter into this in the worst case enter into this game of querying well hold on you you as a validator voted for this block on this chain but yet you voted for that block on that chain why what were you seeing what what signatures did you see that made you switch chains and they can either equivocate and say move don't know because they actually they switch chains in invalidly or they can provide you with the signatures in which case you have to go to the next guy along and say well you signed for this chain but you you know and the game continues basically it's quite a an unwieldy game and it's a it's a bit of a pain it's a bit tedious to play but it's it's something that can happen on chain and it's not the end of the world beyond that it's it's got some very nice proofs about how live it stays in an asynchronous environment and its optimal over the it uses the notion of block transitivity optimally in determining under a pbft style mechanism which is the most recent lock that it can be considered final okay under optimal Network conditions assuming the validators are well connected with each other and that their plurality because I mean it's pbft so you can't get around this N squared message passing stuff requirements but assuming that they're well connected and and there aren't too many of them then you know I don't I mean you know this is where empirical measurements come in but certainly with our test net so far there's no reason to think that we can't handle final final is finalizing most blocks so not staying very far behind the block production head at all so the block production is handled by a separate consensus mechanism that doesn't provide finality at the moment we're moving towards or and which is a randomized shuffled version of hora which basically just sounds for Authority round and you just go around a bunch of round-robin style block production game but it's our intention eventually to move to probably something similar to a ruborous which is a it's basically like proof of authority mapped on a proof-of-work mapped onto a proof of authority schema so all thority get given lucky slots whereby they can mine a block and and it's a way of generating generating these lucky slots and and I'm ministering them in such a way that that you get given a bunch of guarantees about Byzantine tolerance so Network network topology or peer-to-peer networking in general we're using lib p2p which is pretty modular I would in principle there's nothing that would stop you from writing a new module that would provide the sort of networking that yeah I mean if you want something like Onion Routing on like mixed nuts yeah I don't see why that wouldn't be possible using the existing network module system worst case it's probably like implementing it as a as a new API but that's something we'd look into now I think I think it's what you can can build on top of it I mean we'd certainly be interested to sort of explore if the API is a sufficient in order to provide that but I suspect they might be okay more questions when how long it was at 8 p.m. do we want to maybe you think yeah yeah I it will be a little bit harsh but yeah I think ok let's let's erm maybe move the questions towards the end and do a I don't know some exciting stuff do you want to plug in the HDMI oh yeah I'm glad that you're doing this cuz I need to go to toilet yeah yeah sure thing use do we do we have working toilets yeah yeah outside so gay oh cool so let's get started this demo is like well it wasn't prepared at all because of his ins and I and I had to improvise so yeah um yeah let's get started so because I basically don't have any UI because of as I mentioned reasons I have to do like I have to craft in extrinsic by hand basically yeah but I have some little code snippets that actually can help me with that so it's not that problematic is it okay yeah okay so let's start this let's start with a fresh chain for that that make that maybe might take some time yep yep it's basically the branch a second I know I would say now because yeah for some reason I chose to use the soft shoe type oh yeah so let's clear the DB and then let's launch this new chain yeah so it seems to be working and yeah so so to make an extrinsic we need some to do some boilerplate code and for that we need a genetics hash so like it it is required to create extreme six that that can be executed on this particular change so we need to first fetch the block hash of the Ganesha's and for that I will I'm going to use the RPC cash so I will call block hash function this argument zero which which is for Genesis block and so oh yeah actually it's already there yeah and after that I will regenerate all extreme six so yeah so this extrinsic this big blob of up our data is contains instructions to deploy a certain contract and the the most of this data actually represents webassembly smart contract and yeah let's let's actually submit that extrinsic up have this one but it doesn't yeah oh yeah yep so to verify that it actually executed well let's see the substrate UI oh do you have an idea how to look up or a nonce of Ellis yeah yeah yeah as I said network I can connect to you ah yeah it's def okay yeah in JavaScript oh sorry sorry guys I can't stop I come on okay so the runtime and then balances is where the hold on it's not system by the index is stored and then I can't nonce and then which I can't ah Ellis Oh Alice and we should get Alice's so we need to introduce a the seed for Alice which is a pain to do if you don't do you have some key I yep and try to just execute it in here yeah it's okay yeah it just works oh but is it the latest version of something it's from air each hour but I'm not sure yes later yeah does work cool totally I expect okay oh how can I help you I want to get these Safari oh okay right so we put that scene in there you put it yeah so while this has this yeah now this is a short oh yeah this is something that should go over actually because this is kind of cool but I'll do it afterwards so we can try that everyone can see what's happened there right okay Oh doesn't suffice all that well I wouldn't be surprised actually okay [Music] maybe it's not about ten part I mean maybe yeah nons account okay maybe should open fire let's just check decode and then Alice's ID okay so that's done something that wasn't a type error but it's so that means that our transaction actually got in and we deployed the test contract so now I'm gonna show what kind of contract this is yeah so so this contract is basic counter which has actually two functions to action that we can actually execute on it let me do ya so the first one is in command that takes you 32 parameter which specifies by the value by which we should document this counter and get function which basically returns the value and when the contract is executed we just read input data it's basically the same as in Hulme and decode it into this action in a very enumeration and then depending on what actual variant of this you know we performing the action and this in case of increment we just query the contract storage by certain key which is the specified value and then save it back into the storage encoding it and before that and get is basically just we read the storage and return that value and that's it yeah so this contract is already on on the this chain and yeah so there is a extrinsic that which with which we can call this specific contract and it takes address of that contract and address is calculated by the constructor code of this contract and the original address which sent this which sent the create extrinsic and this so again yeah actually it's used and so it's specified right here so for the first transaction it was zero extrinsic and for the second one it's one yeah okay I see what you mean for determining contract address nonce is not used only code of constructor a region and just like input data and that's it yeah yeah basically yes but you can alleviate it with providing different data so we push this issue to user side yeah and yes so we doing call this to the contract at the specified address this we thinking some funds to it and also specifying how much gas we want to allocate to that and also we're providing the input data for the contract and this data is actually just encoding the index of the action so in in our case it's 0 so it corresponds to this variant and these four bytes encodes basically number by which we increment yeah and let's let's execute this yeah for now it's the only way but like we basically don't have either cell right now and it's the thing that is developing right now yeah so yes and so these extreme six extrinsic is for calling this contract yep so I think it is executed and to verify that it's actually performing the the task let's just check the substrate storage for for this corresponding storage key of that contract and I have because it's kind of hard to my to know which address is that I have a special function that actually calculates this for me and yeah and let's take it and [Music] it's really yeah so okay here's the result and it's corresponds to one in encoded in little endian format and this is a specific thing for encoding the length of this data so yeah it basically worked and then let's try to increment it once again by I don't know yeah wait a second I don't understand that so this extrinsic is in memory pool and let's wait until it actually yep it's mind and then let's query the storage and yeah it looks like it's eight yeah sure yeah that's a good question let me show you know so basically it's more more like a few Mike environment and so for now we basically have bare minimum for writing contracts and it's I get said storage and then call create which basically is very similar to thin ones return checking input size and also like this it also have has a scratch buffer and it's something that is not in Hulme so because of yeah I didn't mention that that storage in substrate contracts have like arbitrary size at values so you can put not only you query it you you can basically return it in this user specified area I mean contracts it's fight area of memory but then like it's like if the contract doesn't track track the size of the values that it actually puts in in this in storage then it could easily overwrite the like memory of the contract and this can be a bad thing so because of this we all arbitrary size that values are put into scratch buffer and then contract can actually query this buffer to actually load data from it yeah so it depends actually so you can't use I know anything that depends on files trading and things like that but like everything that doesn't require my saturating system things like files and things like that and can be compile it to the assembly and then probably fine yeah so basically this system is very similar to a theme and we basically have like a smattering very similar to a theme I mean like every year Vice Minister action is metrid and like I mean every instruction in the block just Metford as the price of the dairy prices are similar up and just deducted from some counter and if it goes to the zero then there's out of gas succession yeah so we are planning on bringing in chromatic gas yeah yeah and also they think I wanted to mention that we about the API that we are also thinking about giving the contractor on time chance to call different modules outside of I mean inside the run time so it can actually call do Kevin and well yeah so means governance modules even the power chain module that would forward any potentially could could have open an entry point a function call to forward messages into a para train so we can imagine is a smart contract sitting on one pair of chain sending out messages to a smart contract on another pair of chain or sending messages into a governance system so a smart contract chain like the edgeware chain that was mentioned today could have smart contracts that you know manage people's voting preferences yeah that's something I mean yeah for the gas it differs a little from aetherium one of the things that I wanted to bring into a theorem like when it was too late to bring it in was this notion of chromatic gas which is basically having three different kinds of gas one of them for processing one of them for memory usage and one for storage with the idea being that basically we can compute maximum gas per block in terms of resource usage for each of these three but doesn't make sense that if someone gives up some processing power that they can instead bloat the chain by some storage right then the two are not the two are not somehow mutually exclusive so what we do is we actually have the resource usage independently for each three and then every contract gets basically whenever you spend one gas on processing you sort of get one gas on the other two for free or vice versa the gas sort of comes in in in white light where you get all of the independent gases sort of tied together and then you can use them as you as you want and what you don't use either irem really decided but it either gets sort of ignored or goes back into the pot so that other things can in principle overspend but what this does it basically means you've got much better resource usage utilization and you don't have the issue whereby you can bloat the chain by 3x what you should be able to just by using all of your gas to enter into storage and none of your gas or memory or processing which is what the sort of scenario we're stuck with aetherium oh why not GPU as well well maybe version 2 yeah we'll go into the contracts right so yeah this so for like the gas system is only a concern of contract model and any other modules doesn't know about it at all yeah I think so then cool so I'll mention one other thing which is the account indexing which is what we saw earlier do you want to know I can do it on yours I think I mean yes but it's it's a nice little thing so it's worth it's worth knowing it well can you how do I get to Safari okay so if you noticed before while I was mucking around down here can I make this bigger somehow you can do this little trick oh just so there is a if you hold ctrl you can scroll it like that yeah so if you notice up up here Alice has a so I we've got two accounts here default and Alice default is this big long big long address analysis this lovely little address right so this is a legit these are both legit addresses and if you you know in principle if if a substrate chain gets listed on an exchange then in principle you can get one of these addresses this is just an address like in Bitcoin in etherium right but they both are so Alice this isn't some cunning name registry or something this is an address we understand yeah we're going with this [Music] in principle yeah it will mean different things on different chains because it will reference a different account just this just as the other one the long one would so the long one is a they're both based 58 representations they both got a checksum in them they both got a version byte in them the difference is that the first one is a 32 byte public key from that represents a point on the edy 255 1 nine public key and the other one is an index and that's why it can be so short so every account in in a if you use the SRM L in substrate every account has a an index associated with it I should say every nonzero balance account writes every account that's active has an index associated with it if an account doesn't have doesn't have any balance then it doesn't get one of these nice short IDs because there's no index I so it can't like then you marry every account then you may as well just use the 32 byte identifier but if it's got something in it then you can use this use this index instead to identify it and we've got a mechanism whereby if it's within the first 200 or so then you get to just use one byte and if it's in the next sixty or thousand then you get to use the next byte they're two bytes and I think there's only like tens of thousands of active accounts on of active accounts that have any real significant funds in on like aetherium so i don't i suspect on substrate chains we'll probably see most addresses to be fewer basically be like four six five or six characters and it basically can look that up in its enumeration of all addresses and and as these things become free so if an account goes to zero substrates SRM our balances module will automatically claim reclaim that that address right so it basically deletes everything to do with it and this including this enumeration and so if someone like has one of the earlier Guinea I can't imagine that there's gonna be something like clamor to get the first to enjoy the accounts that have you know these four four letter addresses cause like there's only so many of them and before long they'll go but if someone like reduces their balance disease or to the minimum below the minimum allowed balance there's this notion of an existential deposit which is basically the minimum amount of balance you must have for your account not just to be deleted dying like that if they're iam Bitcoin don't really have this which leads to an awful lot of dust accounts that have like a none spend ibly small amount of of ether in it so small that you know you can't actually send the transaction to but yet they're still recorded by the state so they're still taking up a lot of space on disk exchanges are particularly bad for these things but you know they they leave a bit of gas on the spent and that just that's just a tiny little bit of ether just clogging up the train chain to the like 10,000 accounts a day sort of job so this is why in principle yes so if this account becomes a discount like reduces below the existential deposit and then someone else claims it then that address won't last forever so there's couple of ways of dealing with that the first is that that address has in it a checksum and that checksum refers to not that address itself but to the account that that address points to so if they were to if they were to do it maliciously it wouldn't happen accidentally the checksum would look after that they were to do it maliciously they'd have to mine an address that whose checksum was the same and these accounts these small ones you can choose which address you want to use yes sorry you can choose which address format you want to use and some of the address formats have like eight byte checksums so they'd have to mine an address that had like eight whole byte that shared an eight byte start of a hash with with the address that sort with the address that's IO that's that so I mean I can see this not being so so much of an issue and to be honest if you want if you want an address that's like you know permanent then sure just use the big big long one yeah but if if you want something that's like a payment address or if you absolutely sure that you're never going to go below the minimum amount then as these small addresses should be fine and they're a lot easier to remember and the other notable other point is that if we delete accounts and this came up in aetherium so parity we apparently made a proposal on the IPS to sort of say look we should have disk election that was actually implemented on covin right we rolled it out to covin and the issue one of the issues is that it means that nan basically transactions can be replayed if you're not careful because when you delete an address you don't just delete the balance and reduce that zero but you also delete the nonce which is counting how many transactions it's sent which means the first transactions can now be replayed or the very first transaction in particular can be replayed and then the second third and fourth can if that goes through successfully and that's problematic or it could be problematic because if those transactions do something other than spending the balance then you can actually put balance into the now zero account so it's now got cash to spend and then replay those transactions to do this to replay the side effects this is why we brought in the transaction errors so the idea is that when you construct a transaction it's only valid for a particular period for the future so you can make a trend you can construct a transaction that's valid indefinitely we allow for that but if you do that you've got to accept the fact that if someone else if your account gets deleted then the first transactions can be replayed primarily because there may be well firstly cause we you know we're generalists and we like to you know allow for as much as possible and it's up to our users who we we believe our our esteemed you know we esteem them in terms of their intelligence and we believe that they know what they're doing I mean you know everything goes wrong at some point I I don't believe in making tools you know I don't believe in making kind of safety scissors for you know for people I think that you know the level at least that were at you know we should we should be working with sharp knives for sure official and but I would put this on the user level so I think this is for you know if you read some of the other chains they issue kind of not warnings but directives to their middleware and use a user level like UI engineers say look this you can cut yourself the chain doesn't protect users from doing the stupid thing so it's up to you to protect them by putting in these warnings and we will do the same so for example if you're if you've issued if your wallet knows you've issued transaction resolve doesn't know that you haven't issued IRRI limited transactions and sees that a transaction you're about to issue would remove your account with the would delete it would take you below the minimum amount then it will would basically bring up this big what it would either not let you do it or bring up a big warning saying are you sure you know what you're doing yeah yeah so if you know we don't want to like hamstring people at developing on the platform we want to inform them and we want to inform them when they should hamstring the people who were using their what they're developing or at least give them information to make sure that they don't shoot themselves in the foot yeah it's true I mean there's maybe a trade-off to be made here checksum seemed a perfectly reasonable thing I mean most address formats have checked sums in the original aetherium didn't and that was a really big pain so that was that was just less and learnt in this case I don't think there has been a lesson yet to be learnt and I think it's such a really easy thing to protect against like either wallets shouldn't let you construct transactions without errors that should be a niche thing that you have to build your own applications to do I mean the cambia that I can imagine applications where errors don't fit for example suppose you've got something like a plasma plasma kind of chain and or a state a state channel and you need this transaction to potentially last indefinitely because that's the only guarantee that the other side has that you won't just pull out after the era is ended yeah it's like there's no other way of doing it and there you just have to ensure that for your specific niche use case there is no way of reducing that balance below the existential deposit but in most use cases user level tools can make sure that you don't shoot yourself in the foot say again oh when you see well it's a transaction hold on so when you serialize a transaction I see what you mean yes can we carry yes the answer is yes we can carry our concise address format into transactions as well so normally we would have to put a 32 by identifier for each address for the sender and the receiver irritatingly so one of the things that if you read about Edie two four five one nine they'll be like oh yeah it's really good it's got like compact signatures its signatures are smaller there are only 64 bytes instead of 65 what they don't tell you is that unlike unlike ECDSA you do need to put the sender address in there so yes you might you might shave a bite off in terms of the signature but you have to add an extra 32 bytes on because you have to tell it who the sender is I mean Bitcoin doesn't kind of Bitcoin provides both but you know whatever that was just a questionable decision if there him doesn't we go we don't bother encoding the sender in the transaction because we derive it directly from the signature you can't do that with EDD si sorry with Edie 2 5 1 9 so actually signatures are 96 bytes we have a binary format so we don't have padding we have a binary format that basically uses 33 bytes to encode one other 32 byte addresses and uses one byte to encode the small ones and and so forth and you can determine what it is from the first few bits yeah so it did if you use these small addresses you shave off like 60 bytes potentially a couple more from the transactions and that's that's a pretty decent saving it basically cuts transactions by \u2156 as the relay train yeah I mean so the substrate comes from the relay chain so when we started coding polka dot well when we started coding substrate what has become substrate that was just called polka dot and although even before we started I had in my mind it was going to turn into substrate I didn't really mention that to the other devs so they were a little surprised when I started renaming stuff but yeah it's the biggest the biggest challenge is kind of thing that I mentioned it's getting that level of generalism while still making things be easy too while still making it easy to write the things that you want to be able to write so that that's what you know any design of language or API comes down to this getting this trade-off right and it ultimately comes down to expressivity so expressivity of a of a language in a domain is really just how well you can make it easy to do the things that you want to do and make it possible to do everything yeah and bringing those two closer together is is what we call expressivity or what we call a good language or a good a good domain language and you know substrate has a similar challenge getting it getting it general is not so easy it's something I've you know kind of wanted to do even since CPP aetherium but not having had all of the experience it wasn't so easy to do it the early days but it gets it gets a bit easier with having coded a couple more Sega is data deleted when it's deleted okay so what was the question again okay so specifically with smart contracts or with runtime modules and and the the substrate in general not really but smart contracts kind of have to do their own thing to some degree but okay I'll talk about substrate in general because that's what I can answer yes I see I know what you mean now I know what you mean yes no contracts work differently okay so we have we have archive mode that keeps everything around forever it doesn't run an archive mode by by you by by default it runs in a standard pruning mode by default which basically Clips any state from blocks that are old enough after a 100 or 200 or so if what you're talking about is like in a theory and when a contract delete something if that contract if that call into that contract turns out to be exceptional and everything gets rolled back then that delete doesn't happen in substrate in the basic runtime module in the basic sort of core we don't do roll backs right so as soon as something gets written into storage or deleted from storage it's actually deleted and unless the entire block gets rolled back because it panics then it's done that thing's deleted and there's no way you can you don't have checkpointing in there if you want checkpointing which you may well want it goes into the it goes into the as a runtime module library and the contract runtime module library that the smart contract actually implements checkpointing so it's it implements something that is basically a minimal form of aetherium but has most of the stuff of the etherium environment and the only difference is that it doesn't run in a VM it runs in webassembly of course web assemblies kind of cool and sexy unfashionable and hipster yeah I mean you know to some degree runtime upgrades and these sort of out-of-band state changes are are specifically what we do how we manage what happens when things go south in other ways so ultimately there's the same safeguard if you want to call it that that any other chain would have that doesn't have a governance system which is it can always be hard forked even if the governess system of the polka dot substrate whatever goes Ori I I sort of take a two-prong approach and say well on the one hand we want to be reasonably conservative and try to get solid reviews of our proposed governance mechanism and/or use governance mechanisms that already exist in real life and that we have some idea will probably work okay with the other prong being try it out as much as possible on test nets that actually have value before we put it on to a network that has lots of value potentially and this is you know where the edgeware project could be very helpful and potentially others like it to really provide a network where you know no one's losing anything if it's if it there's no cost to it going down or being problematic or having to suffer a reversion but there is real value at stake because it's got tokens that are worth something and that's that I think is a really nice middle ground to sort of go and try a bunch of stuff that we think probably works okay but we can't be sure to really try you know empirical testing try it in real life in much the same way that when the psychologists want to run a new experiment you know they they get a bit of money and they sort of say look if you if you do this right you get fifty quid and you know this is the instructions offer you go kind of the same thing and we did something similar with the Olympic test net back in PRC nine PRC ten days for the theorem to try and get people to kick the tires of what would become the the main net before we released I actually I think Olympic was a not a failure but I don't think it was a great success not that many people took part in it and it didn't really it didn't discover it didn't uncover one or two of the books that came up which you know we would have otherwise hoped and I think a test net that has real value maybe less value than it would otherwise have but still real value is probably a much more market-oriented and therefore probably more successful way of of trying to incentivize people to to break it or otherwise test it yeah so I mean you know etherium had the consensus tests it had a decent first testing although I will note that when we implemented parity we found two points where the consensus test didn't cover and we had to we had to add new consensus test it's a hard thing to do with with substrate we kind of work around it a little bit by saying there's a single was a reference on chain so it's basically like a machine executable reference spec I think it's it's questionable whether that's such a great thing I mean the Bitcoin guys love that idea because it's like they've got their reference implementation Bitcoin core I kind of like the yellow paper for not being machine executable but yeah I mean in polka dot and substrates case it was largely forced upon us anyway in principle there could be multiple implementations at the same runtime I could you know that's something that I explicitly provide for in the versioning I'm not sure if it will happen the foundation the web sorry foundation is looking to fine teams that yeah cool okay yeah so I mean I'd like to see it happen but as for whether as for whether we could really come out come up with better consensus tests than what we have for theorem I'm not sure it's a really tough thing to do without literally paying someone to painstakingly go through the specification every single conditional write a test for and I mean this gets potential exponentially complex as the different modules I mean you're looking at kind of two to the number of conditions potential number of tests that would have to cover everything it's it's crazy so I would probably just go for taking out a month's rental of a supercomputer and running a huge amount of first test I think with a with a well-designed for sir that that should probably provide as much protection as as you would otherwise get in polkadot so there's there is a mechanism sperm free transactions basically for transactions under the substrate model which polkadot adheres to transactions must sorry under the substrate the SR ml model which polka dot adheres to I should say transactions must pay for their space on the chain so there's a fixed fee for a transaction and there's always I mean can set it to zero if you want but you know in principle there's a fixed fee that a chain can leverage and this is a something that can be changed and upgraded and all the rest of its if it's the parameter and there's also a per byte fee that's charged per byte of the transaction and as it's encoded on the chain so that's non negligible that's sorry that's non-negotiable they have to be paid beyond that there is an if you want to charge additional fees for what the transaction is doing then that's up to the chain and the runtime modules and the sort of the the code that you're writing yourself you can charge for what you want polka dot will probably have some yeah fees associated with the creation of balances with the occasion of accounts so the balances module has a fee schedule that you can again customize if you've depending on you know how much you want to charge for the sorts of things of creating new accounts reaping all the counts transferring balances as a bunch of things that you can customize what else other modules I think most modules actually don't specify much of a much of a fee schedule because most of the modules are yeah there are the governance modules do have a fairly complex system of deposits that's mainly to address sort of a game theoretic concern of a potential quadratic quadratic attacks where quadratic cost attacks where certain algorithms are order N squared to rent or order MN to run and you have to make sure that you know m and n can't both get too big it's ok if one of them gets kind of big but you need to make sure that they can't both get too big otherwise you end up sort of going off off into the distance in terms of the cost and that's managed through as I say a set of deposits and basically incrementally increasing the cost of one or the other depending on how big the other one is I think that's probably about it I'm not so worried about literally charging every single clock of processing like gas would do partly because a lot of a lot of operations are order one and/or they have like a reasonable maximum that is not that you know they don't really go proportional the user can't force or the trans actor can't force a anything over a particular maximum that maximum is relatively and significant and I would look upon it more or less as the Bitcoin chain does where it's fine basically to just charge for space on the chain for the size of the transaction and not think too much about the processing costs because they will be dwarfed by the storage costs obviously in smart contract land it's much more important to charge for the for everything because you know users can potentially write infinite loops and all the rest of it so their contracts module does indeed make sure that there's a proper costing mechanism for them it's not a final design decision to be honest but part of the reason is that it makes a lot of sense when block production is on a individual basis like so - are competing with each other to produce these blocks it's not really the case in the consensus are mechanisms or block production mechanisms that I see substrate working under you in in substrates case that's really more of a sort of collective thing and it doesn't really make sense to reward one over another and partly it's I guess remember the other reason I think there was so in some sense when you burn fees it's a little like paying all of the other participants I guess yeah okay so the reason that that miners collected fees in etherium was because that's what they did in Bitcoin and the reason that - collected fees in Bitcoin was because eventually the block reward was going to go down to zero and that would be the only thing that incentivized - to do anything that's not the case in in polka-dot in poker ah the the validators are are incentivized like permanently through the reward system it basically means though dilution will happen there they're sort of percent or their ratio of their state compared to everyone else will remain the same they're sort of dilution protected and everyone else gets everyone who's not part of the validation nomination sort of system will get diluted and because that's in place it doesn't make so much sense to then reward them extra for for the transaction fees that said it's not a final decision as I said and I'm like you know something to talk about over the next few months and see if there's a compelling reason yeah I mean potentially I'm not sure we really see that in in real life there's plenty of instances where you know aetherium transactions go through four zero gas price censorship you know as always can always happen you know it's just if you're going out of your way to censor some transactions there's a cost associated that selection mechanism and that cost may be insignificant but that cost may be the price you're willing to pay maybe and it may be substantially greater than the cost of you know not collecting a couple of micro sense of fees so for sure but if they do then adding a small transaction fee isn't really going to make much difference unless unless you know the transactions that they're dealing with our micro transactions in which case yeah yeah I mean that's it so staking is more of a sort of collective pursuit rather than something cutthroat yeah I got a feeling there was another reason but I can't remember what it was now but as I say it's not something that I'm happy for this to be a continuing conversation and you know if it turns out that it does make sense for the block producer to to take these fees then this point is just the simplest code like I don't it's one line of code for you basically suppose you have 20% of the chain that is 20% of the total capital contained on the chain total tokens that is part of the staking system and market the market effects are such that 5% of that 20% so the total are being replicated to root for their rewards so I mean this is a half the reward right 25 percent but whatever then in order to prevent the rich get richer situation of the chain where validators just everyone gets diluted and all of that dilution is favoring the validators their percentage of the total state just keeps going up and up and up and up until eventually their total of the amount of the chain approach is like 100 percent to avoid that situation we place a well if we save 20 to 80 then we place an according amount so for X in our 20 to 80 ratio of the amount of that reward goes into a pot right so so we've got 20% a quarter of that gets paid to the to the validators so we're going to mint 25% of of the chains tokens again yep so we're going to dilute by 25% we take a fifth of that so validators whatever so that's that and with the other 20% which which basically is \u2155 of 80 sorry \u00bc of 84 fits over 25 that gets placed into a sort of community Dow for the chain not too dissimilar from you know the thing on - or or even like the Dow although let's boogie hopefully and that will be used as like there's already a treasury module in here it's very simple but there's the treasury module actually sort of put forward ways of spending and and they can be voted on and then the idea is to basically allow additional modules to spend money from this pot and they can be sort of integrated through chain upgrades it could also be a lottery it can also be a reward for people that like accounts that are willing to bet on the price going up if you got an oracle feed of the price so if you're willing to bet that the price goes up and the price does indeed go up after a period of time then then you can get paid from this pot and if it goes down then you can your money gets put into the pot so there's all sorts of interesting don't think about that too hard there's all sorts of interesting oh yeah you can like what I showed you like the thing is what I was trying to think of a toy runtime module that would extol like that I could code live you know that wasn't so big that I couldn't code live but also that sort of got across a degree of sort of generality that this provides and unfortunately everything that you can code live pretty much will look like a smart contract because smart contracts are just tiny little bits of code that you add to block chains but what I did with with the extra module although it looked a bit like a smart contract it worked very differently right this this was a deployment of code that would be run natively and that would sit in principle in the same place as the smart contract as the smart contract bit of the etherium state transition function or the EVM or whatever else you want to think about code I won't even consider coding an EVM interpreter as a smart contract that would just be zany right I'll just be Cray would run so slow and it'd be really horrible but you could do that in one of these modules because it operates at like a 10 X low lower level so you get that 10 X in in performance and in well it uses that it uses some substrate runtime module for its pyro change management yeah I don't call it delegation because that's kind of got a loaded meaning now that EOS uses it in particular when you delegate a stake you don't get punished if the if the party that you delegate to misbehaves and that's usually problematic in terms of getting incentive correctness so we call it nominating and they're critical as I say the critical difference is that when you nominate a validator with your stake they you lose your stake if they misbehave I mean they lose those first but if they don't have enough to pay for the misbehavior then you lose yours yeah yeah so you this is to get around the nothing at stake issue long term long range attack yeah so yeah there's it it's bonded the moment the assumption is it'll be about three months bonding period but it will be at least as big as the expected period between releases of the of the binary of any software that sort of interprets this chain so no the assumption is that the most recent checkpoint will go into the software itself and the bonding period is sufficiently large that and the software will be released sufficiently frequently that the most recent bond most recent software release will be holding current validators currently bonded validators to account okay Sagan you can if you put it in yourself I use fixed point for anything that needs point one more if you're a move floating point then it's deterministic cool okay I call an end to this are you do you want to do it you wanna do the end","title":"Todo"},{"location":"todo/#utxo-model","text":"is kind of an interesting hybrid between the stripped/stricked all full nodes must validate everything and and base their validation they the things that they validate sort of they put a state route/root a storage route if you like state route into each block header and that means that like clients when they come along they can actually in principle validate everything all of the state transition logic of every block based purely upon the state route of the last block right so if you trust that the header of the last block is something or other then you can check that state route and you can come you can be provided with a proof that all of the transactions on the current block where executed correctly and therefore that the state route on the current block is is correct and polka dot very much uses this model it's the model that the power chains are based around and it basically means that validators by having just like client logic can actually validate every power chain equally I'm bitcoins a little different in principle if you trust the previous blocks header you can still be provided with a proof that the current block is valid but the proof is potentially all of the Bitcoin blockchain and therefore not super concise this it's this is the case because Bitcoin doesn't keep a track of the current state at every block and place that in the header as a cryptographic hash rather when you want to so make some transaction on Bitcoin and prove that it's a valid transaction you use unspent transaction outputs and those are outputs that it is expected that nodes will record in their database but if you want the actual proof that those outputs are valid you have to go all the way back to the block where they were they were the outputs from a spend in order to be sure that that they're legit and obviously you have to see the entire chain between now and then in order to be sure that they weren't spent already so it's it's much harder to do a you TXO model in literally the same vein as Bitcoin because this kind of light client sort of model doesn't doesn't quite extend to the conciseness theorems does that said if you instead store the unspent transaction outputs in a murkily structure in the same way that aetherium stores its contract state then you are able to basically get a hash of that structure every block and you can you can provide concise proofs that a particular transaction is valid because you can see the you can demonstrate that those and spent transaction outputs appear in this localized structure and that's how we would implement a u TXO style chain within the para chain model and probably how we would implement it in substrate and that's actually going forward how its we built in principle though as I said that you could introduce a raw database into substrate and actually mimic bitcoins model but it would preclude turning it into a para chain without adding some additional layers of indirection and likely are not likely enough trust which we're not so keen on introducing programmatically speaking you'd introduce a UT EXO's at if we go into the code base so I mentioned before like substrate has three levels of kind of you can dive into substrate of three levels so you can dive into at the core which is right there oh and this is if you use substrate you use substrate core and it's got all of the things that you would expect to see in a in a block chain if we look at the modules or the crates as Arista falls them then we you know you can see things like the consensus and the finality and the keystore and the networking and the our PCs and so forth it would likely be implemented as a outside of the SRM L so the SRM L is here because the SRM L is rather designed around a an account and an index model similar to aetherium in principle you could nonetheless create some additional SRM l modules that kind of introduce you to EXO's I mean in principle as modules of turing-complete they've got entry point functions that can be arbitrary bodies and they've got they can they can do basically anything with storage that they want so there's no reason that you couldn't implement it that way but it'd probably be a bit more efficient and make a bit more sense if you implement it as its own runtime and to do it as its own runtime you would basically just use the underlying abstractions in core that were used in order to pass in order to allow things like the execute block function to be to be implemented and for it to be called into by the the rest of the client and and work with that directly and you define your own block format and your own transaction format and in general build the execute block function and that's in Bitcoin from from scratch where as I say parity is is pushing forward with its with a you TXO chain mostly so partly to make sure that the model that we have is actually general it's it's a good sort of sanity check and partly because we actually want to introduce a payment based system that's that's a sorry a payment system that's based around you TX owes and potentially that has some sort of ZK snark functionality in as well and we're doing that with the by reusing as much of the PBGC block parity Bitcoin and code bases become cool I'm not going to start implementing one here am i okay maybe laters cool what were the other three questions theorem compatibility yeah so how does the RPC RPC and JavaScript work this is a yeah this is an interesting question so substrates meant to be pretty generic and if we go to the RBC module it's split into four four sub sub modules author chain state and system author is to do with block authoring and it contains have a look what it contains submit extrinsic there's a couple formats you can submit them in and a Ana pub/sub to let you watch what's happening with those extrinsic s-- so if you actually want to inter inter oh if you want to communicate with substrate through the AH feces then these are the RPC is you're going to use and it's basically like here's an extrinsic it's already signed it's already done and dusted just submit it broadcast it whatever and let me know how it goes and you from this you'll get back various messages I think I know they were on the have a look maybe I've got some messages yeah I don't you'll get various messages to tell you that it's been validated that it's been broadcast that or that it's about to be broadcast that it's been broadcast and that it's been finalized or if it doesn't get finalized if something else gets finalized in its place and that it's now been dumped then you'll be again told that it's been okay so back to substrate 101 yes right to make to make substrate be as general as possible we didn't want to introduce data into the block header that may not be in every block chain that substrate that need not be in every block chain that substrate is gonna cater for rather we want to make the header strictly the information that is required for substrate and the rest of the rest of the information that might otherwise go into a header in normal block chains for example the timestamp instead is provided under a separate model that's outside of the header called the extrinsic and extrinsic just mean that it's like data that is extrinsic to the block chain so it's not it's not intrinsic to the chain it's not like part of its state or anything like that it's not a previous transaction or anything that it can draw upon directly but rather it's just data from the external world is extrinsic to the chain and so data from the external world is provided in this set of of snippets of pieces and each piece is called extra and extrinsic and it's just short for a piece of extra piece of data extrinsic to the chain so right so specifically the transactions that are coming in coming in from the external world they are indeed extrinsic so most block chains possibly all require there they're sort of transactions to be signed like they have a particular signature scheme and if they're not signed or if the signatures wrong then they'll never be considered they won't even make it into the system substrates a bit different so substrate says extrinsic scan there are perfectly valid extrinsic s-- that are not signed they're extrinsic the only thing special about them is that they're a bit of data and they come with some way of determining their length upfront so you you know you can pass them around on the network without worrying how long they are other than that they're they're just arbitrary bits of data they may be signed they may include a signature they may include a multi-sig they may not it doesn't really matter some pieces of data for example the timestamp so there's literal okay I can think of very easy Taric ways how you might possibly argue that a timestamp could be signed and that would make it valid like maybe if the the what's at the atoll the guys are on the atomic clocks like maybe signed it with one of the keys but still someone could steal the keys and then the signature it doesn't make it specifically valid nothing can make a timestamp specifically valid right it's a piece of data from the external world and the only thing that means a time star is correct as if we all agree that it's correct what time is it right now well I can say well it's 38 minutes past 6:00 in the evening but it's if your watch says that it's 37 minutes past 6:00 then you know there is no way how without like finding a shared Authority there's no way how we can argue that one is more correct than another and certainly signing it isn't going to help all three authors just an arbitrary name that we call when we say author we just mean block author so this is a block authoring API this is an a this is an RPC that you use when you want to interact with the bit of substrate that is authoring blocks and this is actually incorrectly named it's very good that you brought it up it shouldn't be called extrinsic s-- or at least it's it's it's a little over general to call the extrinsic the only extrinsic that you can submit using this API are specifically signed extrinsic because it's coming from the RPC and therefore you have no other way other than looking for a signature to know that it's anything that's really sensible unsigned extrinsic switch for what it's worth we call inherence because they are we treat them as being inherently valid are are generated within substrate so extrinsic s-- is information that come from the outside of substrate and inherent are our extrinsic that come from within substrate and sorry transactions really come from the outside inherent come from with them they're both forms of extrinsic because they're both forms of data that can be introduced to the blockchain and that might make some sense to the runtime now if you don't if you don't sign some data then it's like well you know how does that how does that possibly work you know data's not signed then it could be anything right and the way that it works is the validators so the guys that basically say that this block is valid are the ones that get to be opinionated over whether this data is sensible or not and that's actually how this works in other blockchains as well so if you look to aetherium if the time stamp is actually just an opinion right a validator when they validate an aetherium block have an opinion over whether this time stamp is sensible or not and if it's not sensible they ignore the block they unilaterally decide to ignore the block and in in that sense substrate is equivalent in its treatment of inherent if a is up to a validator when they're proposing the block to put in sensible inherence and if they don't put in sensible inherence if there's inherent in correct or incorrect in the opinion of the other validators then their block will be considered useless and won't get any further attention so it's up to them to put in sensible values for the inherent extrinsic that are required by the block and this basically means that we can do all sorts of interesting stuff aside from time stamps I mean time stamps are the first use but we can do things like for example with para chained candidates for the polkadot relay chain there are that's another form of inherence why because which candidates you choose in order to in order to to be to be therefore finalizing is necessarily an opinion right it's different validators might choose different para chained candidate blocks to be finalized for that particular relay chain block there's no way of deterministic elite oozing the correct set of these guys it's just whichever ones happen to come come by you but if you put forward blocks that the other validators on the relay chain think are invalid perhaps pick they don't have the Associated data because there's no data availability for them or just perhaps because they're empty perhaps because they they just haven't seen them before whatever reason it is if they don't think that your opinion is is a good one over the selection of these blocks and they're free to ignore you in reality you know they'd have to be quite malevolent before they do ignore valid blocks because they get paid basically for passing these things but by and large it's up to the validators to self-police the content of the inherent transactions the the sorry the inherent extrinsic s-- for the transaction extrinsic s-- there they are per se valid or invalid like you can check whether a transaction is valid by virtue of does it have a good signature and whatever account has signed it does it have enough funds at this point in order to pay for the the cost for it to be placed on chain and if those two answers are yes then it's all good and that's the difference between the two so this is the RPC for how you can submit them unlike aetherium we don't provide any account management stuff in here so what you can't do is provide is try and get it to sign in and to sign a transaction all of the signing happens external to the node so the node is minimal we do very well noticed the keystore package is there specifically for for block authors so far the validator nodes just stored their their block authoring keys so basically when you when you set up a node as a validator node which so I got away without doing this on the on the demo that I gave earlier by using the - - dev option which is shorthand","title":"UTXO model"},{"location":"todo/#for-chain-equals-dev-validator","text":"key Alice but I could have typed those in and it would have done the same thing and so when you pass it the key it will it will use that it will basically put that key into the the key store and then if it notices a key in the keystore is one of the validators and it's set to being a validator it will actually start signing what and and join in with the consensus so that's the key store is really just there for the for managing validators keys for consensus yeah I can see yeah so there'll be some shims or middleware in order to manage some of this some of these are pcs to make to make it compatible now I'll go into I'll go because this is kind of an interesting exploration I think so there are a few other modules chain does pretty much what you'd expect it to do it's it's about blocks and headers it lets you get transactions and as I have been chatting to a meal over the last few weeks and months the the point of a substrate node isn't to provide a generic sort of very generalized database for every all of your uses that you might have I mean etherium was kind of pushing in that direction we provided all sorts of lookups that we didn't really have to substrate keeps it minimal it's it's got a fairly you know that's one of its Maxim's of design and one of the ways that we keep it so one of the ways that this sort of minimal RPC comes out is the fact that you can't look up specific transaction hashes you can I think maybe get oh yes so you can get a block and the block will come with a bunch of extrinsic sand in those extrinsic will be the transactions and that's that's basically if you want to index if you want to have a you know get so get a transaction by its hash you're gonna have to go to a chain Explorer or a party service provider or whatever to get that now you can verify that that that's the case just by getting the block and transaction index and then going back to your node and using this RPC to get that block and then lookup that index in the extrinsic and you'll find your transaction or not but we're not going to do that indexing for you because it's too much work it's it's better done on a dedicated software yeah sure i-i'm sure or are all of the author and other extrinsic s-- you mean the entire chains worth if the blocks not created yet then you can't look it up at all when it's when the blocks being executed no no no so either the block has has made its way into the database it's finalized then it's good or you can't you can't read it at all during what sorry execution of the block or well when a block executes I can show you that that that code but basically there's an execute block function and it gets given you get given a bunch of bytes and it's up to you to execute those bytes so at the lowest level so at core a core level yes SR ml it's a lot easier but that that's full of a lot of opinionation that isn't necessarily indicative of your chain that you're writing on substrate yeah yeah you just get given a bunch of bytes and that's your block and it's up to you to interpret the look of the block as you as you desire okay let me let me go through the are pcs and I'll come back to you so yeah we can get header block block hash and there's also a runtime version that should actually be in state but it was a very late edition Thank You Tomic Thank You Tomic we have system which just gives you a bunch of information about the system just the name version and the chain that's basically just the the current running node for example we also have the JavaScript implementation of much of substrate and that will return different things from from these are PCs finally as the state this is the most interesting thing so again back in if we if we think about what you can query of a block of a blockchain state in other block chains usually it's like account balances whether an output is is spent or not how much is sitting there potentially some state of a contract you might even be able to make a call into a contract and have it execute we're a bit lower level with substrate as as might be imagined from the fact this is a library with a framework with which you build block chains but there are things that you can get from the current state of the chain are storage so we have at the moment this RPC reflects a single storage database so basically we have a merkel Merkel tree there is of arbitrary size keys and Val in pairs right so the tree itself stores basically any key value any set of key value pairs and the root is stored as the state root and that goes into every block as you change the storage as we change these keys and values then you can that that will obviously change the state and you can make it's very handy for building pair of chains because you can make very clear like client proofs that one particular block with one state given these transactions that executed or these extrinsic sigh should say that executed left another particular block with another particular State that's nothing nothing no really not really any different to how etherium works the main difference is that of generalization and with our road map that allow where we want to build multiple different cryptographic databases so if we if we think of the Merc alized key value storage that we have here as a one example of a cryptographic database then we want to actually extend this to other cryptographic databases and also add a a means of having many of them at the same time so if you're familiar with how aetherium works there is a every smart contract actually has its own sort of cryptographic database where it stores its key value pairs it's storage if you like and and then there's one sort of big one that all of these other the by virtue of them having state routes all of these other databases hang off substrate only has one but it's one very general one and in principle though that can now be expanded to have as many as as is desired and they can even be of different types and they can be dynamically added and removed in the similar way to that you would dynamically add and remove them in a theory and when smart contracts go in and out of existence we also have metadata which is a wonderful wonderful RPC that I will spend some time talking about when I address one of the other questions which was the color JavaScript sort of magically works and finally we have a pub sub for storage so you can subscribe to particular storage items and you can get notifications when those storage items change so if you understand how storage works and that's one of the other magical things about metadata that's what it kind of provides that's what it partly provides then you can basically keep an eye on that storage and just be notified when that entry changes yeah so Sergei can go into how smart contracts so this this little symposium will be will be split so I'll answer whatever sort of more general questions about substrate and then Sergey is going to do a little sort of walkthrough of deploying a smart contracting because explain some of the technicals behind the smart contracts and we can go into the events and and smart contract storage there this is specifically for substrate chains as a whole and this will be very likely look like the final RPC an API for para chains so with smart contract so we have a smart contract module and that exists as a module within substrates SR ml so you can basically make a substrate chain that can can manage smart contracts as well as do a bunch of other things like have governance and all the rest of it so we we kind of see smart contracts as a piece of functionality that you can answer your chain or not add to your chain as you see fit the on your use case some use cases that require a generalized sort of smart contract environment some a very sort of specific fixed-function chains and if their specific fixed function chains then like for example a plasma chain a plasma chain doesn't require a smart contract modules and these smart contracts in there right it's a fixed function chain that would that basically manages all of the other chains hanging off it and what to do if those chains want to do an early termination or or settle on the upper layer so I don't imagine all chains to have smart contracts from finality in fact I suspect many chain even perhaps a majority of chains won't have smart contract functionality there'll be they'll settle for having fixed function fixed pipe fixed block processing functionality that's upgradeable we like up readability cool so that's that's basically the our pcs now the interesting thing is how these interact with the JavaScript environment so we're developing because we like to give people Choice we're developing multiple JavaScript API is to interact with substrate and substrate modules now these api's are primarily geared towards interacting with the substrate runtime module library the SRM l so they are fairly their highest level right there are lower level components like for example you can use these pub subs with promises I believe at the JavaScript level but if you want to but we make it easy for you to use to build applications based around custom modules that you code in the SRM so you got a taste of that although it might have sort of flown past you a little bit in the demo because that was trying to get it all finished and more or less on time but I don't know if you noticed but when I wrote that that little sort of toy the I was able to interact with the toy in the browser as soon as the chain had been upgraded I actually in the console got like an object that that let me do it in like that was specific to them the code that I'd literally just written in rusty now I that wasn't a trick I didn't have anything up my sleeves it was it was literally that cool what happened was the runtime got upgraded although I didn't code any new JavaScript stuff what the the code that I wrote and annoyingly I can't really I don't have know let me see if I can find that code should be in substrate node template and if I remember correctly I might even have to I do okay so so if we go back to the substrate node template so this is this is the sort of demo node that I that I forked and started coding and I have this demo module and if you remember I did something like this I said I did post sender and then decoded this this little address and then also for the call it's calls demo dot set payment and that just worked despite me not actually having changed anything in the JavaScript I didn't even reload the page I think I certainly shouldn't have had to what happened was when I coded this module with play and set payment and when I coded this storage with the two entries here payment and pot part of this macro generates some metadata about what these functions are and what these storage items are and this includes the types this metadata is compiled into a sort of blob and then amalgamated with all the other metadata from all the other modules by virtue of this macro here construct runtime that you might have remembered I put the demo line in this then gets passed to through this macro which implements the api's into as a something that can be called into from the client so we have here one specific trait that we can implement called metadata as a metadata trait if we implement it it means that metadata RPC will work and what it will do is it will check to make sure it's actually implemented call into it which means dispatching into the newly compiled runtime that's been compiled into webassembly and interpreting this metadata and all this this this function does is it grabs the metadata from the runtime and that was caught that was built from this constructor and time and that was built from all of the individual modules which are each are built from their declarations of what they're stripped their storage are and what their what their module is that in terms of their function entry points and this gets passed into the JavaScript and as part of the substrate JavaScript libraries we have a couple of libraries that you can choose to use one is based on observables one is based on the bomb's framework that I did last year and these libraries will in interpret this metadata blob and turn into real JavaScript utility objects that reflect and [Music] and will dispatch to and utilize all of the all of the module specific stuff so if we go to the way they put it no just live demo yeah so if we go to demo then it will actually interpret will basically make Marshall all the arguments and dispatch it through the transaction dispatch system into yeah and similarly if we query what the pot is it will work out where this runtime given this this module stores the pot in its storage and then go into storage and check that using these storage are PCs and if you part of bonds is the fact that it's reactive so if you tie that into a reactive component if you remember at the end of the demo I very quickly did a little label that that tracked the pot going up and down what it's doing there is it's setting up a pub sub with the thing that it figured out all on its own with the storage location for pot and track the value it knew what the type was because it looked that to see that this pot type is T balanced and decoded it into a balanced type and then put that into a label formatted it correctly and put it on the screen and it did all of that without me really having to do anything other than implement it right here in rust so the idea with this is to make it not just painless but actually fun to code modules and the U is four modules what was one of the other that was another question mempool yes this is an interesting one so we rewrote the meant well Tomek I should say rewrote the mempool recently we call it the transaction pool same thing we wanted something that was general but also easy to use and it took a little bit of thought but what we came up with was a a pool that basically allows runtimes to specify dependency graphs arbitrary dependency graphs of transactions easily we wanted something that would work equally well between UT EXO model and a account and index model so basically a transaction pool that was equally viable to be used for something like Bitcoin and aetherium with the idea being that if we made something general enough for both of them it would probably be pretty general sufficiently at least for doing interesting other chains in the future so the way it basically works is the runtime gets queried and I can show you where this comes in the runtime gets queried through this validate transaction as part of a transaction Q trait so this is a trait that you have to implement in order for this transaction queue to work transaction pool actually just references the executive here so the executive is like a sort of overarching SRM L module that looks after just executing a block in general in particular it runs through each of the extrinsic and dispatches them off into the module that is expecting to that the extrinsic is sort of trying to call into all extrinsic in the SRM L framework have a they they may or may not have a sender they may or may not have a signature they may or may not have an index they may or may not have an error we actually allow we actually force or not force we actually facilitate extrinsic soar transactions to limit the number of blocks that they're valid for inherit right so you can make an extrinsic the transaction I should say that is valid for the 16 blocks between a thousand and twenty four and a thousand and forty right and it after a block a thousand and forty it's just no longer valid it can never possibly be make its way into a block chain this is needed for a bunch of other things particularly for having dust collection which I can go into after after I've talked about this if that's of interesting the transaction the way that the validate transaction thing works the important thing I want to show you is the inputs and the output so the inputs are the transaction fair enough the outputs are the trend is this transaction validity object let's see if I can find where this is defined this is basically a means of we see so we can see it's got like three potential states invalid valid or unknown l invalid oh no no and a pretty obvious what they mean valid so for a valid transaction we have a bunch of we have four sort of fields that we have to define priority so how what's this transactions priority amongst peers for which everything else is the same right so assuming this that everything else is is all other things being equal which one should we favor to put into a block for in aetherium style chain this would basically be what's the gas price if the gas price is higher then we just favorite more we also have requires and provide so requires is and we have this vector of transaction tags transaction tags are just Veck vu8 so in rust lack of UI it's basically just an arbitrary bunch of bytes right it's just a by the string yeah and these tanks they're therefore entirely up to the it's entirely up to the runtime how it what tags it uses it can tag them by hashes it could tighten them by integers it really doesn't matter could tag it by account IDs it could you know concatenate a bunch of these things and that could be the tag they're entirely arbitrary all that a transaction list transaction validity function has to state is what does it what tags does it require and what tanks does it provide now we can imagine for a for an aetherium style chain it would require the tags that requires are all of the tags actually let's start with the tax that it provides tags that provides our one tag that's formed by the concatenation of the account ID the sender ID and the current index the index of the transaction right the nonce yeah so you pop those two together that's your tag right that's just an identifier for the the thing that this transaction provides what it allows us to do is to then state what other transactions require in those terms so suppose you have a my transaction is sent from me my account dev and it's got an index of 10 right so for that to work in the etherium model there has to be a sent by me one with index 0 1 with index yeah and that would make 10 to be the next valid transaction so what it requires is all of those tags now that's a bit unwieldy for when we get into the thousands of or tens of thousands of transactions coming from a single account so what we say is only requires the tags that have not yet made their way onto the chain yeah and if if we get into the silly numbers like hundreds then we just say either unknown or invalid and we just say look this this transaction is just way ahead of schedule send it back sometime future and that that actually is more or less the way that the etherium the the parity etherium transaction queue sort of worked just not in these terms now if you're on a UT EXO chain then it's actually quite a bit easier because a UT EXO model like basically you've got what the tags are they're tags are just transaction output hashes yeah so your tags are it requires these unspent transactions or unspent transaction outputs so those transactions that are providing those outputs are specifically the things that are required and it provides well it provides its own hash its transaction hash so you can very quickly build a very easily build a dependency graph from aut EXO chain that fits the Maps quite fairly well on to this and we also have a longevity so longevity is basically it's valid now but for how many blocks will it continue to be valid in the future 4-bit Connor and aetherium that's infinity basically transactions don't become invalid just because time has passed but for for our substrate chains we have this notion as I said before of errors and the ability to inherently make a make a an extrinsic or a transaction in they're inherently invalid merely after the passing of time specifically blocks and that's what this sort of lets the transaction so yeah that's pretty much how transactions work in substrate this is more for the SR ml it is meant to be general so in theory it can be used perfectly easily from the core from if you want to build like your own from scratch substrate chain in principle this can be used fine but you're also free to write your own like there's there's nothing you can you can plug in your own cue if you want to write your own cue if you have something that this model can't can't manage to embed the nice thing about this though is that it goes to the runtime for all of its rules which means if you want to update your transaction formats and you want to introduce all sorts of new and crazy interesting stuff as long as you can put it in terms of priority requires provides and longevity then you can implement whatever it is that you want and when you upgrade the chain all of the full nodes all of the authoring nodes will all automatically use your new transaction semantics and they'll the transaction queues will function accordingly yep the only you can't modify so can you modify a transaction in the that's in the queue so what you can do is you can if a transaction has made its way into the queue because it said hey it's valid and you want another transaction to be able to to beat that one to it you know if the to a mutually one can you can make it mutually exclusive by by simply giving it the same tag but higher priority that will that will get the transaction kids are sort of boot it out the transaction queue only feeds transactions into the block if you just want a transaction to just become invalid before it's been finalized or before it's been before it makes its way into a block you can do that just as easily by having a sort of you know if in the execute block function if one of the transactions is this transaction then invalid block right and what will happen is the the unlucky guy who's using this transaction queue to to make a block will will find that adding this transaction makes their block invalid and and it's kind of bad form to do it that way you should try and like make it as much of a part of the queue as possible but if for whatever reason you can't do that then yeah you can make it invalid just by virtue of changing the runtime I get in the office Tomic can probably offer a little bit more insight into this basically priority is the is the first thing that it will select on and beyond that so for the transactions that have not yet become valid then basically it's just randomly choose randomly discarding one's not that random is is particularly great but it also minimizes any potential issues regarding censorship so if you've got like tons of nodes on the network and you really try to prevent some particular transaction from getting through and you're doing that just by spamming transaction out onto the transactions out onto the network we minimize the the worst case by by choosing transactions at random to discard because it's likely that eventually one node will eventually will mine that that that transaction that ultimately if lots and lots of people want to transact at the same time then there will be congestion so it's it's really just the case of randomly choosing transactions that come through I mean in principle priority here is that's precisely what priority is for times of congestion the runtime can basically state which transactions should be favored above which others but if if priority isn't enough or for whatever reason maybe everyone's got the same gas price I don't know whatever or you don't introduce any particularly compelling priority prioritization mechanism then random is is the best we can do cool Oh what was the what was the thing after transaction I've forgotten no is there something else to discuss yep okay anything before smart contracts yeah ah yeah okay yeah I can go into that so so the runtime encodes a lot a lot about what what the blockchain does how it works it doesn't encode everything in the substrate model because we don't want some things to be to be special what we could do is literally just put a rest executable on the chain and when that changes you have to kind of download the new one and run it but we don't like that there are I think I may well need to be corrected here but I think there are there is a certain other project that's trying to do governance and upgrade ability and that's more or less the model that it takes so it sort of basically puts its executable on the chain and it's up to the nodes to kind of download the new executable and run that I don't like that model I prefer to be a little bit more conservative about the specific component that can be upgraded and when we accept that part of the logic doesn't sit on chain for example the peer-to-peer networking library I don't think it's sensible to put that logic on the chain and there's even questions about putting consensus logic on the chain it could be that if consensus logic is on the chain then you have this kind of monoculture almost monocultural strategy for the consensus and that may lead to attack vectors by virtue of knowing that all of the nodes use the same strategy so if we're happy with not putting all of our logic onto the chain then the question is given that we need to have the same data structures ostensibly on the chain like in the runtime that's upgradeable and off the chain in the sort of general node itself how do we how do we manage the fact that sometimes those structures will be those data structures like transactions for example could be changed over the course of a chains life how do we how do we like manage the fact that these transactions have to then be sent they have to be stored in a transaction queue and they have to be sent over the network there have there has to be some way of handling these things right so we need some sort of object and that's where these opaque objects come in we need to a block needs to have some characteristics and there has to be some object that we can call a block but we don't need to go into the specific meaning of a block beyond basic the basic semantics of here's how to read a block number here's how to read the parent hash and these these very basic types or what we call the opaque types and they are the fundamental types of a block chain that don't change from Genesis onwards the in principle they're basically fixed now you say oh well hold on the extrinsic format is fixed and the block format is fixed and you know then surely you can't upgrade and it's like well actually it that's the reason that they are opaque is because most of the data that they contain is not stored in terms of specific fields like the the real meaning but rather it's just a blob a generic blob and it's only the bits of the data that we actually need to know for example we need to know the length of the transaction yep the extrinsic we you know because if we're going to send it around we need to how long it is and so what we do is we if we're going to concatenate it together into a block then we need to know how long each particular piece of the concatenation is so we we say write the one bit of a transaction of an extrinsic transactions format is going to be the length at the prefixed length but everything beyond that we're going to leave undefined as to its meaning we're just going to tell you how to decode and encode it you decode it by reading the length and then reading that many other bytes I'm not going to tell you what those bytes mean but that's how you decoded it and you encode it by seeing how long it is and then putting the length at the beginning and then following up with the other things by avoiding defining this stuff we can then define it in the runtime and then as runtimes upgrade we're not left with incompatible data structures that for handling these things in the client now it's important that so this isn't something that we do with every type it's just the fundamental cut types that clients do tend to have to be able to handle basically because we need to pass these types around the network or because we have to interpret them for the consensus algorithm so block headers one type extrinsic one of the type and I think hashes may be although hashes are paint data anyway I think it's basically just those two types yeah yeah although again signatures are opaque data anyway specific so you've got two types of signatures that float around in substrate you have to consent there are signatures on the consensus side and signatures on the signed on the transaction side so signatures on the transaction side they don't need to be the same and the runtime entirely interprets those I can well imagine extra substrate chains that don't have any signing any cryptographic signing on them at all that they're they're just you know the validators choose which things come along they you know from maybe some trusted corporate centralized database and they're just funneling this data in and it's going into the chain and just being recorded and maybe there's some state transitions that happen on the chain but basically it's that that's there's no need for signatures the consensus side yes there are signatures but I guess the consensus algorithm to define their own cryptography anyway I mentioned what sorry yeah so I I kind of spent a while describing that but I mean I can I guess I can probably if I can launch a node do I have one already oh yeah sure okay so yeah I have a node running okay so this is I think the demo node I'm gonna upgrade it okay so yeah okay so is that too small I guess that's way too small right how do i is that still too small it's too big okay so this is template node V - which I think means the demo is in but I can I can check this by so I mentioned there was the run time object fun time okay so the run time has a bunch of these are the various modules in the run time right so balances consensus core demo that's the one I just coded earlier today system timestamp upgrade key and version these as I mentioned come from the metadata so I can I can show you the code I mean it's it's I don't know how interesting is if we go into the double-oh-seven if we go into the double-oh-seven library and then the double-oh-seven substrate and then the bonds this is where they get created let me see if I can make this a bit bigger okay can you read that just about yeah I need a I need the drum player okay so these are these are the sort of easy ones that just they're just sort of hard-coded height header head fash name version and chain I mean you saw the RPC end of these we have this node service that just ensures there's a single WebSockets connection to the node so it's like a singleton and then we can I assure a request and these these are these are single shot requests some of these like head there subscriptions so there they use the pub sub functionality we have runtime version so I can eat I can I can give you a lighter quick and runtime I think it was in the core and then console log and that's what comes back very simple got the api's this this exactly represents this structure in rust that is in runtime template yeah so this this represents exactly this structure if I change this structure and upgrade the upgrade the chain then this will automatically update if I run this this thing again it will it will give me the new values yeah and it's the meta it's actually it's not the metadata that encodes that I think but that is that is fetched in this from the runtime in the same way that the metadata is fetched so the meta metadata is built automatically per module in the runtime amalgamated together by virtue of a couple of macros and then pass the line into the JavaScript and in the JavaScript we have a so we actually have a serialization library very very lightweight basically just memory representation serialization library and we have the opposite in JavaScript so we can serialize and deserialize in rest and we have the same thing in JavaScript and we can kind of a bit like a bit like JSON or whatever except binary and sort of designed to be very fast and very minimal lightweight yeah that's yeah the you mean these modules yeah so these are indeed there is a web pack running somewhere yeah yeah so got like MPM sitting around in the background updating are checking for changes and packing it all together ok so there's there's two things going on so the first is the these module these UI components those you have to code independently so they don't come from rust they're not automatically made you actually if you want to add a new a new module you have to sort of get get yeah typing fingers out and and and go into wherever it was that I went into now here we go yeah where is it now here so this is the yeah this is the UI and this isn't special at all this is just standard reacts semantic UI with web pack and NPM packing things in there looking out and watching it and packing it in the background so there's nothing I don't I don't so if I if I add any module then I have to press controller yeah but what happens I didn't press control I just now to get sorry if I do a blockchain upgrade I don't I don't have to press ctrl R now because the metadata automatically gets updated in the background so that doesn't come from the thing I was mentioning earlier with the hard-coded things so the bonds these bonds here the version bond and the the name chain the hi header hash these are all hard-coded they don't change their fundamental are PCs that substrate provides but the other things the things like if I go to run time and like I don't know balances if I want to get the balance of an account or accounts do I have let's decode an account let's decode this account so I want to get the balance of this guy then I can decode that into an account ID and give it to balance and then print the output and it's going to tell me that this guy doesn't have any money I think yeah balanced zero and then if I if I gave this guy some money so let's send some funds to him or her it's a hex address I'm not sure if they have gender do I have any Alice has got some I guess Alice is a girl and I'm going to send I don't know if I send a thousand units that's going through sent and then if I go back to balance is then we go now it's got a thousand yeah so this stuff when we go into specific run time modules they're not built they're not they don't come in by virtue of this code this code builds them programmatically from the metadata is has a pub/sub relationship with the with the node itself so as the nodes runtime gets upgraded this finds out about the upgrade grabs the metadata and rebuilds all of those objects and data structures and letters now interact with with the new runtime in a organic fashion but if we want to add UI components then we have to go in and do them ourselves and press controller the real a chain what what does it use so polka-dot uses power to codec polka-dot uses basically all of substrate like there's not much in substrate smart contracts is the only thing it doesn't use and yeah other than that it looks pretty similar to our basic substrate node so it's got all of the sort of functionality in apart from a smart contract but it does have an extra module that's specific to polka dot called para chains module so I haven't I'm not like it's been a little while since I looked at the para Chains module but that's something that will become pretty important over the next POC so PRC 3 was dedicated mainly to our new consensus algorithm that would be the final our algorithm for polka dot shaft or grandpa I don't know you know I mean I do know obviously shaft but some people don't not everyone agrees yeah sure so shaft is a actually is al here so al al invented shaft at the time it was called afge Al's finality gadget but we're kind of renaming it and basically it's a progressive adaptive progressive finality consensus algorithm designed specifically for polkadots use case and the idea is that it's a it adapts to network situations and validator pluralities if you have lots of validators sorry if you have few validators and a really good network then shaft will finalize as quickly as instant an instant finality algorithm like tender mint or rhododendron which is our sort of take on pbft for the blockchain but even if you have slower Network and lots of validators it will finalize as fast as it can behind the scenes and the way it does that is by having a transitive relationship over the blocks so the way that pbft derived algorithms work in general is you have a candidate block so every every block number that you want to finalize every block that you want to finalize there is a candidate right it's not yet finalized so it's just one of many and then you put it to a bunch of vault authorities or validators that the participants in this consensus game and they will each if it's a pbft based thing they'll do a a pre commit to basically say this is the one that we think should win and then if they see enough other pre-commit they'll they'll move on to a commit and there were rules about how you whether you can change from a pre given that you've pre committed on one thing whether you can change your you know what what you're allowed to commit to and if you've committed on one thing whether you're allowed to switch that commitment and these rules basically guarantee that assuming no more than two thirds plus one Byzantine nodes or Byzantine participants in the game that you will always come to an agreement on what it is that on a particular candidate now this is fine it's a perfectly reasonable way to go but the problem is that block it's not optimal because block chains have relationships blocks have relationships between each of them so blocks that are all of the same number so they're all at the same level they're just can different candidates for the same potential slot don't have much of a relationship beyond being mutually exclusive but blocks that appear before so parents or ancestor blocks have a very very strong relationship right cryptographic relationship we store their hash which means as an implication that if you voted for block I don't know that that 68 references by virtue of its parent hash you're you've also voted for that right you've also voted for 66 or Genesis block assuming that the network conditions are such that you are not going to be able to afford to finalize every block then a vote for 68 should definitely imply a vote for 64 67 and so forth but for that 67 yep so if there's two folks if there's a fork and what it's made its way to block deep okay maybe asn't made yeah actually you could have in principle have made it's way too much deep just at the production stage then it's important that any vote not allowed to do under this transitive model is both commit to 68 on one fork and to the 67 on the other fork and that that's one of the things that now becomes illegal but because that's illegal it what it means is that we can interpret a vote for 68 as a vote for all of the blocks that haven't yet been finalized on that on that fork and if suppose we suppose where that last the most recently finalized block is terrible network conditions the most recent recent finalized block is like say block 50 yeah so we're running 18 blocks in advance of the of the most recent sort of had agreed on head of the chain then if we've seen let's suppose we have 10 validators and they're basically just validate they're just voting for the blocks that they see we can only get out one vote per block and it's our vote so actually that's not I've got 20 validators and we can only get out one vote per block what would happen is that under Undershaft these votes we would always be running at the actually no because we only need \u2154 so it'd be the 13 th or 14 th most recent vote vote because we can accept all of the votes that are that are were on blocks after let's say where were 50 so suppose we're trying to finalize like I don't know 53 yeah all of the votes on that fork after 53 so every validator is like doing one vote per block so one of them is voted on 54 one of them is voted on 55 one voted on 56 all the way up to 67 or 68 where every were then it's likely that every new block \u2154 plus 1 will have voted on one more than the last block in total access account ensures every new block that's being produced that validator will be voting on that new block which will imply they voted on all of the blocks up until that new block which will imply you've got one more vote assuming a constant cycling of validators one more vote on that chain in general and so because that chains been brought forward by a block because everyone's voting on that chain then the the the the most recent block to be finalized will probably be a bit further along as a network conditions improve we can get invalidated can get more messages out then that will catch up naturally because the greater number of votes will be recent and and therefore again transitive relationships being what they are you'll be able to basically form a consensus that two thirds plus one validators agree that in fact 62 is the most recent shared block that they can all finalize it's a pain to spot when a validator has behaved badly basically because the rules are transitive sorry yeah rules are transitive and so you have to enter into this in the worst case enter into this game of querying well hold on you you as a validator voted for this block on this chain but yet you voted for that block on that chain why what were you seeing what what signatures did you see that made you switch chains and they can either equivocate and say move don't know because they actually they switch chains in invalidly or they can provide you with the signatures in which case you have to go to the next guy along and say well you signed for this chain but you you know and the game continues basically it's quite a an unwieldy game and it's a it's a bit of a pain it's a bit tedious to play but it's it's something that can happen on chain and it's not the end of the world beyond that it's it's got some very nice proofs about how live it stays in an asynchronous environment and its optimal over the it uses the notion of block transitivity optimally in determining under a pbft style mechanism which is the most recent lock that it can be considered final okay under optimal Network conditions assuming the validators are well connected with each other and that their plurality because I mean it's pbft so you can't get around this N squared message passing stuff requirements but assuming that they're well connected and and there aren't too many of them then you know I don't I mean you know this is where empirical measurements come in but certainly with our test net so far there's no reason to think that we can't handle final final is finalizing most blocks so not staying very far behind the block production head at all so the block production is handled by a separate consensus mechanism that doesn't provide finality at the moment we're moving towards or and which is a randomized shuffled version of hora which basically just sounds for Authority round and you just go around a bunch of round-robin style block production game but it's our intention eventually to move to probably something similar to a ruborous which is a it's basically like proof of authority mapped on a proof-of-work mapped onto a proof of authority schema so all thority get given lucky slots whereby they can mine a block and and it's a way of generating generating these lucky slots and and I'm ministering them in such a way that that you get given a bunch of guarantees about Byzantine tolerance so Network network topology or peer-to-peer networking in general we're using lib p2p which is pretty modular I would in principle there's nothing that would stop you from writing a new module that would provide the sort of networking that yeah I mean if you want something like Onion Routing on like mixed nuts yeah I don't see why that wouldn't be possible using the existing network module system worst case it's probably like implementing it as a as a new API but that's something we'd look into now I think I think it's what you can can build on top of it I mean we'd certainly be interested to sort of explore if the API is a sufficient in order to provide that but I suspect they might be okay more questions when how long it was at 8 p.m. do we want to maybe you think yeah yeah I it will be a little bit harsh but yeah I think ok let's let's erm maybe move the questions towards the end and do a I don't know some exciting stuff do you want to plug in the HDMI oh yeah I'm glad that you're doing this cuz I need to go to toilet yeah yeah sure thing use do we do we have working toilets yeah yeah outside so gay oh cool so let's get started this demo is like well it wasn't prepared at all because of his ins and I and I had to improvise so yeah um yeah let's get started so because I basically don't have any UI because of as I mentioned reasons I have to do like I have to craft in extrinsic by hand basically yeah but I have some little code snippets that actually can help me with that so it's not that problematic is it okay yeah okay so let's start this let's start with a fresh chain for that that make that maybe might take some time yep yep it's basically the branch a second I know I would say now because yeah for some reason I chose to use the soft shoe type oh yeah so let's clear the DB and then let's launch this new chain yeah so it seems to be working and yeah so so to make an extrinsic we need some to do some boilerplate code and for that we need a genetics hash so like it it is required to create extreme six that that can be executed on this particular change so we need to first fetch the block hash of the Ganesha's and for that I will I'm going to use the RPC cash so I will call block hash function this argument zero which which is for Genesis block and so oh yeah actually it's already there yeah and after that I will regenerate all extreme six so yeah so this extrinsic this big blob of up our data is contains instructions to deploy a certain contract and the the most of this data actually represents webassembly smart contract and yeah let's let's actually submit that extrinsic up have this one but it doesn't yeah oh yeah yep so to verify that it actually executed well let's see the substrate UI oh do you have an idea how to look up or a nonce of Ellis yeah yeah yeah as I said network I can connect to you ah yeah it's def okay yeah in JavaScript oh sorry sorry guys I can't stop I come on okay so the runtime and then balances is where the hold on it's not system by the index is stored and then I can't nonce and then which I can't ah Ellis Oh Alice and we should get Alice's so we need to introduce a the seed for Alice which is a pain to do if you don't do you have some key I yep and try to just execute it in here yeah it's okay yeah it just works oh but is it the latest version of something it's from air each hour but I'm not sure yes later yeah does work cool totally I expect okay oh how can I help you I want to get these Safari oh okay right so we put that scene in there you put it yeah so while this has this yeah now this is a short oh yeah this is something that should go over actually because this is kind of cool but I'll do it afterwards so we can try that everyone can see what's happened there right okay Oh doesn't suffice all that well I wouldn't be surprised actually okay [Music] maybe it's not about ten part I mean maybe yeah nons account okay maybe should open fire let's just check decode and then Alice's ID okay so that's done something that wasn't a type error but it's so that means that our transaction actually got in and we deployed the test contract so now I'm gonna show what kind of contract this is yeah so so this contract is basic counter which has actually two functions to action that we can actually execute on it let me do ya so the first one is in command that takes you 32 parameter which specifies by the value by which we should document this counter and get function which basically returns the value and when the contract is executed we just read input data it's basically the same as in Hulme and decode it into this action in a very enumeration and then depending on what actual variant of this you know we performing the action and this in case of increment we just query the contract storage by certain key which is the specified value and then save it back into the storage encoding it and before that and get is basically just we read the storage and return that value and that's it yeah so this contract is already on on the this chain and yeah so there is a extrinsic that which with which we can call this specific contract and it takes address of that contract and address is calculated by the constructor code of this contract and the original address which sent this which sent the create extrinsic and this so again yeah actually it's used and so it's specified right here so for the first transaction it was zero extrinsic and for the second one it's one yeah okay I see what you mean for determining contract address nonce is not used only code of constructor a region and just like input data and that's it yeah yeah basically yes but you can alleviate it with providing different data so we push this issue to user side yeah and yes so we doing call this to the contract at the specified address this we thinking some funds to it and also specifying how much gas we want to allocate to that and also we're providing the input data for the contract and this data is actually just encoding the index of the action so in in our case it's 0 so it corresponds to this variant and these four bytes encodes basically number by which we increment yeah and let's let's execute this yeah for now it's the only way but like we basically don't have either cell right now and it's the thing that is developing right now yeah so yes and so these extreme six extrinsic is for calling this contract yep so I think it is executed and to verify that it's actually performing the the task let's just check the substrate storage for for this corresponding storage key of that contract and I have because it's kind of hard to my to know which address is that I have a special function that actually calculates this for me and yeah and let's take it and [Music] it's really yeah so okay here's the result and it's corresponds to one in encoded in little endian format and this is a specific thing for encoding the length of this data so yeah it basically worked and then let's try to increment it once again by I don't know yeah wait a second I don't understand that so this extrinsic is in memory pool and let's wait until it actually yep it's mind and then let's query the storage and yeah it looks like it's eight yeah sure yeah that's a good question let me show you know so basically it's more more like a few Mike environment and so for now we basically have bare minimum for writing contracts and it's I get said storage and then call create which basically is very similar to thin ones return checking input size and also like this it also have has a scratch buffer and it's something that is not in Hulme so because of yeah I didn't mention that that storage in substrate contracts have like arbitrary size at values so you can put not only you query it you you can basically return it in this user specified area I mean contracts it's fight area of memory but then like it's like if the contract doesn't track track the size of the values that it actually puts in in this in storage then it could easily overwrite the like memory of the contract and this can be a bad thing so because of this we all arbitrary size that values are put into scratch buffer and then contract can actually query this buffer to actually load data from it yeah so it depends actually so you can't use I know anything that depends on files trading and things like that but like everything that doesn't require my saturating system things like files and things like that and can be compile it to the assembly and then probably fine yeah so basically this system is very similar to a theme and we basically have like a smattering very similar to a theme I mean like every year Vice Minister action is metrid and like I mean every instruction in the block just Metford as the price of the dairy prices are similar up and just deducted from some counter and if it goes to the zero then there's out of gas succession yeah so we are planning on bringing in chromatic gas yeah yeah and also they think I wanted to mention that we about the API that we are also thinking about giving the contractor on time chance to call different modules outside of I mean inside the run time so it can actually call do Kevin and well yeah so means governance modules even the power chain module that would forward any potentially could could have open an entry point a function call to forward messages into a para train so we can imagine is a smart contract sitting on one pair of chain sending out messages to a smart contract on another pair of chain or sending messages into a governance system so a smart contract chain like the edgeware chain that was mentioned today could have smart contracts that you know manage people's voting preferences yeah that's something I mean yeah for the gas it differs a little from aetherium one of the things that I wanted to bring into a theorem like when it was too late to bring it in was this notion of chromatic gas which is basically having three different kinds of gas one of them for processing one of them for memory usage and one for storage with the idea being that basically we can compute maximum gas per block in terms of resource usage for each of these three but doesn't make sense that if someone gives up some processing power that they can instead bloat the chain by some storage right then the two are not the two are not somehow mutually exclusive so what we do is we actually have the resource usage independently for each three and then every contract gets basically whenever you spend one gas on processing you sort of get one gas on the other two for free or vice versa the gas sort of comes in in in white light where you get all of the independent gases sort of tied together and then you can use them as you as you want and what you don't use either irem really decided but it either gets sort of ignored or goes back into the pot so that other things can in principle overspend but what this does it basically means you've got much better resource usage utilization and you don't have the issue whereby you can bloat the chain by 3x what you should be able to just by using all of your gas to enter into storage and none of your gas or memory or processing which is what the sort of scenario we're stuck with aetherium oh why not GPU as well well maybe version 2 yeah we'll go into the contracts right so yeah this so for like the gas system is only a concern of contract model and any other modules doesn't know about it at all yeah I think so then cool so I'll mention one other thing which is the account indexing which is what we saw earlier do you want to know I can do it on yours I think I mean yes but it's it's a nice little thing so it's worth it's worth knowing it well can you how do I get to Safari okay so if you noticed before while I was mucking around down here can I make this bigger somehow you can do this little trick oh just so there is a if you hold ctrl you can scroll it like that yeah so if you notice up up here Alice has a so I we've got two accounts here default and Alice default is this big long big long address analysis this lovely little address right so this is a legit these are both legit addresses and if you you know in principle if if a substrate chain gets listed on an exchange then in principle you can get one of these addresses this is just an address like in Bitcoin in etherium right but they both are so Alice this isn't some cunning name registry or something this is an address we understand yeah we're going with this [Music] in principle yeah it will mean different things on different chains because it will reference a different account just this just as the other one the long one would so the long one is a they're both based 58 representations they both got a checksum in them they both got a version byte in them the difference is that the first one is a 32 byte public key from that represents a point on the edy 255 1 nine public key and the other one is an index and that's why it can be so short so every account in in a if you use the SRM L in substrate every account has a an index associated with it I should say every nonzero balance account writes every account that's active has an index associated with it if an account doesn't have doesn't have any balance then it doesn't get one of these nice short IDs because there's no index I so it can't like then you marry every account then you may as well just use the 32 byte identifier but if it's got something in it then you can use this use this index instead to identify it and we've got a mechanism whereby if it's within the first 200 or so then you get to just use one byte and if it's in the next sixty or thousand then you get to use the next byte they're two bytes and I think there's only like tens of thousands of active accounts on of active accounts that have any real significant funds in on like aetherium so i don't i suspect on substrate chains we'll probably see most addresses to be fewer basically be like four six five or six characters and it basically can look that up in its enumeration of all addresses and and as these things become free so if an account goes to zero substrates SRM our balances module will automatically claim reclaim that that address right so it basically deletes everything to do with it and this including this enumeration and so if someone like has one of the earlier Guinea I can't imagine that there's gonna be something like clamor to get the first to enjoy the accounts that have you know these four four letter addresses cause like there's only so many of them and before long they'll go but if someone like reduces their balance disease or to the minimum below the minimum allowed balance there's this notion of an existential deposit which is basically the minimum amount of balance you must have for your account not just to be deleted dying like that if they're iam Bitcoin don't really have this which leads to an awful lot of dust accounts that have like a none spend ibly small amount of of ether in it so small that you know you can't actually send the transaction to but yet they're still recorded by the state so they're still taking up a lot of space on disk exchanges are particularly bad for these things but you know they they leave a bit of gas on the spent and that just that's just a tiny little bit of ether just clogging up the train chain to the like 10,000 accounts a day sort of job so this is why in principle yes so if this account becomes a discount like reduces below the existential deposit and then someone else claims it then that address won't last forever so there's couple of ways of dealing with that the first is that that address has in it a checksum and that checksum refers to not that address itself but to the account that that address points to so if they were to if they were to do it maliciously it wouldn't happen accidentally the checksum would look after that they were to do it maliciously they'd have to mine an address that whose checksum was the same and these accounts these small ones you can choose which address you want to use yes sorry you can choose which address format you want to use and some of the address formats have like eight byte checksums so they'd have to mine an address that had like eight whole byte that shared an eight byte start of a hash with with the address that sort with the address that's IO that's that so I mean I can see this not being so so much of an issue and to be honest if you want if you want an address that's like you know permanent then sure just use the big big long one yeah but if if you want something that's like a payment address or if you absolutely sure that you're never going to go below the minimum amount then as these small addresses should be fine and they're a lot easier to remember and the other notable other point is that if we delete accounts and this came up in aetherium so parity we apparently made a proposal on the IPS to sort of say look we should have disk election that was actually implemented on covin right we rolled it out to covin and the issue one of the issues is that it means that nan basically transactions can be replayed if you're not careful because when you delete an address you don't just delete the balance and reduce that zero but you also delete the nonce which is counting how many transactions it's sent which means the first transactions can now be replayed or the very first transaction in particular can be replayed and then the second third and fourth can if that goes through successfully and that's problematic or it could be problematic because if those transactions do something other than spending the balance then you can actually put balance into the now zero account so it's now got cash to spend and then replay those transactions to do this to replay the side effects this is why we brought in the transaction errors so the idea is that when you construct a transaction it's only valid for a particular period for the future so you can make a trend you can construct a transaction that's valid indefinitely we allow for that but if you do that you've got to accept the fact that if someone else if your account gets deleted then the first transactions can be replayed primarily because there may be well firstly cause we you know we're generalists and we like to you know allow for as much as possible and it's up to our users who we we believe our our esteemed you know we esteem them in terms of their intelligence and we believe that they know what they're doing I mean you know everything goes wrong at some point I I don't believe in making tools you know I don't believe in making kind of safety scissors for you know for people I think that you know the level at least that were at you know we should we should be working with sharp knives for sure official and but I would put this on the user level so I think this is for you know if you read some of the other chains they issue kind of not warnings but directives to their middleware and use a user level like UI engineers say look this you can cut yourself the chain doesn't protect users from doing the stupid thing so it's up to you to protect them by putting in these warnings and we will do the same so for example if you're if you've issued if your wallet knows you've issued transaction resolve doesn't know that you haven't issued IRRI limited transactions and sees that a transaction you're about to issue would remove your account with the would delete it would take you below the minimum amount then it will would basically bring up this big what it would either not let you do it or bring up a big warning saying are you sure you know what you're doing yeah yeah so if you know we don't want to like hamstring people at developing on the platform we want to inform them and we want to inform them when they should hamstring the people who were using their what they're developing or at least give them information to make sure that they don't shoot themselves in the foot yeah it's true I mean there's maybe a trade-off to be made here checksum seemed a perfectly reasonable thing I mean most address formats have checked sums in the original aetherium didn't and that was a really big pain so that was that was just less and learnt in this case I don't think there has been a lesson yet to be learnt and I think it's such a really easy thing to protect against like either wallets shouldn't let you construct transactions without errors that should be a niche thing that you have to build your own applications to do I mean the cambia that I can imagine applications where errors don't fit for example suppose you've got something like a plasma plasma kind of chain and or a state a state channel and you need this transaction to potentially last indefinitely because that's the only guarantee that the other side has that you won't just pull out after the era is ended yeah it's like there's no other way of doing it and there you just have to ensure that for your specific niche use case there is no way of reducing that balance below the existential deposit but in most use cases user level tools can make sure that you don't shoot yourself in the foot say again oh when you see well it's a transaction hold on so when you serialize a transaction I see what you mean yes can we carry yes the answer is yes we can carry our concise address format into transactions as well so normally we would have to put a 32 by identifier for each address for the sender and the receiver irritatingly so one of the things that if you read about Edie two four five one nine they'll be like oh yeah it's really good it's got like compact signatures its signatures are smaller there are only 64 bytes instead of 65 what they don't tell you is that unlike unlike ECDSA you do need to put the sender address in there so yes you might you might shave a bite off in terms of the signature but you have to add an extra 32 bytes on because you have to tell it who the sender is I mean Bitcoin doesn't kind of Bitcoin provides both but you know whatever that was just a questionable decision if there him doesn't we go we don't bother encoding the sender in the transaction because we derive it directly from the signature you can't do that with EDD si sorry with Edie 2 5 1 9 so actually signatures are 96 bytes we have a binary format so we don't have padding we have a binary format that basically uses 33 bytes to encode one other 32 byte addresses and uses one byte to encode the small ones and and so forth and you can determine what it is from the first few bits yeah so it did if you use these small addresses you shave off like 60 bytes potentially a couple more from the transactions and that's that's a pretty decent saving it basically cuts transactions by \u2156 as the relay train yeah I mean so the substrate comes from the relay chain so when we started coding polka dot well when we started coding substrate what has become substrate that was just called polka dot and although even before we started I had in my mind it was going to turn into substrate I didn't really mention that to the other devs so they were a little surprised when I started renaming stuff but yeah it's the biggest the biggest challenge is kind of thing that I mentioned it's getting that level of generalism while still making things be easy too while still making it easy to write the things that you want to be able to write so that that's what you know any design of language or API comes down to this getting this trade-off right and it ultimately comes down to expressivity so expressivity of a of a language in a domain is really just how well you can make it easy to do the things that you want to do and make it possible to do everything yeah and bringing those two closer together is is what we call expressivity or what we call a good language or a good a good domain language and you know substrate has a similar challenge getting it getting it general is not so easy it's something I've you know kind of wanted to do even since CPP aetherium but not having had all of the experience it wasn't so easy to do it the early days but it gets it gets a bit easier with having coded a couple more Sega is data deleted when it's deleted okay so what was the question again okay so specifically with smart contracts or with runtime modules and and the the substrate in general not really but smart contracts kind of have to do their own thing to some degree but okay I'll talk about substrate in general because that's what I can answer yes I see I know what you mean now I know what you mean yes no contracts work differently okay so we have we have archive mode that keeps everything around forever it doesn't run an archive mode by by you by by default it runs in a standard pruning mode by default which basically Clips any state from blocks that are old enough after a 100 or 200 or so if what you're talking about is like in a theory and when a contract delete something if that contract if that call into that contract turns out to be exceptional and everything gets rolled back then that delete doesn't happen in substrate in the basic runtime module in the basic sort of core we don't do roll backs right so as soon as something gets written into storage or deleted from storage it's actually deleted and unless the entire block gets rolled back because it panics then it's done that thing's deleted and there's no way you can you don't have checkpointing in there if you want checkpointing which you may well want it goes into the it goes into the as a runtime module library and the contract runtime module library that the smart contract actually implements checkpointing so it's it implements something that is basically a minimal form of aetherium but has most of the stuff of the etherium environment and the only difference is that it doesn't run in a VM it runs in webassembly of course web assemblies kind of cool and sexy unfashionable and hipster yeah I mean you know to some degree runtime upgrades and these sort of out-of-band state changes are are specifically what we do how we manage what happens when things go south in other ways so ultimately there's the same safeguard if you want to call it that that any other chain would have that doesn't have a governance system which is it can always be hard forked even if the governess system of the polka dot substrate whatever goes Ori I I sort of take a two-prong approach and say well on the one hand we want to be reasonably conservative and try to get solid reviews of our proposed governance mechanism and/or use governance mechanisms that already exist in real life and that we have some idea will probably work okay with the other prong being try it out as much as possible on test nets that actually have value before we put it on to a network that has lots of value potentially and this is you know where the edgeware project could be very helpful and potentially others like it to really provide a network where you know no one's losing anything if it's if it there's no cost to it going down or being problematic or having to suffer a reversion but there is real value at stake because it's got tokens that are worth something and that's that I think is a really nice middle ground to sort of go and try a bunch of stuff that we think probably works okay but we can't be sure to really try you know empirical testing try it in real life in much the same way that when the psychologists want to run a new experiment you know they they get a bit of money and they sort of say look if you if you do this right you get fifty quid and you know this is the instructions offer you go kind of the same thing and we did something similar with the Olympic test net back in PRC nine PRC ten days for the theorem to try and get people to kick the tires of what would become the the main net before we released I actually I think Olympic was a not a failure but I don't think it was a great success not that many people took part in it and it didn't really it didn't discover it didn't uncover one or two of the books that came up which you know we would have otherwise hoped and I think a test net that has real value maybe less value than it would otherwise have but still real value is probably a much more market-oriented and therefore probably more successful way of of trying to incentivize people to to break it or otherwise test it yeah so I mean you know etherium had the consensus tests it had a decent first testing although I will note that when we implemented parity we found two points where the consensus test didn't cover and we had to we had to add new consensus test it's a hard thing to do with with substrate we kind of work around it a little bit by saying there's a single was a reference on chain so it's basically like a machine executable reference spec I think it's it's questionable whether that's such a great thing I mean the Bitcoin guys love that idea because it's like they've got their reference implementation Bitcoin core I kind of like the yellow paper for not being machine executable but yeah I mean in polka dot and substrates case it was largely forced upon us anyway in principle there could be multiple implementations at the same runtime I could you know that's something that I explicitly provide for in the versioning I'm not sure if it will happen the foundation the web sorry foundation is looking to fine teams that yeah cool okay yeah so I mean I'd like to see it happen but as for whether as for whether we could really come out come up with better consensus tests than what we have for theorem I'm not sure it's a really tough thing to do without literally paying someone to painstakingly go through the specification every single conditional write a test for and I mean this gets potential exponentially complex as the different modules I mean you're looking at kind of two to the number of conditions potential number of tests that would have to cover everything it's it's crazy so I would probably just go for taking out a month's rental of a supercomputer and running a huge amount of first test I think with a with a well-designed for sir that that should probably provide as much protection as as you would otherwise get in polkadot so there's there is a mechanism sperm free transactions basically for transactions under the substrate model which polkadot adheres to transactions must sorry under the substrate the SR ml model which polka dot adheres to I should say transactions must pay for their space on the chain so there's a fixed fee for a transaction and there's always I mean can set it to zero if you want but you know in principle there's a fixed fee that a chain can leverage and this is a something that can be changed and upgraded and all the rest of its if it's the parameter and there's also a per byte fee that's charged per byte of the transaction and as it's encoded on the chain so that's non negligible that's sorry that's non-negotiable they have to be paid beyond that there is an if you want to charge additional fees for what the transaction is doing then that's up to the chain and the runtime modules and the sort of the the code that you're writing yourself you can charge for what you want polka dot will probably have some yeah fees associated with the creation of balances with the occasion of accounts so the balances module has a fee schedule that you can again customize if you've depending on you know how much you want to charge for the sorts of things of creating new accounts reaping all the counts transferring balances as a bunch of things that you can customize what else other modules I think most modules actually don't specify much of a much of a fee schedule because most of the modules are yeah there are the governance modules do have a fairly complex system of deposits that's mainly to address sort of a game theoretic concern of a potential quadratic quadratic attacks where quadratic cost attacks where certain algorithms are order N squared to rent or order MN to run and you have to make sure that you know m and n can't both get too big it's ok if one of them gets kind of big but you need to make sure that they can't both get too big otherwise you end up sort of going off off into the distance in terms of the cost and that's managed through as I say a set of deposits and basically incrementally increasing the cost of one or the other depending on how big the other one is I think that's probably about it I'm not so worried about literally charging every single clock of processing like gas would do partly because a lot of a lot of operations are order one and/or they have like a reasonable maximum that is not that you know they don't really go proportional the user can't force or the trans actor can't force a anything over a particular maximum that maximum is relatively and significant and I would look upon it more or less as the Bitcoin chain does where it's fine basically to just charge for space on the chain for the size of the transaction and not think too much about the processing costs because they will be dwarfed by the storage costs obviously in smart contract land it's much more important to charge for the for everything because you know users can potentially write infinite loops and all the rest of it so their contracts module does indeed make sure that there's a proper costing mechanism for them it's not a final design decision to be honest but part of the reason is that it makes a lot of sense when block production is on a individual basis like so - are competing with each other to produce these blocks it's not really the case in the consensus are mechanisms or block production mechanisms that I see substrate working under you in in substrates case that's really more of a sort of collective thing and it doesn't really make sense to reward one over another and partly it's I guess remember the other reason I think there was so in some sense when you burn fees it's a little like paying all of the other participants I guess yeah okay so the reason that that miners collected fees in etherium was because that's what they did in Bitcoin and the reason that - collected fees in Bitcoin was because eventually the block reward was going to go down to zero and that would be the only thing that incentivized - to do anything that's not the case in in polka-dot in poker ah the the validators are are incentivized like permanently through the reward system it basically means though dilution will happen there they're sort of percent or their ratio of their state compared to everyone else will remain the same they're sort of dilution protected and everyone else gets everyone who's not part of the validation nomination sort of system will get diluted and because that's in place it doesn't make so much sense to then reward them extra for for the transaction fees that said it's not a final decision as I said and I'm like you know something to talk about over the next few months and see if there's a compelling reason yeah I mean potentially I'm not sure we really see that in in real life there's plenty of instances where you know aetherium transactions go through four zero gas price censorship you know as always can always happen you know it's just if you're going out of your way to censor some transactions there's a cost associated that selection mechanism and that cost may be insignificant but that cost may be the price you're willing to pay maybe and it may be substantially greater than the cost of you know not collecting a couple of micro sense of fees so for sure but if they do then adding a small transaction fee isn't really going to make much difference unless unless you know the transactions that they're dealing with our micro transactions in which case yeah yeah I mean that's it so staking is more of a sort of collective pursuit rather than something cutthroat yeah I got a feeling there was another reason but I can't remember what it was now but as I say it's not something that I'm happy for this to be a continuing conversation and you know if it turns out that it does make sense for the block producer to to take these fees then this point is just the simplest code like I don't it's one line of code for you basically suppose you have 20% of the chain that is 20% of the total capital contained on the chain total tokens that is part of the staking system and market the market effects are such that 5% of that 20% so the total are being replicated to root for their rewards so I mean this is a half the reward right 25 percent but whatever then in order to prevent the rich get richer situation of the chain where validators just everyone gets diluted and all of that dilution is favoring the validators their percentage of the total state just keeps going up and up and up and up until eventually their total of the amount of the chain approach is like 100 percent to avoid that situation we place a well if we save 20 to 80 then we place an according amount so for X in our 20 to 80 ratio of the amount of that reward goes into a pot right so so we've got 20% a quarter of that gets paid to the to the validators so we're going to mint 25% of of the chains tokens again yep so we're going to dilute by 25% we take a fifth of that so validators whatever so that's that and with the other 20% which which basically is \u2155 of 80 sorry \u00bc of 84 fits over 25 that gets placed into a sort of community Dow for the chain not too dissimilar from you know the thing on - or or even like the Dow although let's boogie hopefully and that will be used as like there's already a treasury module in here it's very simple but there's the treasury module actually sort of put forward ways of spending and and they can be voted on and then the idea is to basically allow additional modules to spend money from this pot and they can be sort of integrated through chain upgrades it could also be a lottery it can also be a reward for people that like accounts that are willing to bet on the price going up if you got an oracle feed of the price so if you're willing to bet that the price goes up and the price does indeed go up after a period of time then then you can get paid from this pot and if it goes down then you can your money gets put into the pot so there's all sorts of interesting don't think about that too hard there's all sorts of interesting oh yeah you can like what I showed you like the thing is what I was trying to think of a toy runtime module that would extol like that I could code live you know that wasn't so big that I couldn't code live but also that sort of got across a degree of sort of generality that this provides and unfortunately everything that you can code live pretty much will look like a smart contract because smart contracts are just tiny little bits of code that you add to block chains but what I did with with the extra module although it looked a bit like a smart contract it worked very differently right this this was a deployment of code that would be run natively and that would sit in principle in the same place as the smart contract as the smart contract bit of the etherium state transition function or the EVM or whatever else you want to think about code I won't even consider coding an EVM interpreter as a smart contract that would just be zany right I'll just be Cray would run so slow and it'd be really horrible but you could do that in one of these modules because it operates at like a 10 X low lower level so you get that 10 X in in performance and in well it uses that it uses some substrate runtime module for its pyro change management yeah I don't call it delegation because that's kind of got a loaded meaning now that EOS uses it in particular when you delegate a stake you don't get punished if the if the party that you delegate to misbehaves and that's usually problematic in terms of getting incentive correctness so we call it nominating and they're critical as I say the critical difference is that when you nominate a validator with your stake they you lose your stake if they misbehave I mean they lose those first but if they don't have enough to pay for the misbehavior then you lose yours yeah yeah so you this is to get around the nothing at stake issue long term long range attack yeah so yeah there's it it's bonded the moment the assumption is it'll be about three months bonding period but it will be at least as big as the expected period between releases of the of the binary of any software that sort of interprets this chain so no the assumption is that the most recent checkpoint will go into the software itself and the bonding period is sufficiently large that and the software will be released sufficiently frequently that the most recent bond most recent software release will be holding current validators currently bonded validators to account okay Sagan you can if you put it in yourself I use fixed point for anything that needs point one more if you're a move floating point then it's deterministic cool okay I call an end to this are you do you want to do it you wanna do the end","title":"for - - chain equals dev - - validator"},{"location":"insiders/","text":"Insiders \u00b6 Material for MkDocs follows the sponsorware release strategy, which means that new features are first exclusively released to sponsors as part of Insiders . Read on to learn what sponsorships achieve , how to become a sponsor to get access to Insiders, and what's in it for you ! What is Insiders? \u00b6 Material for MkDocs Insiders is a private fork of Material for MkDocs, hosted as a private GitHub repository. Almost 1 all new features are developed as part of this fork, which means that they are immediately available to all eligible sponsors, as they are made collaborators of this repository. Every feature is tied to a funding goal in monthly subscriptions. When a funding goal is hit, the features that are tied to it are merged back into Material for MkDocs and released for general availability, making them available to all users. Bugfixes are always released in tandem. Sponsorships start as low as $15 a month . 2 What sponsorships achieve \u00b6 Sponsorships make this project sustainable, as they buy the maintainers of this project time \u2013 a very scarce resource \u2013 which is spent on the development of new features, bug fixing, stability improvement, issue triage and general support. The biggest bottleneck in Open Source is time. 3 If you're unsure if you should sponsor this project, check out the list of completed funding goals to learn whether you're already using features that were developed with the help of sponsorships. You're most likely using at least a handful of them, thanks to our awesome sponsors ! What's in it for me? \u00b6 The moment you become a sponsor , you'll get immediate access to 19 additional features that you can start using right away, and which are currently exclusively available to sponsors: Privacy plugin: external links Navigation subtitles Tags plugin: allow list + custom sorting Blog plugin: custom index pages Blog plugin: related links Blog plugin Navigation status Meta plugin Tags plugin: additional indexes Document contributors Automatic light / dark mode Content tabs: anchor links Navigation pruning Tooltips Chinese search support Card grids Privacy plugin Annotations Navigation icons New features are added every other week. Be sure to come back. How to become a sponsor \u00b6 Thanks for your interest in sponsoring! In order to become an eligible sponsor with your GitHub account, visit squidfunk's sponsor profile , and complete a sponsorship of $15 a month or more . You can use your individual or organization GitHub account for sponsoring. Important : If you're sponsoring @squidfunk through a GitHub organization, please send a short email to sponsors@squidfunk.com with the name of your organization and the GitHub account of the individual that should be added as a collaborator. 4 You can cancel your sponsorship anytime. 5 Join our awesome sponsors Special thanks to our premium sponsors : If you sponsor publicly, you're automatically added here with a link to your profile and avatar to show your support for Material for MkDocs. Alternatively, if you wish to keep your sponsorship private, you'll be a silent +1. You can select visibility during checkout and change it afterwards. Funding \u00b6 Goals \u00b6 The following section lists all funding goals. Each goal contains a list of features prefixed with a checkmark symbol, denoting whether a feature is already available or planned, but not yet implemented. When the funding goal is hit, the features are released for general availability. $ 12,000 \u2013 Piri Piri \u00b6 Blog plugin Chinese search support Annotations Navigation icons Navigation pruning Navigation status $ 14,000 \u2013 Goat's Horn \u00b6 Privacy plugin Card grids Tooltips Content tabs: anchor links Automatic light / dark mode Document contributors $ 16,000 \u2013 Chipotle \u00b6 Meta plugin Blog plugin: related links Blog plugin: custom index pages Tags plugin: additional indexes Tags plugin: allow list and custom sorting Navigation subtitles $ 20,000 \u2013 Jalape\u00f1o \u00b6 Privacy plugin: external links Instant previews ... more to be announced Goals completed \u00b6 This section lists all funding goals that were previously completed, which means that those features were part of Insiders, but are now generally available and can be used by all users. $ 10,000 \u2013 Carolina Reaper \u00b6 Brand new search plugin Rich search previews Tokenizer with lookahead Advanced search highlighting Excluding content from search Offline plugin $ 8,000 \u2013 Scotch Bonnet \u00b6 Social cards Code annotations: anchor links Code annotations: strip comments Tag icons Table of contents anchor following Sidebars automatically scroll to active item $ 7,000 \u2013 Royal Gold \u00b6 Cookie consent Was this page helpful? Dismissable announcement bar $ 6,000 \u2013 Trinidad Scorpion \u00b6 Boosting pages in search Custom admonition icons Linking content tabs $ 5,000 \u2013 Aji Panca \u00b6 Mermaid.js integration Stay on page when switching versions Tags with search integration $ 4,000 \u2013 Ghost Pepper \u00b6 Anchor tracking Code annotations Version warning $ 3,000 \u2013 Caribbean Red \u00b6 Sticky navigation tabs Section index pages Remove generator notice $ 2,500 \u2013 Biquinho Vermelho \u00b6 Search suggestions Search highlighting Search sharing $ 2,000 \u2013 Black Pearl \u00b6 Latest release tag Color palette toggle Back-to-top button $ 1,500 \u2013 Bhut Jolokia \u00b6 Admonition inline blocks Site language selection Versioning $ 1,000 \u2013 Prairie Fire \u00b6 Navigation sections Navigation expansion Hiding the sidebars Table of contents in navigation Header hides on scroll $ 500 \u2013 Madame Jeanette \u00b6 Improved search result grouping Improved search result relevance and scoring Missing query terms in search results Frequently asked questions \u00b6 Compatibility \u00b6 We're building an open source project and want to allow outside collaborators to run and build our documentation locally without having access to Insiders. Is this still possible? Yes. Insiders is compatible with Material for MkDocs. Almost all new features and configuration options are either backward-compatible or implemented behind feature flags. When working with outside collaborators, it should be rarely necessary to change the general appearance of your site. Most Insiders features enhance the overall experience, e.g. by adding icons to pages or providing a feedback widget. While this features add value for the user of your site, they shouldn't be necessary for previewing when making changes to content. Currently, the only content-related features in Insiders that can't be properly previewed by non-Insiders users are: Annotations Card grids This means that outside collaborators are able to build the documentation locally with Material for MkDocs and when they push their changes, your CI pipeline will build it with Insiders. When using built-in plugins that are exclusive to Insiders, it's recommended to split configuration into a base mkdocs.yml and one with plugin overrides via configuration inheritance . See the getting started guide for more information. Payment \u00b6 We don't want to pay for sponsorship every month. Are there any other options? Yes. You can sponsor on a yearly basis by switching your GitHub account to a yearly billing cycle . If for some reason you cannot do that, you could also create a dedicated GitHub account with a yearly billing cycle, which you only use for sponsoring (some sponsors already do that). If you have any problems or further questions, please reach out to sponsors@squidfunk.com . Terms \u00b6 Are we allowed to use Insiders under the same terms and conditions as Material for MkDocs? Yes. Whether you're an individual or a company, you may use Material for MkDocs Insiders precisely under the same terms as Material for MkDocs, which are given by the MIT license . However, we kindly ask you to respect our fair use policy : Please don't distribute the source code of Insiders. You may freely use it for public, private or commercial projects, privately fork or mirror it, but please don't make the source code public, as it would counteract the sponsorware strategy. If you cancel your subscription, you're automatically removed as a collaborator and will miss out on all future updates of Insiders. However, you may use the latest version that's available to you as long as you like . Just remember that GitHub deletes private forks . In general, every new feature is first exclusively released to sponsors, but sometimes upstream dependencies like Python Markdown Extensions enhance existing features that must be supported by Material for MkDocs. \u21a9 Note that $15 a month is the minimum amount to become eligible for Insiders. While GitHub Sponsors also allows to sponsor lower amounts or one-time amounts, those can't be granted access to Insiders due to technical reasons. \u21a9 Making an Open Source project sustainable is exceptionally hard: maintainers burn out, projects are abandoned. That's not great and very unpredictable. The sponsorware model ensures that if you decide to use Material for MkDocs, you can be sure that bugs are fixed quickly and new features are added regularly. \u21a9 It's currently not possible to grant access to each member of an organization, as GitHub only allows for adding users. Thus, after sponsoring, please send an email to sponsors@squidfunk.com , stating which account should become a collaborator of the Insiders repository. We're working on a solution which will make access to organizations much simpler. To ensure that access is not tied to a particular individual GitHub account, create a bot account (i.e. a GitHub account that is not tied to a specific individual), and use this account for the sponsoring. After being added to the list of collaborators, the bot account can create a private fork of the private Insiders GitHub repository, and grant access to all members of the organizations. \u21a9 If you cancel your sponsorship, GitHub schedules a cancellation request which will become effective at the end of the billing cycle. This means that even though you cancel your sponsorship, you will keep your access to Insiders as long as your cancellation isn't effective. All charges are processed by GitHub through Stripe. As we don't receive any information regarding your payment, and GitHub doesn't offer refunds, sponsorships are non-refundable. \u21a9","title":"Insiders"},{"location":"insiders/#insiders","text":"Material for MkDocs follows the sponsorware release strategy, which means that new features are first exclusively released to sponsors as part of Insiders . Read on to learn what sponsorships achieve , how to become a sponsor to get access to Insiders, and what's in it for you !","title":"Insiders"},{"location":"insiders/#what-is-insiders","text":"Material for MkDocs Insiders is a private fork of Material for MkDocs, hosted as a private GitHub repository. Almost 1 all new features are developed as part of this fork, which means that they are immediately available to all eligible sponsors, as they are made collaborators of this repository. Every feature is tied to a funding goal in monthly subscriptions. When a funding goal is hit, the features that are tied to it are merged back into Material for MkDocs and released for general availability, making them available to all users. Bugfixes are always released in tandem. Sponsorships start as low as $15 a month . 2","title":"What is Insiders?"},{"location":"insiders/#what-sponsorships-achieve","text":"Sponsorships make this project sustainable, as they buy the maintainers of this project time \u2013 a very scarce resource \u2013 which is spent on the development of new features, bug fixing, stability improvement, issue triage and general support. The biggest bottleneck in Open Source is time. 3 If you're unsure if you should sponsor this project, check out the list of completed funding goals to learn whether you're already using features that were developed with the help of sponsorships. You're most likely using at least a handful of them, thanks to our awesome sponsors !","title":"What sponsorships achieve"},{"location":"insiders/#whats-in-it-for-me","text":"The moment you become a sponsor , you'll get immediate access to 19 additional features that you can start using right away, and which are currently exclusively available to sponsors: Privacy plugin: external links Navigation subtitles Tags plugin: allow list + custom sorting Blog plugin: custom index pages Blog plugin: related links Blog plugin Navigation status Meta plugin Tags plugin: additional indexes Document contributors Automatic light / dark mode Content tabs: anchor links Navigation pruning Tooltips Chinese search support Card grids Privacy plugin Annotations Navigation icons New features are added every other week. Be sure to come back.","title":"What's in it for me?"},{"location":"insiders/#how-to-become-a-sponsor","text":"Thanks for your interest in sponsoring! In order to become an eligible sponsor with your GitHub account, visit squidfunk's sponsor profile , and complete a sponsorship of $15 a month or more . You can use your individual or organization GitHub account for sponsoring. Important : If you're sponsoring @squidfunk through a GitHub organization, please send a short email to sponsors@squidfunk.com with the name of your organization and the GitHub account of the individual that should be added as a collaborator. 4 You can cancel your sponsorship anytime. 5 Join our awesome sponsors Special thanks to our premium sponsors : If you sponsor publicly, you're automatically added here with a link to your profile and avatar to show your support for Material for MkDocs. Alternatively, if you wish to keep your sponsorship private, you'll be a silent +1. You can select visibility during checkout and change it afterwards.","title":"How to become a sponsor"},{"location":"insiders/#funding","text":"","title":"Funding "},{"location":"insiders/#goals","text":"The following section lists all funding goals. Each goal contains a list of features prefixed with a checkmark symbol, denoting whether a feature is already available or planned, but not yet implemented. When the funding goal is hit, the features are released for general availability.","title":"Goals"},{"location":"insiders/#12000-piri-piri","text":"Blog plugin Chinese search support Annotations Navigation icons Navigation pruning Navigation status","title":"$ 12,000 \u2013 Piri Piri"},{"location":"insiders/#14000-goats-horn","text":"Privacy plugin Card grids Tooltips Content tabs: anchor links Automatic light / dark mode Document contributors","title":"$ 14,000 \u2013 Goat's Horn"},{"location":"insiders/#16000-chipotle","text":"Meta plugin Blog plugin: related links Blog plugin: custom index pages Tags plugin: additional indexes Tags plugin: allow list and custom sorting Navigation subtitles","title":"$ 16,000 \u2013 Chipotle"},{"location":"insiders/#20000-jalapeno","text":"Privacy plugin: external links Instant previews ... more to be announced","title":"$ 20,000 \u2013 Jalape\u00f1o"},{"location":"insiders/#goals-completed","text":"This section lists all funding goals that were previously completed, which means that those features were part of Insiders, but are now generally available and can be used by all users.","title":"Goals completed"},{"location":"insiders/#10000-carolina-reaper","text":"Brand new search plugin Rich search previews Tokenizer with lookahead Advanced search highlighting Excluding content from search Offline plugin","title":"$ 10,000 \u2013 Carolina Reaper"},{"location":"insiders/#8000-scotch-bonnet","text":"Social cards Code annotations: anchor links Code annotations: strip comments Tag icons Table of contents anchor following Sidebars automatically scroll to active item","title":"$ 8,000 \u2013 Scotch Bonnet"},{"location":"insiders/#7000-royal-gold","text":"Cookie consent Was this page helpful? Dismissable announcement bar","title":"$ 7,000 \u2013 Royal Gold"},{"location":"insiders/#6000-trinidad-scorpion","text":"Boosting pages in search Custom admonition icons Linking content tabs","title":"$ 6,000 \u2013 Trinidad Scorpion"},{"location":"insiders/#5000-aji-panca","text":"Mermaid.js integration Stay on page when switching versions Tags with search integration","title":"$ 5,000 \u2013 Aji Panca"},{"location":"insiders/#4000-ghost-pepper","text":"Anchor tracking Code annotations Version warning","title":"$ 4,000 \u2013 Ghost Pepper"},{"location":"insiders/#3000-caribbean-red","text":"Sticky navigation tabs Section index pages Remove generator notice","title":"$ 3,000 \u2013 Caribbean Red"},{"location":"insiders/#2500-biquinho-vermelho","text":"Search suggestions Search highlighting Search sharing","title":"$ 2,500 \u2013 Biquinho Vermelho"},{"location":"insiders/#2000-black-pearl","text":"Latest release tag Color palette toggle Back-to-top button","title":"$ 2,000 \u2013 Black Pearl"},{"location":"insiders/#1500-bhut-jolokia","text":"Admonition inline blocks Site language selection Versioning","title":"$ 1,500 \u2013 Bhut Jolokia"},{"location":"insiders/#1000-prairie-fire","text":"Navigation sections Navigation expansion Hiding the sidebars Table of contents in navigation Header hides on scroll","title":"$ 1,000 \u2013 Prairie Fire"},{"location":"insiders/#500-madame-jeanette","text":"Improved search result grouping Improved search result relevance and scoring Missing query terms in search results","title":"$ 500 \u2013 Madame Jeanette"},{"location":"insiders/#frequently-asked-questions","text":"","title":"Frequently asked questions"},{"location":"insiders/#compatibility","text":"We're building an open source project and want to allow outside collaborators to run and build our documentation locally without having access to Insiders. Is this still possible? Yes. Insiders is compatible with Material for MkDocs. Almost all new features and configuration options are either backward-compatible or implemented behind feature flags. When working with outside collaborators, it should be rarely necessary to change the general appearance of your site. Most Insiders features enhance the overall experience, e.g. by adding icons to pages or providing a feedback widget. While this features add value for the user of your site, they shouldn't be necessary for previewing when making changes to content. Currently, the only content-related features in Insiders that can't be properly previewed by non-Insiders users are: Annotations Card grids This means that outside collaborators are able to build the documentation locally with Material for MkDocs and when they push their changes, your CI pipeline will build it with Insiders. When using built-in plugins that are exclusive to Insiders, it's recommended to split configuration into a base mkdocs.yml and one with plugin overrides via configuration inheritance . See the getting started guide for more information.","title":"Compatibility"},{"location":"insiders/#payment","text":"We don't want to pay for sponsorship every month. Are there any other options? Yes. You can sponsor on a yearly basis by switching your GitHub account to a yearly billing cycle . If for some reason you cannot do that, you could also create a dedicated GitHub account with a yearly billing cycle, which you only use for sponsoring (some sponsors already do that). If you have any problems or further questions, please reach out to sponsors@squidfunk.com .","title":"Payment"},{"location":"insiders/#terms","text":"Are we allowed to use Insiders under the same terms and conditions as Material for MkDocs? Yes. Whether you're an individual or a company, you may use Material for MkDocs Insiders precisely under the same terms as Material for MkDocs, which are given by the MIT license . However, we kindly ask you to respect our fair use policy : Please don't distribute the source code of Insiders. You may freely use it for public, private or commercial projects, privately fork or mirror it, but please don't make the source code public, as it would counteract the sponsorware strategy. If you cancel your subscription, you're automatically removed as a collaborator and will miss out on all future updates of Insiders. However, you may use the latest version that's available to you as long as you like . Just remember that GitHub deletes private forks . In general, every new feature is first exclusively released to sponsors, but sometimes upstream dependencies like Python Markdown Extensions enhance existing features that must be supported by Material for MkDocs. \u21a9 Note that $15 a month is the minimum amount to become eligible for Insiders. While GitHub Sponsors also allows to sponsor lower amounts or one-time amounts, those can't be granted access to Insiders due to technical reasons. \u21a9 Making an Open Source project sustainable is exceptionally hard: maintainers burn out, projects are abandoned. That's not great and very unpredictable. The sponsorware model ensures that if you decide to use Material for MkDocs, you can be sure that bugs are fixed quickly and new features are added regularly. \u21a9 It's currently not possible to grant access to each member of an organization, as GitHub only allows for adding users. Thus, after sponsoring, please send an email to sponsors@squidfunk.com , stating which account should become a collaborator of the Insiders repository. We're working on a solution which will make access to organizations much simpler. To ensure that access is not tied to a particular individual GitHub account, create a bot account (i.e. a GitHub account that is not tied to a specific individual), and use this account for the sponsoring. After being added to the list of collaborators, the bot account can create a private fork of the private Insiders GitHub repository, and grant access to all members of the organizations. \u21a9 If you cancel your sponsorship, GitHub schedules a cancellation request which will become effective at the end of the billing cycle. This means that even though you cancel your sponsorship, you will keep your access to Insiders as long as your cancellation isn't effective. All charges are processed by GitHub through Stripe. As we don't receive any information regarding your payment, and GitHub doesn't offer refunds, sponsorships are non-refundable. \u21a9","title":"Terms"},{"location":"insiders/changelog/","text":"Changelog \u00b6 Material for MkDocs Insiders \u00b6 4.26.6 _ November 28, 2022 \u00b6 Fixed #4683 : Tags plugin crashes when a tag is empty 4.26.5 _ November 27, 2022 \u00b6 Fixed #4632 : Post excerpt title link doesn't point to top of the page 4.26.4 _ November 27, 2022 \u00b6 Fixed redundant file extension when using privacy plugin 4.26.3 _ November 15, 2022 \u00b6 Fixed #4637 : Attachments w/o titles in related links error in blog plugin Fixed #4631 : Remote favicons not downloaded and inlined by privacy plugin 4.26.2 _ November 3, 2022 \u00b6 Updated MkDocs to 1.4.2 Added support for tag compare functions when sorting on index pages Fixed footnotes being rendered in post excerpts without separators Fixed error in blog plugin when toc extension is not enabled Fixed issues with invalid asset paths and linked post titles Fixed #4572 : Privacy plugin fails when symlinks cannot be created Fixed #4545 : Blog plugin doesn't automatically link headline to post Fixed #4542 : Blog plugin doesn't allow for multiple instances Fixed #4532 : Blog plugin doesn't allow for mixed use of date and datetime 4.26.1 _ October 22, 2022 \u00b6 Improved reporting of configuration errors in tags plugin Fixed #4515 : Privacy plugin fails when site URL is not defined Fixed #4514 : Privacy plugin doesn't fetch Google fonts (4.26.0 regression) 4.26.0 _ October 18, 2022 \u00b6 Refactored privacy plugin to prepare for new features Added support for rel=noopener links in privacy plugin Resolve encoding issues with blog and privacy plugin 4.25.5 _ October 16, 2022 \u00b6 Updated MkDocs to 1.4.1 Added namespace prefix to built-in plugins Updated content and header partial 4.25.4 _ October 9, 2022 \u00b6 Fixed other path issues for standalone blogs (4.24.2 regression) 4.25.3 _ October 9, 2022 \u00b6 Fixed #4457 : Posts not collected for standalone blog (4.24.2 regression) 4.25.2 _ October 4, 2022 \u00b6 Fixed #4452 : Blog and tags plugin crash when specifying slugify function 4.25.1 _ October 3, 2022 \u00b6 Updated mkdocs-rss-plugin in Dockerfile to fix MkDocs compat errors 4.25.0 _ October 2, 2022 \u00b6 Added support for navigation subtitles Added support for defining an allow list for built-in tags plugin Added support for custom slugify functions for built-in tags plugin Improved stability of search plugin when using --dirtyreload 4.24.2 _ October 1, 2022 \u00b6 Updated MkDocs to 1.4 Fixed compatibility issues with MkDocs 1.4 Fixed incorrectly generated paths in privacy plugin Fixed blog index page not showing navigation when using meta plugin 4.24.1 _ September 30, 2022 \u00b6 Fixed #4430 : build error when enabling consent without repository URL 4.24.0 _ September 27, 2022 \u00b6 Added support for custom content on index pages (blog) Added support for keeping content on paginated index pages (blog) Added support for limiting categories in post excerpts (blog) Added support for simple override of templates via front matter (blog) Added icon in navigation for pages with encrypted content Fixed #4396 : Front matter of index pages not inherited by pagination (blog) Improved performance by building post excerpts once (blog) 4.23.6 _ September 22, 2022 \u00b6 Fixed #4389 : Blog posts in first week of year in wrong archive Fixed (= switched) footer previous and next links for blog posts 4.23.5 _ September 18, 2022 \u00b6 Fixed #4367 : Improved blog plugin date handling for MultiMarkdown syntax Fixed #4374 : Fixed invalid URLs of related links to other blog posts 4.23.4 _ September 14, 2022 \u00b6 Fixed #4365 : Recursion error in blog plugin due to deepcopy Fixed path errors for blog plugin on Windows Fixed publishing workflow in forked repositories 4.23.3 _ September 13, 2022 \u00b6 Fixed previous and next page links for drafts of blog posts 4.23.2 _ September 13, 2022 \u00b6 Fixed #4348 : Blog plugin crashes on custom nav title Fixed blog plugin crashing when category contained only drafts Fixed rendering of content from blog index file 4.23.1 _ September 12, 2022 \u00b6 Fixed #4345 : Blog plugin errors with default settings 4.23.0 _ September 12, 2022 \u00b6 Added blogging support via built-in blog plugin 4.22.1 _ September 7, 2022 \u00b6 Fixed #4217 : Tooltips in data tables render in wrong position 4.22.0 _ August 21, 2022 \u00b6 Added support for navigation status 4.21.1 _ August 13, 2022 \u00b6 Fixed #4176 : Broken image when avatar is served by Gravatar Fixed #4212 : Deferred search initialization for file:// locations 4.21.0 _ July 17, 2022 \u00b6 Added meta plugin: set front matter for all pages in a folder Fixed #4114 : Tags plugin fails if only tags_extra_files is set 4.20.1 _ July 11, 2022 \u00b6 Fixed #4105 : Tags plugin fails if tags_file is not set (4.20.0 regression) 4.20.0 _ July 7, 2022 \u00b6 Added support for additional tags indexes Fixed #4100 : Tag icons not shown in tags index 4.19.2 _ July 4, 2022 \u00b6 Fixed #4051 : Privacy plugin fails if symlinking isn't allowed on Windows 4.19.1 _ June 25, 2022 \u00b6 Added mkdocs-git-committers-plugin to Dockerfile Added mkdocs-git-revision-date-localized-plugin to Dockerfile 4.19.0 _ June 24, 2022 \u00b6 Added support for document contributors Updated French translations for cookie consent 4.18.2 _ June 16, 2022 \u00b6 Fixed #4026 : Fixed tooltips not mounted for nested navigation links 4.18.1 _ June 14, 2022 \u00b6 Fixed #3990 : Chinese search highlighting not working on non-boundaries 4.18.0 _ June 11, 2022 \u00b6 Added support for automatic dark/light mode Fixed #4009 : Privacy plugin uses invalid paths for file cache on Windows 4.17.2 _ June 5, 2022 \u00b6 Added support for custom jieba dictionaries (Chinese search) 4.17.1 _ June 5, 2022 \u00b6 Added support for cookie consent reject button Added support for cookie consent custom button ordering Fixed #3988 : Content tab not focused after alternating anchor links 4.17.0 _ June 4, 2022 \u00b6 Added support for content tabs anchor links (deep linking) Fixed #3975 : Detect composition events in search interface (Chinese) Fixed #3980 : Search plugin doesn't use title set via front matter 4.16.2 _ May 29, 2022 \u00b6 Fixed #3961 : Nested sections triggered build error for navigation tabs 4.16.1 _ May 28, 2022 \u00b6 Switched feedback widget rating titles to tooltips Improved contrast of link colors for light/dark color schemes Fixed #3950 : Sticky navigation tabs rendering broken (4.15.2 regression) Fixed #3958 : Links invisible when using white primary color 4.16.0 _ May 25, 2022 \u00b6 Added support for navigation pruning Fixed search results for non-segmented characters (4.15.2 regression) 4.15.2 _ May 22, 2022 \u00b6 Removed workaround for abbr on touch devices (superseded by tooltips) Fixed #3915 : Improved Chinese search query segmentation Fixed #3938 : Fixed tooltips position for navigation titles with ellipsis 4.15.1 _ May 14, 2022 \u00b6 Improved performance of element focus obervables Fixed #3531 : Added prev/next buttons to content tabs Fixed tooltip positioning when host element is hidden 4.15.0 _ May 8, 2022 \u00b6 Added support for improved tooltips Fixed #3785 : Show tooltip on hover for overflowing navigation link 4.14.0 _ May 5, 2022 \u00b6 Added Chinese language support to built-in search plugin Fixed all-numeric page titles raising error in social plugin 4.13.2 _ April 30, 2022 \u00b6 Improved caching of downloaded resources in privacy plugin Fixed #3851 : External images not downloaded by privacy plugin 4.13.1 _ April 25, 2022 \u00b6 Fixed #3839 : Tags plugin breaks without icons (4.13.0 regression) 4.13.0 _ April 24, 2022 \u00b6 Added support for tag icons 4.12.0 _ March 27, 2022 \u00b6 Added support for card grids and grid layouts Fixed #3685 : Annotations sometimes broken when using instant loading Fixed #3742 : Automatically add Mermaid.js when building for offline usage 4.11.0 _ March 6, 2022 \u00b6 Added support for excluding external assets from privacy plugin 4.10.1 _ March 2, 2022 \u00b6 Added missing build dependencies to Dockerfile Fixed encoding issues in privacy plugin, now forcing UTF-8 encoding Fixed #3624 : Scroll to active navigation item unreliable in Firefox Fixed #3642 : Privacy plugin errors when font setting was omitted 4.10.0 _ February 27, 2022 \u00b6 Added support for offline plugin (supersedes offline search support) Improved built-in privacy plugin to download nested JavaScript assets Refactored configuration of built-in privacy plugin 4.9.1 _ February 21, 2022 \u00b6 Fixed #3610 : missing lxml dependency for privacy plugin Fixed error when charset is missing in content-type header 4.9.0 _ February 20, 2022 \u00b6 Added privacy plugin: automatic downloading of external assets 4.8.3 _ February 13, 2022 \u00b6 Fixed #3560 : Mermaid diagrams don't render for file:// locations 4.8.2 _ February 10, 2022 \u00b6 Fixed #3559 : Mermaid diagrams don't render inside closed details 4.8.1 _ February 6, 2022 \u00b6 Fixed jump back to top on mobile when using anchor following 4.8.0 _ February 6, 2022 \u00b6 Added support for anchor following table of contents (= auto scroll) 4.7.2 _ February 2, 2022 \u00b6 Fixed #3526 : Transparent sidebar title due to Safari bug Fixed #3528 : Firefox sometimes clips text in flow chart diagrams 4.7.1 _ January 30, 2022 \u00b6 Fixed #3506 : Tags index not respecting title set via front matter 4.7.0 _ January 25, 2022 \u00b6 Added native support for offline search 4.6.1 _ January 16, 2022 \u00b6 Fixed #3459 : Section index pages picking up wrong title 4.6.0 _ January 11, 2022 \u00b6 Added support for annotations (outside of code blocks) 4.5.2 _ January 8, 2022 \u00b6 Fixed #3440 : Content tab indicator not moving when using linking Fixed #3445 : Content tab switch flickers/jitters when using linking 4.5.1 _ January 2, 2022 \u00b6 Added support for setting initial state of cookie consent Fixed #3396 : Disappearing link in navigation due to Safari bug 4.5.0 _ December 16, 2021 \u00b6 Added support for navigation icons 4.4.0 _ December 10, 2021 \u00b6 Added support for code annotation anchor links (deep linking) Added new code annotation syntax modifier to strip comment Updated German translations for cookie consent 4.3.0 _ December 5, 2021 \u00b6 Added support for custom fonts in social cards Fixed #3300 : Announcement bar reappearing when using instant loading 4.2.0 _ December 2, 2021 \u00b6 Added support for dismissable announcement bar Added support for named placeholders in feedback widget 4.1.0 _ November 30, 2021 \u00b6 Added support for passing page title to feedback forms 4.0.0 _ November 28, 2021 \u00b6 Removed deprecated content tabs legacy implementation Removed deprecated seealso admonition type Removed deprecated site_keywords setting (unsupported by MkDocs) Removed deprecated prebuilt search index support Removed deprecated web app manifest \u2013 use customization Removed extracopyright variable \u2013 use new copyright partial Removed Disqus integation \u2013 use customization Switched to :is() selectors for simple selector lists Switched autoprefixer from last 4 years to last 2 years Improved CSS overall to match modern standards Improved CSS variable semantics for fonts Improved extensibility by restructuring partials Improved handling of details when printing Improved keyboard navigation for footnotes Fixed #3214 : Search highlighting breaks site when empty 3.2.3 _ November 20, 2021 \u00b6 Updated Swedish and French translations Removed support for .mermaid-experimental class (now .mermaid ) Fixed #3202 : Cookie consent not dismissable on file:// locations Fixed #3216 : Cookie consent not dismissed when invoked via anchor Fixed #3232 : Mermaid.js sometimes runs twice (race condition) 3.2.2 _ November 6, 2021 \u00b6 Fixed always last feedback rating being sent Fixed #3145 : Code annotations eat whole comment lines Fixed #3170 : Feedback widget doesn't send data to GA4 3.2.1 _ November 4, 2021 \u00b6 Added support for custom Mermaid.js version via additional JavaScript Fixed some configuration edge cases for tags plugin (3.1.5 regression) Fixed feedback widget title not being centered in Firefox Fixed #3179 : Safari doesn't send request for feedback widget 3.2.0 _ October 31, 2021 \u00b6 Added support for feedback widget (Was this page helpful?) 3.1.5 _ October 28, 2021 \u00b6 Fixed #3144 : Rogue link when using tags with auto-populated navigation Fixed #3147 : Code block line numbers appear in search results Fixed #3158 : Social cards do not strip HTML tags from title 3.1.4 _ October 17, 2021 \u00b6 Fixed #2974 : Text cropped with other fonts than Roboto in social plugin Fixed #3099 : Encoding problems with non-latin character in social plugin Fixed #3112 : Japanese segmenter not executed as part of new tokenizer Fixed tags (front matter) appearing in search with disabled tags plugin 3.1.3 _ October 12, 2021 \u00b6 Added warnings to search plugin for unsupported options and syntax Fixed #3503 : Search sometimes returns entire page Fixed #3089 : Single-line code annotations disappear when printing 3.1.2 _ October 6, 2021 \u00b6 Fixed incorrect path separators for social cards on Windows 3.1.1 _ September 26, 2021 \u00b6 Fixed ordering bug in search exclusion logic 3.1.0 _ September 26, 2021 \u00b6 Added support for excluding pages, sections, and elements from search Fixed #2803 : Code block annotations not visible when printing 3.0.1 _ September 19, 2021 \u00b6 Added support for using literal h1-6 tags for search plugin Fixed search plugin breaking on void elements without slashes Fixed search plugin filtering link contents from headlines Fixed search plugin handling of multiple h1 headlines Fixed search plugin handling of missing h1 headlines 3.0.0 _ September 13, 2021 \u00b6 Rewrite of MkDocs' search plugin Added support for rich search previews Added support for tokenizer with lookahead Improved search indexing performance (twice as fast) Improved search highlighting 2.13.3 _ September 1, 2021 \u00b6 Added support for disabling social card generation 2.13.2 _ August 25, 2021 \u00b6 Fixed #2965 : Social plugin error when primary color is not defined 2.13.1 _ August 21, 2021 \u00b6 Fixed #2948 : Social cards are not cached Fixed #2953 : Mermaid.js diagrams can't be centered anymore 2.13.0 _ August 7, 2021 \u00b6 Added support for custom colors in social cards 2.12.2 _ August 4, 2021 \u00b6 Fixed #2891 : Division by zero error in social plugin 2.12.1 _ July 26, 2021 \u00b6 Fixed error in social plugin when site_description was not set Fixed error in social plugin for non-ASCII characters 2.12.0 _ July 25, 2021 \u00b6 Added support for social cards 2.11.1 _ July 20, 2021 \u00b6 Fixed order of tags index, now sorted alphabetically 2.11.0 _ July 18, 2021 \u00b6 Improved Mermaid.js intergration, now stable Added support for sequence diagrams Added support for entity relationship diagrams Added support for cookie consent configuration Added feature flag to always enable annotations 2.10.0 _ July 10, 2021 \u00b6 Added support for cookie consent Fixed #2807 : Back-to-top button not hidden when using sticky tabs 2.9.2 _ May 30, 2021 \u00b6 Moved tags to partial for easier customization Added support for hiding tags on any page 2.9.1 _ May 24, 2021 \u00b6 Added missing guard for linking of content tabs 2.9.0 _ May 23, 2021 \u00b6 Added support for linking of content tabs 2.8.0 _ May 12, 2021 \u00b6 Added support for boosting pages in search 2.7.2 _ May 8, 2021 \u00b6 Fixed #2638 : Warnings shown when using tags plugin without directory URLs 2.7.1 _ May 3, 2021 \u00b6 Fixed git-revision-date-localized plugin integration (2.7.0 regression) 2.7.0 _ May 1, 2021 \u00b6 Added support for tags (with search integration) 2.6.0 _ April 11, 2021 \u00b6 Stay on page when switching versions 2.5.0 _ March 28, 2021 \u00b6 Added support for version warning 2.4.0 _ March 20, 2021 \u00b6 Added support for custom admonition icons Fixed #2444 : Code block annotations with extra comments have wrong index 2.3.1 _ March 14, 2021 \u00b6 Fixed anchor offset for permalinks when using sticky navigation tabs 2.3.0 _ March 13, 2021 \u00b6 Added support for back-to-top button 2.2.1 _ March 4, 2021 \u00b6 Fixed #2382 : Repository stats failing when no release tag is present 2.2.0 _ February 28, 2021 \u00b6 Added support for code block annotations 2.1.0 _ February 26, 2021 \u00b6 Added support for anchor tracking 2.0.0 _ February 24, 2021 \u00b6 Migrated Insiders to the new architecture Swapped color palette toggle configuration 1.17.0 _ January 31, 2021 \u00b6 Added support for section index pages 1.16.1 _ January 26, 2021 \u00b6 Fixed #2249 : Instant loading + sticky tabs result in invalid links Fixed #2248 : Search highlighting URL parameter always added Fixed #2235 : Version selector doesn't select current version for aliases 1.16.0 _ January 7, 2021 \u00b6 Added latest release to repository info (GitHub) Slight facelift of repository info (lighter fonts, spacing and icons) 1.15.0 _ January 2, 2021 \u00b6 Added support for native Mermaid.js integration 1.14.0 _ December 30, 2020 \u00b6 Added support for sharing searches 1.13.2 _ December 22, 2020 \u00b6 Fixed version selector + sticky tabs navigation rendering issues Fixed version selector wrapping 1.13.1 _ December 20, 2020 \u00b6 Removed horizontal scrollbars on language and version selector Fixed type conversion in JavaScript config 1.13.0 _ December 13, 2020 \u00b6 Refactored navigation tabs to simplify grouping behavior Added support for sticky navigation tabs Added support for arbitrary links in navigation tabs Fixed #2098 : Subsequent active subsection not highlighted correctly 1.12.1 _ December 8, 2020 \u00b6 Fixed empty language selector being shown 1.12.0 _ December 6, 2020 \u00b6 Added support for adding a language selector 1.11.2 _ November 29, 2020 \u00b6 Fixed #2068 : Search highlight interprets code blocks as JavaScript 1.11.1 _ November 29, 2020 \u00b6 Refactored styling to be more stable and easier to adjust Fixed some styling regressions from latest features 1.11.0 _ November 22, 2020 \u00b6 Added support for rendering admonitions as inline blocks 1.10.0 _ November 15, 2020 \u00b6 Added support for integrating table of contents into navigation 1.9.0 _ November 7, 2020 \u00b6 Added support for hiding navigation and table of contents on any page Removed autohiding table of contents when empty 1.8.0 _ November 1, 2020 \u00b6 Added support for navigation sections Fixed appearance of inactive search suggestions 1.7.0 _ October 25, 2020 \u00b6 Added support for deploying multiple versions Fixed alignment of sidebar when content area is too small 1.6.0 _ October 11, 2020 \u00b6 Added support for search suggestions to save keystrokes Added support for removing Made with Material for MkDocs from footer Fixed #1915 : search should go to first result by pressing Enter 1.5.1 _ September 21, 2020 \u00b6 Fixed content area stretching to whole width for long code blocks 1.5.0 _ September 19, 2020 \u00b6 Added support for autohiding table of contents when empty 1.4.1 _ September 6, 2020 \u00b6 Improved typeahead and search result relevance and scoring 1.4.0 _ August 30, 2020 \u00b6 Added support for autohiding header on scroll 1.3.0 _ August 26, 2020 \u00b6 Added support for user-selectable color palettes 1.2.0 _ August 11, 2020 \u00b6 Added feature to expand navigation by default 1.1.0 _ August 3, 2020 \u00b6 Added highlighting of search results 1.0.0 _ July 14, 2020 \u00b6 Added grouping of search results Added missing query terms to search result Improved search result relevance and scoring","title":"Changelog"},{"location":"insiders/changelog/#changelog","text":"","title":"Changelog"},{"location":"insiders/changelog/#material-for-mkdocs-insiders","text":"","title":"Material for MkDocs Insiders"},{"location":"insiders/changelog/#4.26.6","text":"Fixed #4683 : Tags plugin crashes when a tag is empty","title":"4.26.6 _ November 28, 2022"},{"location":"insiders/changelog/#4.26.5","text":"Fixed #4632 : Post excerpt title link doesn't point to top of the page","title":"4.26.5 _ November 27, 2022"},{"location":"insiders/changelog/#4.26.4","text":"Fixed redundant file extension when using privacy plugin","title":"4.26.4 _ November 27, 2022"},{"location":"insiders/changelog/#4.26.3","text":"Fixed #4637 : Attachments w/o titles in related links error in blog plugin Fixed #4631 : Remote favicons not downloaded and inlined by privacy plugin","title":"4.26.3 _ November 15, 2022"},{"location":"insiders/changelog/#4.26.2","text":"Updated MkDocs to 1.4.2 Added support for tag compare functions when sorting on index pages Fixed footnotes being rendered in post excerpts without separators Fixed error in blog plugin when toc extension is not enabled Fixed issues with invalid asset paths and linked post titles Fixed #4572 : Privacy plugin fails when symlinks cannot be created Fixed #4545 : Blog plugin doesn't automatically link headline to post Fixed #4542 : Blog plugin doesn't allow for multiple instances Fixed #4532 : Blog plugin doesn't allow for mixed use of date and datetime","title":"4.26.2 _ November 3, 2022"},{"location":"insiders/changelog/#4.26.1","text":"Improved reporting of configuration errors in tags plugin Fixed #4515 : Privacy plugin fails when site URL is not defined Fixed #4514 : Privacy plugin doesn't fetch Google fonts (4.26.0 regression)","title":"4.26.1 _ October 22, 2022"},{"location":"insiders/changelog/#4.26.0","text":"Refactored privacy plugin to prepare for new features Added support for rel=noopener links in privacy plugin Resolve encoding issues with blog and privacy plugin","title":"4.26.0 _ October 18, 2022"},{"location":"insiders/changelog/#4.25.5","text":"Updated MkDocs to 1.4.1 Added namespace prefix to built-in plugins Updated content and header partial","title":"4.25.5 _ October 16, 2022"},{"location":"insiders/changelog/#4.25.4","text":"Fixed other path issues for standalone blogs (4.24.2 regression)","title":"4.25.4 _ October 9, 2022"},{"location":"insiders/changelog/#4.25.3","text":"Fixed #4457 : Posts not collected for standalone blog (4.24.2 regression)","title":"4.25.3 _ October 9, 2022"},{"location":"insiders/changelog/#4.25.2","text":"Fixed #4452 : Blog and tags plugin crash when specifying slugify function","title":"4.25.2 _ October 4, 2022"},{"location":"insiders/changelog/#4.25.1","text":"Updated mkdocs-rss-plugin in Dockerfile to fix MkDocs compat errors","title":"4.25.1 _ October 3, 2022"},{"location":"insiders/changelog/#4.25.0","text":"Added support for navigation subtitles Added support for defining an allow list for built-in tags plugin Added support for custom slugify functions for built-in tags plugin Improved stability of search plugin when using --dirtyreload","title":"4.25.0 _ October 2, 2022"},{"location":"insiders/changelog/#4.24.2","text":"Updated MkDocs to 1.4 Fixed compatibility issues with MkDocs 1.4 Fixed incorrectly generated paths in privacy plugin Fixed blog index page not showing navigation when using meta plugin","title":"4.24.2 _ October 1, 2022"},{"location":"insiders/changelog/#4.24.1","text":"Fixed #4430 : build error when enabling consent without repository URL","title":"4.24.1 _ September 30, 2022"},{"location":"insiders/changelog/#4.24.0","text":"Added support for custom content on index pages (blog) Added support for keeping content on paginated index pages (blog) Added support for limiting categories in post excerpts (blog) Added support for simple override of templates via front matter (blog) Added icon in navigation for pages with encrypted content Fixed #4396 : Front matter of index pages not inherited by pagination (blog) Improved performance by building post excerpts once (blog)","title":"4.24.0 _ September 27, 2022"},{"location":"insiders/changelog/#4.23.6","text":"Fixed #4389 : Blog posts in first week of year in wrong archive Fixed (= switched) footer previous and next links for blog posts","title":"4.23.6 _ September 22, 2022"},{"location":"insiders/changelog/#4.23.5","text":"Fixed #4367 : Improved blog plugin date handling for MultiMarkdown syntax Fixed #4374 : Fixed invalid URLs of related links to other blog posts","title":"4.23.5 _ September 18, 2022"},{"location":"insiders/changelog/#4.23.4","text":"Fixed #4365 : Recursion error in blog plugin due to deepcopy Fixed path errors for blog plugin on Windows Fixed publishing workflow in forked repositories","title":"4.23.4 _ September 14, 2022"},{"location":"insiders/changelog/#4.23.3","text":"Fixed previous and next page links for drafts of blog posts","title":"4.23.3 _ September 13, 2022"},{"location":"insiders/changelog/#4.23.2","text":"Fixed #4348 : Blog plugin crashes on custom nav title Fixed blog plugin crashing when category contained only drafts Fixed rendering of content from blog index file","title":"4.23.2 _ September 13, 2022"},{"location":"insiders/changelog/#4.23.1","text":"Fixed #4345 : Blog plugin errors with default settings","title":"4.23.1 _ September 12, 2022"},{"location":"insiders/changelog/#4.23.0","text":"Added blogging support via built-in blog plugin","title":"4.23.0 _ September 12, 2022"},{"location":"insiders/changelog/#4.22.1","text":"Fixed #4217 : Tooltips in data tables render in wrong position","title":"4.22.1 _ September 7, 2022"},{"location":"insiders/changelog/#4.22.0","text":"Added support for navigation status","title":"4.22.0 _ August 21, 2022"},{"location":"insiders/changelog/#4.21.1","text":"Fixed #4176 : Broken image when avatar is served by Gravatar Fixed #4212 : Deferred search initialization for file:// locations","title":"4.21.1 _ August 13, 2022"},{"location":"insiders/changelog/#4.21.0","text":"Added meta plugin: set front matter for all pages in a folder Fixed #4114 : Tags plugin fails if only tags_extra_files is set","title":"4.21.0 _ July 17, 2022"},{"location":"insiders/changelog/#4.20.1","text":"Fixed #4105 : Tags plugin fails if tags_file is not set (4.20.0 regression)","title":"4.20.1 _ July 11, 2022"},{"location":"insiders/changelog/#4.20.0","text":"Added support for additional tags indexes Fixed #4100 : Tag icons not shown in tags index","title":"4.20.0 _ July 7, 2022"},{"location":"insiders/changelog/#4.19.2","text":"Fixed #4051 : Privacy plugin fails if symlinking isn't allowed on Windows","title":"4.19.2 _ July 4, 2022"},{"location":"insiders/changelog/#4.19.1","text":"Added mkdocs-git-committers-plugin to Dockerfile Added mkdocs-git-revision-date-localized-plugin to Dockerfile","title":"4.19.1 _ June 25, 2022"},{"location":"insiders/changelog/#4.19.0","text":"Added support for document contributors Updated French translations for cookie consent","title":"4.19.0 _ June 24, 2022"},{"location":"insiders/changelog/#4.18.2","text":"Fixed #4026 : Fixed tooltips not mounted for nested navigation links","title":"4.18.2 _ June 16, 2022"},{"location":"insiders/changelog/#4.18.1","text":"Fixed #3990 : Chinese search highlighting not working on non-boundaries","title":"4.18.1 _ June 14, 2022"},{"location":"insiders/changelog/#4.18.0","text":"Added support for automatic dark/light mode Fixed #4009 : Privacy plugin uses invalid paths for file cache on Windows","title":"4.18.0 _ June 11, 2022"},{"location":"insiders/changelog/#4.17.2","text":"Added support for custom jieba dictionaries (Chinese search)","title":"4.17.2 _ June 5, 2022"},{"location":"insiders/changelog/#4.17.1","text":"Added support for cookie consent reject button Added support for cookie consent custom button ordering Fixed #3988 : Content tab not focused after alternating anchor links","title":"4.17.1 _ June 5, 2022"},{"location":"insiders/changelog/#4.17.0","text":"Added support for content tabs anchor links (deep linking) Fixed #3975 : Detect composition events in search interface (Chinese) Fixed #3980 : Search plugin doesn't use title set via front matter","title":"4.17.0 _ June 4, 2022"},{"location":"insiders/changelog/#4.16.2","text":"Fixed #3961 : Nested sections triggered build error for navigation tabs","title":"4.16.2 _ May 29, 2022"},{"location":"insiders/changelog/#4.16.1","text":"Switched feedback widget rating titles to tooltips Improved contrast of link colors for light/dark color schemes Fixed #3950 : Sticky navigation tabs rendering broken (4.15.2 regression) Fixed #3958 : Links invisible when using white primary color","title":"4.16.1 _ May 28, 2022"},{"location":"insiders/changelog/#4.16.0","text":"Added support for navigation pruning Fixed search results for non-segmented characters (4.15.2 regression)","title":"4.16.0 _ May 25, 2022"},{"location":"insiders/changelog/#4.15.2","text":"Removed workaround for abbr on touch devices (superseded by tooltips) Fixed #3915 : Improved Chinese search query segmentation Fixed #3938 : Fixed tooltips position for navigation titles with ellipsis","title":"4.15.2 _ May 22, 2022"},{"location":"insiders/changelog/#4.15.1","text":"Improved performance of element focus obervables Fixed #3531 : Added prev/next buttons to content tabs Fixed tooltip positioning when host element is hidden","title":"4.15.1 _ May 14, 2022"},{"location":"insiders/changelog/#4.15.0","text":"Added support for improved tooltips Fixed #3785 : Show tooltip on hover for overflowing navigation link","title":"4.15.0 _ May 8, 2022"},{"location":"insiders/changelog/#4.14.0","text":"Added Chinese language support to built-in search plugin Fixed all-numeric page titles raising error in social plugin","title":"4.14.0 _ May 5, 2022"},{"location":"insiders/changelog/#4.13.2","text":"Improved caching of downloaded resources in privacy plugin Fixed #3851 : External images not downloaded by privacy plugin","title":"4.13.2 _ April 30, 2022"},{"location":"insiders/changelog/#4.13.1","text":"Fixed #3839 : Tags plugin breaks without icons (4.13.0 regression)","title":"4.13.1 _ April 25, 2022"},{"location":"insiders/changelog/#4.13.0","text":"Added support for tag icons","title":"4.13.0 _ April 24, 2022"},{"location":"insiders/changelog/#4.12.0","text":"Added support for card grids and grid layouts Fixed #3685 : Annotations sometimes broken when using instant loading Fixed #3742 : Automatically add Mermaid.js when building for offline usage","title":"4.12.0 _ March 27, 2022"},{"location":"insiders/changelog/#4.11.0","text":"Added support for excluding external assets from privacy plugin","title":"4.11.0 _ March 6, 2022"},{"location":"insiders/changelog/#4.10.1","text":"Added missing build dependencies to Dockerfile Fixed encoding issues in privacy plugin, now forcing UTF-8 encoding Fixed #3624 : Scroll to active navigation item unreliable in Firefox Fixed #3642 : Privacy plugin errors when font setting was omitted","title":"4.10.1 _ March 2, 2022"},{"location":"insiders/changelog/#4.10.0","text":"Added support for offline plugin (supersedes offline search support) Improved built-in privacy plugin to download nested JavaScript assets Refactored configuration of built-in privacy plugin","title":"4.10.0 _ February 27, 2022"},{"location":"insiders/changelog/#4.9.1","text":"Fixed #3610 : missing lxml dependency for privacy plugin Fixed error when charset is missing in content-type header","title":"4.9.1 _ February 21, 2022"},{"location":"insiders/changelog/#4.9.0","text":"Added privacy plugin: automatic downloading of external assets","title":"4.9.0 _ February 20, 2022"},{"location":"insiders/changelog/#4.8.3","text":"Fixed #3560 : Mermaid diagrams don't render for file:// locations","title":"4.8.3 _ February 13, 2022"},{"location":"insiders/changelog/#4.8.2","text":"Fixed #3559 : Mermaid diagrams don't render inside closed details","title":"4.8.2 _ February 10, 2022"},{"location":"insiders/changelog/#4.8.1","text":"Fixed jump back to top on mobile when using anchor following","title":"4.8.1 _ February 6, 2022"},{"location":"insiders/changelog/#4.8.0","text":"Added support for anchor following table of contents (= auto scroll)","title":"4.8.0 _ February 6, 2022"},{"location":"insiders/changelog/#4.7.2","text":"Fixed #3526 : Transparent sidebar title due to Safari bug Fixed #3528 : Firefox sometimes clips text in flow chart diagrams","title":"4.7.2 _ February 2, 2022"},{"location":"insiders/changelog/#4.7.1","text":"Fixed #3506 : Tags index not respecting title set via front matter","title":"4.7.1 _ January 30, 2022"},{"location":"insiders/changelog/#4.7.0","text":"Added native support for offline search","title":"4.7.0 _ January 25, 2022"},{"location":"insiders/changelog/#4.6.1","text":"Fixed #3459 : Section index pages picking up wrong title","title":"4.6.1 _ January 16, 2022"},{"location":"insiders/changelog/#4.6.0","text":"Added support for annotations (outside of code blocks)","title":"4.6.0 _ January 11, 2022"},{"location":"insiders/changelog/#4.5.2","text":"Fixed #3440 : Content tab indicator not moving when using linking Fixed #3445 : Content tab switch flickers/jitters when using linking","title":"4.5.2 _ January 8, 2022"},{"location":"insiders/changelog/#4.5.1","text":"Added support for setting initial state of cookie consent Fixed #3396 : Disappearing link in navigation due to Safari bug","title":"4.5.1 _ January 2, 2022"},{"location":"insiders/changelog/#4.5.0","text":"Added support for navigation icons","title":"4.5.0 _ December 16, 2021"},{"location":"insiders/changelog/#4.4.0","text":"Added support for code annotation anchor links (deep linking) Added new code annotation syntax modifier to strip comment Updated German translations for cookie consent","title":"4.4.0 _ December 10, 2021"},{"location":"insiders/changelog/#4.3.0","text":"Added support for custom fonts in social cards Fixed #3300 : Announcement bar reappearing when using instant loading","title":"4.3.0 _ December 5, 2021"},{"location":"insiders/changelog/#4.2.0","text":"Added support for dismissable announcement bar Added support for named placeholders in feedback widget","title":"4.2.0 _ December 2, 2021"},{"location":"insiders/changelog/#4.1.0","text":"Added support for passing page title to feedback forms","title":"4.1.0 _ November 30, 2021"},{"location":"insiders/changelog/#4.0.0","text":"Removed deprecated content tabs legacy implementation Removed deprecated seealso admonition type Removed deprecated site_keywords setting (unsupported by MkDocs) Removed deprecated prebuilt search index support Removed deprecated web app manifest \u2013 use customization Removed extracopyright variable \u2013 use new copyright partial Removed Disqus integation \u2013 use customization Switched to :is() selectors for simple selector lists Switched autoprefixer from last 4 years to last 2 years Improved CSS overall to match modern standards Improved CSS variable semantics for fonts Improved extensibility by restructuring partials Improved handling of details when printing Improved keyboard navigation for footnotes Fixed #3214 : Search highlighting breaks site when empty","title":"4.0.0 _ November 28, 2021"},{"location":"insiders/changelog/#3.2.3","text":"Updated Swedish and French translations Removed support for .mermaid-experimental class (now .mermaid ) Fixed #3202 : Cookie consent not dismissable on file:// locations Fixed #3216 : Cookie consent not dismissed when invoked via anchor Fixed #3232 : Mermaid.js sometimes runs twice (race condition)","title":"3.2.3 _ November 20, 2021"},{"location":"insiders/changelog/#3.2.2","text":"Fixed always last feedback rating being sent Fixed #3145 : Code annotations eat whole comment lines Fixed #3170 : Feedback widget doesn't send data to GA4","title":"3.2.2 _ November 6, 2021"},{"location":"insiders/changelog/#3.2.1","text":"Added support for custom Mermaid.js version via additional JavaScript Fixed some configuration edge cases for tags plugin (3.1.5 regression) Fixed feedback widget title not being centered in Firefox Fixed #3179 : Safari doesn't send request for feedback widget","title":"3.2.1 _ November 4, 2021"},{"location":"insiders/changelog/#3.2.0","text":"Added support for feedback widget (Was this page helpful?)","title":"3.2.0 _ October 31, 2021"},{"location":"insiders/changelog/#3.1.5","text":"Fixed #3144 : Rogue link when using tags with auto-populated navigation Fixed #3147 : Code block line numbers appear in search results Fixed #3158 : Social cards do not strip HTML tags from title","title":"3.1.5 _ October 28, 2021"},{"location":"insiders/changelog/#3.1.4","text":"Fixed #2974 : Text cropped with other fonts than Roboto in social plugin Fixed #3099 : Encoding problems with non-latin character in social plugin Fixed #3112 : Japanese segmenter not executed as part of new tokenizer Fixed tags (front matter) appearing in search with disabled tags plugin","title":"3.1.4 _ October 17, 2021"},{"location":"insiders/changelog/#3.1.3","text":"Added warnings to search plugin for unsupported options and syntax Fixed #3503 : Search sometimes returns entire page Fixed #3089 : Single-line code annotations disappear when printing","title":"3.1.3 _ October 12, 2021"},{"location":"insiders/changelog/#3.1.2","text":"Fixed incorrect path separators for social cards on Windows","title":"3.1.2 _ October 6, 2021"},{"location":"insiders/changelog/#3.1.1","text":"Fixed ordering bug in search exclusion logic","title":"3.1.1 _ September 26, 2021"},{"location":"insiders/changelog/#3.1.0","text":"Added support for excluding pages, sections, and elements from search Fixed #2803 : Code block annotations not visible when printing","title":"3.1.0 _ September 26, 2021"},{"location":"insiders/changelog/#3.0.1","text":"Added support for using literal h1-6 tags for search plugin Fixed search plugin breaking on void elements without slashes Fixed search plugin filtering link contents from headlines Fixed search plugin handling of multiple h1 headlines Fixed search plugin handling of missing h1 headlines","title":"3.0.1 _ September 19, 2021"},{"location":"insiders/changelog/#3.0.0","text":"Rewrite of MkDocs' search plugin Added support for rich search previews Added support for tokenizer with lookahead Improved search indexing performance (twice as fast) Improved search highlighting","title":"3.0.0 _ September 13, 2021"},{"location":"insiders/changelog/#2.13.3","text":"Added support for disabling social card generation","title":"2.13.3 _ September 1, 2021"},{"location":"insiders/changelog/#2.13.2","text":"Fixed #2965 : Social plugin error when primary color is not defined","title":"2.13.2 _ August 25, 2021"},{"location":"insiders/changelog/#2.13.1","text":"Fixed #2948 : Social cards are not cached Fixed #2953 : Mermaid.js diagrams can't be centered anymore","title":"2.13.1 _ August 21, 2021"},{"location":"insiders/changelog/#2.13.0","text":"Added support for custom colors in social cards","title":"2.13.0 _ August 7, 2021"},{"location":"insiders/changelog/#2.12.2","text":"Fixed #2891 : Division by zero error in social plugin","title":"2.12.2 _ August 4, 2021"},{"location":"insiders/changelog/#2.12.1","text":"Fixed error in social plugin when site_description was not set Fixed error in social plugin for non-ASCII characters","title":"2.12.1 _ July 26, 2021"},{"location":"insiders/changelog/#2.12.0","text":"Added support for social cards","title":"2.12.0 _ July 25, 2021"},{"location":"insiders/changelog/#2.11.1","text":"Fixed order of tags index, now sorted alphabetically","title":"2.11.1 _ July 20, 2021"},{"location":"insiders/changelog/#2.11.0","text":"Improved Mermaid.js intergration, now stable Added support for sequence diagrams Added support for entity relationship diagrams Added support for cookie consent configuration Added feature flag to always enable annotations","title":"2.11.0 _ July 18, 2021"},{"location":"insiders/changelog/#2.10.0","text":"Added support for cookie consent Fixed #2807 : Back-to-top button not hidden when using sticky tabs","title":"2.10.0 _ July 10, 2021"},{"location":"insiders/changelog/#2.9.2","text":"Moved tags to partial for easier customization Added support for hiding tags on any page","title":"2.9.2 _ May 30, 2021"},{"location":"insiders/changelog/#2.9.1","text":"Added missing guard for linking of content tabs","title":"2.9.1 _ May 24, 2021"},{"location":"insiders/changelog/#2.9.0","text":"Added support for linking of content tabs","title":"2.9.0 _ May 23, 2021"},{"location":"insiders/changelog/#2.8.0","text":"Added support for boosting pages in search","title":"2.8.0 _ May 12, 2021"},{"location":"insiders/changelog/#2.7.2","text":"Fixed #2638 : Warnings shown when using tags plugin without directory URLs","title":"2.7.2 _ May 8, 2021"},{"location":"insiders/changelog/#2.7.1","text":"Fixed git-revision-date-localized plugin integration (2.7.0 regression)","title":"2.7.1 _ May 3, 2021"},{"location":"insiders/changelog/#2.7.0","text":"Added support for tags (with search integration)","title":"2.7.0 _ May 1, 2021"},{"location":"insiders/changelog/#2.6.0","text":"Stay on page when switching versions","title":"2.6.0 _ April 11, 2021"},{"location":"insiders/changelog/#2.5.0","text":"Added support for version warning","title":"2.5.0 _ March 28, 2021"},{"location":"insiders/changelog/#2.4.0","text":"Added support for custom admonition icons Fixed #2444 : Code block annotations with extra comments have wrong index","title":"2.4.0 _ March 20, 2021"},{"location":"insiders/changelog/#2.3.1","text":"Fixed anchor offset for permalinks when using sticky navigation tabs","title":"2.3.1 _ March 14, 2021"},{"location":"insiders/changelog/#2.3.0","text":"Added support for back-to-top button","title":"2.3.0 _ March 13, 2021"},{"location":"insiders/changelog/#2.2.1","text":"Fixed #2382 : Repository stats failing when no release tag is present","title":"2.2.1 _ March 4, 2021"},{"location":"insiders/changelog/#2.2.0","text":"Added support for code block annotations","title":"2.2.0 _ February 28, 2021"},{"location":"insiders/changelog/#2.1.0","text":"Added support for anchor tracking","title":"2.1.0 _ February 26, 2021"},{"location":"insiders/changelog/#2.0.0","text":"Migrated Insiders to the new architecture Swapped color palette toggle configuration","title":"2.0.0 _ February 24, 2021"},{"location":"insiders/changelog/#1.17.0","text":"Added support for section index pages","title":"1.17.0 _ January 31, 2021"},{"location":"insiders/changelog/#1.16.1","text":"Fixed #2249 : Instant loading + sticky tabs result in invalid links Fixed #2248 : Search highlighting URL parameter always added Fixed #2235 : Version selector doesn't select current version for aliases","title":"1.16.1 _ January 26, 2021"},{"location":"insiders/changelog/#1.16.0","text":"Added latest release to repository info (GitHub) Slight facelift of repository info (lighter fonts, spacing and icons)","title":"1.16.0 _ January 7, 2021"},{"location":"insiders/changelog/#1.15.0","text":"Added support for native Mermaid.js integration","title":"1.15.0 _ January 2, 2021"},{"location":"insiders/changelog/#1.14.0","text":"Added support for sharing searches","title":"1.14.0 _ December 30, 2020"},{"location":"insiders/changelog/#1.13.2","text":"Fixed version selector + sticky tabs navigation rendering issues Fixed version selector wrapping","title":"1.13.2 _ December 22, 2020"},{"location":"insiders/changelog/#1.13.1","text":"Removed horizontal scrollbars on language and version selector Fixed type conversion in JavaScript config","title":"1.13.1 _ December 20, 2020"},{"location":"insiders/changelog/#1.13.0","text":"Refactored navigation tabs to simplify grouping behavior Added support for sticky navigation tabs Added support for arbitrary links in navigation tabs Fixed #2098 : Subsequent active subsection not highlighted correctly","title":"1.13.0 _ December 13, 2020"},{"location":"insiders/changelog/#1.12.1","text":"Fixed empty language selector being shown","title":"1.12.1 _ December 8, 2020"},{"location":"insiders/changelog/#1.12.0","text":"Added support for adding a language selector","title":"1.12.0 _ December 6, 2020"},{"location":"insiders/changelog/#1.11.2","text":"Fixed #2068 : Search highlight interprets code blocks as JavaScript","title":"1.11.2 _ November 29, 2020"},{"location":"insiders/changelog/#1.11.1","text":"Refactored styling to be more stable and easier to adjust Fixed some styling regressions from latest features","title":"1.11.1 _ November 29, 2020"},{"location":"insiders/changelog/#1.11.0","text":"Added support for rendering admonitions as inline blocks","title":"1.11.0 _ November 22, 2020"},{"location":"insiders/changelog/#1.10.0","text":"Added support for integrating table of contents into navigation","title":"1.10.0 _ November 15, 2020"},{"location":"insiders/changelog/#1.9.0","text":"Added support for hiding navigation and table of contents on any page Removed autohiding table of contents when empty","title":"1.9.0 _ November 7, 2020"},{"location":"insiders/changelog/#1.8.0","text":"Added support for navigation sections Fixed appearance of inactive search suggestions","title":"1.8.0 _ November 1, 2020"},{"location":"insiders/changelog/#1.7.0","text":"Added support for deploying multiple versions Fixed alignment of sidebar when content area is too small","title":"1.7.0 _ October 25, 2020"},{"location":"insiders/changelog/#1.6.0","text":"Added support for search suggestions to save keystrokes Added support for removing Made with Material for MkDocs from footer Fixed #1915 : search should go to first result by pressing Enter","title":"1.6.0 _ October 11, 2020"},{"location":"insiders/changelog/#1.5.1","text":"Fixed content area stretching to whole width for long code blocks","title":"1.5.1 _ September 21, 2020"},{"location":"insiders/changelog/#1.5.0","text":"Added support for autohiding table of contents when empty","title":"1.5.0 _ September 19, 2020"},{"location":"insiders/changelog/#1.4.1","text":"Improved typeahead and search result relevance and scoring","title":"1.4.1 _ September 6, 2020"},{"location":"insiders/changelog/#1.4.0","text":"Added support for autohiding header on scroll","title":"1.4.0 _ August 30, 2020"},{"location":"insiders/changelog/#1.3.0","text":"Added support for user-selectable color palettes","title":"1.3.0 _ August 26, 2020"},{"location":"insiders/changelog/#1.2.0","text":"Added feature to expand navigation by default","title":"1.2.0 _ August 11, 2020"},{"location":"insiders/changelog/#1.1.0","text":"Added highlighting of search results","title":"1.1.0 _ August 3, 2020"},{"location":"insiders/changelog/#1.0.0","text":"Added grouping of search results Added missing query terms to search result Improved search result relevance and scoring","title":"1.0.0 _ July 14, 2020"},{"location":"insiders/getting-started/","text":"Getting started with Insiders \u00b6 Material for MkDocs Insiders is a compatible drop-in replacement for Material for MkDocs, and can be installed similarily using pip , docker or git . Note that in order to access the Insiders repository, you need to become an eligible sponsor of @squidfunk on GitHub. Requirements \u00b6 After you've been added to the list of collaborators and accepted the repository invitation, the next step is to create a personal access token for your GitHub account in order to access the Insiders repository programmatically (from the command line or GitHub Actions workflows): Go to https://github.com/settings/tokens Click on Generate a new token Enter a name and select the repo scope Generate the token and store it in a safe place Installation \u00b6 with pip \u00b6 Material for MkDocs Insiders can be installed with pip : pip install git+https:// ${ GH_TOKEN } @github.com/squidfunk/mkdocs-material-insiders.git The GH_TOKEN environment variable must be set to the value of the personal access token you generated in the previous step. Note that the personal access token must be kept secret at all times, as it allows the owner to access your private repositories. with docker \u00b6 In case you want to use Material for MkDocs Insiders from within Docker, some additional steps are necessary. While we cannot provide a hosted Docker image for Insiders 1 , GitHub Container Registry allows for simple and comfortable self-hosting: Fork the Insiders repository Enable GitHub Actions on your fork 2 Create a new personal access token 3 Go to https://github.com/settings/tokens Click on Generate a new token Enter a name and select the write:packages scope Generate the token and store it in a safe place Add a GitHub Actions secret on your fork Set the name to GHCR_TOKEN Set the value to the personal access token created in the previous step Create a new release to build and publish the Docker image Install Pull App on your fork to stay in-sync with upstream The publish workflow 4 is automatically run when a new tag (release) is created. When a new Insiders version is released on the upstream repository, the Pull App will create a pull request with the changes and pull in the new tag, which is picked up by the publish workflow that builds and publishes the Docker image automatically to your private registry. Now, you should be able to pull the Docker image from your private registry: docker login -u ${GH_USERNAME} -p ${GHCR_TOKEN} ghcr.io docker pull ghcr.io/${GH_USERNAME}/mkdocs-material-insiders with git \u00b6 Of course, you can use Material for MkDocs Insiders directly from git : git clone git@github.com:squidfunk/mkdocs-material-insiders.git mkdocs-material The theme will reside in the folder mkdocs-material/material . When cloning from git , the theme must be installed, so MkDocs can find the built-in plugins: pip install -e mkdocs-material Upgrading \u00b6 When upgrading Insiders, you should always check the version of Material for MkDocs which makes up the first part of the version qualifier, e.g.Insiders 4.x.x is currently based on 8.x.x : 8.x.x-insiders-4.x.x If the major version increased, it's a good idea to consult the upgrade guide and go through the steps to ensure your configuration is up to date and all necessary changes have been made. If you installed Insiders via pip , you can upgrade your installation with the following command: pip install --upgrade git+https://${GH_TOKEN}@github.com/squidfunk/mkdocs-material-insiders.git Caveats \u00b6 This section describes some aspects to consider when using Insiders together with Material for MkDocs to ensure that users without access to Insiders can still build your documentation. Built-in plugins \u00b6 When using built-in plugins that are solely available via Insiders, it might be necessary to split the mkdocs.yml configuration into a base configuration, and one with plugin overrides. Note that this is a limitation of MkDocs, which can be mitigated by using configuration inheritance : mkdocs.insiders.yml mkdocs.yml INHERIT : mkdocs.yml plugins : - search - social - tags # Configuration with everything except Insiders plugins Now, when you're in an environment with access to Insiders (e.g. in your CI pipeline), you can build your documentation project with the following lines: mkdocs build --config-file mkdocs.insiders.yml Sharing plugin and extension configuration If you want to share plugins or markdown_extensions between both configuration files mkdocs.insiders.yml and mkdocs.yml , you can use the alternative key-value syntax in both files. The above example would then look like: mkdocs.insiders.yml mkdocs.yml INHERIT : mkdocs.yml plugins : social : {} # Additional configuration above plugins : search : {} tags : {} Earlier, Insiders provided a dedicated Docker image which was available to all sponsors. On March 21, 2021, the image was deprecated for the reasons outlined and discussed in #2442 . It was removed on June 1, 2021. \u21a9 When forking a repository, GitHub will disables all workflows. While this is a reasonable default setting, you need to enable GitHub Actions to be able to automatically build and publish a Docker image on GitHub Container Registry . \u21a9 While you could just add the write:packages scope to the personal access token created to access the Insiders repository, it's safer to create a dedicated token which you'll only use for publishing the Docker image. \u21a9 The Insiders repository contains two GitHub Actions workflows: build.yml \u2013 Build and lint the project (disabled on forks) publish.yml \u2013 Build and publish the Docker image \u21a9","title":"Getting started with Insiders"},{"location":"insiders/getting-started/#getting-started-with-insiders","text":"Material for MkDocs Insiders is a compatible drop-in replacement for Material for MkDocs, and can be installed similarily using pip , docker or git . Note that in order to access the Insiders repository, you need to become an eligible sponsor of @squidfunk on GitHub.","title":"Getting started with Insiders"},{"location":"insiders/getting-started/#requirements","text":"After you've been added to the list of collaborators and accepted the repository invitation, the next step is to create a personal access token for your GitHub account in order to access the Insiders repository programmatically (from the command line or GitHub Actions workflows): Go to https://github.com/settings/tokens Click on Generate a new token Enter a name and select the repo scope Generate the token and store it in a safe place","title":"Requirements"},{"location":"insiders/getting-started/#installation","text":"","title":"Installation"},{"location":"insiders/getting-started/#with-pip","text":"Material for MkDocs Insiders can be installed with pip : pip install git+https:// ${ GH_TOKEN } @github.com/squidfunk/mkdocs-material-insiders.git The GH_TOKEN environment variable must be set to the value of the personal access token you generated in the previous step. Note that the personal access token must be kept secret at all times, as it allows the owner to access your private repositories.","title":"with pip"},{"location":"insiders/getting-started/#with-docker","text":"In case you want to use Material for MkDocs Insiders from within Docker, some additional steps are necessary. While we cannot provide a hosted Docker image for Insiders 1 , GitHub Container Registry allows for simple and comfortable self-hosting: Fork the Insiders repository Enable GitHub Actions on your fork 2 Create a new personal access token 3 Go to https://github.com/settings/tokens Click on Generate a new token Enter a name and select the write:packages scope Generate the token and store it in a safe place Add a GitHub Actions secret on your fork Set the name to GHCR_TOKEN Set the value to the personal access token created in the previous step Create a new release to build and publish the Docker image Install Pull App on your fork to stay in-sync with upstream The publish workflow 4 is automatically run when a new tag (release) is created. When a new Insiders version is released on the upstream repository, the Pull App will create a pull request with the changes and pull in the new tag, which is picked up by the publish workflow that builds and publishes the Docker image automatically to your private registry. Now, you should be able to pull the Docker image from your private registry: docker login -u ${GH_USERNAME} -p ${GHCR_TOKEN} ghcr.io docker pull ghcr.io/${GH_USERNAME}/mkdocs-material-insiders","title":"with docker"},{"location":"insiders/getting-started/#with-git","text":"Of course, you can use Material for MkDocs Insiders directly from git : git clone git@github.com:squidfunk/mkdocs-material-insiders.git mkdocs-material The theme will reside in the folder mkdocs-material/material . When cloning from git , the theme must be installed, so MkDocs can find the built-in plugins: pip install -e mkdocs-material","title":"with git"},{"location":"insiders/getting-started/#upgrading","text":"When upgrading Insiders, you should always check the version of Material for MkDocs which makes up the first part of the version qualifier, e.g.Insiders 4.x.x is currently based on 8.x.x : 8.x.x-insiders-4.x.x If the major version increased, it's a good idea to consult the upgrade guide and go through the steps to ensure your configuration is up to date and all necessary changes have been made. If you installed Insiders via pip , you can upgrade your installation with the following command: pip install --upgrade git+https://${GH_TOKEN}@github.com/squidfunk/mkdocs-material-insiders.git","title":"Upgrading"},{"location":"insiders/getting-started/#caveats","text":"This section describes some aspects to consider when using Insiders together with Material for MkDocs to ensure that users without access to Insiders can still build your documentation.","title":"Caveats"},{"location":"insiders/getting-started/#built-in-plugins","text":"When using built-in plugins that are solely available via Insiders, it might be necessary to split the mkdocs.yml configuration into a base configuration, and one with plugin overrides. Note that this is a limitation of MkDocs, which can be mitigated by using configuration inheritance : mkdocs.insiders.yml mkdocs.yml INHERIT : mkdocs.yml plugins : - search - social - tags # Configuration with everything except Insiders plugins Now, when you're in an environment with access to Insiders (e.g. in your CI pipeline), you can build your documentation project with the following lines: mkdocs build --config-file mkdocs.insiders.yml Sharing plugin and extension configuration If you want to share plugins or markdown_extensions between both configuration files mkdocs.insiders.yml and mkdocs.yml , you can use the alternative key-value syntax in both files. The above example would then look like: mkdocs.insiders.yml mkdocs.yml INHERIT : mkdocs.yml plugins : social : {} # Additional configuration above plugins : search : {} tags : {} Earlier, Insiders provided a dedicated Docker image which was available to all sponsors. On March 21, 2021, the image was deprecated for the reasons outlined and discussed in #2442 . It was removed on June 1, 2021. \u21a9 When forking a repository, GitHub will disables all workflows. While this is a reasonable default setting, you need to enable GitHub Actions to be able to automatically build and publish a Docker image on GitHub Container Registry . \u21a9 While you could just add the write:packages scope to the personal access token created to access the Insiders repository, it's safer to create a dedicated token which you'll only use for publishing the Docker image. \u21a9 The Insiders repository contains two GitHub Actions workflows: build.yml \u2013 Build and lint the project (disabled on forks) publish.yml \u2013 Build and publish the Docker image \u21a9","title":"Built-in plugins"},{"location":"public/myvideos/","text":"[[Rust 2021 A Scratch Blockchain-1]] Rust 2021 A Scratch Blockchain-1 [[Rust 2021 A Scratch Blockchain-2]] Rust 2021 A Scratch Blockchain-2 [[Solidity]] Solidity [[Guide-Website]] Guide-Website [[AboutMe]] AboutMe","title":"Myvideos"},{"location":"public/public/","text":"Day-Notes 2022 Blockchain Rust Programming Commands DevOps Engineer Cryptocurrency-Trade Master Thesis Archive-Projects How to learn quickly RoadMap Links Preferred Films Of Website Entertainment","title":"Walk-through"},{"location":"public/archive/archive-2016-2019/","text":"[[Archived]]-2016-2019 \u00b6 Devops Engineer Demo version of organization portal Angular 6 GraphQl SqlServer Rest Api 2018 Management e-commerce Deployed On Container & Orchestration with Kubernetes MongoDB Asp.#NetCore 3.1 2020 Management e-commerce 1 Management e-commerce 2 Management e-commerce 3 Angular 6 \u00b6 GraphQl \u00b6 SqlServer \u00b6 MongoDB \u00b6 Asp.Netcore \u00b6 Container & #Orchestration with #Kubernetes \u00b6","title":"[[Archived]]-2016-2019"},{"location":"public/archive/archive-2016-2019/#archived-2016-2019","text":"Devops Engineer Demo version of organization portal Angular 6 GraphQl SqlServer Rest Api 2018 Management e-commerce Deployed On Container & Orchestration with Kubernetes MongoDB Asp.#NetCore 3.1 2020 Management e-commerce 1 Management e-commerce 2 Management e-commerce 3","title":"[[Archived]]-2016-2019"},{"location":"public/archive/archive-2016-2019/#angular-6","text":"","title":"Angular 6"},{"location":"public/archive/archive-2016-2019/#graphql","text":"","title":"GraphQl"},{"location":"public/archive/archive-2016-2019/#sqlserver","text":"","title":"SqlServer"},{"location":"public/archive/archive-2016-2019/#mongodb","text":"","title":"MongoDB"},{"location":"public/archive/archive-2016-2019/#aspnetcore","text":"","title":"Asp.Netcore"},{"location":"public/archive/archive-2016-2019/#container-orchestration-with-kubernetes","text":"","title":"Container &amp; #Orchestration with #Kubernetes"},{"location":"public/archive/archive-2019-2020/","text":"[[Archived]]-2019-2020 \u00b6 Devops Engineer Reactjs-API-CouchDB API-CouchDB-IBMCloud Crypto Trading","title":"[[Archived]]-2019-2020"},{"location":"public/archive/archive-2019-2020/#archived-2019-2020","text":"Devops Engineer Reactjs-API-CouchDB API-CouchDB-IBMCloud Crypto Trading","title":"[[Archived]]-2019-2020"},{"location":"public/archive/archive-until-2016/","text":"[[Archived]]-until-2016 \u00b6 Website Cultural Store CMS builder Website Carpet Factory Website Computer Store Resume WebSite Website Sales Photo Dadyar-Advocacy Software CNG Warehouse Software University Archive Software Website Conference Base on Network-P2P Info","title":"[[Archived]]-until-2016"},{"location":"public/archive/archive-until-2016/#archived-until-2016","text":"Website Cultural Store CMS builder Website Carpet Factory Website Computer Store Resume WebSite Website Sales Photo Dadyar-Advocacy Software CNG Warehouse Software University Archive Software Website Conference Base on Network-P2P Info","title":"[[Archived]]-until-2016"},{"location":"public/archive/archive/","text":"2019-2020 2016-2019 Until-2016","title":"Archive"},{"location":"public/archive/cms-builder/","text":"CMS Builder [[Archived]] \u00b6 Use AngularJs & WebApi technology Responds to all your operations without the need to refresh the page Single Page Application SPA Define tree structure #Angular \u00b6 #SPA \u00b6 #CMS \u00b6 Info","title":"CMS Builder [[Archived]]"},{"location":"public/archive/cms-builder/#cms-builder-archived","text":"Use AngularJs & WebApi technology Responds to all your operations without the need to refresh the page Single Page Application SPA Define tree structure","title":"CMS Builder [[Archived]]"},{"location":"public/archive/cms-builder/#angular","text":"","title":"#Angular"},{"location":"public/archive/cms-builder/#spa","text":"","title":"#SPA"},{"location":"public/archive/cms-builder/#cms","text":"Info","title":"#CMS"},{"location":"public/archive/cng/","text":"CNG Warehouse Software [[Archived]] \u00b6 Advanced reporting features with a variety of search filters by Crystal Report Computing facilities in the accounting department and presenting invoices to the Customer Very user friendly interface Dynamic content presentation Security facilities for anonymous people to enter Ability to remind checks on the main page of the application #Reporter \u00b6 #Desktop \u00b6 #Windows \u00b6 #Telerik \u00b6 Info","title":"CNG Warehouse Software [[Archived]]"},{"location":"public/archive/cng/#cng-warehouse-software-archived","text":"Advanced reporting features with a variety of search filters by Crystal Report Computing facilities in the accounting department and presenting invoices to the Customer Very user friendly interface Dynamic content presentation Security facilities for anonymous people to enter Ability to remind checks on the main page of the application","title":"CNG Warehouse Software [[Archived]]"},{"location":"public/archive/cng/#reporter","text":"","title":"#Reporter"},{"location":"public/archive/cng/#desktop","text":"","title":"#Desktop"},{"location":"public/archive/cng/#windows","text":"","title":"#Windows"},{"location":"public/archive/cng/#telerik","text":"Info","title":"#Telerik"},{"location":"public/archive/dadyar/","text":"Advocate-Dadyar [[Archived]] \u00b6 Advanced reporting features with a variety of search filters by Crystal Report Dynamic printing facilities for all types of petition forms and ... Has a very strong and stylish user interface Record client details Has dynamic content presentation Security facilities for anonymous people to enter #Windows \u00b6 #CrystalReporter \u00b6 #Printer \u00b6 #Telerik \u00b6 Info None","title":"Dadyar"},{"location":"public/archive/dadyar/#advocate-dadyar-archived","text":"Advanced reporting features with a variety of search filters by Crystal Report Dynamic printing facilities for all types of petition forms and ... Has a very strong and stylish user interface Record client details Has dynamic content presentation Security facilities for anonymous people to enter","title":"Advocate-Dadyar [[Archived]]"},{"location":"public/archive/dadyar/#windows","text":"","title":"#Windows"},{"location":"public/archive/dadyar/#crystalreporter","text":"","title":"#CrystalReporter"},{"location":"public/archive/dadyar/#printer","text":"","title":"#Printer"},{"location":"public/archive/dadyar/#telerik","text":"Info None","title":"#Telerik"},{"location":"public/archive/main/","text":"Archive 2019-2020 Archive 2016-2019 Archive before 2016","title":"Main"},{"location":"public/archive/my-old-website/","text":"My Old Resume WebSite [[Archived]] \u00b6 Used MVC architecture Script features to display the slide section as well as on the main page of the site Define dynamic photos and upload for display in the Slide Show section ##### #MVC ##### C# ##### #JQuery Info","title":"My Old Resume WebSite [[Archived]]"},{"location":"public/archive/my-old-website/#my-old-resume-website-archived","text":"Used MVC architecture Script features to display the slide section as well as on the main page of the site Define dynamic photos and upload for display in the Slide Show section ##### #MVC ##### C# ##### #JQuery Info","title":"My Old Resume WebSite [[Archived]]"},{"location":"public/archive/trading-archive-2021/","text":"[[Archived]] Trade 2021 \u00b6 Captured Films Without translating To English Monetization and how to use the digital currency platform-Part 1 Monetization and how to use the digital currency platform-Part 2 Spot trading in low-risk-Binance-Part 1 Future trading-Binance-Part 2-1 Future trading-Binance-Part 2-2 Trading on the Binance-Part 3","title":"[[Archived]] Trade 2021"},{"location":"public/archive/trading-archive-2021/#archived-trade-2021","text":"Captured Films Without translating To English Monetization and how to use the digital currency platform-Part 1 Monetization and how to use the digital currency platform-Part 2 Spot trading in low-risk-Binance-Part 1 Future trading-Binance-Part 2-1 Future trading-Binance-Part 2-2 Trading on the Binance-Part 3","title":"[[Archived]] Trade 2021"},{"location":"public/archive/university-archive-software/","text":"University Archive Software [[Archived]] \u00b6 Advanced reporting features with a variety of search filters by Crystal Report The software is under the network within the organization User friendly interface Dynamics in content presentation and reporting Archive files with serial number and barcode Archive #Software \u00b6 Network \u00b6 #SqlServer \u00b6 Socket \u00b6 #Windows \u00b6 C \u00b6 Info","title":"University Archive Software [[Archived]]"},{"location":"public/archive/university-archive-software/#university-archive-software-archived","text":"Advanced reporting features with a variety of search filters by Crystal Report The software is under the network within the organization User friendly interface Dynamics in content presentation and reporting Archive files with serial number and barcode","title":"University Archive Software [[Archived]]"},{"location":"public/archive/university-archive-software/#archive-software","text":"","title":"Archive #Software"},{"location":"public/archive/university-archive-software/#network","text":"","title":"Network"},{"location":"public/archive/university-archive-software/#sqlserver","text":"","title":"#SqlServer"},{"location":"public/archive/university-archive-software/#socket","text":"","title":"Socket"},{"location":"public/archive/university-archive-software/#windows","text":"","title":"#Windows"},{"location":"public/archive/university-archive-software/#c","text":"Info","title":"C"},{"location":"public/archive/website-carpet-factory/","text":"WebSite Carpet Factory [[Archived]] \u00b6 Possibility of electronic payment Send promotional SMS as well as after each customer purchase Post a poll without refreshing the browser Script features to display the gallery section and also on the main page of the site Ability to insert news dynamically It has got separate CRM section ##### [[CRM]] ##### Electronic Payment ##### [[ASP.NET]] ##### #SMS ##### [[Payment]] [[Archive]] Info","title":"WebSite Carpet Factory [[Archived]]"},{"location":"public/archive/website-carpet-factory/#website-carpet-factory-archived","text":"Possibility of electronic payment Send promotional SMS as well as after each customer purchase Post a poll without refreshing the browser Script features to display the gallery section and also on the main page of the site Ability to insert news dynamically It has got separate CRM section ##### [[CRM]] ##### Electronic Payment ##### [[ASP.NET]] ##### #SMS ##### [[Payment]] [[Archive]] Info","title":"WebSite Carpet Factory [[Archived]]"},{"location":"public/archive/website-computer-store/","text":"Website Computer Store [[Archived]] \u00b6 Used MVC architecture Event-oriented Drag & Drop home screen Script features to display the slide section as well as on the main page of the site Define dynamic photos and upload for display in the Slide Show section Define their category management of products Possibility of electronic payment by PEC WebServices #MVC \u00b6 #JQuery \u00b6 #CMS \u00b6 #Electronic Payment \u00b6 C \u00b6 Info","title":"Website Computer Store [[Archived]]"},{"location":"public/archive/website-computer-store/#website-computer-store-archived","text":"Used MVC architecture Event-oriented Drag & Drop home screen Script features to display the slide section as well as on the main page of the site Define dynamic photos and upload for display in the Slide Show section Define their category management of products Possibility of electronic payment by PEC WebServices","title":"Website Computer Store [[Archived]]"},{"location":"public/archive/website-computer-store/#mvc","text":"","title":"#MVC"},{"location":"public/archive/website-computer-store/#jquery","text":"","title":"#JQuery"},{"location":"public/archive/website-computer-store/#cms","text":"","title":"#CMS"},{"location":"public/archive/website-computer-store/#electronic-payment","text":"","title":"#Electronic Payment"},{"location":"public/archive/website-computer-store/#c","text":"Info","title":"C"},{"location":"public/archive/website-conference/","text":"Website Conference Base on Network-P2P [[Archived]] \u00b6 No need to install any software through the Silverlight web browser plugin/extension. Contains management software of the desktop application type on the server as well as coded (Socket-SilverLight) on web clients that call the server ID on their browser. Ability to text chat and send files simultaneously and online #Conference \u00b6 Network Conference Site \u00b6 #WebApp Chat \u00b6 Network #Software \u00b6 Simultaneous chat schedule \u00b6 #Silverlight \u00b6 C \u00b6 Info","title":"Website Conference Base on Network-P2P [[Archived]]"},{"location":"public/archive/website-conference/#website-conference-base-on-network-p2p-archived","text":"No need to install any software through the Silverlight web browser plugin/extension. Contains management software of the desktop application type on the server as well as coded (Socket-SilverLight) on web clients that call the server ID on their browser. Ability to text chat and send files simultaneously and online","title":"Website Conference Base on Network-P2P [[Archived]]"},{"location":"public/archive/website-conference/#conference","text":"","title":"#Conference"},{"location":"public/archive/website-conference/#network-conference-site","text":"","title":"Network Conference Site"},{"location":"public/archive/website-conference/#webapp-chat","text":"","title":"#WebApp Chat"},{"location":"public/archive/website-conference/#network-software","text":"","title":"Network #Software"},{"location":"public/archive/website-conference/#simultaneous-chat-schedule","text":"","title":"Simultaneous chat schedule"},{"location":"public/archive/website-conference/#silverlight","text":"","title":"#Silverlight"},{"location":"public/archive/website-conference/#c","text":"Info","title":"C"},{"location":"public/archive/website-cultural-store/","text":"Website Cultural Store [[Archived]] \u00b6 Used AngularJs & WebApi technology Respond to all user operations synchronously without to need to refresh the page Single Page Application Having a shopping cart dynamically and simultaneously Display the contents of orders completely simultaneously Used BootStrap Dynamic categories from the Category attribute with getting updates from the database ##### #Angularjs ##### #Electronic Payment ##### #SPA ##### #BootStrap ##### C# Info","title":"Website Cultural Store [[Archived]]"},{"location":"public/archive/website-cultural-store/#website-cultural-store-archived","text":"Used AngularJs & WebApi technology Respond to all user operations synchronously without to need to refresh the page Single Page Application Having a shopping cart dynamically and simultaneously Display the contents of orders completely simultaneously Used BootStrap Dynamic categories from the Category attribute with getting updates from the database ##### #Angularjs ##### #Electronic Payment ##### #SPA ##### #BootStrap ##### C# Info","title":"Website Cultural Store [[Archived]]"},{"location":"public/archive/website-sales-photo/","text":"WebSite Sales Photo [[Archived]] \u00b6 Ability to online payment Ability to upload and download multiple image files simultaneously Having a website visitor statistics section Ability to search advanced images in the gallery Script features to display the gallery section and also on the main page of the site Ability to insert news dynamically Having a separated CRM section [[CRM]] \u00b6 Electronic Payment \u00b6 Editor \u00b6 Filter \u00b6 Crop \u00b6 [[ASP.NET]] \u00b6 [[C#]] \u00b6 [[Archive]] Info","title":"WebSite Sales Photo [[Archived]]"},{"location":"public/archive/website-sales-photo/#website-sales-photo-archived","text":"Ability to online payment Ability to upload and download multiple image files simultaneously Having a website visitor statistics section Ability to search advanced images in the gallery Script features to display the gallery section and also on the main page of the site Ability to insert news dynamically Having a separated CRM section","title":"WebSite Sales Photo [[Archived]]"},{"location":"public/archive/website-sales-photo/#crm","text":"","title":"[[CRM]]"},{"location":"public/archive/website-sales-photo/#electronic-payment","text":"","title":"Electronic Payment"},{"location":"public/archive/website-sales-photo/#editor","text":"","title":"Editor"},{"location":"public/archive/website-sales-photo/#filter","text":"","title":"Filter"},{"location":"public/archive/website-sales-photo/#crop","text":"","title":"Crop"},{"location":"public/archive/website-sales-photo/#aspnet","text":"","title":"[[ASP.NET]]"},{"location":"public/archive/website-sales-photo/#c","text":"[[Archive]] Info","title":"[[C#]]"},{"location":"public/blockchain/Blockchain-tutorials/","text":"\u25d8 BlockV BlockV - Enterprise Plug & Play Interoperability, TV, VR \u25d8 UniBright UniBright- Dashboard with Any block,360\u00b0 Security token platform(Token Generator), Cross-chain functionality, Voting template, Milestone Payment template. \u25d8 Blockstream Blockstream - Liquid Swaps, multi-part payments by c-lightning plugins. Prometheus Plugin and Grafana, Script can be used to represent complex conditions required to release a transaction by Miniscript. \u25d8 Blockstack Blockstack - Modular, supply minimal infrastructure for hosting the application code, don't need to worry about maintaining and securing databases, universal usernames. \u25d8 DTube DTube - Design new model Avalon social blockchain\u200a-\u200aSimplify User Experience \u25d8 Quorum Quorum - Tools: Cakeshop IDE,Quorum Wizard npm,anonymous-zether payment system. \u25d8 IBM IBM - Contains \"vscode\" extensions. \u25d8 SkyCoin SkyCoin Blockchain popular [[platforms]] \u25d8 BlockV \u00b6 BlockV - Enterprise Plug & Play Interoperability, TV, VR \u00b6 \u25d8 UniBright \u00b6 UniBright- Dashboard with Any block,360\u00b0 Security token platform(Token Generator), Cross-chain functionality, Voting template, Milestone Payment template. \u00b6 Unibright Framework: (Workflow Designer),(Lifecycle Manager),(Connector),(Explorer) Unibright Framework consists of 4 components to visually define business processes (Workflow Designer), publish and maintain automatically generated smart contracts to different blockchains (Lifecycle Manager), integrate these contracts with on- and off-chain system landscapes (Connector) and visually monitor all ongoing processes (Explorer). \u25d8 Blockstream \u00b6 Blockstream - Liquid Swaps, multi-part payments by c-lightning plugins. Prometheus Plugin and Grafana, Script can be used to represent complex conditions required to release a transaction by Miniscript. \u00b6 Miniscript: efficient analysis, composition, generic signing. Transaction: Data Feed(History Transaction), low transaction weights Main Systems: (Liquid),(Elements),(Satellite network) \u25d8 Blockstack \u00b6 Blockstack - Modular, supply minimal infrastructure for hosting the application code, don't need to worry about maintaining and securing databases, universal usernames. \u00b6 (build high-quality applications).(Tunable Proofs election system to securely bootstrap a new blockchain).(on-chain expressibility). (security and predictability of smart contracts). (admitting static analysis for all transactions.)(decentralized storage system, called Gaia).(A universal ID and authentication system, called Blockstack Auth),(do not need to worry about running servers or databases.)(Blockstack's \ufb01rst-generation blockchain operated logically on top of Layer-1 (L1), and each transaction was in 1-to-1 correspondence with an L1 Bitcoin transaction).(Have a Browser) Ease of Use, Scalability User Control Minimal logic and state at the blockchain layer Localized state changes vs. global state changes Reliable cloud-like storage vs. peer storage Full-stack SDKs for developers A novel peer network (Atlas).Blockstack DApps are not required to use smart contracts at all.v2 general-purpose smart contracts written in a non-Turing-complete language \u25d8 DTube \u00b6 DTube - Design new model Avalon social blockchain\u200a-\u200aSimplify User Experience \u00b6 Users on the DTube Chain will now earn 1 single liquid cryptocurrency token: the DTC (instead of 3 on Steem). Spending Voting Power (VP) is simplified and all rewards are collected in real time. Ease adoption Creating an account on DTube Chain will be instant and as easy as 2 clicks (versus a few weeks on Steem) Increase retention On DTube Chain, VP stacks up indefinitely to incentive returning visitors (on Steem, voting power caps after a few days of user inactivity). Foster long term user growth with a dynamic inflation\u200a-\u200aBenefits of the DTube Chain: More efficient governance DTube Chain is a decentralized organization governed by leaders. It is much easier to obtain a consensus and implement changes for the DTube community where all stakeholders interests are aligned rather than on Steem where more than 400 Apps share the same chain and economy, yet gave different interests and visions. (Higher scalability). DTube Chain, which is exclusively dedicated to the DTube app, can handle thousands of transactions per second (i.e. tens of millions of daily active users). On Steem, DApps need to share bandwidth generation which limits the overall capacity of each app. Focus on Transaction manager is very good. Transaction manager\u200a-\u200aQurioum node\u200a-\u200aGood Api -Local state database on node and Transaction manager. DTube, at the first implemented on Steem Network\u200a-\u200ait's own DTube Chain, DTC (Type of IEO), DTube Chain is a \"onechain-oneapp\" model where each App uses its own blockchain database in opposition to the classic model where all users and programs share and pay a transaction fee to the same Chain. \u25d8 Quorum \u00b6 Quorum - Tools: Cakeshop IDE,Quorum Wizard npm,anonymous-zether payment system. \u00b6 Based on the official Go implementation of the Ethereum.We're powered by strong partnerships with Microsoft and JPMorgan. \u25d8 IBM \u00b6 IBM - Contains \"vscode\" extensions. \u00b6 Simplified DevOps in a seamless environment for your team to move easily from development to test to production. Peer, Ordering Service, Certificate Authority. Start small, with no upfront investment. Then pay as you grow and upgrade easily through Kubernetes. Connect to nodes running in any environment (on-premises, public, hybrid clouds). Easily connect a single peer to multiple industry networks. \u25d8 SkyCoin \u00b6 SkyCoin \u00b6 Lightning Fast Zero Fees Secure Private Sustainable Incentivized Utility Backed Free Fee Transaction Skycoin: fast and secure currency backed by bandwidth. Skywire: anonymous, decentralized mesh-Internet. Skyminer: hardware and access point for Skywire. Fiber: decentralized open blockchain network. Skysuite: suite of decentralized applications. armanriazi/Doc-Blockchain Contribute to armanriazi/Doc-Blockchain development by creating an account on GitHub.github.com","title":"Blockchain tutorials"},{"location":"public/blockchain/Blockchain-tutorials/#blockv","text":"","title":"\u25d8 BlockV"},{"location":"public/blockchain/Blockchain-tutorials/#blockv-enterprise-plug-play-interoperability-tv-vr","text":"","title":"BlockV - Enterprise Plug &amp; Play Interoperability, TV, VR"},{"location":"public/blockchain/Blockchain-tutorials/#unibright","text":"","title":"\u25d8 UniBright"},{"location":"public/blockchain/Blockchain-tutorials/#unibright-dashboard-with-any-block360-security-token-platformtoken-generator-cross-chain-functionality-voting-template-milestone-payment-template","text":"Unibright Framework: (Workflow Designer),(Lifecycle Manager),(Connector),(Explorer) Unibright Framework consists of 4 components to visually define business processes (Workflow Designer), publish and maintain automatically generated smart contracts to different blockchains (Lifecycle Manager), integrate these contracts with on- and off-chain system landscapes (Connector) and visually monitor all ongoing processes (Explorer).","title":"UniBright- Dashboard with Any block,360\u00b0 Security token platform(Token Generator), Cross-chain functionality, Voting template, Milestone Payment template."},{"location":"public/blockchain/Blockchain-tutorials/#blockstream","text":"","title":"\u25d8 Blockstream"},{"location":"public/blockchain/Blockchain-tutorials/#blockstream-liquid-swaps-multi-part-payments-by-c-lightning-plugins-prometheus-plugin-and-grafana-script-can-be-used-to-represent-complex-conditions-required-to-release-a-transaction-by-miniscript","text":"Miniscript: efficient analysis, composition, generic signing. Transaction: Data Feed(History Transaction), low transaction weights Main Systems: (Liquid),(Elements),(Satellite network)","title":"Blockstream - Liquid Swaps, multi-part payments by c-lightning plugins. Prometheus Plugin and Grafana, Script can be used to represent complex conditions required to release a transaction by Miniscript."},{"location":"public/blockchain/Blockchain-tutorials/#blockstack","text":"","title":"\u25d8 Blockstack"},{"location":"public/blockchain/Blockchain-tutorials/#blockstack-modular-supply-minimal-infrastructure-for-hosting-the-application-code-dont-need-to-worry-about-maintaining-and-securing-databases-universal-usernames","text":"(build high-quality applications).(Tunable Proofs election system to securely bootstrap a new blockchain).(on-chain expressibility). (security and predictability of smart contracts). (admitting static analysis for all transactions.)(decentralized storage system, called Gaia).(A universal ID and authentication system, called Blockstack Auth),(do not need to worry about running servers or databases.)(Blockstack's \ufb01rst-generation blockchain operated logically on top of Layer-1 (L1), and each transaction was in 1-to-1 correspondence with an L1 Bitcoin transaction).(Have a Browser) Ease of Use, Scalability User Control Minimal logic and state at the blockchain layer Localized state changes vs. global state changes Reliable cloud-like storage vs. peer storage Full-stack SDKs for developers A novel peer network (Atlas).Blockstack DApps are not required to use smart contracts at all.v2 general-purpose smart contracts written in a non-Turing-complete language","title":"Blockstack - Modular, supply minimal infrastructure for hosting the application code, don't need to worry about maintaining and securing databases, universal usernames."},{"location":"public/blockchain/Blockchain-tutorials/#dtube","text":"","title":"\u25d8 DTube"},{"location":"public/blockchain/Blockchain-tutorials/#dtube-design-new-model-avalon-social-blockchain-simplify-user-experience","text":"Users on the DTube Chain will now earn 1 single liquid cryptocurrency token: the DTC (instead of 3 on Steem). Spending Voting Power (VP) is simplified and all rewards are collected in real time. Ease adoption Creating an account on DTube Chain will be instant and as easy as 2 clicks (versus a few weeks on Steem) Increase retention On DTube Chain, VP stacks up indefinitely to incentive returning visitors (on Steem, voting power caps after a few days of user inactivity). Foster long term user growth with a dynamic inflation\u200a-\u200aBenefits of the DTube Chain: More efficient governance DTube Chain is a decentralized organization governed by leaders. It is much easier to obtain a consensus and implement changes for the DTube community where all stakeholders interests are aligned rather than on Steem where more than 400 Apps share the same chain and economy, yet gave different interests and visions. (Higher scalability). DTube Chain, which is exclusively dedicated to the DTube app, can handle thousands of transactions per second (i.e. tens of millions of daily active users). On Steem, DApps need to share bandwidth generation which limits the overall capacity of each app. Focus on Transaction manager is very good. Transaction manager\u200a-\u200aQurioum node\u200a-\u200aGood Api -Local state database on node and Transaction manager. DTube, at the first implemented on Steem Network\u200a-\u200ait's own DTube Chain, DTC (Type of IEO), DTube Chain is a \"onechain-oneapp\" model where each App uses its own blockchain database in opposition to the classic model where all users and programs share and pay a transaction fee to the same Chain.","title":"DTube - Design new model Avalon social blockchain\u200a-\u200aSimplify User Experience"},{"location":"public/blockchain/Blockchain-tutorials/#quorum","text":"","title":"\u25d8 Quorum"},{"location":"public/blockchain/Blockchain-tutorials/#quorum-tools-cakeshop-idequorum-wizard-npmanonymous-zether-payment-system","text":"Based on the official Go implementation of the Ethereum.We're powered by strong partnerships with Microsoft and JPMorgan.","title":"Quorum - Tools: Cakeshop IDE,Quorum Wizard npm,anonymous-zether payment system."},{"location":"public/blockchain/Blockchain-tutorials/#ibm","text":"","title":"\u25d8 IBM"},{"location":"public/blockchain/Blockchain-tutorials/#ibm-contains-vscode-extensions","text":"Simplified DevOps in a seamless environment for your team to move easily from development to test to production. Peer, Ordering Service, Certificate Authority. Start small, with no upfront investment. Then pay as you grow and upgrade easily through Kubernetes. Connect to nodes running in any environment (on-premises, public, hybrid clouds). Easily connect a single peer to multiple industry networks.","title":"IBM - Contains \"vscode\" extensions."},{"location":"public/blockchain/Blockchain-tutorials/#skycoin","text":"","title":"\u25d8 SkyCoin"},{"location":"public/blockchain/Blockchain-tutorials/#skycoin_1","text":"Lightning Fast Zero Fees Secure Private Sustainable Incentivized Utility Backed Free Fee Transaction Skycoin: fast and secure currency backed by bandwidth. Skywire: anonymous, decentralized mesh-Internet. Skyminer: hardware and access point for Skywire. Fiber: decentralized open blockchain network. Skysuite: suite of decentralized applications. armanriazi/Doc-Blockchain Contribute to armanriazi/Doc-Blockchain development by creating an account on GitHub.github.com","title":"SkyCoin"},{"location":"public/blockchain/Blockchain/","text":"Blockchain \u00b6 Blockchain 4.0 Blockchain Canvas Blockchain Taxonomy Blockchain Stack MindMapping \u00b6 If you want to get update-mind-mapping image, send me the Email Title: armanriazi.github.io _ MindMapping Substrate MindMapping 2021-2023 \u00b6 My Current Consideration \u00b6 Scratched Implementation of Blockchain(Latest) Rust-Lang Substrate Kusama Polkadot ParaState Research \u00b6 Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Part(1) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Part(2) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/CrowdLoan/Part(3) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/ParaState/Part(4) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/EWASM/Part(5) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/SecondState/Part(6) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Rust-Lang/Part(7) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/NodeSetup/Part(8) Passed self-study tutorials \u00b6 Substrate workshop with Dr.Gavin Wood and Sergei Shulepov Build a Bitcoin-like Blockchain with Substrate Intro to Substrate-1-10 Substrate based ParaChains (Polkadot) support via Parastate Substrate Recipes Workshop - Learn to Build a Custom Blockchain Build a Bitcoin-like Blockchain with Substrate - Beginner Friendly 2019-2020 \u00b6 Sample Projects \u00b6 Solidity Hyperledger Corda-r3 Research \u00b6 Blockchain-tutorials Passed self-study tutorials \u00b6 \u25d8 Sample My Academic & Experiences On Blockchain Subject(2020-2021) \u25d8 Archived Video Packages( Seen ) \u00b6 INE Understanding Crypto Currencies Bitcoins and Blockchains Lynda Ethereum Building Blockchain Decentralized Apps DApps Packtpub Blockchain for Business 2018 The New Industrial Revolution Packtpub Blockchain Real World Projects StoneRiverElearning Building Cryptocurrencies and Smart Contracts StoneRiverElearning Starting with NEM (Not yet) TechnicsPublications Data Modeling and Blockchain Build a Blockchain and a cryptocurrnecy from scratch IBM Blockchain Solutions Youtube Channels \u00b6 Hyperledger IBM DApp university Skycoin Blockstack Ethereum Samples have runned by test network \u00b6 DAapp university by web3.js (Reactjs,Js)- Solidity Solidity (build a game) Build blockchain with Golang (Websocket) Trading \u00b6 Investment Cryptocurrentcy Trading On The Platforms Of The Cryptocurrency Binance Trading Trading on Civil Platforms (native financial) Knowledge Of Technical & Conceptual Trading \u25d8 And many bookmarks that taked my attention and time for understanding leaf subjects of blockchain \u25d8 Shared Research White Papers \u00b6 OneNote-Online","title":"Blockchain"},{"location":"public/blockchain/Blockchain/#blockchain","text":"Blockchain 4.0 Blockchain Canvas Blockchain Taxonomy Blockchain Stack","title":"Blockchain"},{"location":"public/blockchain/Blockchain/#mindmapping","text":"If you want to get update-mind-mapping image, send me the Email Title: armanriazi.github.io _ MindMapping Substrate MindMapping","title":"MindMapping"},{"location":"public/blockchain/Blockchain/#2021-2023","text":"","title":"2021-2023"},{"location":"public/blockchain/Blockchain/#my-current-consideration","text":"Scratched Implementation of Blockchain(Latest) Rust-Lang Substrate Kusama Polkadot ParaState","title":"My Current Consideration"},{"location":"public/blockchain/Blockchain/#research","text":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Part(1) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Part(2) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/CrowdLoan/Part(3) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/ParaState/Part(4) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/EWASM/Part(5) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/SecondState/Part(6) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Rust-Lang/Part(7) Highlighted Deep Dive Into Polkadot/Substrate/Kusama/NodeSetup/Part(8)","title":"Research"},{"location":"public/blockchain/Blockchain/#passed-self-study-tutorials","text":"Substrate workshop with Dr.Gavin Wood and Sergei Shulepov Build a Bitcoin-like Blockchain with Substrate Intro to Substrate-1-10 Substrate based ParaChains (Polkadot) support via Parastate Substrate Recipes Workshop - Learn to Build a Custom Blockchain Build a Bitcoin-like Blockchain with Substrate - Beginner Friendly","title":"Passed self-study tutorials"},{"location":"public/blockchain/Blockchain/#2019-2020","text":"","title":"2019-2020"},{"location":"public/blockchain/Blockchain/#sample-projects","text":"Solidity Hyperledger Corda-r3","title":"Sample Projects"},{"location":"public/blockchain/Blockchain/#research_1","text":"Blockchain-tutorials","title":"Research"},{"location":"public/blockchain/Blockchain/#passed-self-study-tutorials_1","text":"\u25d8 Sample My Academic & Experiences On Blockchain Subject(2020-2021) \u25d8","title":"Passed self-study tutorials"},{"location":"public/blockchain/Blockchain/#archived-video-packagesseen","text":"INE Understanding Crypto Currencies Bitcoins and Blockchains Lynda Ethereum Building Blockchain Decentralized Apps DApps Packtpub Blockchain for Business 2018 The New Industrial Revolution Packtpub Blockchain Real World Projects StoneRiverElearning Building Cryptocurrencies and Smart Contracts StoneRiverElearning Starting with NEM (Not yet) TechnicsPublications Data Modeling and Blockchain Build a Blockchain and a cryptocurrnecy from scratch IBM Blockchain Solutions","title":"Archived Video Packages(Seen)"},{"location":"public/blockchain/Blockchain/#youtube-channels","text":"Hyperledger IBM DApp university Skycoin Blockstack Ethereum","title":"Youtube Channels"},{"location":"public/blockchain/Blockchain/#samples-have-runned-by-test-network","text":"DAapp university by web3.js (Reactjs,Js)- Solidity Solidity (build a game) Build blockchain with Golang (Websocket)","title":"Samples have runned by test network"},{"location":"public/blockchain/Blockchain/#trading","text":"Investment Cryptocurrentcy Trading On The Platforms Of The Cryptocurrency Binance Trading Trading on Civil Platforms (native financial) Knowledge Of Technical & Conceptual Trading \u25d8 And many bookmarks that taked my attention and time for understanding leaf subjects of blockchain \u25d8","title":"Trading"},{"location":"public/blockchain/Blockchain/#shared-research-white-papers","text":"OneNote-Online","title":"Shared Research White Papers"},{"location":"public/blockchain/Corda-r3/","tags":["java","simulation","corda"],"text":"Corda-R3 \u00b6 The platform defines blockchain network standards; It provides smart contracts and tokens that work with JVM virtual machines. It is similar to EVM to execute designed protocols. Quote It seems to me that could use the Corda for the simulation of blockchain.","title":"Corda-R3"},{"location":"public/blockchain/Corda-r3/#corda-r3","text":"The platform defines blockchain network standards; It provides smart contracts and tokens that work with JVM virtual machines. It is similar to EVM to execute designed protocols. Quote It seems to me that could use the Corda for the simulation of blockchain.","title":"Corda-R3"},{"location":"public/blockchain/Ethereum_Ecosystem_Research/","text":"","title":"Ethereum Ecosystem Research"},{"location":"public/blockchain/Hyperledger/","tags":["hyperledger","devops","ibm"],"text":"HyperLedger-IBM \u00b6 Quote I remember, used hyperledger-fabric with composer, kubernetes, and even Node-Red.The framework is suit for specialist who have experience with [[Devops]] and I can say that Composer is good idea for this developing. Using standards defined: flexibility, scalability, availability of service under any circumstances, the above mentioned through another branch of technology called DevOps that is compatible with web applications and blockchain, the ability to implement and strengthen the blockchain The author of this project has been working on it. Due to the learning of [[Blockchain]], we are faced with several technologies. The use of HyperLedger, which is provided under the supervision of Linux and is also used by #IBM, and the second case is the use of Ethereum, the second version of which is scheduled to be released by the end of 2021 based on the POS consensus algorithm. The figure above shows the fact that large companies today rely on open source tools for their infrastructure components, and what you see is all free, but the company has been able to establish an effective communication platform base on the cloud. In short, we are not dealing with occasional challenges, but rather \"wheels will not move unless the engine works right.\" Hyperledger-Golang \u00b6 Features \u00b6 Golang \u00b6 On-permise Define Blockchain as manual and changeable Scratch Structure Deploy on docker Scale-up by Kubernetes No need for pay-as-you-go services Complex implementation Hyperledger-Azure \u00b6 Features \u00b6 Blockchain as a service Scale-up with Kubernetes Docker -Compose Wrote by Hyperledger-Compose Pay-as-you-go Secured by Microsoft [[IBM]]","title":"Hyperledger"},{"location":"public/blockchain/Hyperledger/#hyperledger-ibm","text":"Quote I remember, used hyperledger-fabric with composer, kubernetes, and even Node-Red.The framework is suit for specialist who have experience with [[Devops]] and I can say that Composer is good idea for this developing. Using standards defined: flexibility, scalability, availability of service under any circumstances, the above mentioned through another branch of technology called DevOps that is compatible with web applications and blockchain, the ability to implement and strengthen the blockchain The author of this project has been working on it. Due to the learning of [[Blockchain]], we are faced with several technologies. The use of HyperLedger, which is provided under the supervision of Linux and is also used by #IBM, and the second case is the use of Ethereum, the second version of which is scheduled to be released by the end of 2021 based on the POS consensus algorithm. The figure above shows the fact that large companies today rely on open source tools for their infrastructure components, and what you see is all free, but the company has been able to establish an effective communication platform base on the cloud. In short, we are not dealing with occasional challenges, but rather \"wheels will not move unless the engine works right.\"","title":"HyperLedger-IBM"},{"location":"public/blockchain/Hyperledger/#hyperledger-golang","text":"","title":"Hyperledger-Golang"},{"location":"public/blockchain/Hyperledger/#features","text":"","title":"Features"},{"location":"public/blockchain/Hyperledger/#golang","text":"On-permise Define Blockchain as manual and changeable Scratch Structure Deploy on docker Scale-up by Kubernetes No need for pay-as-you-go services Complex implementation","title":"Golang"},{"location":"public/blockchain/Hyperledger/#hyperledger-azure","text":"","title":"Hyperledger-Azure"},{"location":"public/blockchain/Hyperledger/#features_1","text":"Blockchain as a service Scale-up with Kubernetes Docker -Compose Wrote by Hyperledger-Compose Pay-as-you-go Secured by Microsoft [[IBM]]","title":"Features"},{"location":"public/blockchain/Kusama/","text":"Kusama \u00b6 Implement \u00b6 Comming Soon... Research \u00b6 Crowdloan-Research-Intro [[Polkadot-Ecosystem-Research]]","title":"Kusama"},{"location":"public/blockchain/Kusama/#kusama","text":"","title":"Kusama"},{"location":"public/blockchain/Kusama/#implement","text":"Comming Soon...","title":"Implement"},{"location":"public/blockchain/Kusama/#research","text":"Crowdloan-Research-Intro [[Polkadot-Ecosystem-Research]]","title":"Research"},{"location":"public/blockchain/ParaState/","tags":["polkadot_ecosystem","substrate","project","sample","research","ewasm"],"text":"ParaState \u00b6 Implement \u00b6 Comming Soon... Research \u00b6 Parastate-Research-Intro [[Polkadot-Ecosystem-Research]]","title":"ParaState"},{"location":"public/blockchain/ParaState/#parastate","text":"","title":"ParaState"},{"location":"public/blockchain/ParaState/#implement","text":"Comming Soon...","title":"Implement"},{"location":"public/blockchain/ParaState/#research","text":"Parastate-Research-Intro [[Polkadot-Ecosystem-Research]]","title":"Research"},{"location":"public/blockchain/Polkadot-Ecosystem-Research/","text":"","title":"Polkadot Ecosystem Research"},{"location":"public/blockchain/Polkadot/","tags":["polkadot_ecosystem","substrate","project","sample","research"],"text":"Polkadot \u00b6 Implement \u00b6 Comming Soon... Research \u00b6 Polkadot-Research-Intro [[Polkadot-Ecosystem-Research]]","title":"Polkadot"},{"location":"public/blockchain/Polkadot/#polkadot","text":"","title":"Polkadot"},{"location":"public/blockchain/Polkadot/#implement","text":"Comming Soon...","title":"Implement"},{"location":"public/blockchain/Polkadot/#research","text":"Polkadot-Research-Intro [[Polkadot-Ecosystem-Research]]","title":"Research"},{"location":"public/blockchain/SecondState/","tags":["wasm"],"text":"[[Polkadot-Ecosystem-Research]] Secondstate-Research-Intro","title":"SecondState"},{"location":"public/blockchain/Solidity/","tags":["smartcontract","ethereum_ecosystem"],"text":"Solidity \u00b6 Sample Projects \u00b6 Smart Contract-Sales-Energy Smart Contract-RealState Smart Contract-Sale Product Smart Contract-Vote","title":"Solidity"},{"location":"public/blockchain/Solidity/#solidity","text":"","title":"Solidity"},{"location":"public/blockchain/Solidity/#sample-projects","text":"Smart Contract-Sales-Energy Smart Contract-RealState Smart Contract-Sale Product Smart Contract-Vote","title":"Sample Projects"},{"location":"public/blockchain/Substrate/","tags":["polkadot_ecosystem","project","sample","substrate","github"],"text":"Substrate \u00b6 If you want to get updated-mind-mapping image, send me Email to armanriazi.blockchain@gmail.com (Title: armanriazi.github.io _ MindMapping) Implement \u00b6 Comming Soon... Highlighted Deep Dive Into Polkadot/Substrate/Kusama/NodeSetup/Part(8) Research \u00b6 Substrate-Framework-Research-Intro [[Polkadot-Ecosystem-Research]]","title":"Substrate"},{"location":"public/blockchain/Substrate/#substrate","text":"If you want to get updated-mind-mapping image, send me Email to armanriazi.blockchain@gmail.com (Title: armanriazi.github.io _ MindMapping)","title":"Substrate"},{"location":"public/blockchain/Substrate/#implement","text":"Comming Soon... Highlighted Deep Dive Into Polkadot/Substrate/Kusama/NodeSetup/Part(8)","title":"Implement"},{"location":"public/blockchain/Substrate/#research","text":"Substrate-Framework-Research-Intro [[Polkadot-Ecosystem-Research]]","title":"Research"},{"location":"public/blockchain/WASM/","tags":["wasm","ewasm"],"text":"[[Polkadot-Ecosystem-Research]] Ewasm-Research-Intro","title":"WASM"},{"location":"public/blockchain/parastate/parastate-research-intro/","tags":["parastate","polkadot_ecosystem","pos"],"text":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Parastate(4) \ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb Introducing \u00b6 ParaState is a proof-of-stake blockchain platform that says its goal is to ParaState aims to become a Polkadot parachain that extends the frontier of Ethereum with substrate framework. By supporting 20+ programming languages to create Ethereum-compatible multi-chain smart contract. @State-Token ParaState is a decentralized autonomous organization (DAO) funded by license fees (as a percentage of gas fees) generated by transactions on other networks using ParaState technology. Any blockchain project that is interested in taking advantage of the technical advantages of ParaState EWASM will be charged licensing fees in the native currencies of these blockchains. Therefore, the intrinsic value of STATE is backed by a basket of native cryptocurrencies from these blockchain projects. \ud83d\udc46\ud83d\udc46\ud83d\udc46 Polkadot (bridge assets via Snowfork/Interlay). \ud83d\udcda\ud83d\udcda\ud83d\udcda Literature \u00b6 intermediate representation = IR Substrate-Glossary \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Substrate]]","title":"Parastate research intro"},{"location":"public/blockchain/parastate/parastate-research-intro/#introducing","text":"ParaState is a proof-of-stake blockchain platform that says its goal is to ParaState aims to become a Polkadot parachain that extends the frontier of Ethereum with substrate framework. By supporting 20+ programming languages to create Ethereum-compatible multi-chain smart contract. @State-Token ParaState is a decentralized autonomous organization (DAO) funded by license fees (as a percentage of gas fees) generated by transactions on other networks using ParaState technology. Any blockchain project that is interested in taking advantage of the technical advantages of ParaState EWASM will be charged licensing fees in the native currencies of these blockchains. Therefore, the intrinsic value of STATE is backed by a basket of native cryptocurrencies from these blockchain projects. \ud83d\udc46\ud83d\udc46\ud83d\udc46 Polkadot (bridge assets via Snowfork/Interlay). \ud83d\udcda\ud83d\udcda\ud83d\udcda","title":"Introducing"},{"location":"public/blockchain/parastate/parastate-research-intro/#literature","text":"intermediate representation = IR Substrate-Glossary \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Substrate]]","title":"Literature"},{"location":"public/blockchain/secondstate/secondstate-research-intro/","tags":["secondstate","iot"],"text":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Secondstate(6) \ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb Introducing \u00b6 For automakers, the runtime isolation reduces complexity in integration and operation. For parts makers, the virtualized runtime supports \u201cwrite once run on any car\u201d. Second State is developing a real-time, deterministic, and efficient runtime sandbox for automotive applications. It is completely open source and already used by leading auto suppliers. Rust could be 25x faster than Python for machine learning. \ud83d\udc46\ud83d\udc46\ud83d\udc46 SSVM \u00b6 The Second State Functions is based on the Second State WebAssembly VM (SSVM). It is specifically optimized for server-side applications. SSVM is a high-performance WebAssembly runtime for server-side apps. It is safer and 10x faster than Docker. It supports OS access (WASI), AOT compiler , stateful apps, seamless integration with Node.js, and access to hardware (AI chips). Second State provides an open-source WebAssembly implementation (Second State Virtual Machine, or SSVM) that is specifically optimized for server side applications. It is Best in-class in performance. It is 1000x faster than Docker for cold starts.It starts and runs much faster than VM or container-based alternatives. It excels in compute intensive media, data, and edge AI apps. Seamlessly supports server application frameworks, such as the Node.js. You can build high performance Node.js apps with SSVM. Supports safe access to external resources, such as databases, message queues, and even new AI hardware Allows precise metering of computational resources for serverless apps. Serverless \u00b6 @FaaS is one of the fastest growing areas of cloud computing. FaaS allows developers to focus on the code. Once the developer uploads the code, the FaaS takes care of deployment, service availability, and scalability. The developer only pays for resources the service uses, not reserved idle time. This approach, known as serverless computing, is the way to build inter-connected and microservice-based applications. The result are fast development turn around, easy deployment, high availability, infinite scalability, at low cost. However, traditional FaaS are based on microVM (eg Firecracker and gVisor) and application container (eg Docker) technologies. They are general computing platforms not optimized for software stacks. To boot an entire OS and then heavy-weight runtimes just to run a single function is very inefficient. Therefore, existing FaaS solutions suffer from issues such as slow cold start, slow runtime performance, bloated runtime, and time-based billing. They are not suitable for computationally intensive applications. High-level language VMs, such as WebAssembly , offer a combination of ease-of-use, runtime safety, and high performance. The WasmEdge Runtime is a WebAssembly VM that is designed for edge cloud and device applications. It is a great fit for computationally intensive FaaS applications such as edge AI, real-time data analytics, multimedia processing, as well as typical transactional functions that need to start in sub-millisecond and make a quick call to another web service. \ud83d\udc46\ud83d\udc46\ud83d\udc46 Features \u00b6 @WasmEdge WasmEdge is a lightweight, high-performance, and extensible WebAssembly runtime for cloud native, edge, and decentralized applications. It powers serverless apps, embedded functions, microservices, smart contracts, and IoT devices. Today\u2019s web apps often have statically generated front ends that use JavaScript to interact with APIs on the backend (ie, the Jamstack). The WasmEdge is ideally suited for running backend API services as serverless functions . It is fast, secure, low maintainence, cross-platform, and can be easily deployed on edge networks for high performance. WebAssembly is the de facto runtime for modern blockchain smart contracts. Ethereum flavored WebAssembly (Ewasm) is a collaborative effort to bring the earliest and largest smart contract platform, Ethereum, to the WebAssembly world. WasmEdge is a leading Ewasm implementation , and it is already being adopted by leading public blockchains. @WASI @Tensorflow @ConvolutionalNeuralNetworks WASI provides a design pattern for sandboxed WebAssembly programs to securely access native host functions. The WasmEdge Runtime extends the WASI model to support access to native Tensorflow libraries from WebAssembly programs . It provides the security, portability, and ease-of-use of WebAssembly and native speed for Tensorflow. Second State FaaS provides a Rust API to run Tensorflow-based MobileNet models at native speeds. In this article, we will use a MobileNet model trained from the ImageNet dataset as an example. MobileNet is a class of CNN models for computer vision applications. The most common application for MobileNet models is image classification. You can train (or retrain) a MobileNet model to recognize objects that are interesting to your application (e.g., to classify birds in a bird watching application). The MTCNN is a class of Multi-task Cascaded Convolutional Network models. They are very good at detection faces and facial features. You can train (or retrain) MTCNN models with your own faces dataset so that it can accurately detect faces for your application. Second State FaaS provides a Rust API to run Tensorflow-based MTCNN models at native speeds. In this article, we will use the original MTCNN model trained in the FaceNet dataset as an example \ud83d\udc46\ud83d\udc46\ud83d\udc46 \ud83d\udcda\ud83d\udcda\ud83d\udcda Literature \u00b6 WebAssembly System Interface = WASI Convolutional Neural Networks = CNN Function as a Service = FaaS \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Substrate]]","title":"Secondstate research intro"},{"location":"public/blockchain/secondstate/secondstate-research-intro/#introducing","text":"For automakers, the runtime isolation reduces complexity in integration and operation. For parts makers, the virtualized runtime supports \u201cwrite once run on any car\u201d. Second State is developing a real-time, deterministic, and efficient runtime sandbox for automotive applications. It is completely open source and already used by leading auto suppliers. Rust could be 25x faster than Python for machine learning. \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Introducing"},{"location":"public/blockchain/secondstate/secondstate-research-intro/#ssvm","text":"The Second State Functions is based on the Second State WebAssembly VM (SSVM). It is specifically optimized for server-side applications. SSVM is a high-performance WebAssembly runtime for server-side apps. It is safer and 10x faster than Docker. It supports OS access (WASI), AOT compiler , stateful apps, seamless integration with Node.js, and access to hardware (AI chips). Second State provides an open-source WebAssembly implementation (Second State Virtual Machine, or SSVM) that is specifically optimized for server side applications. It is Best in-class in performance. It is 1000x faster than Docker for cold starts.It starts and runs much faster than VM or container-based alternatives. It excels in compute intensive media, data, and edge AI apps. Seamlessly supports server application frameworks, such as the Node.js. You can build high performance Node.js apps with SSVM. Supports safe access to external resources, such as databases, message queues, and even new AI hardware Allows precise metering of computational resources for serverless apps.","title":"SSVM"},{"location":"public/blockchain/secondstate/secondstate-research-intro/#serverless","text":"@FaaS is one of the fastest growing areas of cloud computing. FaaS allows developers to focus on the code. Once the developer uploads the code, the FaaS takes care of deployment, service availability, and scalability. The developer only pays for resources the service uses, not reserved idle time. This approach, known as serverless computing, is the way to build inter-connected and microservice-based applications. The result are fast development turn around, easy deployment, high availability, infinite scalability, at low cost. However, traditional FaaS are based on microVM (eg Firecracker and gVisor) and application container (eg Docker) technologies. They are general computing platforms not optimized for software stacks. To boot an entire OS and then heavy-weight runtimes just to run a single function is very inefficient. Therefore, existing FaaS solutions suffer from issues such as slow cold start, slow runtime performance, bloated runtime, and time-based billing. They are not suitable for computationally intensive applications. High-level language VMs, such as WebAssembly , offer a combination of ease-of-use, runtime safety, and high performance. The WasmEdge Runtime is a WebAssembly VM that is designed for edge cloud and device applications. It is a great fit for computationally intensive FaaS applications such as edge AI, real-time data analytics, multimedia processing, as well as typical transactional functions that need to start in sub-millisecond and make a quick call to another web service. \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Serverless"},{"location":"public/blockchain/secondstate/secondstate-research-intro/#features","text":"@WasmEdge WasmEdge is a lightweight, high-performance, and extensible WebAssembly runtime for cloud native, edge, and decentralized applications. It powers serverless apps, embedded functions, microservices, smart contracts, and IoT devices. Today\u2019s web apps often have statically generated front ends that use JavaScript to interact with APIs on the backend (ie, the Jamstack). The WasmEdge is ideally suited for running backend API services as serverless functions . It is fast, secure, low maintainence, cross-platform, and can be easily deployed on edge networks for high performance. WebAssembly is the de facto runtime for modern blockchain smart contracts. Ethereum flavored WebAssembly (Ewasm) is a collaborative effort to bring the earliest and largest smart contract platform, Ethereum, to the WebAssembly world. WasmEdge is a leading Ewasm implementation , and it is already being adopted by leading public blockchains. @WASI @Tensorflow @ConvolutionalNeuralNetworks WASI provides a design pattern for sandboxed WebAssembly programs to securely access native host functions. The WasmEdge Runtime extends the WASI model to support access to native Tensorflow libraries from WebAssembly programs . It provides the security, portability, and ease-of-use of WebAssembly and native speed for Tensorflow. Second State FaaS provides a Rust API to run Tensorflow-based MobileNet models at native speeds. In this article, we will use a MobileNet model trained from the ImageNet dataset as an example. MobileNet is a class of CNN models for computer vision applications. The most common application for MobileNet models is image classification. You can train (or retrain) a MobileNet model to recognize objects that are interesting to your application (e.g., to classify birds in a bird watching application). The MTCNN is a class of Multi-task Cascaded Convolutional Network models. They are very good at detection faces and facial features. You can train (or retrain) MTCNN models with your own faces dataset so that it can accurately detect faces for your application. Second State FaaS provides a Rust API to run Tensorflow-based MTCNN models at native speeds. In this article, we will use the original MTCNN model trained in the FaceNet dataset as an example \ud83d\udc46\ud83d\udc46\ud83d\udc46 \ud83d\udcda\ud83d\udcda\ud83d\udcda","title":"Features"},{"location":"public/blockchain/secondstate/secondstate-research-intro/#literature","text":"WebAssembly System Interface = WASI Convolutional Neural Networks = CNN Function as a Service = FaaS \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Substrate]]","title":"Literature"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/","tags":["smartcontract","ethereum_ecosystem","sample","github"],"text":"A guide to demoing the [[energy]] contract \u00b6 Prerequisites \u00b6 This documentation has been intended for readers with a basic understanding on the Solidity smart contract programming language and on basic web developing tools. In order to run, the demo requires the following software to be installed. For verified functionality, the specified versions are recommended: Ubuntu 16.04.2 LTS TestRPC, version 3.0.4 Truffle, version 3.2.1 Node.js, version 7.9.0 Running an [[Ethereum]] client Install dependencies \u00b6 Before the first run, dependencies need to be installed for the test scripts and the status viewer. cd scripts/ npm install cd scripts/status bower install Run a deterministic TestRPC session \u00b6 For demoing purposes, TestRPC is a good choice for a client, for a number of reasons. Firstly, TestRPC creates a new blockchain instance and transactions can be paid with tokens of the said blockchain. The creator of the TestRPC session gains access to the tokens for free and therefore transactions can be made without a cost. Secondly, by default, TestRPC is configured in such a way that there is no block time\u2014instead, blocks are created on demand, whenever transactions occur. This type of a configuration is well suited for quick testing and demoing. Finally, TestRPC can be run in deterministic mode. This means that a smart contract\u2019s address, for example, can be known already before deploying it in the blockchain. This makes it possible to reference the address in scripts made for testing or demoing purposes. testrpc -d Deploy the contract \u00b6 The smart contracts written in Solidity need to be compiled and deployed to the blockchain. This can be achieved by using a development environment for Ethereum called Truffle. A simple migration script needs to be created for Truffle, after which the contracts can be deployed using the following command: truffle migrate Run the issuer script that issues smart meter ownerships \u00b6 For the demo, a seller and a buyer of electricity are needed. Furthermore, the ownership of a smart meter needs to be assigned to both of these parties. In our demo, we utilize an approach where a master key holder has the power to establish ownerships to the system participants. We establish a master key holder of smart meters for the electricity marketplace and have the key holder assign ownership to the smart meters. cd scripts/ node issuer.js Open the status view in browser \u00b6 Without a graphical user interface, none of the process steps can be visually observed in any way. Therefore, a simple web-browser-based status viewer has been added to the demo appli cation. It shows the changes in the status of the different entities as a crude HTML table. The status viewer can be accessed by opening the web page index.html in any web browser. Open scripts/status/index.html in browser. Create sell offers \u00b6 For the purposes of the demo, the market should be populated with sell offers of energy. The script offer.js is used for this purpose. The script\u2019s optional command line parameter index can be used to create different pre-populated sell offers. Change the optional index argument to create different pre-populated offers. The default behavior is to choose the offer at index 0 so the index must be within range 0 to 9. When omitting the index parameter, the script defaults to using index 0. node offer [ <index> ] Accept offers as a buyer \u00b6 Any sell offers created earlier can be accepted by the buyer. The script acceptoffer.js can be used to do so. The optional index parameter of the script works similarly as the parameter earlier specified for the offer.js script and can be used to accept offers. For example, if an offer was created using the command node offer 4, then running the command node acceptoffer 4 will make the buyer accept it. node acceptoffer [ <index> ] Send reports from smart meters (or wait until the report deadline) \u00b6 Once an offer has been created and accepted, and the scheduled transfer of electricity is due, both the seller\u2019s and the buyer\u2019s smart meters are expected to report on the successfulness of the transfer. The Ethereum transactions submitting these reports can be created using the scripts sellerreport.js and buyerreport.js. The optional index parameter can be used to refer to different sell offers exactly the same way as in the scripts described earlier. Both scripts, sellerreport.js and buyerreport.js need to be run in order to move an instance of electricity transfer to its next state in the smart contract. The reports have a deadline before which they need to be submitted. According to the deadline, the reports must be submitted and written into the blockchain no later than 30 minutes after the transfer is completed. In the case a transacting party fails to report within the allocated time frame, the smart contract will assume the worst possible economic outcome for the abstinent party. node sellerreport [ <index> ] node buyerreport [ <index> ] Withdraw money \u00b6 Once both smart meters have submitted their reports (or the deadline has expired), the assets stored in the contract can be withdrawn. The withdrawal can be initiated by anyone, in which case the assets are sent to their rightful owner, as determined by the logic of the smart contract. The script withdraw.js can be used to execute the withdrawal. The optional index parameter can be used to refer to different instances of electricity transfer. node withdraw [ <index> ] A part of this project was got from an article Smart Contracts \u00b6 The logic of the electricity market smart contract is defined in the Solidity file ElectricityMarket.sol. The contract defines the public methods for creating sell offers, accepting them, sending smart meter reports and withdrawing assets. GUI \u00b6 The status viewer is a web page which is useful for observing changes in the blockchain while running the demo. It shows the status of all the created sell offers and the account balances of the buyer, the seller and the electricity market smart contract. The status viewer can be run by opening the file index.html in any web browser. Sourcecode \u00b6 Armanriazi-Github-Energy-Sample Project nodejs #metamask #rpc \u00b6 [[Ethereum_Ecosystem_Research]] [[smart-contract]]","title":"Arman Riazi"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#a-guide-to-demoing-the-energy-contract","text":"","title":"A guide to demoing the [[energy]] contract"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#prerequisites","text":"This documentation has been intended for readers with a basic understanding on the Solidity smart contract programming language and on basic web developing tools. In order to run, the demo requires the following software to be installed. For verified functionality, the specified versions are recommended: Ubuntu 16.04.2 LTS TestRPC, version 3.0.4 Truffle, version 3.2.1 Node.js, version 7.9.0 Running an [[Ethereum]] client","title":"Prerequisites"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#install-dependencies","text":"Before the first run, dependencies need to be installed for the test scripts and the status viewer. cd scripts/ npm install cd scripts/status bower install","title":"Install dependencies"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#run-a-deterministic-testrpc-session","text":"For demoing purposes, TestRPC is a good choice for a client, for a number of reasons. Firstly, TestRPC creates a new blockchain instance and transactions can be paid with tokens of the said blockchain. The creator of the TestRPC session gains access to the tokens for free and therefore transactions can be made without a cost. Secondly, by default, TestRPC is configured in such a way that there is no block time\u2014instead, blocks are created on demand, whenever transactions occur. This type of a configuration is well suited for quick testing and demoing. Finally, TestRPC can be run in deterministic mode. This means that a smart contract\u2019s address, for example, can be known already before deploying it in the blockchain. This makes it possible to reference the address in scripts made for testing or demoing purposes. testrpc -d","title":"Run a deterministic TestRPC session"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#deploy-the-contract","text":"The smart contracts written in Solidity need to be compiled and deployed to the blockchain. This can be achieved by using a development environment for Ethereum called Truffle. A simple migration script needs to be created for Truffle, after which the contracts can be deployed using the following command: truffle migrate","title":"Deploy the contract"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#run-the-issuer-script-that-issues-smart-meter-ownerships","text":"For the demo, a seller and a buyer of electricity are needed. Furthermore, the ownership of a smart meter needs to be assigned to both of these parties. In our demo, we utilize an approach where a master key holder has the power to establish ownerships to the system participants. We establish a master key holder of smart meters for the electricity marketplace and have the key holder assign ownership to the smart meters. cd scripts/ node issuer.js","title":"Run the issuer script that issues smart meter ownerships"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#open-the-status-view-in-browser","text":"Without a graphical user interface, none of the process steps can be visually observed in any way. Therefore, a simple web-browser-based status viewer has been added to the demo appli cation. It shows the changes in the status of the different entities as a crude HTML table. The status viewer can be accessed by opening the web page index.html in any web browser. Open scripts/status/index.html in browser.","title":"Open the status view in browser"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#create-sell-offers","text":"For the purposes of the demo, the market should be populated with sell offers of energy. The script offer.js is used for this purpose. The script\u2019s optional command line parameter index can be used to create different pre-populated sell offers. Change the optional index argument to create different pre-populated offers. The default behavior is to choose the offer at index 0 so the index must be within range 0 to 9. When omitting the index parameter, the script defaults to using index 0. node offer [ <index> ]","title":"Create sell offers"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#accept-offers-as-a-buyer","text":"Any sell offers created earlier can be accepted by the buyer. The script acceptoffer.js can be used to do so. The optional index parameter of the script works similarly as the parameter earlier specified for the offer.js script and can be used to accept offers. For example, if an offer was created using the command node offer 4, then running the command node acceptoffer 4 will make the buyer accept it. node acceptoffer [ <index> ]","title":"Accept offers as a buyer"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#send-reports-from-smart-meters-or-wait-until-the-report-deadline","text":"Once an offer has been created and accepted, and the scheduled transfer of electricity is due, both the seller\u2019s and the buyer\u2019s smart meters are expected to report on the successfulness of the transfer. The Ethereum transactions submitting these reports can be created using the scripts sellerreport.js and buyerreport.js. The optional index parameter can be used to refer to different sell offers exactly the same way as in the scripts described earlier. Both scripts, sellerreport.js and buyerreport.js need to be run in order to move an instance of electricity transfer to its next state in the smart contract. The reports have a deadline before which they need to be submitted. According to the deadline, the reports must be submitted and written into the blockchain no later than 30 minutes after the transfer is completed. In the case a transacting party fails to report within the allocated time frame, the smart contract will assume the worst possible economic outcome for the abstinent party. node sellerreport [ <index> ] node buyerreport [ <index> ]","title":"Send reports from smart meters (or wait until the report deadline)"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#withdraw-money","text":"Once both smart meters have submitted their reports (or the deadline has expired), the assets stored in the contract can be withdrawn. The withdrawal can be initiated by anyone, in which case the assets are sent to their rightful owner, as determined by the logic of the smart contract. The script withdraw.js can be used to execute the withdrawal. The optional index parameter can be used to refer to different instances of electricity transfer. node withdraw [ <index> ] A part of this project was got from an article","title":"Withdraw money"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#smart-contracts","text":"The logic of the electricity market smart contract is defined in the Solidity file ElectricityMarket.sol. The contract defines the public methods for creating sell offers, accepting them, sending smart meter reports and withdrawing assets.","title":"Smart Contracts"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#gui","text":"The status viewer is a web page which is useful for observing changes in the blockchain while running the demo. It shows the status of all the created sell offers and the account balances of the buyer, the seller and the electricity market smart contract. The status viewer can be run by opening the file index.html in any web browser.","title":"GUI"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#sourcecode","text":"Armanriazi-Github-Energy-Sample Project","title":"Sourcecode"},{"location":"public/blockchain/solidity/smart-contract-marketplace-in-energy/#nodejs-metamask-rpc","text":"[[Ethereum_Ecosystem_Research]] [[smart-contract]]","title":"nodejs #metamask #rpc"},{"location":"public/blockchain/solidity/smart-contract-real-estate/","tags":["smartcontract","ethereum_ecosystem","sample","github"],"text":"A guide to demoing the [[real-estate]] contract \u00b6 Prerequisites \u00b6 This documentation has been intended for readers with a basic understanding on the Solidity smart contract programming language and on basic web developing tools. In order to run, the demo requires the following software to be installed. For verified functionality, the specified versions are recommended: Ubuntu 16.04.2 LTS Test[[RPC]], version 3.0.4 Truffle, version 3.2.1 Node.js, version 7.9.0 Running an [[Ethereum]] client Run a deterministic TestRPC session \u00b6 At first, an Ethereum client needs to be run testrpc -d Deploy the contract \u00b6 For demoing purposes, Test[[RPC]] is a good choice for a client, for a number of reasons. First ly, TestRPC creates a new blockchain instance and transactions can be paid with tokens of the said blockchain. The creator of the TestRPC session gains access to the tokens for free and therefore transactions can be made without a cost. Secondly, by default, TestRPC is configured in such a way that there is no block time\u2014instead, blocks are created on demand, whenever transactions occur. This type of a configuration is well suited for quick testing and demoing. Finally, TestRPC can be run in deterministic mode. This means that a smart contract\u2019s address, for example, can be known already before deploying it in the blockchain. This makes it possi ble to reference the address in scripts made for testing or demoing purposes. Deploying the smart contracts The smart contracts written in Solidity need to be compiled and deployed to the blockchain. This can be achieved by using a development environment for Ethereum called Truffle. A sim ple migration script needs to be created for Truffle, after which the contracts can be deployed using the following command: truffle migrate Open the status view in browser \u00b6 Without a graphical user interface, none of the process steps can be visually observed in any way. Therefore, a simple web-browser-based status viewer has been added to the demo application. It shows the changes in the status of the different entities as a crude HTML table. The status viewer can be accessed by opening the web page index.html in any web browser. Open scripts/status/index.html in browser. Run the issuer script that creates real estates, owners and agents in the contract. \u00b6 Creating the assets and the agents, and establishing ownership For the demo, agents are needed in order to facilitate a workflow between them. Furthermore, for the purposes of facilitating the sale of a share in a housing association, the ownership of assets and documents needs to be assigned to these parties. In our demo, we utilize an approach where a master key holder has the power to establish ownerships to the system participants. We establish a master key holder that is allowed to create owners for shares of stock, property agents and shares of stock in housing companies in the application. By running the script 0-issuer.js, we create a number of owners, agents and a number of shares of stock, and we assign the first owner to each created share of stock. cd scripts/ node 0 -issuer Initiate the sale of a real estate \u00b6 The process of selling a share of stock in a housing company usually starts with the seller contacting a property agent or agents for a listing offer. In the case of our demo application, the seller can announce a solicitation for listing offers by initiating a transaction in the smart contract designed to facilitate the workflow. For the purposes of the demo, the smart contract should therefore be populated with at least one request for listing offers. The script 1-initiateSale.js is used for this purpose node 1 -initiateSale Open IPFS web user interface \u00b6 Uploading documents to the IPFS Selling a share of stocks in a housing corporation requires a housing manager\u2019s certificate to be drafted.2 In order to draft the certificate, the building manager must check the validity of the required information by combining data from several public and private information pools, e.g. the title and the mortgage register of the National Land Survey, the trade register of the Finnish Patent and Registration Office, the housing company debt report of the creditor banks, the property management planning report of the housing company in question, and so on. In our demo application\u2019s workflow, the data required for the housing manager\u2019s certificate are requested from the information pools. The pools directly store the requested files in the Interplanetary File System (IPFS) and enter the associated hash values into the smart contract facilitating the workflow.3 To emulate this in our demo, the hashes of three random documents followed by the hash of the housing manager\u2019s certificate are recorded into the blockchain. We first run the following command to set up a local IPFS node. ipfs daemon We then open the web user interface at http://localhost:5001/webui in browser, drag-and-drop the information pool documents to the web user interface to upload them, and make note of the hash values of the documents Upload three documents related to the real estate \u00b6 Upload the document to IPFS by drag-and-drop in the web UI. See what the hash of the document is and announce it in the smart contract. As the next step, the command above is executed three times, each time replacing with the hash of a different document. We then run the following command once to upload the actual housing manager\u2019s certificate, compiled from the already uploaded documents: node 2 -uploadDocument <document hash> Upload confirmation letter \u00b6 As the next step, the command above is executed three times, each time replacing with the hash of a different document. We then run the following command once to up load the actual housing manager\u2019s certificate, compiled from the already uploaded documents: node 3 -uploadConfirmationLetter <document hash> Create offers to sell the property as a real estate agent/broker \u00b6 Create offers from real estate agents to sell the property When the housing manager\u2019s certificate has been received, the real estate can be sold. In the workflow of our demo application, real estate agents compete for who gets to sell the real estate by making offers to the seller of the real estate, specifying a fee (e.g. a percentual cut) that they\u2019ll sell it for. node 4 -makeAgentOffer <fee> As the owner of the real estate, accept one of the agent offers \u00b6 To emulate this market behavior, we run the command above any number of times, each time changing the fee variable to differentiate between offers. Accepting a real estate agents offer As the last step of the workflow modelled in our demo application, the seller of the share of stocks in a housing company chooses one of the listing offers made by one of the agents. This is emulated by executing the command below, along with the proper offer ID from the status viewer window. node 5 -chooseAgentOffer <offer id> Ganache Commands \u00b6 npm run ganache ganache-cli --accounts Smart Contract \u00b6 The logic of the smart contract facilitating the workflow is defined in the Solidity file RealEstateMarket.sol. The contract defines the public methods for initiating sales, creating housing manager certificates, as well as creating listing offers and accepting them. GUI \u00b6 The status viewer is a web page which is useful for observing changes in the blockchain while running the demo. It shows the status of the workflow process, with all the contributions to it by the various participants. The status viewer can be run by opening the file index.html in any web browser. Sourcecode \u00b6 Armanriazi-Github-RealState-Sample Project nodejs #truffle #ganache #eth #ethereum \u00b6 [[Ethereum_Ecosystem_Research]] [[smart-contract]]","title":"Arman Riazi"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#a-guide-to-demoing-the-real-estate-contract","text":"","title":"A guide to demoing the [[real-estate]] contract"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#prerequisites","text":"This documentation has been intended for readers with a basic understanding on the Solidity smart contract programming language and on basic web developing tools. In order to run, the demo requires the following software to be installed. For verified functionality, the specified versions are recommended: Ubuntu 16.04.2 LTS Test[[RPC]], version 3.0.4 Truffle, version 3.2.1 Node.js, version 7.9.0 Running an [[Ethereum]] client","title":"Prerequisites"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#run-a-deterministic-testrpc-session","text":"At first, an Ethereum client needs to be run testrpc -d","title":"Run a deterministic TestRPC session"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#deploy-the-contract","text":"For demoing purposes, Test[[RPC]] is a good choice for a client, for a number of reasons. First ly, TestRPC creates a new blockchain instance and transactions can be paid with tokens of the said blockchain. The creator of the TestRPC session gains access to the tokens for free and therefore transactions can be made without a cost. Secondly, by default, TestRPC is configured in such a way that there is no block time\u2014instead, blocks are created on demand, whenever transactions occur. This type of a configuration is well suited for quick testing and demoing. Finally, TestRPC can be run in deterministic mode. This means that a smart contract\u2019s address, for example, can be known already before deploying it in the blockchain. This makes it possi ble to reference the address in scripts made for testing or demoing purposes. Deploying the smart contracts The smart contracts written in Solidity need to be compiled and deployed to the blockchain. This can be achieved by using a development environment for Ethereum called Truffle. A sim ple migration script needs to be created for Truffle, after which the contracts can be deployed using the following command: truffle migrate","title":"Deploy the contract"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#open-the-status-view-in-browser","text":"Without a graphical user interface, none of the process steps can be visually observed in any way. Therefore, a simple web-browser-based status viewer has been added to the demo application. It shows the changes in the status of the different entities as a crude HTML table. The status viewer can be accessed by opening the web page index.html in any web browser. Open scripts/status/index.html in browser.","title":"Open the status view  in browser"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#run-the-issuer-script-that-creates-real-estates-owners-and-agents-in-the-contract","text":"Creating the assets and the agents, and establishing ownership For the demo, agents are needed in order to facilitate a workflow between them. Furthermore, for the purposes of facilitating the sale of a share in a housing association, the ownership of assets and documents needs to be assigned to these parties. In our demo, we utilize an approach where a master key holder has the power to establish ownerships to the system participants. We establish a master key holder that is allowed to create owners for shares of stock, property agents and shares of stock in housing companies in the application. By running the script 0-issuer.js, we create a number of owners, agents and a number of shares of stock, and we assign the first owner to each created share of stock. cd scripts/ node 0 -issuer","title":"Run the issuer script that creates real estates, owners and agents in the contract."},{"location":"public/blockchain/solidity/smart-contract-real-estate/#initiate-the-sale-of-a-real-estate","text":"The process of selling a share of stock in a housing company usually starts with the seller contacting a property agent or agents for a listing offer. In the case of our demo application, the seller can announce a solicitation for listing offers by initiating a transaction in the smart contract designed to facilitate the workflow. For the purposes of the demo, the smart contract should therefore be populated with at least one request for listing offers. The script 1-initiateSale.js is used for this purpose node 1 -initiateSale","title":"Initiate the sale of a real estate"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#open-ipfs-web-user-interface","text":"Uploading documents to the IPFS Selling a share of stocks in a housing corporation requires a housing manager\u2019s certificate to be drafted.2 In order to draft the certificate, the building manager must check the validity of the required information by combining data from several public and private information pools, e.g. the title and the mortgage register of the National Land Survey, the trade register of the Finnish Patent and Registration Office, the housing company debt report of the creditor banks, the property management planning report of the housing company in question, and so on. In our demo application\u2019s workflow, the data required for the housing manager\u2019s certificate are requested from the information pools. The pools directly store the requested files in the Interplanetary File System (IPFS) and enter the associated hash values into the smart contract facilitating the workflow.3 To emulate this in our demo, the hashes of three random documents followed by the hash of the housing manager\u2019s certificate are recorded into the blockchain. We first run the following command to set up a local IPFS node. ipfs daemon We then open the web user interface at http://localhost:5001/webui in browser, drag-and-drop the information pool documents to the web user interface to upload them, and make note of the hash values of the documents","title":"Open IPFS web user interface"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#upload-three-documents-related-to-the-real-estate","text":"Upload the document to IPFS by drag-and-drop in the web UI. See what the hash of the document is and announce it in the smart contract. As the next step, the command above is executed three times, each time replacing with the hash of a different document. We then run the following command once to upload the actual housing manager\u2019s certificate, compiled from the already uploaded documents: node 2 -uploadDocument <document hash>","title":"Upload three documents related to the real estate"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#upload-confirmation-letter","text":"As the next step, the command above is executed three times, each time replacing with the hash of a different document. We then run the following command once to up load the actual housing manager\u2019s certificate, compiled from the already uploaded documents: node 3 -uploadConfirmationLetter <document hash>","title":"Upload confirmation letter"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#create-offers-to-sell-the-property-as-a-real-estate-agentbroker","text":"Create offers from real estate agents to sell the property When the housing manager\u2019s certificate has been received, the real estate can be sold. In the workflow of our demo application, real estate agents compete for who gets to sell the real estate by making offers to the seller of the real estate, specifying a fee (e.g. a percentual cut) that they\u2019ll sell it for. node 4 -makeAgentOffer <fee>","title":"Create offers to sell the property as a real estate agent/broker"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#as-the-owner-of-the-real-estate-accept-one-of-the-agent-offers","text":"To emulate this market behavior, we run the command above any number of times, each time changing the fee variable to differentiate between offers. Accepting a real estate agents offer As the last step of the workflow modelled in our demo application, the seller of the share of stocks in a housing company chooses one of the listing offers made by one of the agents. This is emulated by executing the command below, along with the proper offer ID from the status viewer window. node 5 -chooseAgentOffer <offer id>","title":"As the owner of the real estate, accept one of the agent offers"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#ganache-commands","text":"npm run ganache ganache-cli --accounts","title":"Ganache Commands"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#smart-contract","text":"The logic of the smart contract facilitating the workflow is defined in the Solidity file RealEstateMarket.sol. The contract defines the public methods for initiating sales, creating housing manager certificates, as well as creating listing offers and accepting them.","title":"Smart Contract"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#gui","text":"The status viewer is a web page which is useful for observing changes in the blockchain while running the demo. It shows the status of the workflow process, with all the contributions to it by the various participants. The status viewer can be run by opening the file index.html in any web browser.","title":"GUI"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#sourcecode","text":"Armanriazi-Github-RealState-Sample Project","title":"Sourcecode"},{"location":"public/blockchain/solidity/smart-contract-real-estate/#nodejs-truffle-ganache-eth-ethereum","text":"[[Ethereum_Ecosystem_Research]] [[smart-contract]]","title":"nodejs #truffle #ganache #eth #ethereum"},{"location":"public/blockchain/solidity/smart-contract-sale/","tags":["smartcontract","ethereum_ecosystem","sample","github","faucet","kovan"],"text":"A guide to demoing the [[marketplace]] contract \u00b6 Prerequisites \u00b6 This documentation has been intended for readers with a basic understanding on the Solidity smart contract programming language and on basic web developing tools. In order to run, the demo requires the following software to be installed. For verified functionality, the specified versions are recommended: Ubuntu 18.04.0 LTS Node.js, version 8.9.0 MetaMask Running an [[Ethereum]] client Install dependencies \u00b6 Before the first run, dependencies need to be installed for the test scripts and the status viewer. cd scripts/ npm install Sale Contract \u00b6 Who Wants to build Smartcontracts and DApps. basic knowledge on Ethereum Eco-System and Solidity Language is necessary to understand These Concepts. I\u2019m writing this step-by-step guide and I wish it is the best way to explain what Smart Contracts are. So let's get started. E-commerce involves buying and selling of goods or services. So mainly it has buyers and sellers. The following example is made of ethereum blockchain using a point-to-point product trading system. Each user buys a product via their MetaMask, which leads to the deduction of the amount of ethereum in the buyer's wallet and at the same time is credited to the seller's account according to the smart contract deployed. This sample does not follow the internal network in the previous sample It has got an ethereum test network called Kovan. Truffle Commands \u00b6 npm run truffle-migrate-reset //gitter.im/kovan-testnet/faucet Sourcecode \u00b6 Armanriazi-Github-Marketplace-Sample Project nodejs #metamask \u00b6 [[Ethereum_Ecosystem_Research]] [[smart-contract]] [[Faucet]] [[Kovan]]","title":"Arman Riazi"},{"location":"public/blockchain/solidity/smart-contract-sale/#a-guide-to-demoing-the-marketplace-contract","text":"","title":"A guide to demoing the [[marketplace]] contract"},{"location":"public/blockchain/solidity/smart-contract-sale/#prerequisites","text":"This documentation has been intended for readers with a basic understanding on the Solidity smart contract programming language and on basic web developing tools. In order to run, the demo requires the following software to be installed. For verified functionality, the specified versions are recommended: Ubuntu 18.04.0 LTS Node.js, version 8.9.0 MetaMask Running an [[Ethereum]] client","title":"Prerequisites"},{"location":"public/blockchain/solidity/smart-contract-sale/#install-dependencies","text":"Before the first run, dependencies need to be installed for the test scripts and the status viewer. cd scripts/ npm install","title":"Install dependencies"},{"location":"public/blockchain/solidity/smart-contract-sale/#sale-contract","text":"Who Wants to build Smartcontracts and DApps. basic knowledge on Ethereum Eco-System and Solidity Language is necessary to understand These Concepts. I\u2019m writing this step-by-step guide and I wish it is the best way to explain what Smart Contracts are. So let's get started. E-commerce involves buying and selling of goods or services. So mainly it has buyers and sellers. The following example is made of ethereum blockchain using a point-to-point product trading system. Each user buys a product via their MetaMask, which leads to the deduction of the amount of ethereum in the buyer's wallet and at the same time is credited to the seller's account according to the smart contract deployed. This sample does not follow the internal network in the previous sample It has got an ethereum test network called Kovan.","title":"Sale Contract"},{"location":"public/blockchain/solidity/smart-contract-sale/#truffle-commands","text":"npm run truffle-migrate-reset //gitter.im/kovan-testnet/faucet","title":"Truffle Commands"},{"location":"public/blockchain/solidity/smart-contract-sale/#sourcecode","text":"Armanriazi-Github-Marketplace-Sample Project","title":"Sourcecode"},{"location":"public/blockchain/solidity/smart-contract-sale/#nodejs-metamask","text":"[[Ethereum_Ecosystem_Research]] [[smart-contract]] [[Faucet]] [[Kovan]]","title":"nodejs #metamask"},{"location":"public/blockchain/solidity/smart-contract-voting/","tags":["smartcontract","ethereum_ecosystem","sample","github"],"text":"A guide to the [[vote]] contract \u00b6 Prerequisites \u00b6 This documentation has been intended for readers with a basic understanding on the Solidity smart contract programming language and on basic web developing tools. In order to run, the demo requires the following software to be installed. For verified functionality, the specified versions are recommended: Ubuntu 18.04.0 LTS Node.js, version 8.9.0 Ganache MetaMask Running an [[Ethereum]] client Install dependencies \u00b6 Before the first run, dependencies need to be installed for the test scripts and the status viewer. cd scripts/ npm install Vote Contract \u00b6 There is no doubt that the revolutionary concept of the blockchain, which is the underlying technology behind the famous cryptocurrency Bitcoin and its successors, is triggering the start of a new era in the Internet and the online services. While most people focus only at cryptocurrencies; in fact, many administrative operations, fintech procedures, and everyday services that can only be done offline and/or in person, can now safely be moved to the Internet as online services. What makes it a powerful tool for digitalizing everyday services is the introduction of smart contracts, as in the Ethereum platform. Smart contracts are meaningful pieces of codes, to be integrated in the blockchain and executed as scheduled in every step of blockchain updates. E-voting on the other hand, is another trending, yet critical, topic related to the online services. The blockchain with the smart contracts, emerges as a good candidate to use in developments of safer, cheaper, more secure, more transparent, and easier-to-use e-voting systems. Ethereum and its network is one of the most suitable ones, due to its consistency, widespread use, and provision of smart contracts logic. An e-voting system must be secure, as it should not allow duplicated votes and be fully transparent, while protecting the privacy of the attendees. In this work, we have implemented and tested a sample e-voting application as a smart contract for the Ethereum network using the Ethereum wallets and the Solidity language. In the following example, demonstrated a voting app on ethereum network which per-account will be have a franchise. Features \u00b6 Transparency Distributed Private Test Network Integrate to the Metamask Ganache Commands \u00b6 npm run ganache ganache-cli --accounts Sourcecode \u00b6 Armanriazi-Github-Vote-Sample Project [[Ethereum_Ecosystem_Research]] [[smart-contract]]","title":"Arman Riazi"},{"location":"public/blockchain/solidity/smart-contract-voting/#a-guide-to-the-vote-contract","text":"","title":"A guide to the [[vote]] contract"},{"location":"public/blockchain/solidity/smart-contract-voting/#prerequisites","text":"This documentation has been intended for readers with a basic understanding on the Solidity smart contract programming language and on basic web developing tools. In order to run, the demo requires the following software to be installed. For verified functionality, the specified versions are recommended: Ubuntu 18.04.0 LTS Node.js, version 8.9.0 Ganache MetaMask Running an [[Ethereum]] client","title":"Prerequisites"},{"location":"public/blockchain/solidity/smart-contract-voting/#install-dependencies","text":"Before the first run, dependencies need to be installed for the test scripts and the status viewer. cd scripts/ npm install","title":"Install dependencies"},{"location":"public/blockchain/solidity/smart-contract-voting/#vote-contract","text":"There is no doubt that the revolutionary concept of the blockchain, which is the underlying technology behind the famous cryptocurrency Bitcoin and its successors, is triggering the start of a new era in the Internet and the online services. While most people focus only at cryptocurrencies; in fact, many administrative operations, fintech procedures, and everyday services that can only be done offline and/or in person, can now safely be moved to the Internet as online services. What makes it a powerful tool for digitalizing everyday services is the introduction of smart contracts, as in the Ethereum platform. Smart contracts are meaningful pieces of codes, to be integrated in the blockchain and executed as scheduled in every step of blockchain updates. E-voting on the other hand, is another trending, yet critical, topic related to the online services. The blockchain with the smart contracts, emerges as a good candidate to use in developments of safer, cheaper, more secure, more transparent, and easier-to-use e-voting systems. Ethereum and its network is one of the most suitable ones, due to its consistency, widespread use, and provision of smart contracts logic. An e-voting system must be secure, as it should not allow duplicated votes and be fully transparent, while protecting the privacy of the attendees. In this work, we have implemented and tested a sample e-voting application as a smart contract for the Ethereum network using the Ethereum wallets and the Solidity language. In the following example, demonstrated a voting app on ethereum network which per-account will be have a franchise.","title":"Vote Contract"},{"location":"public/blockchain/solidity/smart-contract-voting/#features","text":"Transparency Distributed Private Test Network Integrate to the Metamask","title":"Features"},{"location":"public/blockchain/solidity/smart-contract-voting/#ganache-commands","text":"npm run ganache ganache-cli --accounts","title":"Ganache Commands"},{"location":"public/blockchain/solidity/smart-contract-voting/#sourcecode","text":"Armanriazi-Github-Vote-Sample Project [[Ethereum_Ecosystem_Research]] [[smart-contract]]","title":"Sourcecode"},{"location":"public/blockchain/solidity/smart-contract/","tags":["smartcontract","ethereum_ecosystem","sample","github"],"text":"SmartContract \u00b6 Sample Projects \u00b6 Smart Contract-Sales-Energy Smart Contract-RealState Smart Contract-Sale Product Smart Contract-Vote [[Ethereum_Ecosystem_Research]] [[smart-contract]]","title":"SmartContract"},{"location":"public/blockchain/solidity/smart-contract/#smartcontract","text":"","title":"SmartContract"},{"location":"public/blockchain/solidity/smart-contract/#sample-projects","text":"Smart Contract-Sales-Energy Smart Contract-RealState Smart Contract-Sale Product Smart Contract-Vote [[Ethereum_Ecosystem_Research]] [[smart-contract]]","title":"Sample Projects"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/","tags":["kusama","polkadot_ecosystem","substrate","whitepapaer","polkadot"],"text":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Part(1) \ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb Introducing \u00b6 Polkadot unites a network of heterogeneous blockchain shards called parachains. These chains connect to and are secured by the Polkadot Relay Chain. They can also connect with external networks via bridges. Inbound-outboundTransaction \u00b6 @Ingress Dynamic information includes aspects of the transaction routing system that must have global agreement such as the parachain\u2019s ingress queue @Egress ... \ud83d\udc46\ud83d\udc46\ud83d\udc46 Parachain \u00b6 A first parachain implementation, likely to be based heavily on an existing blockchain protocol such as Bitcoin or (more likely, since it provides for rich transactions) Ethereum. This will include an integration with the proof-of-stake chain, allowing the parachain to gain consensus without its own internal consensus mechanism. Each parachain is defined in this registry. It is a relatively simple database-like construct and holds both static and dynamic information on each chain.Static information includes the chain index (a simple integer), along with the validation protocol identity. Each parachain brings with it the potential to grief validators with an over-burdensome validation algorithm. @zk-SNARKs A parachain utilising the properties of zk-SNARKs in order to ensure identities of transactors on it are kept private. A stretch goal dependent on the relay-chain. Relay-chains \u00b6 This is the final stage of the relay-chain, allowing the dynamic addition, removal and emergency pausing of parachains, the reporting of bad behaviour and includes implementation of the \\fisherman\" functionality Polkadot will be able to scale even further in the future with a planned feature known as nested relay chains, which will increase the number of shards that can be added to the network. Interchain \u00b6 (according to the logic of that chain) able to effect the dispatch of a transaction into a second parachain or, potentially , the relay-chain. Like external transactions on production blockchains, they are fully asynchronous and there is no intrinsic ability for them to return any kind of information back to its origin. @MessageProtocol The secret sauce of parachain interoperability lies in XCMP. XCMP enables parachains to share trusted logic, for example, transferring tokens between networks, without any additional trust assumptions! XCM is related to cross-chain in the same way that REST is related RESTful. XCM cannot actually send messages between systems. It is a format for how message transfer should be performed, similar to how RESTful services use REST as an architectural style of deployment. @Queue Interchain transactions are resolved using a simple queuing mechanism based around a Merkle tree to ensure fidelity. @Routing Posts Routing. Each parachain header includes an egress-trie-root; These posts are structured as several FIFO queues; the number of lists is known as the routing base and may be around 16. Notably, this number represents the quantity of parachains we can support without having to resort to multi-phase routing. Initially, Polkadot will support this kind of direct routing. Hyper-cube Routing. Hyper-cube routing is a mechanism which can mostly be build as an extension to the basic routing mechanism described above. Validators \u00b6 Validators may provide only a \\null\" block containing no external \"transactions\" data, but may run the risk of getting a reduced reward if they do. List of punishable validator misbehaviour includes: \u2022 Being part of a parachain group unable to provide consensus over the validity of a parachain block. \u2022 Actively signing for the validity of an invalid parachain block. \u2022 Inability to supply egress payloads previously voted as available. \u2022 Inactivity during the consensus process. \u2022 Validating relay-chain blocks on competing forks. Parachain validators will need to collect additional input data from the previous set of validators or the availability guarantors. Each participant (validator) has a set of information, in the form of signed-statements (\"votes\") from other participants, regarding each parachain block candidate as well the relaychain block candidate. The set of information is two pieces: Availability: does this validator have egress transaction-post information from this block so they are able to properly validate parachain candidates on the following block? They may vote either 1(known) or 0 (not yet known). Validity: is the parachain block valid and is all externally-referenced data (e.g. transactions). They may vote either 1 (valid), -1 (invalid) or 0 (not yet known). The basic rules for validity of the individual blocks (that allow the total set of validators as a whole to come to consensus on it becoming the unique parachain candidate to be referenced from the canonical relay): \u2022 must have at least two thirds of its validators voting positively and none voting negatively; \u2022 must have over one third validators voting positively to the availability of egress queue information. @BFT All validators must submit votes; votes may be resubmitted, qualified by the rules above. The progression of consensus may be modelled as multiple standard BFT consensus algorithms over each parachain happening in parallel. @Bonded-Validator It allows an account to register a desire to become a bonded validator (along with its requirements), to nominate to some identity, and for preexisting bonded validators to register their desire to exit this status. @Sealing Under a PoW chain,sealing is effectively a synonym for mining. In our case, it involves the collection of signed statements from validators over the validity, availability and canonicality of a particular relay-chain block and the parachain blocks that it represents. The relay-chain block may then be sealed and the process of sealing the next block begun. The sealing process takes place under a single consensus-generating mechanism addressing both the relay-chain\u2019s block and the parachains\u2019 blocks. @Improvments-for-sealing-relay-blocks Public Participation . One more possible direction is to enlist public participation in the process through a micro-complaints system. Similar to the fishermen, there could be external parties to police the validators who claim availability. Their task is to find one who appears unable to demonstrate such availability. Availability Guarantors . A (this may be represented by Validators in the basic form of the protocol). Availability guarantors will mostly aim to maintain a stable connection to each other and to validators. A final route would be to nominate a second set of bonded validators as \"availability guarantors\". Unlike normal validators, they would not switch between parachains but rather would form a single group to attest to the availability of all important interchain data. This has the advantage of relaxing the equivalence between participants and chains. Overweight Blocks. If a validator set is compromised, they may create and propose a block which though valid, takes an inordinate amount of time to execute and validate. This is a problem since a validator group could reasonably form a block which takes a very long time to execute unless some particular piece of information is already known allowing a short cut, e.g. factoring a large prime. If a single collator knew that information, then they would have a clear advantage in getting their own candidates accepted as long as the others were busy processing the old block. We call these blocks overweight. To ensure validators can predict when they may be proposing an overweight block, it may be sensible to require them to publish information on their own performance for each block. Collator Insurance. One issue remains for validators: unlike with PoW networks, to check a collator\u2019s block for validity, they must actually execute the transactions in it. Malicious collators can feed invalid or overweight blocks to validators causing them grief and exacting a potentially substantial opportunity cost. To mitigate this, we propose a simple strategy on the part of validators. Firstly, parachain block candidates sent to validators must be signed from a relay chain account with funds; if they are not, then the validator should drop it immediately. Collator Preferences. One important aspect of this system is to ensure that there is a healthy selection of collators creating the blocks in any given parachain. If a single collator dominated a parachain then some attacks become more feasible. Collators \u00b6 it is quite possible that this mechanism enables even very small stakeholders to contribute as a collator. This is the delivery of an alternative chain-specific collator functionality. It includes proof creation (for collators), parachain misbehaviour detection (for fishermen) and the validation function (for validators). It also includes any additional networking required to allow the two to discover and communicate. @zero-knowledge @gossip Validators work alongside a parachain gossip protocol with collators individuals who collate transactions into blocks and provide a noninteractive, zero-knowledge proof that the block constitutes a valid child of its parent (and taking any transaction fees for their trouble Fishermen \u00b6 The parties get a reward for reporting such activity; their term, \"fishermen\" stems from the unlikeliness of such a reward. Fishermen, as well as general relay-chain and parachain clients will generally aim to keep a connection open to a validator or guarantor. Queue \u00b6 These queues are administered on the relay-chain allowing parachains to determine each other\u2019s saturation status; this way a failed attempt to post a transaction to a stalled destination may be reported synchronously. (Though since no return path exists, if a secondary transaction failed for that reason.) Networking \u00b6 @overlay @devp2p @p2p solved around a few request and answer message types. While Ethereum made progress on current protocol offerings with the devp2p protocol, which allowed for many subprotocols to be multiplexed over a single peer connection and thus have the same peer overlay support many p2p protocols simultaneously.To ensure an efficient transport mechanism, a \"flat\" overlay network like Ethereum\u2019s devp2p. Polkadot are rather more substantial. Rather then a wholly uniform network, Polkadot has several types of participants each with different requirements over their peer makeup and several network \"avenues\" whose participants will tend to converse about particular data. This means a substantially more structured network overlay|and a protocol supporting that will likely be necessary. network participants into two sets (relay-chain, parachains) each of three subsets. Path to an Effective Network Protocol. Likely the most effective and reasonable development effort will focus on utilising a pre-existing protocol rather than rolling our own. Several peer-to-peer base protocols exist that we may use or augment including Ethereum\u2019s own devp2p, IPFS\u2019s libp2p and GNU\u2019s GNUnet. A full review of these protocols and their relevance for building a modular peer network supporting certain structural guarantees, dynamic peer steering and extensible sub-protocols is well beyond the scope of this document. \ud83d\udc46\ud83d\udc46\ud83d\udc46 Parachain-Block \u00b6 @Candidate Such subsets of validators are required to provide a parachain block candidate which is guaranteed valid (on pain of bond confiscation). Transaction-forwarding-contract \u00b6 In short, we envision that transactions from Polkadot can be signed by validators and then fed into Ethereum where they can be interpreted and enacted by a transaction-forwarding contract. Break-in-contract \u00b6 Ethereum is able to host a \"break-in contract\" which can maintain the 144 signatories and be controlled by them. we can imagine a \"break-in\" contract within a parachain which allows a validator to be guaranteed payment in exchange for the provision of a particular volume of processing resources. These resources may be measured in something like gas, but could also be some entirely novel model such as subjective time-to-execute or a Bitcoin-like flat-fee model. Breakout-contract \u00b6 @Header we can imagine our Polkadot-side Ethereum interface to have some simple functions: to be able to accept a new header from the Ethereum network and validate the PoW, to be able to accept some proof that a particular log was emitted by the Ethereum-side breakout contract for a header of sufficient depth (and forward the corresponding message within Polkadot) and finally to be able to accept proofs that a previously accepted but not-yet-enacted header contains an invalid receipt root. Delivering a transaction from Bitcoin to Polkadot can in principle be done with a process similar to that for Ethereum; a \\break-out address\" controlled in some way by the Polkadot validators could receive transferred tokens (and data sent alongside them). Any tokens then owned in the \"break-out address\" would then, in principle, be controlled by those same validators for later dispersal Staking-Contract \u00b6 This contract maintains the validator set. It manages: \u2022 which accounts are currently validators; \u2022 which are available to become validators at short notice; \u2022 which accounts have placed stake nominating to a validator; \u2022 properties of each including staking volume, acceptable payout-rates and addresses and short term (session) identities. \ud83d\udc46\ud83d\udc46\ud83d\udc46 POS \u00b6 Proof-of-stake chain: Extending the consensus mechanism into proof-of stake territory; this module includes staking tokens, managing entry and exit from the validator pool, a market mechanism for determining validator rewards, finalising the approval-voting nomination mechanism and managing bond-confiscation and dismissal. It includes a substantial amount of research and prototyping prior to final development. NPOS \u00b6 @Stake-Token-Liquidity Keeping with our tenets, we elect for the simplest solution: not all tokens be staked . This would mean that some proportion (perhaps 20%) of tokens will forcibly remain liquid. Though this is imperfect from a security perspective , it is unlikely to make a fundamental difference in the security of the network; 80% of the reparations possible from bond confiscations would still be able to be made compared to the perfect case\" of 100% staking. sessions would happen regularly, perhaps as often as once per hour. @Nominate Nominating works through an approval-voting system.Each session, nominators\u2019 bonds are dispersed to be represented by one or more validators. POA \u00b6 Proof-of-authority consensus mechanism supporting rich validator statements and allowing multiple independent items to be agreed upon under a single series based upon subjective reception of the partial set of validator statements. The mechanism should allow the proof of misbehaviour for the dismissal of malicious validators but need not involve any staking mechanism. A substantial amount of research and prototyping will precede the development of this component POC \u00b6 An initial proof-of-concept would focus on placing the new validation algorithms into clients themselves, effectively requiring a hard fork of the protocol each time an additional class of chain were added. \ud83d\udc46\ud83d\udc46\ud83d\udc46 Features \u00b6 @Forkless often taking months of work, and particularly contentious hard forks can break apart a community.Polkadot revolutionizes this process, enabling blockchains to upgrade themselves without the need to fork the chain. These forkless upgrades are enacted through Polkadot\u2019s transparent on-chain governance system. @runtime @substrate How can a blockchain network automatically upgrade? Substrate has a unique property where the runtime (state transition function) is stored within the blockchain state. This means nodes update themselves by default rather than through manual intervention. DAO \u00b6 @governance Initially, this will be a meta-protocol on the relay-chain for managing exceptional events such as hard-forks, soft-forks and protocol reparameterisation. It will include a modern structure to help manage conflict and prevent live-lock. Ultimately, this may become a full meta protocol layer able to enact changes normally reserved for hard-forks. Requires the relay chain. The registry is able to have parachains added only through full referendum voting; this could be managed internally but would more likely be placed in an external referendum contract in order to facilitate re-usage under more general governance components. The parameters to voting requirements (e.g. any quorum required, majority required) for registration of additional chains. two thirds supermajority to pass with more than one third of total system stake voting positively may be a sensible starting point. The removal of parachains altogether would come only after a referendum . Crowdloan \u00b6 @Slot If the slots cannot be filled, the lower bound could be repeatedly reduced by some factor in order to satisfy. @StakeHolder Essentially, the community of stakeholders will need to be incentivized to add child chains|either financially or through the desire to add featureful chains to the relay. \ud83d\udc46\ud83d\udc46\ud83d\udc46 Fees \u00b6 @Negotiation-logic The transaction has an origin segment, providing the ability to identify a parachain, and an address which may be of arbitrary size. Unlike common current systems such as Bitcoin and Ethereum, interchain transactions do not come with any kind of payment\" of fee associated ; any such payment must be managed through negotiation logic on the source and destination parachains. Calling into another such chain would mean proxying through this bridge, which would provide the means of negotiating the value transfer between chains in order to pay for the computation resources required on the destination parachain. Gas \u00b6 cost of Ethereum confirming that an instruction was properly validated as coming from the Polkadot network would be no more than 300,000 gas|a mere 6% of the total block gas limit at 5.5M. then the cost to the network of maintaining this Ethereum-forwarding bridge would be around 540,000 gas per day or, at present gas prices, $45 per year. without gas, how does one parachain avoid another parachain from forcing it to do computation? While we can rely on transaction-post ingress queue buffers to prevent one chain from spamming another with transaction data, there is no equivalent mechanism provided by the protocol to prevent the spamming of transaction processing. Because of Substrate\u2019s modularity, gas is completely optional, and the introduction of off-chain features greatly reduces computation and storage costs. \u270d\ufe0f\u270d\ufe0f\u270d\ufe0f Signature \u00b6 One interesting, and cheaper, alternative to this multisignature contract model would be to use \u270d\ufe0fthreshold signatures in order to achieve the multi-lateral ownership semantics . While threshold signature schemes for ECDSA are computationally expensive, those for other schemes such as \u270d\ufe0f Schnorr signatures are very reasonable. Bitcoin is substantially more limited, with most clients accepting only multisignature transactions with a maximum of 3 parties SPV \u00b6 refers to Simplified Payment Verification in Bitcoin and describes a method for clients to verify transactions while keeping only a copy of all blocks headers of the longest PoW chain. \u2753\u2753\u2753 Appendix B. Frequently Asked Questions Is Polkadot designed to replace (insert blockchain here)? No. The goal of Polkadot is to provide a framework under which new blockchains may be created and to which existing blockchains can, if their communities desire, be transitioned. Is Polkadot designed to replace (insert crypto-currency here)? No. Polkadot tokens are neither intended nor designed to be used as a currency. They would make a bad currency: most will remain illiquid in the staking system and those that are liquid will face substantial fees for transfer of ownership. Rather, the purpose of Polkadot tokens is to be a direct representation of stake in the Polkadot network. What is the inflation rate for Polkadot staking tokens? The Polkadot staking token base expansion is unlimited. It rises and lowers according to market effects in order to target a particular proportion of tokens held under long-term bond in the validation process. Why does staking token ownership reflect stakeholding? This is a mechanism realised by the fact that they underpin the network\u2019s security. As such their value is tied to the overall economic value that Polkadot provides. Any actors who gain overall value from Polkadot operating correctly are incentivised to ensure it continues to do so. The best means of doing so is to take part in the validation process. This generally implies ownership of staking tokens. \ud83d\udcda\ud83d\udcda\ud83d\udcda Literature \u00b6 external data referenced = transactions grief = wasting their resources a posted transaction = post XCMP = Cross-Chain Message Passing runtime = state transition function Substrate-Glossary \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f If you liked this article or if it helped you please clap on this post to help the Read.Cash algorithm recommend it to more people. If you have any questions or remarks please feel free to leave a comment below. Alternatively, please feel free to send donations 0xde5D732a5AB44832E1c69b18be30834639F44A2c \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Polkadot]] [[Kusama]] [[Substrate]]","title":"Polka research intro"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#introducing","text":"Polkadot unites a network of heterogeneous blockchain shards called parachains. These chains connect to and are secured by the Polkadot Relay Chain. They can also connect with external networks via bridges.","title":"Introducing"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#inbound-outboundtransaction","text":"@Ingress Dynamic information includes aspects of the transaction routing system that must have global agreement such as the parachain\u2019s ingress queue @Egress ... \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Inbound-outboundTransaction"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#parachain","text":"A first parachain implementation, likely to be based heavily on an existing blockchain protocol such as Bitcoin or (more likely, since it provides for rich transactions) Ethereum. This will include an integration with the proof-of-stake chain, allowing the parachain to gain consensus without its own internal consensus mechanism. Each parachain is defined in this registry. It is a relatively simple database-like construct and holds both static and dynamic information on each chain.Static information includes the chain index (a simple integer), along with the validation protocol identity. Each parachain brings with it the potential to grief validators with an over-burdensome validation algorithm. @zk-SNARKs A parachain utilising the properties of zk-SNARKs in order to ensure identities of transactors on it are kept private. A stretch goal dependent on the relay-chain.","title":"Parachain"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#relay-chains","text":"This is the final stage of the relay-chain, allowing the dynamic addition, removal and emergency pausing of parachains, the reporting of bad behaviour and includes implementation of the \\fisherman\" functionality Polkadot will be able to scale even further in the future with a planned feature known as nested relay chains, which will increase the number of shards that can be added to the network.","title":"Relay-chains"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#interchain","text":"(according to the logic of that chain) able to effect the dispatch of a transaction into a second parachain or, potentially , the relay-chain. Like external transactions on production blockchains, they are fully asynchronous and there is no intrinsic ability for them to return any kind of information back to its origin. @MessageProtocol The secret sauce of parachain interoperability lies in XCMP. XCMP enables parachains to share trusted logic, for example, transferring tokens between networks, without any additional trust assumptions! XCM is related to cross-chain in the same way that REST is related RESTful. XCM cannot actually send messages between systems. It is a format for how message transfer should be performed, similar to how RESTful services use REST as an architectural style of deployment. @Queue Interchain transactions are resolved using a simple queuing mechanism based around a Merkle tree to ensure fidelity. @Routing Posts Routing. Each parachain header includes an egress-trie-root; These posts are structured as several FIFO queues; the number of lists is known as the routing base and may be around 16. Notably, this number represents the quantity of parachains we can support without having to resort to multi-phase routing. Initially, Polkadot will support this kind of direct routing. Hyper-cube Routing. Hyper-cube routing is a mechanism which can mostly be build as an extension to the basic routing mechanism described above.","title":"Interchain"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#validators","text":"Validators may provide only a \\null\" block containing no external \"transactions\" data, but may run the risk of getting a reduced reward if they do. List of punishable validator misbehaviour includes: \u2022 Being part of a parachain group unable to provide consensus over the validity of a parachain block. \u2022 Actively signing for the validity of an invalid parachain block. \u2022 Inability to supply egress payloads previously voted as available. \u2022 Inactivity during the consensus process. \u2022 Validating relay-chain blocks on competing forks. Parachain validators will need to collect additional input data from the previous set of validators or the availability guarantors. Each participant (validator) has a set of information, in the form of signed-statements (\"votes\") from other participants, regarding each parachain block candidate as well the relaychain block candidate. The set of information is two pieces: Availability: does this validator have egress transaction-post information from this block so they are able to properly validate parachain candidates on the following block? They may vote either 1(known) or 0 (not yet known). Validity: is the parachain block valid and is all externally-referenced data (e.g. transactions). They may vote either 1 (valid), -1 (invalid) or 0 (not yet known). The basic rules for validity of the individual blocks (that allow the total set of validators as a whole to come to consensus on it becoming the unique parachain candidate to be referenced from the canonical relay): \u2022 must have at least two thirds of its validators voting positively and none voting negatively; \u2022 must have over one third validators voting positively to the availability of egress queue information. @BFT All validators must submit votes; votes may be resubmitted, qualified by the rules above. The progression of consensus may be modelled as multiple standard BFT consensus algorithms over each parachain happening in parallel. @Bonded-Validator It allows an account to register a desire to become a bonded validator (along with its requirements), to nominate to some identity, and for preexisting bonded validators to register their desire to exit this status. @Sealing Under a PoW chain,sealing is effectively a synonym for mining. In our case, it involves the collection of signed statements from validators over the validity, availability and canonicality of a particular relay-chain block and the parachain blocks that it represents. The relay-chain block may then be sealed and the process of sealing the next block begun. The sealing process takes place under a single consensus-generating mechanism addressing both the relay-chain\u2019s block and the parachains\u2019 blocks. @Improvments-for-sealing-relay-blocks Public Participation . One more possible direction is to enlist public participation in the process through a micro-complaints system. Similar to the fishermen, there could be external parties to police the validators who claim availability. Their task is to find one who appears unable to demonstrate such availability. Availability Guarantors . A (this may be represented by Validators in the basic form of the protocol). Availability guarantors will mostly aim to maintain a stable connection to each other and to validators. A final route would be to nominate a second set of bonded validators as \"availability guarantors\". Unlike normal validators, they would not switch between parachains but rather would form a single group to attest to the availability of all important interchain data. This has the advantage of relaxing the equivalence between participants and chains. Overweight Blocks. If a validator set is compromised, they may create and propose a block which though valid, takes an inordinate amount of time to execute and validate. This is a problem since a validator group could reasonably form a block which takes a very long time to execute unless some particular piece of information is already known allowing a short cut, e.g. factoring a large prime. If a single collator knew that information, then they would have a clear advantage in getting their own candidates accepted as long as the others were busy processing the old block. We call these blocks overweight. To ensure validators can predict when they may be proposing an overweight block, it may be sensible to require them to publish information on their own performance for each block. Collator Insurance. One issue remains for validators: unlike with PoW networks, to check a collator\u2019s block for validity, they must actually execute the transactions in it. Malicious collators can feed invalid or overweight blocks to validators causing them grief and exacting a potentially substantial opportunity cost. To mitigate this, we propose a simple strategy on the part of validators. Firstly, parachain block candidates sent to validators must be signed from a relay chain account with funds; if they are not, then the validator should drop it immediately. Collator Preferences. One important aspect of this system is to ensure that there is a healthy selection of collators creating the blocks in any given parachain. If a single collator dominated a parachain then some attacks become more feasible.","title":"Validators"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#collators","text":"it is quite possible that this mechanism enables even very small stakeholders to contribute as a collator. This is the delivery of an alternative chain-specific collator functionality. It includes proof creation (for collators), parachain misbehaviour detection (for fishermen) and the validation function (for validators). It also includes any additional networking required to allow the two to discover and communicate. @zero-knowledge @gossip Validators work alongside a parachain gossip protocol with collators individuals who collate transactions into blocks and provide a noninteractive, zero-knowledge proof that the block constitutes a valid child of its parent (and taking any transaction fees for their trouble","title":"Collators"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#fishermen","text":"The parties get a reward for reporting such activity; their term, \"fishermen\" stems from the unlikeliness of such a reward. Fishermen, as well as general relay-chain and parachain clients will generally aim to keep a connection open to a validator or guarantor.","title":"Fishermen"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#queue","text":"These queues are administered on the relay-chain allowing parachains to determine each other\u2019s saturation status; this way a failed attempt to post a transaction to a stalled destination may be reported synchronously. (Though since no return path exists, if a secondary transaction failed for that reason.)","title":"Queue"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#networking","text":"@overlay @devp2p @p2p solved around a few request and answer message types. While Ethereum made progress on current protocol offerings with the devp2p protocol, which allowed for many subprotocols to be multiplexed over a single peer connection and thus have the same peer overlay support many p2p protocols simultaneously.To ensure an efficient transport mechanism, a \"flat\" overlay network like Ethereum\u2019s devp2p. Polkadot are rather more substantial. Rather then a wholly uniform network, Polkadot has several types of participants each with different requirements over their peer makeup and several network \"avenues\" whose participants will tend to converse about particular data. This means a substantially more structured network overlay|and a protocol supporting that will likely be necessary. network participants into two sets (relay-chain, parachains) each of three subsets. Path to an Effective Network Protocol. Likely the most effective and reasonable development effort will focus on utilising a pre-existing protocol rather than rolling our own. Several peer-to-peer base protocols exist that we may use or augment including Ethereum\u2019s own devp2p, IPFS\u2019s libp2p and GNU\u2019s GNUnet. A full review of these protocols and their relevance for building a modular peer network supporting certain structural guarantees, dynamic peer steering and extensible sub-protocols is well beyond the scope of this document. \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Networking"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#parachain-block","text":"@Candidate Such subsets of validators are required to provide a parachain block candidate which is guaranteed valid (on pain of bond confiscation).","title":"Parachain-Block"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#transaction-forwarding-contract","text":"In short, we envision that transactions from Polkadot can be signed by validators and then fed into Ethereum where they can be interpreted and enacted by a transaction-forwarding contract.","title":"Transaction-forwarding-contract"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#break-in-contract","text":"Ethereum is able to host a \"break-in contract\" which can maintain the 144 signatories and be controlled by them. we can imagine a \"break-in\" contract within a parachain which allows a validator to be guaranteed payment in exchange for the provision of a particular volume of processing resources. These resources may be measured in something like gas, but could also be some entirely novel model such as subjective time-to-execute or a Bitcoin-like flat-fee model.","title":"Break-in-contract"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#breakout-contract","text":"@Header we can imagine our Polkadot-side Ethereum interface to have some simple functions: to be able to accept a new header from the Ethereum network and validate the PoW, to be able to accept some proof that a particular log was emitted by the Ethereum-side breakout contract for a header of sufficient depth (and forward the corresponding message within Polkadot) and finally to be able to accept proofs that a previously accepted but not-yet-enacted header contains an invalid receipt root. Delivering a transaction from Bitcoin to Polkadot can in principle be done with a process similar to that for Ethereum; a \\break-out address\" controlled in some way by the Polkadot validators could receive transferred tokens (and data sent alongside them). Any tokens then owned in the \"break-out address\" would then, in principle, be controlled by those same validators for later dispersal","title":"Breakout-contract"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#staking-contract","text":"This contract maintains the validator set. It manages: \u2022 which accounts are currently validators; \u2022 which are available to become validators at short notice; \u2022 which accounts have placed stake nominating to a validator; \u2022 properties of each including staking volume, acceptable payout-rates and addresses and short term (session) identities. \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Staking-Contract"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#pos","text":"Proof-of-stake chain: Extending the consensus mechanism into proof-of stake territory; this module includes staking tokens, managing entry and exit from the validator pool, a market mechanism for determining validator rewards, finalising the approval-voting nomination mechanism and managing bond-confiscation and dismissal. It includes a substantial amount of research and prototyping prior to final development.","title":"POS"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#npos","text":"@Stake-Token-Liquidity Keeping with our tenets, we elect for the simplest solution: not all tokens be staked . This would mean that some proportion (perhaps 20%) of tokens will forcibly remain liquid. Though this is imperfect from a security perspective , it is unlikely to make a fundamental difference in the security of the network; 80% of the reparations possible from bond confiscations would still be able to be made compared to the perfect case\" of 100% staking. sessions would happen regularly, perhaps as often as once per hour. @Nominate Nominating works through an approval-voting system.Each session, nominators\u2019 bonds are dispersed to be represented by one or more validators.","title":"NPOS"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#poa","text":"Proof-of-authority consensus mechanism supporting rich validator statements and allowing multiple independent items to be agreed upon under a single series based upon subjective reception of the partial set of validator statements. The mechanism should allow the proof of misbehaviour for the dismissal of malicious validators but need not involve any staking mechanism. A substantial amount of research and prototyping will precede the development of this component","title":"POA"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#poc","text":"An initial proof-of-concept would focus on placing the new validation algorithms into clients themselves, effectively requiring a hard fork of the protocol each time an additional class of chain were added. \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"POC"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#features","text":"@Forkless often taking months of work, and particularly contentious hard forks can break apart a community.Polkadot revolutionizes this process, enabling blockchains to upgrade themselves without the need to fork the chain. These forkless upgrades are enacted through Polkadot\u2019s transparent on-chain governance system. @runtime @substrate How can a blockchain network automatically upgrade? Substrate has a unique property where the runtime (state transition function) is stored within the blockchain state. This means nodes update themselves by default rather than through manual intervention.","title":"Features"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#dao","text":"@governance Initially, this will be a meta-protocol on the relay-chain for managing exceptional events such as hard-forks, soft-forks and protocol reparameterisation. It will include a modern structure to help manage conflict and prevent live-lock. Ultimately, this may become a full meta protocol layer able to enact changes normally reserved for hard-forks. Requires the relay chain. The registry is able to have parachains added only through full referendum voting; this could be managed internally but would more likely be placed in an external referendum contract in order to facilitate re-usage under more general governance components. The parameters to voting requirements (e.g. any quorum required, majority required) for registration of additional chains. two thirds supermajority to pass with more than one third of total system stake voting positively may be a sensible starting point. The removal of parachains altogether would come only after a referendum .","title":"DAO"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#crowdloan","text":"@Slot If the slots cannot be filled, the lower bound could be repeatedly reduced by some factor in order to satisfy. @StakeHolder Essentially, the community of stakeholders will need to be incentivized to add child chains|either financially or through the desire to add featureful chains to the relay. \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Crowdloan"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#fees","text":"@Negotiation-logic The transaction has an origin segment, providing the ability to identify a parachain, and an address which may be of arbitrary size. Unlike common current systems such as Bitcoin and Ethereum, interchain transactions do not come with any kind of payment\" of fee associated ; any such payment must be managed through negotiation logic on the source and destination parachains. Calling into another such chain would mean proxying through this bridge, which would provide the means of negotiating the value transfer between chains in order to pay for the computation resources required on the destination parachain.","title":"Fees"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#gas","text":"cost of Ethereum confirming that an instruction was properly validated as coming from the Polkadot network would be no more than 300,000 gas|a mere 6% of the total block gas limit at 5.5M. then the cost to the network of maintaining this Ethereum-forwarding bridge would be around 540,000 gas per day or, at present gas prices, $45 per year. without gas, how does one parachain avoid another parachain from forcing it to do computation? While we can rely on transaction-post ingress queue buffers to prevent one chain from spamming another with transaction data, there is no equivalent mechanism provided by the protocol to prevent the spamming of transaction processing. Because of Substrate\u2019s modularity, gas is completely optional, and the introduction of off-chain features greatly reduces computation and storage costs. \u270d\ufe0f\u270d\ufe0f\u270d\ufe0f","title":"Gas"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#signature","text":"One interesting, and cheaper, alternative to this multisignature contract model would be to use \u270d\ufe0fthreshold signatures in order to achieve the multi-lateral ownership semantics . While threshold signature schemes for ECDSA are computationally expensive, those for other schemes such as \u270d\ufe0f Schnorr signatures are very reasonable. Bitcoin is substantially more limited, with most clients accepting only multisignature transactions with a maximum of 3 parties","title":"Signature"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#spv","text":"refers to Simplified Payment Verification in Bitcoin and describes a method for clients to verify transactions while keeping only a copy of all blocks headers of the longest PoW chain. \u2753\u2753\u2753 Appendix B. Frequently Asked Questions Is Polkadot designed to replace (insert blockchain here)? No. The goal of Polkadot is to provide a framework under which new blockchains may be created and to which existing blockchains can, if their communities desire, be transitioned. Is Polkadot designed to replace (insert crypto-currency here)? No. Polkadot tokens are neither intended nor designed to be used as a currency. They would make a bad currency: most will remain illiquid in the staking system and those that are liquid will face substantial fees for transfer of ownership. Rather, the purpose of Polkadot tokens is to be a direct representation of stake in the Polkadot network. What is the inflation rate for Polkadot staking tokens? The Polkadot staking token base expansion is unlimited. It rises and lowers according to market effects in order to target a particular proportion of tokens held under long-term bond in the validation process. Why does staking token ownership reflect stakeholding? This is a mechanism realised by the fact that they underpin the network\u2019s security. As such their value is tied to the overall economic value that Polkadot provides. Any actors who gain overall value from Polkadot operating correctly are incentivised to ensure it continues to do so. The best means of doing so is to take part in the validation process. This generally implies ownership of staking tokens. \ud83d\udcda\ud83d\udcda\ud83d\udcda","title":"SPV"},{"location":"public/blockchain/substrate-polka-kus/polka-research-intro/#literature","text":"external data referenced = transactions grief = wasting their resources a posted transaction = post XCMP = Cross-Chain Message Passing runtime = state transition function Substrate-Glossary \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f If you liked this article or if it helped you please clap on this post to help the Read.Cash algorithm recommend it to more people. If you have any questions or remarks please feel free to leave a comment below. Alternatively, please feel free to send donations 0xde5D732a5AB44832E1c69b18be30834639F44A2c \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Polkadot]] [[Kusama]] [[Substrate]]","title":"Literature"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/","tags":["kusama","polkadot_ecosystem","substrate","polkadot"],"text":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Part(2) \ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb Introducing \u00b6 Polkadot and Substrate are not dependent on each other . Polkadot parachains can be built and maintained without ever touching Substrate. Substrate-based chains can exist as \u2018solo-chains\u2019 on an independent basis. Substrate is a fully modular blockchain framework that unleashes developers instead of forcing them to work within the confines of others' design decisions. Building a custom blockchain with Substrate offers greater freedom, flexibility, and optimization than building on top of a general-purpose smart-contract blockchain. you're not only free to choose your parameters such gas costs, governance, and consensus, you're also free to choose how your blockchain is deployed and if/how it should communicate with other networks. On my opinion for substrate future(DNA Replication) Limitations-Resolved \u00b6 For example, reusing the Ethereum codebase implies several limitations: having to place all of your business logic in terms of the EVM , being forced to use one of the two EVM languages , having all business logic dynamically metered, and being limited to Ethereum's transaction pool and lack of core upgradability. Without Substrate, there would be no easy way to build the blockchains that constitute the Polkadot ecosystem, and many builders would be forced into using a constrictive and uniform smart contract environment, limiting innovation and leaving Polkadot\u2019s remarkable heterogeneous sharding system unutilized. MainModules \u00b6 Frame \u00b6 business logic is provided through a modular system known as FRAME . is a set of modules and support libraries that simplify runtime development. In Substrate, these modules are called Pallets , each hosting domain-specific logic to include in a chain's runtime. FRAME also provides some helper modules to interact with important Substrate Primitives that provide the interface to the core client. FRAME not only provides a library of commonly used Substrate pallets but also a framework to build custom domain-specific pallets, giving runtime engineers the flexibility to define their runtime's behavior according to their target use case. The result is each pallet has its own discrete logic which can modify the features and functionality of your blockchain's state transition functions. For example, the Balances pallet, which is included in FRAME, defines cryptocurrency capabilities for your blockchain. More specifically, it defines: Storage items that keep track of the tokens a user owns. Functions that users can call to transfer and manage those tokens. APIs which allow other pallets to make use of those tokens and their capabilities. Hooks which allow other pallets to trigger function calls when a user's balance changes. A FRAME pallet is composed of 7 sections: Imports and Dependencies Declaration of the Pallet type Runtime Configuration Trait Runtime Storage Runtime Events Hooks Extrinsics An example is as follows: https://docs.substrate.io/v3/runtime/frame/ Pallets can be composed of as many sections as needed, giving runtime engineers a lot of flexibility on top of the basic skeletons depicted above. Refer to the Substrate Runtime Macros to learn more about adding functionality to a FRAME pallet. @System crate The FRAME System crate frame_system provides low-level types, storage, and functions for your blockchain. All other pallets depend on the System crate as the basis of your Substrate runtime. The System crate defines all the core types for the Substrate runtime , such as: *Origin *Block Number *Account Id *Hash * *Header *Version * *etc... *It also has a number of system-critical storage items, such as: *Account Nonce * *Block Hash *Block Number *Events *etc... Finally, it defines a number of low level functions which can access your blockchain storage, verify the origin of an extrinsic, and more. @Support crate@System crate The FRAME Support Crate frame_support is a collection of Rust macros, types, traits, and modules that simplify the development of Substrate pallets. The support macros expanded at compile time generate boilerplate code needed for the common structure of a pallet and save developers from writing them repeatedly. @Executive pallet@System crate The FRAME Executive Pallet frame_executive acts as the orchestration layer for the runtime. It dispatches incoming extrinsic calls to the respective pallets in the runtime. @Runtime @System crate The runtime library brings together all these components and pallets. It defines which pallets are included with your runtime and configures them to work together to compose your final runtime. When calls are made to your runtime, it uses the Executive pallet to dispatch those calls to the individual pallets. Pallet \u00b6 A developer may choose to have a pallet that enables smart contracts , or specifically not include pallets to keep their blockchain network lean and reduce attack vectors. For example, a developer may want to enable users to gain access to accounts even if they lose their private keys or other authentication mechanism. In this case, the developer would simply include the Recovery pallet. From the Oracle pallet to the Zero-Knowledge Verifier pallet and the Governance pallet, there are numerous existing pallets that can be integrated from the start or added later with forkless runtime upgrades. Developers can choose and even hot-swap components (pallets) such as the network stack, consensus, even the finality engine. Simply select from the growing list of pallets or create your own. When building with FRAME, the Substrate runtime is composed of several smaller components called pallets. A pallet contains a set of types, storage items, and functions that define a set of features and functionality for a runtime. @Prebuilt pallets https://docs.substrate.io/v3/runtime/frame/ Atomic Swap, Aura, Authority Discovery, Authorship, BABE , Balances, Benchmark, Collective, Contracts, Democracy, Elections Phragm\u00e9n, Elections, GRANDPA, Identity, I'm Online, Indices, Membership, Multisig, Nicks, Offences, Proxy, Recovery, Randomness Collective Flip, Scheduler, Scored Pool, Session, Society, Staking, Sudo, Timestamp, Transaction Payment, Treasury, Utility, Vesting Execution environment \u00b6 Off-chain features run in their own Wasm execution environment outside of the Substrate runtime. Conceptes \u00b6 Extrinsics \u00b6 An extrinsic is a piece of information that comes from outside the chain and is included in a block. Extrinsics fall into three categories: inherents, signed transactions, and unsigned transactions. Note that events are not extrinsics. The chain emits events for pieces of information that are intrinsic to the chain itself. For example, staking rewards are events, not extrinsics, because the reward is triggered by circumstances intrinsic to the chain's logic . The header contains a block height, parent hash, extrinsics root, state root, and digest. @Inherents Inherents are pieces of information that are not signed and only inserted into a block by the block author . They are not gossiped on the network or stored in the transaction queue. For example, the author of the block may insert a timestamp inherent into the block. There is no way to prove that a timestamp is true the way the desire to send funds is proved with a signature. Rather, validators accept or reject the block based on how reasonable the other validators find the timestamp, which may mean it is within some acceptable range of their own system clocks. @SignedTransactions Contain a signature of the account that issued the transaction and stands to pay a fee to have the transaction included on chain. Because the value of including signed transactions on-chain can be recognized prior to execution, they can be gossiped on the network between nodes with a low risk of spam. @UnsignedTransactions Since the transaction is not signed, there is nobody to pay a fee . Because of this, the transaction queue lacks economic logic to prevent spam. Unsigned transactions also lack a nonce, making replay protection difficult . A few transactions warrant using the unsigned variant, but they will require some form of spam prevention based on a custom implementation of signed extension, which can exist on unsigned transactions. An example of unsigned transactions in Substrate is the I'm Online heartbeat transaction sent by authorities . The transaction includes a signature from a Session key, which does not control funds and therefore cannot pay a fee. The transaction pool controls spam by checking if a heartbeat has already been submitted in the session. \ud83d\udc46\ud83d\udc46\ud83d\udc46 Features \u00b6 Configurable \u00b6 @Feeless Unlike many legacy blockchain networks, which have hard limits for transaction throughput, Substrate is configurable. Transaction latency can be alleviated through configurable blocktimes, flexible transaction queues, and/or horizontal scaling. Transaction fees are configurable even to the point of feeless transactions. Development is faster since developers can use the tooling they prefer and select from a growing list of pallets instead of building from scratch. Upgrades happen faster thanks to forkless runtime upgrades. Light-client-first \u00b6 Another unique attribute of Substrate is its \u201clight-client-first\u201d design which can run directly in-browser and interact with a chain in a fully trustless way. Traditional approaches for syncing nodes require users to run dedicated hardware and wait a long time for their node to sync, or as a workaround, use a centralized service provider. Substrate light-clients sync lightning fast and drastically increase the decentralization of blockchain networks. Developers can relax, knowing their end users aren\u2019t reliant on a separate node infrastructure susceptible to downtime or hacking. Security \u00b6 Substrate chains can inherit security from Substrate-based relay chains like Polkadot or Kusama. Offchain \u00b6 Off-chain features run in their own execution environment outside of the Substrate runtime . This creates a separation of concerns and ensures block production is not impacted by long-running off-chain tasks. Although the primary benefit of off-chain features may be cost, there are many other benefits. For example, off-chain features can enable private data to be easily stored and retrievable off-chain to support record deletion and other needs of GDPR-compliant use cases and applications. Off-Chain Worker subsystems allows execution of long-running and possibly non-deterministic tasks (e.g. web requests, encryption/decryption and signing of data, random number generation, CPU-intensive computations, enumeration/aggregation of on-chain data, etc.) that could otherwise require longer than the block execution time. Off-chain workers have access to extended APIs for communicating with the external world: Ability to submit transactions (either signed or unsigned) to the chain to publish computation results. A fully-featured HTTP client allowing the worker to access and fetch data from external services. Access to the local keystore to sign and verify statements or transactions. An additional, local key-value database shared between all off-chain workers. A secure, local entropy source for random number generation. Access to the node's precise local time. The ability to sleep and resume work. Note that the results from off-chain workers are not subject to regular transaction verification. A verification mechanism should be implemented to determine what information gets into the chain. Off-Chain Storage offers storage that is local to a Substrate node that can be accessed both by off-chain workers (both read and write access) and on-chain logic (write access via off-chain indexing but not read access). This allows different worker threads to communicate to each other and to store user or node-specific data that does not require consensus over the whole network. It can also be read using RPC. Off-Chain Indexing allows the runtime, if opted-in, to write directly to the off-chain storage independently from OCWs. This serves as a local/temporary storage for on-chain logic and complement to its on-chain state. Nodes have to opt-in for persistency of this data via --enable-offchain-indexing flag when starting up the Substrate node. Unlike OCWs, which are not executed during initial blockchain synchronization, off-chain indexing is populating the storage every time a block is processed, so the data is always consistent and will be exactly the same for every node with indexing enabled. \ud83d\udc46\ud83d\udc46\ud83d\udc46 Compatibility \u00b6 SRML \u00b6 SRML provides the basic building blocks for Substrate-based blockchains and includes all the essential functionality for a purpose-built blockchain. Among the various modules included with the SRML is the Contracts module, designed for executing \"native\" Wasm smart contracts on any Substrate-based chain. @Parity Moreover, Parity Technologies is a long-term supporter and builder in the Ethereum ecosystem, and we want to continue to provide support and infrastructure as we can to teams who have built on the Parity platform as we move from \u201cBlockchain 2.0\u201d to \u201c3.0\u201d. As part of this ongoing support, and to ensure that Substrate and Polkadot remain as inclusive as possible to the broader DApp community, we\u2019ve (Parity Team)built an EVM implementation for the SRML. Substrate EVM is an SRML module that provides an EVM execution environment for running unmodified Solidity code \u201cnatively\u201d on a Substrate-based blockchain. In essence, Substrate EVM will allow Substrate-based blockchains, including Polkadot parachains, to host a nearly-complete instance of the Ethereum state transition function on-chain, alongside any additional Substrate modules as required for custom functionality. Existing Solidity applications can be deployed and executed in this environment, and will gain the added benefits of being part of a Substrate-based blockchain. These benefits include the possibility of integration with other Substrate modules and of connecting to the broader Polkadot network, thereby enabling interoperability not only with other Polkadot parachains but, via bridges, with external blockchains as well, including Ethereum mainnet. Interoperability with other Substrate modules is possible thanks to custom-built \"pre-compiled contract\" APIs, which will allow all basic SRML functionality, including calls between modules, balance transfers, and interchain messaging. Differences between the Substrate EVM module and the Ethereum mainnet EVM include block hashes, which are fetched via the System module. In addition, the underlying EVM engine ( SputnikVM ) has been modified to make it modular, which will allow us to enable users to swap out and customize individual components (such as the gasometer) to their applications' specific needs. Substrate EVM is an SRML module that provides an EVM execution environment for running unmodified Solidity code \u201cnatively\u201d on a Substrate-based blockchain. In essence, Substrate EVM will allow Substrate-based blockchains, including Polkadot parachains, to host a nearly-complete instance of the Ethereum state transition function on-chain, alongside any additional Substrate modules as required for custom functionality. Existing Solidity applications can be deployed and executed in this environment, and will gain the added benefits of being part of a Substrate-based blockchain. Interoperability with other Substrate modules is possible thanks to custom-built \"pre-compiled contract\" APIs, which will allow all basic SRML functionality, including calls between modules, balance transfers, and interchain messaging. \ud83d\udcda\ud83d\udcda\ud83d\udcda Literature \u00b6 hot-swap components = pallets Off-Chain Worker = OCW Remote procedure calls = RPC Framework for Runtime Aggregation of Modularized Entities = FRAME runtime = state transition function pot = The Treasury pallet provides a \"pot\" of funds The Sudo pallet allows for a single account = Sudo verifiable random function = VRF A verification mechanism =e.g. voting, averaging, checking sender signatures, or simply \"trusting\" Substrate Runtime Module Library = SRML Substrate-Glossary \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Researcher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Polkadot]] [[Substrate]]","title":"Substrate framework research intro"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#introducing","text":"Polkadot and Substrate are not dependent on each other . Polkadot parachains can be built and maintained without ever touching Substrate. Substrate-based chains can exist as \u2018solo-chains\u2019 on an independent basis. Substrate is a fully modular blockchain framework that unleashes developers instead of forcing them to work within the confines of others' design decisions. Building a custom blockchain with Substrate offers greater freedom, flexibility, and optimization than building on top of a general-purpose smart-contract blockchain. you're not only free to choose your parameters such gas costs, governance, and consensus, you're also free to choose how your blockchain is deployed and if/how it should communicate with other networks. On my opinion for substrate future(DNA Replication)","title":"Introducing"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#limitations-resolved","text":"For example, reusing the Ethereum codebase implies several limitations: having to place all of your business logic in terms of the EVM , being forced to use one of the two EVM languages , having all business logic dynamically metered, and being limited to Ethereum's transaction pool and lack of core upgradability. Without Substrate, there would be no easy way to build the blockchains that constitute the Polkadot ecosystem, and many builders would be forced into using a constrictive and uniform smart contract environment, limiting innovation and leaving Polkadot\u2019s remarkable heterogeneous sharding system unutilized.","title":"Limitations-Resolved"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#mainmodules","text":"","title":"MainModules"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#frame","text":"business logic is provided through a modular system known as FRAME . is a set of modules and support libraries that simplify runtime development. In Substrate, these modules are called Pallets , each hosting domain-specific logic to include in a chain's runtime. FRAME also provides some helper modules to interact with important Substrate Primitives that provide the interface to the core client. FRAME not only provides a library of commonly used Substrate pallets but also a framework to build custom domain-specific pallets, giving runtime engineers the flexibility to define their runtime's behavior according to their target use case. The result is each pallet has its own discrete logic which can modify the features and functionality of your blockchain's state transition functions. For example, the Balances pallet, which is included in FRAME, defines cryptocurrency capabilities for your blockchain. More specifically, it defines: Storage items that keep track of the tokens a user owns. Functions that users can call to transfer and manage those tokens. APIs which allow other pallets to make use of those tokens and their capabilities. Hooks which allow other pallets to trigger function calls when a user's balance changes. A FRAME pallet is composed of 7 sections: Imports and Dependencies Declaration of the Pallet type Runtime Configuration Trait Runtime Storage Runtime Events Hooks Extrinsics An example is as follows: https://docs.substrate.io/v3/runtime/frame/ Pallets can be composed of as many sections as needed, giving runtime engineers a lot of flexibility on top of the basic skeletons depicted above. Refer to the Substrate Runtime Macros to learn more about adding functionality to a FRAME pallet. @System crate The FRAME System crate frame_system provides low-level types, storage, and functions for your blockchain. All other pallets depend on the System crate as the basis of your Substrate runtime. The System crate defines all the core types for the Substrate runtime , such as: *Origin *Block Number *Account Id *Hash * *Header *Version * *etc... *It also has a number of system-critical storage items, such as: *Account Nonce * *Block Hash *Block Number *Events *etc... Finally, it defines a number of low level functions which can access your blockchain storage, verify the origin of an extrinsic, and more. @Support crate@System crate The FRAME Support Crate frame_support is a collection of Rust macros, types, traits, and modules that simplify the development of Substrate pallets. The support macros expanded at compile time generate boilerplate code needed for the common structure of a pallet and save developers from writing them repeatedly. @Executive pallet@System crate The FRAME Executive Pallet frame_executive acts as the orchestration layer for the runtime. It dispatches incoming extrinsic calls to the respective pallets in the runtime. @Runtime @System crate The runtime library brings together all these components and pallets. It defines which pallets are included with your runtime and configures them to work together to compose your final runtime. When calls are made to your runtime, it uses the Executive pallet to dispatch those calls to the individual pallets.","title":"Frame"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#pallet","text":"A developer may choose to have a pallet that enables smart contracts , or specifically not include pallets to keep their blockchain network lean and reduce attack vectors. For example, a developer may want to enable users to gain access to accounts even if they lose their private keys or other authentication mechanism. In this case, the developer would simply include the Recovery pallet. From the Oracle pallet to the Zero-Knowledge Verifier pallet and the Governance pallet, there are numerous existing pallets that can be integrated from the start or added later with forkless runtime upgrades. Developers can choose and even hot-swap components (pallets) such as the network stack, consensus, even the finality engine. Simply select from the growing list of pallets or create your own. When building with FRAME, the Substrate runtime is composed of several smaller components called pallets. A pallet contains a set of types, storage items, and functions that define a set of features and functionality for a runtime. @Prebuilt pallets https://docs.substrate.io/v3/runtime/frame/ Atomic Swap, Aura, Authority Discovery, Authorship, BABE , Balances, Benchmark, Collective, Contracts, Democracy, Elections Phragm\u00e9n, Elections, GRANDPA, Identity, I'm Online, Indices, Membership, Multisig, Nicks, Offences, Proxy, Recovery, Randomness Collective Flip, Scheduler, Scored Pool, Session, Society, Staking, Sudo, Timestamp, Transaction Payment, Treasury, Utility, Vesting","title":"Pallet"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#execution-environment","text":"Off-chain features run in their own Wasm execution environment outside of the Substrate runtime.","title":"Execution environment"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#conceptes","text":"","title":"Conceptes"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#extrinsics","text":"An extrinsic is a piece of information that comes from outside the chain and is included in a block. Extrinsics fall into three categories: inherents, signed transactions, and unsigned transactions. Note that events are not extrinsics. The chain emits events for pieces of information that are intrinsic to the chain itself. For example, staking rewards are events, not extrinsics, because the reward is triggered by circumstances intrinsic to the chain's logic . The header contains a block height, parent hash, extrinsics root, state root, and digest. @Inherents Inherents are pieces of information that are not signed and only inserted into a block by the block author . They are not gossiped on the network or stored in the transaction queue. For example, the author of the block may insert a timestamp inherent into the block. There is no way to prove that a timestamp is true the way the desire to send funds is proved with a signature. Rather, validators accept or reject the block based on how reasonable the other validators find the timestamp, which may mean it is within some acceptable range of their own system clocks. @SignedTransactions Contain a signature of the account that issued the transaction and stands to pay a fee to have the transaction included on chain. Because the value of including signed transactions on-chain can be recognized prior to execution, they can be gossiped on the network between nodes with a low risk of spam. @UnsignedTransactions Since the transaction is not signed, there is nobody to pay a fee . Because of this, the transaction queue lacks economic logic to prevent spam. Unsigned transactions also lack a nonce, making replay protection difficult . A few transactions warrant using the unsigned variant, but they will require some form of spam prevention based on a custom implementation of signed extension, which can exist on unsigned transactions. An example of unsigned transactions in Substrate is the I'm Online heartbeat transaction sent by authorities . The transaction includes a signature from a Session key, which does not control funds and therefore cannot pay a fee. The transaction pool controls spam by checking if a heartbeat has already been submitted in the session. \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Extrinsics"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#features","text":"","title":"Features"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#configurable","text":"@Feeless Unlike many legacy blockchain networks, which have hard limits for transaction throughput, Substrate is configurable. Transaction latency can be alleviated through configurable blocktimes, flexible transaction queues, and/or horizontal scaling. Transaction fees are configurable even to the point of feeless transactions. Development is faster since developers can use the tooling they prefer and select from a growing list of pallets instead of building from scratch. Upgrades happen faster thanks to forkless runtime upgrades.","title":"Configurable"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#light-client-first","text":"Another unique attribute of Substrate is its \u201clight-client-first\u201d design which can run directly in-browser and interact with a chain in a fully trustless way. Traditional approaches for syncing nodes require users to run dedicated hardware and wait a long time for their node to sync, or as a workaround, use a centralized service provider. Substrate light-clients sync lightning fast and drastically increase the decentralization of blockchain networks. Developers can relax, knowing their end users aren\u2019t reliant on a separate node infrastructure susceptible to downtime or hacking.","title":"Light-client-first"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#security","text":"Substrate chains can inherit security from Substrate-based relay chains like Polkadot or Kusama.","title":"Security"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#offchain","text":"Off-chain features run in their own execution environment outside of the Substrate runtime . This creates a separation of concerns and ensures block production is not impacted by long-running off-chain tasks. Although the primary benefit of off-chain features may be cost, there are many other benefits. For example, off-chain features can enable private data to be easily stored and retrievable off-chain to support record deletion and other needs of GDPR-compliant use cases and applications. Off-Chain Worker subsystems allows execution of long-running and possibly non-deterministic tasks (e.g. web requests, encryption/decryption and signing of data, random number generation, CPU-intensive computations, enumeration/aggregation of on-chain data, etc.) that could otherwise require longer than the block execution time. Off-chain workers have access to extended APIs for communicating with the external world: Ability to submit transactions (either signed or unsigned) to the chain to publish computation results. A fully-featured HTTP client allowing the worker to access and fetch data from external services. Access to the local keystore to sign and verify statements or transactions. An additional, local key-value database shared between all off-chain workers. A secure, local entropy source for random number generation. Access to the node's precise local time. The ability to sleep and resume work. Note that the results from off-chain workers are not subject to regular transaction verification. A verification mechanism should be implemented to determine what information gets into the chain. Off-Chain Storage offers storage that is local to a Substrate node that can be accessed both by off-chain workers (both read and write access) and on-chain logic (write access via off-chain indexing but not read access). This allows different worker threads to communicate to each other and to store user or node-specific data that does not require consensus over the whole network. It can also be read using RPC. Off-Chain Indexing allows the runtime, if opted-in, to write directly to the off-chain storage independently from OCWs. This serves as a local/temporary storage for on-chain logic and complement to its on-chain state. Nodes have to opt-in for persistency of this data via --enable-offchain-indexing flag when starting up the Substrate node. Unlike OCWs, which are not executed during initial blockchain synchronization, off-chain indexing is populating the storage every time a block is processed, so the data is always consistent and will be exactly the same for every node with indexing enabled. \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Offchain"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#compatibility","text":"","title":"Compatibility"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#srml","text":"SRML provides the basic building blocks for Substrate-based blockchains and includes all the essential functionality for a purpose-built blockchain. Among the various modules included with the SRML is the Contracts module, designed for executing \"native\" Wasm smart contracts on any Substrate-based chain. @Parity Moreover, Parity Technologies is a long-term supporter and builder in the Ethereum ecosystem, and we want to continue to provide support and infrastructure as we can to teams who have built on the Parity platform as we move from \u201cBlockchain 2.0\u201d to \u201c3.0\u201d. As part of this ongoing support, and to ensure that Substrate and Polkadot remain as inclusive as possible to the broader DApp community, we\u2019ve (Parity Team)built an EVM implementation for the SRML. Substrate EVM is an SRML module that provides an EVM execution environment for running unmodified Solidity code \u201cnatively\u201d on a Substrate-based blockchain. In essence, Substrate EVM will allow Substrate-based blockchains, including Polkadot parachains, to host a nearly-complete instance of the Ethereum state transition function on-chain, alongside any additional Substrate modules as required for custom functionality. Existing Solidity applications can be deployed and executed in this environment, and will gain the added benefits of being part of a Substrate-based blockchain. These benefits include the possibility of integration with other Substrate modules and of connecting to the broader Polkadot network, thereby enabling interoperability not only with other Polkadot parachains but, via bridges, with external blockchains as well, including Ethereum mainnet. Interoperability with other Substrate modules is possible thanks to custom-built \"pre-compiled contract\" APIs, which will allow all basic SRML functionality, including calls between modules, balance transfers, and interchain messaging. Differences between the Substrate EVM module and the Ethereum mainnet EVM include block hashes, which are fetched via the System module. In addition, the underlying EVM engine ( SputnikVM ) has been modified to make it modular, which will allow us to enable users to swap out and customize individual components (such as the gasometer) to their applications' specific needs. Substrate EVM is an SRML module that provides an EVM execution environment for running unmodified Solidity code \u201cnatively\u201d on a Substrate-based blockchain. In essence, Substrate EVM will allow Substrate-based blockchains, including Polkadot parachains, to host a nearly-complete instance of the Ethereum state transition function on-chain, alongside any additional Substrate modules as required for custom functionality. Existing Solidity applications can be deployed and executed in this environment, and will gain the added benefits of being part of a Substrate-based blockchain. Interoperability with other Substrate modules is possible thanks to custom-built \"pre-compiled contract\" APIs, which will allow all basic SRML functionality, including calls between modules, balance transfers, and interchain messaging. \ud83d\udcda\ud83d\udcda\ud83d\udcda","title":"SRML"},{"location":"public/blockchain/substrate-polka-kus/substrate-framework-research-intro/#literature","text":"hot-swap components = pallets Off-Chain Worker = OCW Remote procedure calls = RPC Framework for Runtime Aggregation of Modularized Entities = FRAME runtime = state transition function pot = The Treasury pallet provides a \"pot\" of funds The Sudo pallet allows for a single account = Sudo verifiable random function = VRF A verification mechanism =e.g. voting, averaging, checking sender signatures, or simply \"trusting\" Substrate Runtime Module Library = SRML Substrate-Glossary \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Researcher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Polkadot]] [[Substrate]]","title":"Literature"},{"location":"public/blockchain/substrate-polka-kus/substrate-setup-research-intro/","tags":["kusama","polkadot_ecosystem","substrate","rust","node","rpc"],"text":"Walk-Through/Substrate/NodeSetup \ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb Introducing \u00b6 substrate-node-template Create-your-first-substrate-chain Prerequisites \u00b6 Ubuntu 20.04, Docker 19-20, Ngnix, Nodejs 16.13.2, ReactJs, VirtualBox(Optional). installing \u00b6 Manifest for installing rust and build-essentials on ubuntu 20.04.03 rustup self uninstall apt-get update sudo add-apt-repository \"deb http://archive.ubuntu.com/ubuntu $(lsb_release -sc) main universe\" apt-get -u dist-upgrade apt install aptitude sudo aptitude install libc6=2.31-0ubuntu9 sudo aptitude install build-essential apt-get update sudo apt install -y cmake pkg-config libssl-dev git gcc build-essential clang libclang-dev curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- --default-toolchain none -y rustup toolchain install nightly --allow-downgrade --profile minimal --component clippy rustup default stable rustup update nightly rustup update stable rustup target add wasm32-unknown-unknown --toolchain nightly rustup component add rust-src --toolchain stable-x86_64-unknown-linux-gnu rustc --version source $HOME/.cargo/env cargo install --git https://github.com/alexcrichton/wasm-gc --force No tested on me Fast Installation: Install all the required dependencies with a single command. (Be patient, this can take up to> 30 minutes) curl https://getsubstrate.io -sSf | bash -s -- --fast Finally step test: Cargo Getting Start \ud83e\udd37\u200d\u2642\ufe0f\ud83e\udd37\u200d\u2642\ufe0f\ud83e\udd37\u200d\u2642\ufe0f:\ud83d\udc31\u200d\ud83d\udc64 linking_with_cc_failed_exit_code_1/build-essential-fails-because-of-unmet-dependencies \ud83d\udc46\ud83d\udc46\ud83d\udc46 Manifest for cargo and compiling #rustup component add --toolchain=nightly rust-src rustfmt rustup target add wasm32-unknown-unknown apt-get install llvm clang linux-headers-\"$(uname -r)\" apt install llvm clang cargo build --release Other commands(Maybe you needs follow): cargo clear cargo fix --allow-dirty cargo fix --edition My Runner System -lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.3 LTS Release: 20.04 Codename: focal -docker --version Docker version 20.10.12, build e91ed57 -ldconfig --version ldconfig (Ubuntu GLIBC 2.31-0ubuntu9.2) 2.31 -cargo --version cargo 1.60.0-nightly (25fcb13 2022-02-01) -rustc --version rustc 1.60.0-nightly (f624427f8 2022-02-06) -rustup show Default host: x86_64-unknown-linux-gnu rustup home: /root/.rustup installed targets for active toolchain -------------------------------------- wasm32-unknown-unknown x86_64-unknown-linux-gnu active toolchain ---------------- nightly-x86_64-unknown-linux-gnu (default) rustc 1.60.0-nightly (f624427f8 2022-02-06) \ud83e\udd37\u200d\u2642\ufe0f\ud83e\udd37\u200d\u2642\ufe0f\ud83e\udd37\u200d\u2642\ufe0f:\ud83d\udc31\u200d\ud83d\udc64 Error: failed to run custom build command for librocksdb-sys v6 \ud83d\udc46\ud83d\udc46\ud83d\udc46 Single-Node Development Chain \u00b6 This command will start the single-node development chain with persistent state: /substrate-node-template cargo build --release && ./target/release/node-template --ws-external --base-path ./my-chain-state --enable-offchain-indexing true --rpc-cors all --name \"Arman Riazi\" --pruning archive --prometheus-external --chain local --dev #(or --chain fir) ./target/release/node-template --dev Purge the development chain's state: ./target/release/node-template purge-chain --chain local --dev Start the development chain with detailed logging: RUST_LOG=debug RUST_BACKTRACE=1 ./target/release/node-template -lruntime=debug --dev \u270d\ufe0f\u270d\ufe0f\u270d\ufe0f After Running Node(Limited Lines): root@ubuntu:/home/substrate-node-template# ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 12:49 ? 00:00:02 /sbin/init splash root 2 0 0 12:49 ? 00:00:00 [kthreadd] root 3 2 0 12:49 ? 00:00:00 [rcu_gp] root 4 2 0 12:49 ? 00:00:00 [rcu_par_gp] root 6 2 0 12:49 ? 00:00:00 [kworker/0:0H-events_highpri] root 9 2 0 12:49 ? 00:00:00 [mm_percpu_wq] root 10 2 0 12:49 ? 00:00:00 [rcu_tasks_rude_] root 11 2 0 12:49 ? 00:00:00 [rcu_tasks_trace] root 12 2 0 12:49 ? 00:00:00 [ksoftirqd/0] root 13 2 0 12:49 ? 00:00:05 [rcu_sched] root 14 2 0 12:49 ? 00:00:00 [migration/0] root 15 2 0 12:49 ? 00:00:00 [idle_inject/0] root 16 2 0 12:49 ? 00:00:00 [cpuhp/0] root 17 2 0 12:49 ? 00:00:00 [cpuhp/1] root 18 2 0 12:49 ? 00:00:00 [idle_inject/1] root 19 2 0 12:49 ? 00:00:00 [migration/1] root 20 2 0 12:49 ? 00:00:00 [ksoftirqd/1] root 22 2 0 12:49 ? 00:00:00 [kworker/1:0H-events_highpri] root 23 2 0 12:49 ? 00:00:00 [cpuhp/2] root 24 2 0 12:49 ? 00:00:00 [idle_inject/2] root 25 2 0 12:49 ? 00:00:00 [migration/2] root 26 2 0 12:49 ? 00:00:00 [ksoftirqd/2] root 28 2 0 12:49 ? 00:00:00 [kworker/2:0H-events_highpri] root 29 2 0 12:49 ? 00:00:00 [kdevtmpfs] root 30 2 0 12:49 ? 00:00:00 [netns] root 31 2 0 12:49 ? 00:00:00 [inet_frag_wq] root 32 2 0 12:49 ? 00:00:00 [kauditd] root 33 2 0 12:49 ? 00:00:00 [khungtaskd] root 34 2 0 12:49 ? 00:00:00 [oom_reaper] root 35 2 0 12:49 ? 00:00:00 [writeback] root 36 2 0 12:49 ? 00:00:00 [kcompactd0] root 37 2 0 12:49 ? 00:00:00 [ksmd] root 38 2 0 12:49 ? 00:00:00 [khugepaged] root 86 2 0 12:49 ? 00:00:00 [kintegrityd] root 87 2 0 12:49 ? 00:00:00 [kblockd] root 88 2 0 12:49 ? 00:00:00 [blkcg_punt_bio] root 89 2 0 12:49 ? 00:00:00 [tpm_dev_wq] root 90 2 0 12:49 ? 00:00:00 [ata_sff] root 91 2 0 12:49 ? 00:00:00 [md] root 92 2 0 12:49 ? 00:00:00 [edac-poller] root 93 2 0 12:49 ? 00:00:00 [devfreq_wq] root 94 2 0 12:49 ? 00:00:00 [watchdogd] root 96 2 0 12:49 ? 00:00:00 [kworker/0:1H-kblockd] root 98 2 0 12:49 ? 00:00:17 [kswapd0] root 99 2 0 12:49 ? 00:00:00 [ecryptfs-kthrea] root 101 2 0 12:49 ? 00:00:00 [kthrotld] root 102 2 0 12:49 ? 00:00:00 [acpi_thermal_pm] root 103 2 0 12:49 ? 00:00:00 [scsi_eh_0] root 104 2 0 12:49 ? 00:00:00 [scsi_tmf_0] root 105 2 0 12:49 ? 00:00:00 [scsi_eh_1] root 106 2 0 12:49 ? 00:00:00 [scsi_tmf_1] root 108 2 0 12:49 ? 00:00:00 [vfio-irqfd-clea] root 111 2 0 12:49 ? 00:00:00 [ipv6_addrconf] root 120 2 0 12:49 ? 00:00:00 [kstrp] root 123 2 0 12:49 ? 00:00:00 [zswap-shrink] root 124 2 0 12:49 ? 00:00:00 [kworker/u7:0] root 129 2 0 12:49 ? 00:00:00 [charger_manager] root 153 2 0 12:49 ? 00:00:01 [kworker/1:1H-kblockd] root 178 2 0 12:49 ? 00:00:00 [scsi_eh_2] root 179 2 0 12:49 ? 00:00:00 [scsi_tmf_2] root 183 2 0 12:49 ? 00:00:01 [kworker/2:1H-kblockd] root 203 2 0 12:49 ? 00:00:00 [jbd2/sda5-8] root 204 2 0 12:49 ? 00:00:00 [ext4-rsv-conver] root 247 1 0 12:49 ? 00:00:00 /lib/systemd/systemd-journald root 279 1 0 12:49 ? 00:00:00 /lib/systemd/systemd-udevd root 283 2 0 12:49 ? 00:00:00 [loop0] root 343 2 0 12:49 ? 00:00:00 [iprt-VBoxWQueue] root 348 2 0 12:49 ? 00:00:00 [cryptd] root 367 2 0 12:49 ? 00:00:01 [irq/18-vmwgfx] root 371 2 0 12:49 ? 00:00:00 [ttm_swap] root 372 2 0 12:49 ? 00:00:00 [card0-crtc0] systemd+ 584 1 0 12:49 ? 00:00:01 /lib/systemd/systemd-resolved root 618 1 0 12:49 ? 00:00:00 /usr/lib/accountsservice/accounts-daemon root 619 1 0 12:49 ? 00:00:00 /usr/sbin/acpid avahi 622 1 0 12:49 ? 00:00:00 avahi-daemon: running [u2004zero.local] message+ 624 1 0 12:49 ? 00:00:03 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only root 626 1 0 12:49 ? 00:00:24 /usr/sbin/NetworkManager --no-daemon root 636 1 0 12:49 ? 00:00:00 /usr/sbin/irqbalance --foreground root 639 1 0 12:49 ? 00:00:00 /usr/bin/python3 /usr/bin/networkd-dispatcher --run-startup-triggers root 643 1 0 12:49 ? 00:00:00 /usr/lib/policykit-1/polkitd --no-debug syslog 647 1 0 12:49 ? 00:00:00 /usr/sbin/rsyslogd -n -iNONE root 650 1 0 12:49 ? 00:00:02 /usr/lib/snapd/snapd root 651 1 0 12:49 ? 00:00:00 /usr/libexec/switcheroo-control root 658 1 0 12:49 ? 00:00:00 /lib/systemd/systemd-logind root 659 1 0 12:49 ? 00:00:00 /usr/lib/udisks2/udisksd root 662 1 0 12:49 ? 00:00:00 /sbin/wpa_supplicant -u -s -O /run/wpa_supplicant avahi 673 622 0 12:49 ? 00:00:00 avahi-daemon: chroot helper root 695 1 0 12:49 ? 00:00:00 /usr/sbin/inetutils-inetd root 724 1 0 12:49 ? 00:00:00 /usr/sbin/cups-browsed root 731 1 0 12:49 ? 00:00:00 /usr/sbin/ModemManager --filter-policy=strict root 734 1 0 12:49 ? 00:00:00 /usr/sbin/cupsd -l root 743 1 0 12:49 ? 00:01:49 /opt/piavpn/bin/pia-daemon root 746 1 0 12:49 ? 00:00:00 /usr/bin/python3 /usr/share/unattended-upgrades/unattended-upgrade-shutdown --wait-for-signal root 747 1 0 12:49 ? 00:00:00 /usr/sbin/winbindd --foreground --no-process-group root 754 1 0 12:49 ? 00:00:12 /usr/bin/containerd root 805 1 0 12:49 ? 00:00:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; postgres 833 1 0 12:49 ? 00:00:00 /usr/lib/postgresql/14/bin/postgres -D /var/lib/postgresql/14/main -c config_file=/etc/postgresql/14/main/postgresql.conf root 844 2 0 12:49 ? 00:00:00 bpfilter_umh root 851 747 0 12:49 ? 00:00:00 winbindd: domain child [U2004ZERO] postgres 878 833 0 12:49 ? 00:00:00 postgres: 14/main: checkpointer postgres 879 833 0 12:49 ? 00:00:00 postgres: 14/main: background writer postgres 880 833 0 12:49 ? 00:00:00 postgres: 14/main: walwriter postgres 881 833 0 12:49 ? 00:00:00 postgres: 14/main: autovacuum launcher postgres 883 833 0 12:49 ? 00:00:00 postgres: 14/main: stats collector postgres 884 833 0 12:49 ? 00:00:00 postgres: 14/main: logical replication launcher root 2731 1 0 12:49 ? 00:00:03 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock root 2735 1 0 12:49 ? 00:00:00 /usr/lib/ipsec/starter --daemon charon --nofork whoopsie 2736 1 0 12:49 ? 00:00:00 /usr/bin/whoopsie -f root 2744 1 0 12:49 ? 00:00:00 /usr/sbin/cron -f kernoops 2756 1 0 12:49 ? 00:00:00 /usr/sbin/kerneloops --test kernoops 2764 1 0 12:49 ? 00:00:00 /usr/sbin/kerneloops root 2781 1 0 12:49 ? 00:00:00 /usr/sbin/xl2tpd root 2789 2735 0 12:49 ? 00:00:00 /usr/lib/ipsec/charon root 3249 2731 0 12:49 ? 00:00:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 3000 -container-ip 172.17.0.2 -container-port 3000 root 3263 2731 0 12:49 ? 00:00:00 /usr/bin/docker-proxy -proto tcp -host-ip :: -host-port 3000 -container-ip 172.17.0.2 -container-port 3000 root 3350 1 0 12:49 ? 00:00:00 /usr/bin/containerd-shim-runc-v2 -namespace moby -id b186d352f80cdecbe7d8ea5759074adbcc9a146f457ed333f4c3fe9cba8bd3f8 -address /run/containe root 3427 3350 0 12:49 pts/0 00:00:00 /bin/bash root 3535 1 0 12:49 ? 00:00:00 /usr/sbin/gdm3 root 3553 1 0 12:49 ? 00:00:02 /usr/sbin/VBoxService --pidfile /var/run/vboxadd-service.sh root 3566 3535 0 12:49 ? 00:00:00 gdm-session-worker [pam/gdm-autologin] u2004ze+ 3590 1 0 12:49 ? 00:00:00 /lib/systemd/systemd --user u2004ze+ 3591 3590 0 12:49 ? 00:00:00 (sd-pam) u2004ze+ 3596 3590 0 12:49 ? 00:00:00 /usr/bin/pulseaudio --daemonize=no --log-target=journal u2004ze+ 3598 3590 0 12:49 ? 00:00:00 /usr/libexec/tracker-miner-fs u2004ze+ 3601 1 0 12:49 ? 00:00:00 /usr/bin/gnome-keyring-daemon --daemonize --login u2004ze+ 3605 3566 0 12:49 tty2 00:00:00 /usr/lib/gdm3/gdm-x-session --run-script env GNOME_SHELL_SESSION_MODE=ubuntu /usr/bin/gnome-session --systemd --session=ubuntu u2004ze+ 3608 3590 0 12:49 ? 00:00:00 /usr/bin/dbus-daemon --session --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only u2004ze+ 3610 3605 0 12:49 tty2 00:01:42 /usr/lib/xorg/Xorg vt2 -displayfd 3 -auth /run/user/1000/gdm/Xauthority -background none -noreset -keeptty -verbose 3 root 3681 1 0 12:49 ? 00:00:00 /usr/lib/upower/upowerd u2004ze+ 3708 3605 0 12:49 tty2 00:00:00 /usr/libexec/gnome-session-binary --systemd --systemd --session=ubuntu u2004ze+ 3818 3708 0 12:49 ? 00:00:00 /usr/bin/ssh-agent /usr/bin/im-launch env GNOME_SHELL_SESSION_MODE=ubuntu /usr/bin/gnome-session --systemd --session=ubuntu u2004ze+ 3971 3590 0 12:49 ? 00:00:00 /usr/libexec/at-spi-bus-launcher u2004ze+ 3976 3971 0 12:49 ? 00:00:00 /usr/bin/dbus-daemon --config-file=/usr/share/defaults/at-spi2/accessibility.conf --nofork --print-address 3 u2004ze+ 3980 3590 0 12:49 ? 00:00:00 /usr/libexec/gnome-session-ctl --monitor u2004ze+ 3987 3590 0 12:49 ? 00:00:00 /usr/libexec/gnome-session-binary --systemd-service --session=ubuntu u2004ze+ 4001 3590 0 12:49 ? 00:01:32 /usr/bin/gnome-shell u2004ze+ 4032 3590 0 12:49 ? 00:00:00 /usr/libexec/at-spi2-registryd --use-gnome-session u2004ze+ 4037 4001 0 12:49 ? 00:00:00 ibus-daemon --panel disable --xim u2004ze+ 5205 5197 0 12:50 pts/0 00:00:00 bash u2004ze+ 5234 3987 0 12:50 ? 00:00:00 update-notifier root 5251 5205 0 12:50 pts/0 00:00:00 sudo su root 5257 5251 0 12:50 pts/0 00:00:00 su root 5258 5257 0 12:50 pts/0 00:00:00 bash root 5285 5258 0 12:52 pts/0 00:00:01 docker exec -it node-armanriazi /bin/bash root 5303 3350 0 12:52 pts/1 00:00:00 /bin/bash root 5403 5303 0 12:53 pts/1 00:00:00 node /opt/yarn-v1.22.15/bin/yarn.js start root 5420 5403 0 12:53 pts/1 00:00:01 /usr/local/bin/node /home/node/app/substrate-front-end-template/.yarn/releases/yarn-3.1.1.cjs start root 5431 5420 0 12:53 pts/1 00:00:00 /usr/local/bin/node /home/node/app/substrate-front-end-template/node_modules/react-app-rewired/bin/index.js start root 5438 5431 0 12:53 pts/1 00:00:16 /usr/local/bin/node /home/node/app/substrate-front-end-template/node_modules/react-app-rewired/scripts/start.js u2004ze+ 25088 4001 0 13:52 ? 00:01:26 /opt/piavpn/bin/pia-client root 27503 2 0 14:20 ? 00:00:01 [kworker/2:2-rcu_gp] root 82028 2 0 16:18 ? 00:00:01 [kworker/0:0-events] root 82133 2 0 16:18 ? 00:00:01 [kworker/1:2-events] root 82779 2 0 16:21 ? 00:00:00 [kworker/1:3-cgroup_destroy] root 83197 2 0 16:27 ? 00:00:00 [kworker/0:1-events] root 83559 2 0 16:37 ? 00:00:00 [kworker/u6:1-events_unbound] root 84293 2 0 17:03 ? 00:00:00 [kworker/u6:0-events_power_efficient] root 84338 2 0 17:13 ? 00:00:00 [kworker/u6:2-events_unbound] root 84348 34026 1 17:16 pts/1 00:00:01 ./target/release/node-template --dev --ws-external root 84704 75818 0 17:18 pts/3 00:00:00 ps -ef Multi-Node Local Testnet \u00b6 If you want to see the multi-node consensus algorithm in action, refer to our Start a Private Network tutorial. Purge the development chain's state: ./target/release/node-template purge-chain --base-path /tmp/alice --chain local ./target/release/node-template purge-chain --base-path /tmp/bob --chain local ./target/release/node-template \\ --base-path /tmp/alice \\ --chain local \\ --alice \\ --port 30333 \\ --ws-port 9945 \\ --rpc-port 9933 \\ --unsafe-rpc-external \\ --rpc-methods=unsafe \\ --validator \\ --ws-external \\ --rpc-cors all \\ --no-mdns \\ --name \"Arman Riazi\" \\ --node-key 0000000000000000000000000000000000000000000000000000000000000001 ./target/release/node-template \\ --base-path /tmp/bob \\ --chain local \\ --bob \\ --port 30334 \\ --ws-port 9946 \\ --unsafe-rpc-external \\ --rpc-methods=unsafe \\ --rpc-port 9934 \\ --validator \\ --ws-external \\ --rpc-cors all \\ --no-mdns \\ --name \"Arman Riazi 2\" \\ --bootnodes /ip4/192.168.8.110/tcp/30333/p2p/12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp Other commands subkey restore Alice --telemetry-url 'wss://telemetry.polkadot.io/submit/ 0' --pruning archive --prometheus-external --chain local --tmp --dev --fir --base-path ./my-chain-state --enable-offchain-indexing true The private network substrate was made by manifest polkadot-js cloudflare-ipfs { \"AccountInfo\": \"AccountInfoWithTripleRefCount\", \"Address\": \"AccountId\", \"LookupSource\": \"AccountId\", \"AccountInfo\": \"AccountInfoWithDualRefCount\", \"ContinuousAccountData\": { \"principal\": \"u64\", \"deposit_date\": \"BlockNumber\" }, \"U16F16\": \"[u8; 4]\", \"GroupIndex\": \"u32\", \"ValueStruct\": { \"integer\": \"i32\", \"boolean\": \"bool\" }, \"BufferIndex\": \"u8\", \"AccountIdOf\": \"AccountId\", \"BalanceOf\": \"Balance\", \"FundInfoOf\": \"FundInfo\", \"FundInfo\": { \"beneficiary\": \"AccountId\", \"deposit\": \"Balance\", \"raised\": \"Balance\", \"end\": \"BlockNumber\", \"goal\": \"Balance\" }, \"FundIndex\": \"u32\", \"InnerThing\": { \"number\": \"u32\", \"hash\": \"Hash\", \"balance\": \"Balance\" }, \"SuperThing\": { \"super_number\": \"u32\", \"inner_thing\": \"InnerThing\" }, \"InnerThingOf\": \"InnerThing\" } Try introductory tutorial for creating your first runtime module \ud83d\udcda\ud83d\udcda\ud83d\udcda Literature \u00b6 Error-Rust-Lang Rustup Start-a-private-network Substrate-based-chain Substrate-Glossary \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f If you liked this article or if it helped you please clap on this post to help the Read.Cash algorithm recommend it to more people. If you have any questions or remarks please feel free to leave a comment below. Alternatively, please feel free to send donations 0xde5D732a5AB44832E1c69b18be30834639F44A2c \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Substrate]]","title":"Substrate setup research intro"},{"location":"public/blockchain/substrate-polka-kus/substrate-setup-research-intro/#introducing","text":"substrate-node-template Create-your-first-substrate-chain","title":"Introducing"},{"location":"public/blockchain/substrate-polka-kus/substrate-setup-research-intro/#prerequisites","text":"Ubuntu 20.04, Docker 19-20, Ngnix, Nodejs 16.13.2, ReactJs, VirtualBox(Optional).","title":"Prerequisites"},{"location":"public/blockchain/substrate-polka-kus/substrate-setup-research-intro/#installing","text":"Manifest for installing rust and build-essentials on ubuntu 20.04.03 rustup self uninstall apt-get update sudo add-apt-repository \"deb http://archive.ubuntu.com/ubuntu $(lsb_release -sc) main universe\" apt-get -u dist-upgrade apt install aptitude sudo aptitude install libc6=2.31-0ubuntu9 sudo aptitude install build-essential apt-get update sudo apt install -y cmake pkg-config libssl-dev git gcc build-essential clang libclang-dev curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- --default-toolchain none -y rustup toolchain install nightly --allow-downgrade --profile minimal --component clippy rustup default stable rustup update nightly rustup update stable rustup target add wasm32-unknown-unknown --toolchain nightly rustup component add rust-src --toolchain stable-x86_64-unknown-linux-gnu rustc --version source $HOME/.cargo/env cargo install --git https://github.com/alexcrichton/wasm-gc --force No tested on me Fast Installation: Install all the required dependencies with a single command. (Be patient, this can take up to> 30 minutes) curl https://getsubstrate.io -sSf | bash -s -- --fast Finally step test: Cargo Getting Start \ud83e\udd37\u200d\u2642\ufe0f\ud83e\udd37\u200d\u2642\ufe0f\ud83e\udd37\u200d\u2642\ufe0f:\ud83d\udc31\u200d\ud83d\udc64 linking_with_cc_failed_exit_code_1/build-essential-fails-because-of-unmet-dependencies \ud83d\udc46\ud83d\udc46\ud83d\udc46 Manifest for cargo and compiling #rustup component add --toolchain=nightly rust-src rustfmt rustup target add wasm32-unknown-unknown apt-get install llvm clang linux-headers-\"$(uname -r)\" apt install llvm clang cargo build --release Other commands(Maybe you needs follow): cargo clear cargo fix --allow-dirty cargo fix --edition My Runner System -lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.3 LTS Release: 20.04 Codename: focal -docker --version Docker version 20.10.12, build e91ed57 -ldconfig --version ldconfig (Ubuntu GLIBC 2.31-0ubuntu9.2) 2.31 -cargo --version cargo 1.60.0-nightly (25fcb13 2022-02-01) -rustc --version rustc 1.60.0-nightly (f624427f8 2022-02-06) -rustup show Default host: x86_64-unknown-linux-gnu rustup home: /root/.rustup installed targets for active toolchain -------------------------------------- wasm32-unknown-unknown x86_64-unknown-linux-gnu active toolchain ---------------- nightly-x86_64-unknown-linux-gnu (default) rustc 1.60.0-nightly (f624427f8 2022-02-06) \ud83e\udd37\u200d\u2642\ufe0f\ud83e\udd37\u200d\u2642\ufe0f\ud83e\udd37\u200d\u2642\ufe0f:\ud83d\udc31\u200d\ud83d\udc64 Error: failed to run custom build command for librocksdb-sys v6 \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"installing"},{"location":"public/blockchain/substrate-polka-kus/substrate-setup-research-intro/#single-node-development-chain","text":"This command will start the single-node development chain with persistent state: /substrate-node-template cargo build --release && ./target/release/node-template --ws-external --base-path ./my-chain-state --enable-offchain-indexing true --rpc-cors all --name \"Arman Riazi\" --pruning archive --prometheus-external --chain local --dev #(or --chain fir) ./target/release/node-template --dev Purge the development chain's state: ./target/release/node-template purge-chain --chain local --dev Start the development chain with detailed logging: RUST_LOG=debug RUST_BACKTRACE=1 ./target/release/node-template -lruntime=debug --dev \u270d\ufe0f\u270d\ufe0f\u270d\ufe0f After Running Node(Limited Lines): root@ubuntu:/home/substrate-node-template# ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 12:49 ? 00:00:02 /sbin/init splash root 2 0 0 12:49 ? 00:00:00 [kthreadd] root 3 2 0 12:49 ? 00:00:00 [rcu_gp] root 4 2 0 12:49 ? 00:00:00 [rcu_par_gp] root 6 2 0 12:49 ? 00:00:00 [kworker/0:0H-events_highpri] root 9 2 0 12:49 ? 00:00:00 [mm_percpu_wq] root 10 2 0 12:49 ? 00:00:00 [rcu_tasks_rude_] root 11 2 0 12:49 ? 00:00:00 [rcu_tasks_trace] root 12 2 0 12:49 ? 00:00:00 [ksoftirqd/0] root 13 2 0 12:49 ? 00:00:05 [rcu_sched] root 14 2 0 12:49 ? 00:00:00 [migration/0] root 15 2 0 12:49 ? 00:00:00 [idle_inject/0] root 16 2 0 12:49 ? 00:00:00 [cpuhp/0] root 17 2 0 12:49 ? 00:00:00 [cpuhp/1] root 18 2 0 12:49 ? 00:00:00 [idle_inject/1] root 19 2 0 12:49 ? 00:00:00 [migration/1] root 20 2 0 12:49 ? 00:00:00 [ksoftirqd/1] root 22 2 0 12:49 ? 00:00:00 [kworker/1:0H-events_highpri] root 23 2 0 12:49 ? 00:00:00 [cpuhp/2] root 24 2 0 12:49 ? 00:00:00 [idle_inject/2] root 25 2 0 12:49 ? 00:00:00 [migration/2] root 26 2 0 12:49 ? 00:00:00 [ksoftirqd/2] root 28 2 0 12:49 ? 00:00:00 [kworker/2:0H-events_highpri] root 29 2 0 12:49 ? 00:00:00 [kdevtmpfs] root 30 2 0 12:49 ? 00:00:00 [netns] root 31 2 0 12:49 ? 00:00:00 [inet_frag_wq] root 32 2 0 12:49 ? 00:00:00 [kauditd] root 33 2 0 12:49 ? 00:00:00 [khungtaskd] root 34 2 0 12:49 ? 00:00:00 [oom_reaper] root 35 2 0 12:49 ? 00:00:00 [writeback] root 36 2 0 12:49 ? 00:00:00 [kcompactd0] root 37 2 0 12:49 ? 00:00:00 [ksmd] root 38 2 0 12:49 ? 00:00:00 [khugepaged] root 86 2 0 12:49 ? 00:00:00 [kintegrityd] root 87 2 0 12:49 ? 00:00:00 [kblockd] root 88 2 0 12:49 ? 00:00:00 [blkcg_punt_bio] root 89 2 0 12:49 ? 00:00:00 [tpm_dev_wq] root 90 2 0 12:49 ? 00:00:00 [ata_sff] root 91 2 0 12:49 ? 00:00:00 [md] root 92 2 0 12:49 ? 00:00:00 [edac-poller] root 93 2 0 12:49 ? 00:00:00 [devfreq_wq] root 94 2 0 12:49 ? 00:00:00 [watchdogd] root 96 2 0 12:49 ? 00:00:00 [kworker/0:1H-kblockd] root 98 2 0 12:49 ? 00:00:17 [kswapd0] root 99 2 0 12:49 ? 00:00:00 [ecryptfs-kthrea] root 101 2 0 12:49 ? 00:00:00 [kthrotld] root 102 2 0 12:49 ? 00:00:00 [acpi_thermal_pm] root 103 2 0 12:49 ? 00:00:00 [scsi_eh_0] root 104 2 0 12:49 ? 00:00:00 [scsi_tmf_0] root 105 2 0 12:49 ? 00:00:00 [scsi_eh_1] root 106 2 0 12:49 ? 00:00:00 [scsi_tmf_1] root 108 2 0 12:49 ? 00:00:00 [vfio-irqfd-clea] root 111 2 0 12:49 ? 00:00:00 [ipv6_addrconf] root 120 2 0 12:49 ? 00:00:00 [kstrp] root 123 2 0 12:49 ? 00:00:00 [zswap-shrink] root 124 2 0 12:49 ? 00:00:00 [kworker/u7:0] root 129 2 0 12:49 ? 00:00:00 [charger_manager] root 153 2 0 12:49 ? 00:00:01 [kworker/1:1H-kblockd] root 178 2 0 12:49 ? 00:00:00 [scsi_eh_2] root 179 2 0 12:49 ? 00:00:00 [scsi_tmf_2] root 183 2 0 12:49 ? 00:00:01 [kworker/2:1H-kblockd] root 203 2 0 12:49 ? 00:00:00 [jbd2/sda5-8] root 204 2 0 12:49 ? 00:00:00 [ext4-rsv-conver] root 247 1 0 12:49 ? 00:00:00 /lib/systemd/systemd-journald root 279 1 0 12:49 ? 00:00:00 /lib/systemd/systemd-udevd root 283 2 0 12:49 ? 00:00:00 [loop0] root 343 2 0 12:49 ? 00:00:00 [iprt-VBoxWQueue] root 348 2 0 12:49 ? 00:00:00 [cryptd] root 367 2 0 12:49 ? 00:00:01 [irq/18-vmwgfx] root 371 2 0 12:49 ? 00:00:00 [ttm_swap] root 372 2 0 12:49 ? 00:00:00 [card0-crtc0] systemd+ 584 1 0 12:49 ? 00:00:01 /lib/systemd/systemd-resolved root 618 1 0 12:49 ? 00:00:00 /usr/lib/accountsservice/accounts-daemon root 619 1 0 12:49 ? 00:00:00 /usr/sbin/acpid avahi 622 1 0 12:49 ? 00:00:00 avahi-daemon: running [u2004zero.local] message+ 624 1 0 12:49 ? 00:00:03 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only root 626 1 0 12:49 ? 00:00:24 /usr/sbin/NetworkManager --no-daemon root 636 1 0 12:49 ? 00:00:00 /usr/sbin/irqbalance --foreground root 639 1 0 12:49 ? 00:00:00 /usr/bin/python3 /usr/bin/networkd-dispatcher --run-startup-triggers root 643 1 0 12:49 ? 00:00:00 /usr/lib/policykit-1/polkitd --no-debug syslog 647 1 0 12:49 ? 00:00:00 /usr/sbin/rsyslogd -n -iNONE root 650 1 0 12:49 ? 00:00:02 /usr/lib/snapd/snapd root 651 1 0 12:49 ? 00:00:00 /usr/libexec/switcheroo-control root 658 1 0 12:49 ? 00:00:00 /lib/systemd/systemd-logind root 659 1 0 12:49 ? 00:00:00 /usr/lib/udisks2/udisksd root 662 1 0 12:49 ? 00:00:00 /sbin/wpa_supplicant -u -s -O /run/wpa_supplicant avahi 673 622 0 12:49 ? 00:00:00 avahi-daemon: chroot helper root 695 1 0 12:49 ? 00:00:00 /usr/sbin/inetutils-inetd root 724 1 0 12:49 ? 00:00:00 /usr/sbin/cups-browsed root 731 1 0 12:49 ? 00:00:00 /usr/sbin/ModemManager --filter-policy=strict root 734 1 0 12:49 ? 00:00:00 /usr/sbin/cupsd -l root 743 1 0 12:49 ? 00:01:49 /opt/piavpn/bin/pia-daemon root 746 1 0 12:49 ? 00:00:00 /usr/bin/python3 /usr/share/unattended-upgrades/unattended-upgrade-shutdown --wait-for-signal root 747 1 0 12:49 ? 00:00:00 /usr/sbin/winbindd --foreground --no-process-group root 754 1 0 12:49 ? 00:00:12 /usr/bin/containerd root 805 1 0 12:49 ? 00:00:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; postgres 833 1 0 12:49 ? 00:00:00 /usr/lib/postgresql/14/bin/postgres -D /var/lib/postgresql/14/main -c config_file=/etc/postgresql/14/main/postgresql.conf root 844 2 0 12:49 ? 00:00:00 bpfilter_umh root 851 747 0 12:49 ? 00:00:00 winbindd: domain child [U2004ZERO] postgres 878 833 0 12:49 ? 00:00:00 postgres: 14/main: checkpointer postgres 879 833 0 12:49 ? 00:00:00 postgres: 14/main: background writer postgres 880 833 0 12:49 ? 00:00:00 postgres: 14/main: walwriter postgres 881 833 0 12:49 ? 00:00:00 postgres: 14/main: autovacuum launcher postgres 883 833 0 12:49 ? 00:00:00 postgres: 14/main: stats collector postgres 884 833 0 12:49 ? 00:00:00 postgres: 14/main: logical replication launcher root 2731 1 0 12:49 ? 00:00:03 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock root 2735 1 0 12:49 ? 00:00:00 /usr/lib/ipsec/starter --daemon charon --nofork whoopsie 2736 1 0 12:49 ? 00:00:00 /usr/bin/whoopsie -f root 2744 1 0 12:49 ? 00:00:00 /usr/sbin/cron -f kernoops 2756 1 0 12:49 ? 00:00:00 /usr/sbin/kerneloops --test kernoops 2764 1 0 12:49 ? 00:00:00 /usr/sbin/kerneloops root 2781 1 0 12:49 ? 00:00:00 /usr/sbin/xl2tpd root 2789 2735 0 12:49 ? 00:00:00 /usr/lib/ipsec/charon root 3249 2731 0 12:49 ? 00:00:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 3000 -container-ip 172.17.0.2 -container-port 3000 root 3263 2731 0 12:49 ? 00:00:00 /usr/bin/docker-proxy -proto tcp -host-ip :: -host-port 3000 -container-ip 172.17.0.2 -container-port 3000 root 3350 1 0 12:49 ? 00:00:00 /usr/bin/containerd-shim-runc-v2 -namespace moby -id b186d352f80cdecbe7d8ea5759074adbcc9a146f457ed333f4c3fe9cba8bd3f8 -address /run/containe root 3427 3350 0 12:49 pts/0 00:00:00 /bin/bash root 3535 1 0 12:49 ? 00:00:00 /usr/sbin/gdm3 root 3553 1 0 12:49 ? 00:00:02 /usr/sbin/VBoxService --pidfile /var/run/vboxadd-service.sh root 3566 3535 0 12:49 ? 00:00:00 gdm-session-worker [pam/gdm-autologin] u2004ze+ 3590 1 0 12:49 ? 00:00:00 /lib/systemd/systemd --user u2004ze+ 3591 3590 0 12:49 ? 00:00:00 (sd-pam) u2004ze+ 3596 3590 0 12:49 ? 00:00:00 /usr/bin/pulseaudio --daemonize=no --log-target=journal u2004ze+ 3598 3590 0 12:49 ? 00:00:00 /usr/libexec/tracker-miner-fs u2004ze+ 3601 1 0 12:49 ? 00:00:00 /usr/bin/gnome-keyring-daemon --daemonize --login u2004ze+ 3605 3566 0 12:49 tty2 00:00:00 /usr/lib/gdm3/gdm-x-session --run-script env GNOME_SHELL_SESSION_MODE=ubuntu /usr/bin/gnome-session --systemd --session=ubuntu u2004ze+ 3608 3590 0 12:49 ? 00:00:00 /usr/bin/dbus-daemon --session --address=systemd: --nofork --nopidfile --systemd-activation --syslog-only u2004ze+ 3610 3605 0 12:49 tty2 00:01:42 /usr/lib/xorg/Xorg vt2 -displayfd 3 -auth /run/user/1000/gdm/Xauthority -background none -noreset -keeptty -verbose 3 root 3681 1 0 12:49 ? 00:00:00 /usr/lib/upower/upowerd u2004ze+ 3708 3605 0 12:49 tty2 00:00:00 /usr/libexec/gnome-session-binary --systemd --systemd --session=ubuntu u2004ze+ 3818 3708 0 12:49 ? 00:00:00 /usr/bin/ssh-agent /usr/bin/im-launch env GNOME_SHELL_SESSION_MODE=ubuntu /usr/bin/gnome-session --systemd --session=ubuntu u2004ze+ 3971 3590 0 12:49 ? 00:00:00 /usr/libexec/at-spi-bus-launcher u2004ze+ 3976 3971 0 12:49 ? 00:00:00 /usr/bin/dbus-daemon --config-file=/usr/share/defaults/at-spi2/accessibility.conf --nofork --print-address 3 u2004ze+ 3980 3590 0 12:49 ? 00:00:00 /usr/libexec/gnome-session-ctl --monitor u2004ze+ 3987 3590 0 12:49 ? 00:00:00 /usr/libexec/gnome-session-binary --systemd-service --session=ubuntu u2004ze+ 4001 3590 0 12:49 ? 00:01:32 /usr/bin/gnome-shell u2004ze+ 4032 3590 0 12:49 ? 00:00:00 /usr/libexec/at-spi2-registryd --use-gnome-session u2004ze+ 4037 4001 0 12:49 ? 00:00:00 ibus-daemon --panel disable --xim u2004ze+ 5205 5197 0 12:50 pts/0 00:00:00 bash u2004ze+ 5234 3987 0 12:50 ? 00:00:00 update-notifier root 5251 5205 0 12:50 pts/0 00:00:00 sudo su root 5257 5251 0 12:50 pts/0 00:00:00 su root 5258 5257 0 12:50 pts/0 00:00:00 bash root 5285 5258 0 12:52 pts/0 00:00:01 docker exec -it node-armanriazi /bin/bash root 5303 3350 0 12:52 pts/1 00:00:00 /bin/bash root 5403 5303 0 12:53 pts/1 00:00:00 node /opt/yarn-v1.22.15/bin/yarn.js start root 5420 5403 0 12:53 pts/1 00:00:01 /usr/local/bin/node /home/node/app/substrate-front-end-template/.yarn/releases/yarn-3.1.1.cjs start root 5431 5420 0 12:53 pts/1 00:00:00 /usr/local/bin/node /home/node/app/substrate-front-end-template/node_modules/react-app-rewired/bin/index.js start root 5438 5431 0 12:53 pts/1 00:00:16 /usr/local/bin/node /home/node/app/substrate-front-end-template/node_modules/react-app-rewired/scripts/start.js u2004ze+ 25088 4001 0 13:52 ? 00:01:26 /opt/piavpn/bin/pia-client root 27503 2 0 14:20 ? 00:00:01 [kworker/2:2-rcu_gp] root 82028 2 0 16:18 ? 00:00:01 [kworker/0:0-events] root 82133 2 0 16:18 ? 00:00:01 [kworker/1:2-events] root 82779 2 0 16:21 ? 00:00:00 [kworker/1:3-cgroup_destroy] root 83197 2 0 16:27 ? 00:00:00 [kworker/0:1-events] root 83559 2 0 16:37 ? 00:00:00 [kworker/u6:1-events_unbound] root 84293 2 0 17:03 ? 00:00:00 [kworker/u6:0-events_power_efficient] root 84338 2 0 17:13 ? 00:00:00 [kworker/u6:2-events_unbound] root 84348 34026 1 17:16 pts/1 00:00:01 ./target/release/node-template --dev --ws-external root 84704 75818 0 17:18 pts/3 00:00:00 ps -ef","title":"Single-Node Development Chain"},{"location":"public/blockchain/substrate-polka-kus/substrate-setup-research-intro/#multi-node-local-testnet","text":"If you want to see the multi-node consensus algorithm in action, refer to our Start a Private Network tutorial. Purge the development chain's state: ./target/release/node-template purge-chain --base-path /tmp/alice --chain local ./target/release/node-template purge-chain --base-path /tmp/bob --chain local ./target/release/node-template \\ --base-path /tmp/alice \\ --chain local \\ --alice \\ --port 30333 \\ --ws-port 9945 \\ --rpc-port 9933 \\ --unsafe-rpc-external \\ --rpc-methods=unsafe \\ --validator \\ --ws-external \\ --rpc-cors all \\ --no-mdns \\ --name \"Arman Riazi\" \\ --node-key 0000000000000000000000000000000000000000000000000000000000000001 ./target/release/node-template \\ --base-path /tmp/bob \\ --chain local \\ --bob \\ --port 30334 \\ --ws-port 9946 \\ --unsafe-rpc-external \\ --rpc-methods=unsafe \\ --rpc-port 9934 \\ --validator \\ --ws-external \\ --rpc-cors all \\ --no-mdns \\ --name \"Arman Riazi 2\" \\ --bootnodes /ip4/192.168.8.110/tcp/30333/p2p/12D3KooWEyoppNCUx8Yx66oV9fJnriXwCcXwDDUA2kj6vnc6iDEp Other commands subkey restore Alice --telemetry-url 'wss://telemetry.polkadot.io/submit/ 0' --pruning archive --prometheus-external --chain local --tmp --dev --fir --base-path ./my-chain-state --enable-offchain-indexing true The private network substrate was made by manifest polkadot-js cloudflare-ipfs { \"AccountInfo\": \"AccountInfoWithTripleRefCount\", \"Address\": \"AccountId\", \"LookupSource\": \"AccountId\", \"AccountInfo\": \"AccountInfoWithDualRefCount\", \"ContinuousAccountData\": { \"principal\": \"u64\", \"deposit_date\": \"BlockNumber\" }, \"U16F16\": \"[u8; 4]\", \"GroupIndex\": \"u32\", \"ValueStruct\": { \"integer\": \"i32\", \"boolean\": \"bool\" }, \"BufferIndex\": \"u8\", \"AccountIdOf\": \"AccountId\", \"BalanceOf\": \"Balance\", \"FundInfoOf\": \"FundInfo\", \"FundInfo\": { \"beneficiary\": \"AccountId\", \"deposit\": \"Balance\", \"raised\": \"Balance\", \"end\": \"BlockNumber\", \"goal\": \"Balance\" }, \"FundIndex\": \"u32\", \"InnerThing\": { \"number\": \"u32\", \"hash\": \"Hash\", \"balance\": \"Balance\" }, \"SuperThing\": { \"super_number\": \"u32\", \"inner_thing\": \"InnerThing\" }, \"InnerThingOf\": \"InnerThing\" } Try introductory tutorial for creating your first runtime module \ud83d\udcda\ud83d\udcda\ud83d\udcda","title":"Multi-Node Local Testnet"},{"location":"public/blockchain/substrate-polka-kus/substrate-setup-research-intro/#literature","text":"Error-Rust-Lang Rustup Start-a-private-network Substrate-based-chain Substrate-Glossary \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f If you liked this article or if it helped you please clap on this post to help the Read.Cash algorithm recommend it to more people. If you have any questions or remarks please feel free to leave a comment below. Alternatively, please feel free to send donations 0xde5D732a5AB44832E1c69b18be30834639F44A2c \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Substrate]]","title":"Literature"},{"location":"public/blockchain/substrate-polka-kus/crowdloan/crowdloan-research-intro/","tags":["kusama","polkadot_ecosystem","substrate","crowdloan"],"text":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/CrowdLoan(3) \ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb Introducing \u00b6 Kusama is a canary network for Polkadot; Kusama is a proving ground for runtime upgrades, on-chain governance, and parachains . The network is a permissionless.Kusama does not support smart contracts natively.The Kusama network is Polkadot's experimental, community-focused R&D network. \ud83d\udc46\ud83d\udc46\ud83d\udc46 AccountThese are transfer and transfer_keep_alive. transfer will allow you to send KSM regardless of the consequence; transfer_keep_alive will not allow you to send an amount that would allow the sending account to be removed due to it going below the existential deposit. By default, Polkadot-JS Apps will use transfer_keep_alive, ensuring that the account you send from cannot drop below the existential deposit of 0.001666 KSM. it may be that you **do not want to keep this account alive (for example, because you are moving all of your funds to a different address). ** Note: Even if the transfer fails due to a keep-alive check, the transaction fee will be deducted from the sending account if you attempt to transfer. Currently, Kusama does not use the Assets Pallet, so this is probably not the reason for your tokens having existing references. Currently, Kusama does not use the Recovery Pallet, so this is probably not the reason for your tokens having existing references. On Kusama, you can check if recovery has been set up by checking the recovery.recoverable(AccountId) chain state. This can be found under Developer > Chain state in PolkadotJS Apps. \ud83d\udc46\ud83d\udc46\ud83d\udc46 Parachain-Slots-Auction \u00b6 Polkadot Parachain Auctions do not offer a free and open environment as we have seen with ERC20 tokens, where the only thing needed was a white paper to deploy a smart contract on the Ethereum Blockchain. Such a feature allows for flexibility in the Polkadot ecosystem where every Parachain can create its own set of rules Basically, Polkadot Parachain Auctions are automated candle auctions (with some adjustments relevant to blockchain technology). It means that there is an opening period and an ending period. At any moment the winner can be chosen but we will only find it out at the end. It is not easy to get access to the Polkadot Relay Chain, and, currently, Parachains prefer to use crowdloan mechanism to collect funds to participate in Polkadot Parchain Auctions. To participate in the PolkadotParachain Auction and compete for a slot, prospective Parachains can bid in two ways: Parachains can bid their own DOT, through a single account **Parachains can use crowdloans to crowdsource DOT and bid it in the auctions ** Users cannot participate in the Polkadot Parachain Auction directly. Users can only participate indirectly via crowd loans by contributing and locking DOT. Shared security and processing of transactions don\u2019t come for free. One of the ways to access them is to lease a slot on the Relay Chain. Projects compete to place the highest bid to get the slot. The first Polkadot Parachain Auction winner, via the process known as Crowdloan Campaign, raised 32.5 million DOT (around 1.3 billion USD at that time) to lease the slot for two years. A Parachain slot is a scarce resource. Given an increase in the number of Parachains, every few months new Parachains slots will be added. The Polkadot ultimate goal is to have 100 slots. crowdsale-VS-crowdloan \u00b6 crowdsale and crowdloan which makes sense because they sound the same. they are similar but there are some very key differences for example crowdsale I am sure you're familiar with it's kind of like platforms along the lines of kickstarter so you fund a project say creating a backpack that sings and lights up and then you give the funds to eventually get the product knowing that it's not created yet and then the creator uses those funds to make the product and then eventually you'll get that product in the mail so you are buying an actual thing and then you get that thing but you never get your original funds back where a crowdloan is very different so you're finding a specific function for example a parachain slot and it can only be used for that purpose it can't be used for anything else and then all funds that you contribute are delivered back to you once the lease is up so anything you contributed originally comes right back to you and it's not like you're putting funds down and you never see them again but you get something else in return and so parachain teams don't have control over the funds it's locked in the relay chain which prevents rug pull so all of a sudden funds can't just disappear or someone takes all of them it's pretty much impossible for that to happen and then if the first attempt to score slot isn't successful the crowd loan continues to try to score a parachain slot in the next round and then the next round until they do and all crowdloans do have an expiration date and that will all be specified in the outset so you should never be left in the dark you'll always have all the information you need so you can look forward to all the exciting things to come. the other thing to keep in mind is some projects have a rewards cap for their crowd loans so they can only give out so many rewards or they can only take so many contributions to the crowd loan or a certain amount so if you are set on wanting to participate it's always good to do it as soon as you feel ready um just in case you know there's a cut off or in case you can get bonus rewards. ParachainAcution-vs-eBayAcution \u00b6 a common misconception in the cryptocurrency space is that a para chain slot auction is something that you have to actively participate in kind of like an auction on ebay but that actually couldn't be further from the truth and all you have to do is contribute you don't have to bid and the crowdloan does on behalf of the project so there's no stress for you and then there's a difference between a regular auction and then a parachain slot option which is used to decide which pair of chains get to be connected to the relay chain so it's not like bidding on ebay for a handbag or something like that and then there's the concept of a candle auction which means in the ending period which is the last five days the auction can just end at any time and no one knows when this will be no single human knows and it's completely automated and a mystery to everyone and so the crowdloan opens before the auction starts and it stays open until a winner is declared so definitely make sure to contribute while the crowd loan is still open and hopefully before your team scores a slot and you get lots of rewards. There is also the possibility of a malicious bidder or a block producer trying to grief honest bidders by sniping auctions. For this reason, Vickrey auctions, a variant of second price auction in which bids are hidden and only revealed in a later phase, have emerged as a well-regarded mechanic. For example, it is implemented as the mechanism to auction human readable names on the ENS. The Candle auction is another solution that does not need the two-step commit and reveal schemes (a main component of Vickrey auctions), and for this reason allows smart contracts to participate. Polkadot will use a random beacon based on the VRF that's used also in other places of the protocol. The VRF will provide the base of the randomness, which will retroactively determine the end-time of the auction. 1) Slot Action compatition(Weekly) 2) if Won then 3) Parachain Lease Relay chain (Yearly) The slot durations are capped to 1 year and divided into 6-week periods(KSM- 12m/3m=4m); The slot durations are capped to 2 years and divided into 3-month periods (DOT- 24m/3m=8m);Once the parachain lease ends (48 weeks maximum on Kusama, 96 weeks on Polkadot), funds are returned to the contributors. Parachains may lease a slot for any combination of periods of the slot duration. Parachains may lease more than one slot over time, meaning that they could extend their lease to Polkadot past the maximum duration by leasing a contiguous slot. Note: Individual parachain slots are fungible. This means that parachains do not need to always inhabit the same slot, but **as long as a parachain inhabits any slot it can continue as a parachain.**You Can\u2019t (Technically) Combine Crowdloans and Private Bids Each period of the range 1 - 4 represents a 3-month duration for a total of 2 years. Bidders will submit a configuration of bids specifying the token amount they are willing to bond and for which periods. The slot ranges may be any of the periods 1 - n, where n is the number of periods available for a slot (n will be 8 for both Polkadot and Kusama). highest bidder for any given slot lease period might not always win (see the example below). There is one parachain slot available. Charlie bids 75 for the range 1 - 8. Dave bids 100 for the range 5 - 8. Emily bids 40 for the range 1 - 4. Let's calculate each bidder's valuation according to the algorithm. We do this by multiplying the bond amount by the number of periods in the specified range of the bid. Charlie - 75 * 8 = 600 for range 1 - 8 Dave - 100 * 4 = 400 for range 5 - 8 Emily - 40 * 4 = 160 for range 1 - 4 Although Dave had the highest bid in accordance to token amount, when we do the calculations we see that since he only bid for a range of 4, he would need to share the slot with Emily who bid much less. Together Dave's and Emily's bids only equals a valuation of 560. A random number, which is based on the VRF used by Polkadot, is determined at each block. Additionally, each auction will have a threshold that starts at 0 and increases to 1. The random number produced by the VRF is examined next to the threshold to determine if that block is the end of the auction within the so-called ending period. Charlie's valuation for the entire range is 600. Therefore Charlie is awarded the complete range of the parachain slot. While each parachain auction is scheduled for seven days, the candle auction format means that the \u201cend\u201d date and time is a bit of a wildcard. The first two days are confirmed to be an \u201copen\u201d period of the auction. The following five days, however, fall within the \u201cwick\u201d of this theoretical candle, and the auction will end sometime in this five-day period. so you won\u2019t actually know in real-time when the auction ends. project must specify the following information: Parachain ID/Index (which parachain the bid or crowdloan will support) First and Last Slot (the lease is broken into 8 increments, and projects can bid on a partial or full lease period) While these crowdloan bids occur, the private-bid projects (Turquoise/Salmon) don\u2019t have to enter additional bids. However, after Day 2, it becomes risky to wait since the auction can end at any time. Finally, on Day 4, Salmon Parachain enters a private bid of 5000 DOT and briefly takes the lead in the auction. Unfortunately, on Day 5, Salmon Parachain is quickly outbid by a private bid from Turquoise Parachain AND an increased bid from the Purple Parachain crowdloan module. These antics continue until Day 7 when the highest bid is Purple Parachain with 18,000 DOT. However, importantly, Purple does not win. The winner is Turquoise. Turquoise Parachain wins the slot and is now able to connect to the Kusama network. This will likely happen soon after the slot is won since the lease period begins immediately. After the end of a lease period (48 week periods on Kusama and 96 week lease periods on Polkadot), the slot will be available for renewal or for another project to occupy. The remaining parachains must continue to compete for a slot, assuming their crowdloan modules remain open and the private bidders have the interest in pursuing a slot again, rather than waiting for a less competitive auction. Unbonding takes 28 days on Polkadot and 7 on Kusama . Ensure your staking and democracy holds are cleared. \ud83d\udc46\ud83d\udc46\ud83d\udc46 \ud83d\udcda\ud83d\udcda\ud83d\udcda Literature \u00b6 authorities win slots based on a verifiable random function = VRF the private-bid projects = Individual parachain Substrate-Glossary \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Researcher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Kusama]] [[Polkadot]] [[CrowdLoan]]","title":"Crowdloan research intro"},{"location":"public/blockchain/substrate-polka-kus/crowdloan/crowdloan-research-intro/#introducing","text":"Kusama is a canary network for Polkadot; Kusama is a proving ground for runtime upgrades, on-chain governance, and parachains . The network is a permissionless.Kusama does not support smart contracts natively.The Kusama network is Polkadot's experimental, community-focused R&D network. \ud83d\udc46\ud83d\udc46\ud83d\udc46 AccountThese are transfer and transfer_keep_alive. transfer will allow you to send KSM regardless of the consequence; transfer_keep_alive will not allow you to send an amount that would allow the sending account to be removed due to it going below the existential deposit. By default, Polkadot-JS Apps will use transfer_keep_alive, ensuring that the account you send from cannot drop below the existential deposit of 0.001666 KSM. it may be that you **do not want to keep this account alive (for example, because you are moving all of your funds to a different address). ** Note: Even if the transfer fails due to a keep-alive check, the transaction fee will be deducted from the sending account if you attempt to transfer. Currently, Kusama does not use the Assets Pallet, so this is probably not the reason for your tokens having existing references. Currently, Kusama does not use the Recovery Pallet, so this is probably not the reason for your tokens having existing references. On Kusama, you can check if recovery has been set up by checking the recovery.recoverable(AccountId) chain state. This can be found under Developer > Chain state in PolkadotJS Apps. \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Introducing"},{"location":"public/blockchain/substrate-polka-kus/crowdloan/crowdloan-research-intro/#parachain-slots-auction","text":"Polkadot Parachain Auctions do not offer a free and open environment as we have seen with ERC20 tokens, where the only thing needed was a white paper to deploy a smart contract on the Ethereum Blockchain. Such a feature allows for flexibility in the Polkadot ecosystem where every Parachain can create its own set of rules Basically, Polkadot Parachain Auctions are automated candle auctions (with some adjustments relevant to blockchain technology). It means that there is an opening period and an ending period. At any moment the winner can be chosen but we will only find it out at the end. It is not easy to get access to the Polkadot Relay Chain, and, currently, Parachains prefer to use crowdloan mechanism to collect funds to participate in Polkadot Parchain Auctions. To participate in the PolkadotParachain Auction and compete for a slot, prospective Parachains can bid in two ways: Parachains can bid their own DOT, through a single account **Parachains can use crowdloans to crowdsource DOT and bid it in the auctions ** Users cannot participate in the Polkadot Parachain Auction directly. Users can only participate indirectly via crowd loans by contributing and locking DOT. Shared security and processing of transactions don\u2019t come for free. One of the ways to access them is to lease a slot on the Relay Chain. Projects compete to place the highest bid to get the slot. The first Polkadot Parachain Auction winner, via the process known as Crowdloan Campaign, raised 32.5 million DOT (around 1.3 billion USD at that time) to lease the slot for two years. A Parachain slot is a scarce resource. Given an increase in the number of Parachains, every few months new Parachains slots will be added. The Polkadot ultimate goal is to have 100 slots.","title":"Parachain-Slots-Auction"},{"location":"public/blockchain/substrate-polka-kus/crowdloan/crowdloan-research-intro/#crowdsale-vs-crowdloan","text":"crowdsale and crowdloan which makes sense because they sound the same. they are similar but there are some very key differences for example crowdsale I am sure you're familiar with it's kind of like platforms along the lines of kickstarter so you fund a project say creating a backpack that sings and lights up and then you give the funds to eventually get the product knowing that it's not created yet and then the creator uses those funds to make the product and then eventually you'll get that product in the mail so you are buying an actual thing and then you get that thing but you never get your original funds back where a crowdloan is very different so you're finding a specific function for example a parachain slot and it can only be used for that purpose it can't be used for anything else and then all funds that you contribute are delivered back to you once the lease is up so anything you contributed originally comes right back to you and it's not like you're putting funds down and you never see them again but you get something else in return and so parachain teams don't have control over the funds it's locked in the relay chain which prevents rug pull so all of a sudden funds can't just disappear or someone takes all of them it's pretty much impossible for that to happen and then if the first attempt to score slot isn't successful the crowd loan continues to try to score a parachain slot in the next round and then the next round until they do and all crowdloans do have an expiration date and that will all be specified in the outset so you should never be left in the dark you'll always have all the information you need so you can look forward to all the exciting things to come. the other thing to keep in mind is some projects have a rewards cap for their crowd loans so they can only give out so many rewards or they can only take so many contributions to the crowd loan or a certain amount so if you are set on wanting to participate it's always good to do it as soon as you feel ready um just in case you know there's a cut off or in case you can get bonus rewards.","title":"crowdsale-VS-crowdloan"},{"location":"public/blockchain/substrate-polka-kus/crowdloan/crowdloan-research-intro/#parachainacution-vs-ebayacution","text":"a common misconception in the cryptocurrency space is that a para chain slot auction is something that you have to actively participate in kind of like an auction on ebay but that actually couldn't be further from the truth and all you have to do is contribute you don't have to bid and the crowdloan does on behalf of the project so there's no stress for you and then there's a difference between a regular auction and then a parachain slot option which is used to decide which pair of chains get to be connected to the relay chain so it's not like bidding on ebay for a handbag or something like that and then there's the concept of a candle auction which means in the ending period which is the last five days the auction can just end at any time and no one knows when this will be no single human knows and it's completely automated and a mystery to everyone and so the crowdloan opens before the auction starts and it stays open until a winner is declared so definitely make sure to contribute while the crowd loan is still open and hopefully before your team scores a slot and you get lots of rewards. There is also the possibility of a malicious bidder or a block producer trying to grief honest bidders by sniping auctions. For this reason, Vickrey auctions, a variant of second price auction in which bids are hidden and only revealed in a later phase, have emerged as a well-regarded mechanic. For example, it is implemented as the mechanism to auction human readable names on the ENS. The Candle auction is another solution that does not need the two-step commit and reveal schemes (a main component of Vickrey auctions), and for this reason allows smart contracts to participate. Polkadot will use a random beacon based on the VRF that's used also in other places of the protocol. The VRF will provide the base of the randomness, which will retroactively determine the end-time of the auction. 1) Slot Action compatition(Weekly) 2) if Won then 3) Parachain Lease Relay chain (Yearly) The slot durations are capped to 1 year and divided into 6-week periods(KSM- 12m/3m=4m); The slot durations are capped to 2 years and divided into 3-month periods (DOT- 24m/3m=8m);Once the parachain lease ends (48 weeks maximum on Kusama, 96 weeks on Polkadot), funds are returned to the contributors. Parachains may lease a slot for any combination of periods of the slot duration. Parachains may lease more than one slot over time, meaning that they could extend their lease to Polkadot past the maximum duration by leasing a contiguous slot. Note: Individual parachain slots are fungible. This means that parachains do not need to always inhabit the same slot, but **as long as a parachain inhabits any slot it can continue as a parachain.**You Can\u2019t (Technically) Combine Crowdloans and Private Bids Each period of the range 1 - 4 represents a 3-month duration for a total of 2 years. Bidders will submit a configuration of bids specifying the token amount they are willing to bond and for which periods. The slot ranges may be any of the periods 1 - n, where n is the number of periods available for a slot (n will be 8 for both Polkadot and Kusama). highest bidder for any given slot lease period might not always win (see the example below). There is one parachain slot available. Charlie bids 75 for the range 1 - 8. Dave bids 100 for the range 5 - 8. Emily bids 40 for the range 1 - 4. Let's calculate each bidder's valuation according to the algorithm. We do this by multiplying the bond amount by the number of periods in the specified range of the bid. Charlie - 75 * 8 = 600 for range 1 - 8 Dave - 100 * 4 = 400 for range 5 - 8 Emily - 40 * 4 = 160 for range 1 - 4 Although Dave had the highest bid in accordance to token amount, when we do the calculations we see that since he only bid for a range of 4, he would need to share the slot with Emily who bid much less. Together Dave's and Emily's bids only equals a valuation of 560. A random number, which is based on the VRF used by Polkadot, is determined at each block. Additionally, each auction will have a threshold that starts at 0 and increases to 1. The random number produced by the VRF is examined next to the threshold to determine if that block is the end of the auction within the so-called ending period. Charlie's valuation for the entire range is 600. Therefore Charlie is awarded the complete range of the parachain slot. While each parachain auction is scheduled for seven days, the candle auction format means that the \u201cend\u201d date and time is a bit of a wildcard. The first two days are confirmed to be an \u201copen\u201d period of the auction. The following five days, however, fall within the \u201cwick\u201d of this theoretical candle, and the auction will end sometime in this five-day period. so you won\u2019t actually know in real-time when the auction ends. project must specify the following information: Parachain ID/Index (which parachain the bid or crowdloan will support) First and Last Slot (the lease is broken into 8 increments, and projects can bid on a partial or full lease period) While these crowdloan bids occur, the private-bid projects (Turquoise/Salmon) don\u2019t have to enter additional bids. However, after Day 2, it becomes risky to wait since the auction can end at any time. Finally, on Day 4, Salmon Parachain enters a private bid of 5000 DOT and briefly takes the lead in the auction. Unfortunately, on Day 5, Salmon Parachain is quickly outbid by a private bid from Turquoise Parachain AND an increased bid from the Purple Parachain crowdloan module. These antics continue until Day 7 when the highest bid is Purple Parachain with 18,000 DOT. However, importantly, Purple does not win. The winner is Turquoise. Turquoise Parachain wins the slot and is now able to connect to the Kusama network. This will likely happen soon after the slot is won since the lease period begins immediately. After the end of a lease period (48 week periods on Kusama and 96 week lease periods on Polkadot), the slot will be available for renewal or for another project to occupy. The remaining parachains must continue to compete for a slot, assuming their crowdloan modules remain open and the private bidders have the interest in pursuing a slot again, rather than waiting for a less competitive auction. Unbonding takes 28 days on Polkadot and 7 on Kusama . Ensure your staking and democracy holds are cleared. \ud83d\udc46\ud83d\udc46\ud83d\udc46 \ud83d\udcda\ud83d\udcda\ud83d\udcda","title":"ParachainAcution-vs-eBayAcution"},{"location":"public/blockchain/substrate-polka-kus/crowdloan/crowdloan-research-intro/#literature","text":"authorities win slots based on a verifiable random function = VRF the private-bid projects = Individual parachain Substrate-Glossary \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Researcher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Kusama]] [[Polkadot]] [[CrowdLoan]]","title":"Literature"},{"location":"public/blockchain/wasm/ewasm-research-intro/","tags":["substrate","polkadot_ecosystem","webassembly","wasm","llvm"],"text":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/EWASM(5) \ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb Introducing \u00b6 WebAssembly (or Wasm as a contraction) is a new, portable, size- and load-time-efficient format. A few key points: WebAssembly defines an instruction set, intermediate source format (WAST) and a binary encoded format (WASM). WebAssembly has a few higher level features, such as the ability to import and execute outside methods defined via an interface. WASM \u00b6 Fast. WebAssembly achieves near native performance. Compared with the Java, Python or JavaScript runtimes, it can be 10x to 100x faster (how is this possible?). It is also much faster than Docker, especially in cold start and system access. Safe. WebAssembly is a sandbox with a capability-based security model. It is not only safer than native binaries, but also safer than OS-level containers like Docker. Yet it provides access to the underlying system, icnluding new hardware features. Portable. WebAssembly apps can be written in C, C++, Rust, Go, and run without change on different OS and hardware platforms. Manageable. WebAssembly programs can be provisioned, started, hot swapped, stopped, and moved around by other applications. Goals \u00b6 To provide a specification of ewasm contract semantics and the Ethereum interface To provide an EVM transcompiler, preferably as an ewasm contract To provide a metering injector, preferably as an ewasm contract To provide a VM implementation for executing ewasm contracts To implement an ewasm backend in the Solidity compiler To provide a library and instructions for writing contracts in Rust To provide a library and instructions for writing contracts in C. ImportantContent \u00b6 The project VP Hung-Ying Tai (hydai) from Second State shared the current research content and future direction of Ewasm VM. The content is very exciting, including EVM bytecode, Webassembly, Ewasm1.0 and Ewasm2.0. PALLET \u00b6 While supporting the EVM pallet to provide seamless compatibility with all existing Ethereum applications, ParaState also provides developers with a next-gen smart contract implementation environment, EWASM (Ethereum-flavored WebAssembly) . All existing Ethereum smart contracts work on ParaState\u2019s Ewasm VM (Pallet SSVM) without any change.We see more and more parachain projects like Acala, Clover Finance, and Darwinia etc to integrate the EVM pallet into their parachains in order to interact with Ethereum ecosystem. EEI \u00b6 Ethereum defines the EEI to allow the client Corresponding function libraries can be implemented in different languages, and it is easier to complete prototypes and upgrades. A set of methods available to ewasm contracts. The smart contract of Ewasm 2.0 is renamed Execution Environments (EE). LLVM \u00b6 LLVM includes a WebAssembly backend to generate WASM output. Major browser JavaScript engines will notably have native support for WebAssembly, including but not limited to: Google's V8 engine (Node.js and Chromium-based browsers), Microsoft's Chakra engine (Microsoft Edge), Mozilla's Spidermonkey engine (Firefox and Thunderbird). * Other non-browser implementations exist too: wasm-jit-prototype (a standalone VM using an LLVM backend), wabt (a stack-based interpreter), ml-proto (the OCaml reference interpreter), etc. it future-proofs the Ethereum protocol by bringing the LLVM and WebAssembly developer communities into the Polkadot ecosystem. It is your best choice among one-stop development platforms for next-gen Web3 applications. It is Ethereum on Steroids. SecondState developers recently built a Solidity to Ewasm compiler called Soll. solc/solc --strict-assembly --optimize ~/simple_storage/simple_storage_yul_ir.txt SewUp \u00b6 The Second State EWasm Utility Program (SewUp) is a library that helps you sew up your Ethereum project with Rust, just like development in a common backend. Set-up-Sewup [Tutorial-Hello-World]]( https://docs.parastate.io/developers-resources/sewup-ewasm/tutorial-hello-world ) \ud83d\udc46\ud83d\udc46\ud83d\udc46 @SSVN @SOLL @LLVM @Compiler @AOT @JIT @WasmEdge @DAO @STAKE \ud83d\udcda\ud83d\udcda\ud83d\udcda Literature \u00b6 Ewasm contract: a contract adhering to the ewasm specification Ethereum environment interface = EEI metering: the act of measuring execution cost in a deterministic way metering injector: a transformation tool inserting metering code to an ewasm contract EVM transcompiler: an EVM bytecode (the current Ethereum VM) to ewasm transcompiler. See this chapter. \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Substrate]]","title":"Ewasm research intro"},{"location":"public/blockchain/wasm/ewasm-research-intro/#introducing","text":"WebAssembly (or Wasm as a contraction) is a new, portable, size- and load-time-efficient format. A few key points: WebAssembly defines an instruction set, intermediate source format (WAST) and a binary encoded format (WASM). WebAssembly has a few higher level features, such as the ability to import and execute outside methods defined via an interface.","title":"Introducing"},{"location":"public/blockchain/wasm/ewasm-research-intro/#wasm","text":"Fast. WebAssembly achieves near native performance. Compared with the Java, Python or JavaScript runtimes, it can be 10x to 100x faster (how is this possible?). It is also much faster than Docker, especially in cold start and system access. Safe. WebAssembly is a sandbox with a capability-based security model. It is not only safer than native binaries, but also safer than OS-level containers like Docker. Yet it provides access to the underlying system, icnluding new hardware features. Portable. WebAssembly apps can be written in C, C++, Rust, Go, and run without change on different OS and hardware platforms. Manageable. WebAssembly programs can be provisioned, started, hot swapped, stopped, and moved around by other applications.","title":"WASM"},{"location":"public/blockchain/wasm/ewasm-research-intro/#goals","text":"To provide a specification of ewasm contract semantics and the Ethereum interface To provide an EVM transcompiler, preferably as an ewasm contract To provide a metering injector, preferably as an ewasm contract To provide a VM implementation for executing ewasm contracts To implement an ewasm backend in the Solidity compiler To provide a library and instructions for writing contracts in Rust To provide a library and instructions for writing contracts in C.","title":"Goals"},{"location":"public/blockchain/wasm/ewasm-research-intro/#importantcontent","text":"The project VP Hung-Ying Tai (hydai) from Second State shared the current research content and future direction of Ewasm VM. The content is very exciting, including EVM bytecode, Webassembly, Ewasm1.0 and Ewasm2.0.","title":"ImportantContent"},{"location":"public/blockchain/wasm/ewasm-research-intro/#pallet","text":"While supporting the EVM pallet to provide seamless compatibility with all existing Ethereum applications, ParaState also provides developers with a next-gen smart contract implementation environment, EWASM (Ethereum-flavored WebAssembly) . All existing Ethereum smart contracts work on ParaState\u2019s Ewasm VM (Pallet SSVM) without any change.We see more and more parachain projects like Acala, Clover Finance, and Darwinia etc to integrate the EVM pallet into their parachains in order to interact with Ethereum ecosystem.","title":"PALLET"},{"location":"public/blockchain/wasm/ewasm-research-intro/#eei","text":"Ethereum defines the EEI to allow the client Corresponding function libraries can be implemented in different languages, and it is easier to complete prototypes and upgrades. A set of methods available to ewasm contracts. The smart contract of Ewasm 2.0 is renamed Execution Environments (EE).","title":"EEI"},{"location":"public/blockchain/wasm/ewasm-research-intro/#llvm","text":"LLVM includes a WebAssembly backend to generate WASM output. Major browser JavaScript engines will notably have native support for WebAssembly, including but not limited to: Google's V8 engine (Node.js and Chromium-based browsers), Microsoft's Chakra engine (Microsoft Edge), Mozilla's Spidermonkey engine (Firefox and Thunderbird). * Other non-browser implementations exist too: wasm-jit-prototype (a standalone VM using an LLVM backend), wabt (a stack-based interpreter), ml-proto (the OCaml reference interpreter), etc. it future-proofs the Ethereum protocol by bringing the LLVM and WebAssembly developer communities into the Polkadot ecosystem. It is your best choice among one-stop development platforms for next-gen Web3 applications. It is Ethereum on Steroids. SecondState developers recently built a Solidity to Ewasm compiler called Soll. solc/solc --strict-assembly --optimize ~/simple_storage/simple_storage_yul_ir.txt","title":"LLVM"},{"location":"public/blockchain/wasm/ewasm-research-intro/#sewup","text":"The Second State EWasm Utility Program (SewUp) is a library that helps you sew up your Ethereum project with Rust, just like development in a common backend. Set-up-Sewup [Tutorial-Hello-World]]( https://docs.parastate.io/developers-resources/sewup-ewasm/tutorial-hello-world ) \ud83d\udc46\ud83d\udc46\ud83d\udc46 @SSVN @SOLL @LLVM @Compiler @AOT @JIT @WasmEdge @DAO @STAKE \ud83d\udcda\ud83d\udcda\ud83d\udcda","title":"SewUp"},{"location":"public/blockchain/wasm/ewasm-research-intro/#literature","text":"Ewasm contract: a contract adhering to the ewasm specification Ethereum environment interface = EEI metering: the act of measuring execution cost in a deterministic way metering injector: a transformation tool inserting metering code to an ewasm contract EVM transcompiler: an EVM bytecode (the current Ethereum VM) to ewasm transcompiler. See this chapter. \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4fArman-Riazi\ud83e\udd1d [[Polkadot-Ecosystem-Research]] [[Substrate]]","title":"Literature"},{"location":"public/cryptocurrency/cryptocurrency/","tags":["cryprocurrency","trade"],"text":"Cryptocurrency \u00b6 Trading-Technical-Fundamental-Sheets","title":"Cryptocurrency"},{"location":"public/cryptocurrency/cryptocurrency/#cryptocurrency","text":"Trading-Technical-Fundamental-Sheets","title":"Cryptocurrency"},{"location":"public/cryptocurrency/trade/","tags":["cryprocurrency","trade"],"text":"Balance Sheets (Archived) \u00b6 Balance Sheets Trading-Technical-Fundamental (Archived) \u00b6 Crypto Trading All the information calculated for you in other cells","title":"Balance Sheets (Archived)"},{"location":"public/cryptocurrency/trade/#balance-sheets-archived","text":"Balance Sheets","title":"Balance Sheets (Archived)"},{"location":"public/cryptocurrency/trade/#trading-technical-fundamental-archived","text":"Crypto Trading All the information calculated for you in other cells","title":"Trading-Technical-Fundamental (Archived)"},{"location":"public/day-notes/2022/","text":"04","title":"2022"},{"location":"public/day-notes/2022/04/","text":"2022-04-01 2022-04-02 2022-04-03","title":"04"},{"location":"public/day-notes/2022/04/days/2022-04-15/","text":"Published Website Captured 3 movie About me, Guide website, Solidity Teach to Mr.kia","title":"2022 04 15"},{"location":"public/day-notes/2022/04/days/2022-04-16/","text":"Social business network","title":"2022 04 16"},{"location":"public/day-notes/2022/04/days/2022-04-17/","text":"Teach to Mr.kia","title":"2022 04 17"},{"location":"public/devops/CICD/","tags":["devops","cicd"],"text":"CICD \u00b6 Features \u00b6 Automation publish Fast Release On-premise Cloud-Native Run Analyzer Test/Stage Customized Pipelines Good Solution for #Microservice Management product release per team Quote I captured 6h about implement of ci-cd with kubernetes and docker that I did not want upload it. Info #VSTS #CICD #Pipline #TFS-Code2018 #Rancher #CICD #CaaS #CloudNative Rancher - CaaS","title":"CICD"},{"location":"public/devops/CICD/#cicd","text":"","title":"CICD"},{"location":"public/devops/CICD/#features","text":"Automation publish Fast Release On-premise Cloud-Native Run Analyzer Test/Stage Customized Pipelines Good Solution for #Microservice Management product release per team Quote I captured 6h about implement of ci-cd with kubernetes and docker that I did not want upload it. Info #VSTS #CICD #Pipline #TFS-Code2018 #Rancher #CICD #CaaS #CloudNative Rancher - CaaS","title":"Features"},{"location":"public/devops/Cloud/","tags":["devops","cloud"],"text":"I worked a little bit on AWS. I used services like #Cloud9 for online editor like gitpod. I am into IBM cloud for Couchdb (+ Medium link) and Blockchain as a service. My master thesis is about cloud simulation.[[master]]","title":"Cloud"},{"location":"public/devops/Devops/","tags":["devops"],"text":"DevOps \u00b6 Kubernetes Rancher Docker CICD Elastic-Search Cloud Virtualization Quote I success to launched #Microservice either of [[dotnetcore]] and a sample with python I captured 6h about implement of ci-cd with [[kubernetes]] and docker that I did not want upload it. For devOps you should better know a little bit about programing languages but it will be ok, if you do not know. e.g I have not write any code by python but I was able to [[[deploy]] it.For devops you need to know about configuration, esxi, on-permise, cloud, windows server, linux dist/ubuntu that is out of scope for now surely.","title":"DevOps"},{"location":"public/devops/Devops/#devops","text":"Kubernetes Rancher Docker CICD Elastic-Search Cloud Virtualization Quote I success to launched #Microservice either of [[dotnetcore]] and a sample with python I captured 6h about implement of ci-cd with [[kubernetes]] and docker that I did not want upload it. For devOps you should better know a little bit about programing languages but it will be ok, if you do not know. e.g I have not write any code by python but I was able to [[[deploy]] it.For devops you need to know about configuration, esxi, on-permise, cloud, windows server, linux dist/ubuntu that is out of scope for now surely.","title":"DevOps"},{"location":"public/devops/Docker/","tags":["devops","docker","container"],"text":"Docker \u00b6 DevOps: Docker registry Basic Authentication and HTTPS There are two links for handling insecure and docker\u2019 notices about different solutions although we proposed a secure registry so it is better to know a little bit of another information. (Registry, Insecure) ufw allow http ufw allow https curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -apt-key fingerprint 0EBFCD88 apt install ca-certificates curl openssh-server ufw apt-transport-https -y apt update apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - add-apt-repository \u201cdeb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) \\stable\u201d apt-get install docker-ce docker-ce-cli containerd.io usermod -aG docker linuxusername usermod -aG docker root docker run hello-world docker ps -a docker pull registry:2 (optional)reboot *docker run \u2014 entrypoint htpasswd registery:2 -Bbn dockerregistry dockerregistery > auth/htpasswd *docker run -d -p 5000:5000 \u2014 restart=always \u2014 name registry -v /opt/auth:/auth -e \u201cREGISTRY_AUTH=htpasswd\u201d -e \u201cREGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\u201d -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd -v /opt/certs:/certs -v /opt/data:/var/lib/registry -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/server.crt -e REGISTRY_HTTP_TLS_KEY=/certs/server.key registry:2 *curl -kiv -H \u201cAuthorization: Basic $(echo -n \u201cdockerregistry:dockerregistry\u201d | base64)\u201d https://localhost:5000/v2 *docker login localhost:5000 *docker pull nginx:latest Good luck","title":"Docker"},{"location":"public/devops/Docker/#docker","text":"DevOps: Docker registry Basic Authentication and HTTPS There are two links for handling insecure and docker\u2019 notices about different solutions although we proposed a secure registry so it is better to know a little bit of another information. (Registry, Insecure) ufw allow http ufw allow https curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -apt-key fingerprint 0EBFCD88 apt install ca-certificates curl openssh-server ufw apt-transport-https -y apt update apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - add-apt-repository \u201cdeb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) \\stable\u201d apt-get install docker-ce docker-ce-cli containerd.io usermod -aG docker linuxusername usermod -aG docker root docker run hello-world docker ps -a docker pull registry:2 (optional)reboot *docker run \u2014 entrypoint htpasswd registery:2 -Bbn dockerregistry dockerregistery > auth/htpasswd *docker run -d -p 5000:5000 \u2014 restart=always \u2014 name registry -v /opt/auth:/auth -e \u201cREGISTRY_AUTH=htpasswd\u201d -e \u201cREGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\u201d -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd -v /opt/certs:/certs -v /opt/data:/var/lib/registry -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/server.crt -e REGISTRY_HTTP_TLS_KEY=/certs/server.key registry:2 *curl -kiv -H \u201cAuthorization: Basic $(echo -n \u201cdockerregistry:dockerregistry\u201d | base64)\u201d https://localhost:5000/v2 *docker login localhost:5000 *docker pull nginx:latest Good luck","title":"Docker"},{"location":"public/devops/Elastic-Search/","tags":["elastic","search","devops"],"text":"Elastic-Search \u00b6 Features \u00b6 Rest API Database Search Crawler Analyze Dashboard Quaryable Scalability Machine learning Quote To Configure ELK stack you need a lot of hardware resource I rented VPS to work in 2020. My experience says it is so power-full and all-in-one database rather than the other DBs. Info ELK-Dashboard ELK-captured 2020 Report of Gartner 2020 about ELK stack Dashboards(Location, System APIs, Logs of resources system, Filter,Advance search,...)","title":"Elastic-Search"},{"location":"public/devops/Elastic-Search/#elastic-search","text":"","title":"Elastic-Search"},{"location":"public/devops/Elastic-Search/#features","text":"Rest API Database Search Crawler Analyze Dashboard Quaryable Scalability Machine learning Quote To Configure ELK stack you need a lot of hardware resource I rented VPS to work in 2020. My experience says it is so power-full and all-in-one database rather than the other DBs. Info ELK-Dashboard ELK-captured 2020 Report of Gartner 2020 about ELK stack Dashboards(Location, System APIs, Logs of resources system, Filter,Advance search,...)","title":"Features"},{"location":"public/devops/Kubernetes/","tags":["devops","cicd","kubernetes"],"text":"Kubernetes \u00b6 Capabilities: Scheduling and orchestrating application containers As an Infrastructure for Microservices Integrate with hundreds of tools such as (ELK, Rancher, ...) Optimal use of consume resources To increase speed and self-organize while the team doing develop Protecting the Website from Attacks Website maintenance without interruption and guaranteed It has been defined go through the CaaS layers like Rancher, but we know that this service itself is a Micro PaaS. I prefer to use kubernetes in the Rancher. Quote I eager to try it again especially use it in [[HyperLedger-IBM]] projects. Info Version ~2018 Show used Features Show Part 1- used kubernetes version 1.0","title":"Kubernetes"},{"location":"public/devops/Kubernetes/#kubernetes","text":"Capabilities: Scheduling and orchestrating application containers As an Infrastructure for Microservices Integrate with hundreds of tools such as (ELK, Rancher, ...) Optimal use of consume resources To increase speed and self-organize while the team doing develop Protecting the Website from Attacks Website maintenance without interruption and guaranteed It has been defined go through the CaaS layers like Rancher, but we know that this service itself is a Micro PaaS. I prefer to use kubernetes in the Rancher. Quote I eager to try it again especially use it in [[HyperLedger-IBM]] projects. Info Version ~2018 Show used Features Show Part 1- used kubernetes version 1.0","title":"Kubernetes"},{"location":"public/devops/Rancher/","tags":["container","rancher","kubernetes","caas","devops"],"text":"Rancher \u00b6 One Platform for Kubernetes Management Rancher is a complete software stack for teams adopting containers. It addresses the operational and security challenges of managing multiple Kubernetes clusters, while providing DevOps teams with integrated tools for running containerized workloads. Rancher Kubernetes Engine (RKE) is a CNCF-certified #[[Kubernetes]] distribution that runs entirely within Docker containers. It works on bare-metal and virtualized servers. RKE solves the problem of installation complexity, a common issue in the Kubernetes community. With RKE, the installation and operation of Kubernetes is both simplified and easily automated, and it\u2019s entirely independent of the operating system and platform you\u2019re running. As long as you can run a supported version of Docker, you can deploy and run Kubernetes with RKE.Rancher has got [[CICD]] pipelines Quote Rancher is a CaaS platform and service provider that you can use it on cloud or #air-gap #high-avalibility. I deployed the Rancher via Helm and It was fascinated when I found kubernetes on rancher without trying to scratch. Rancher has got RKE-Cli like Google kubernetes and Amazon kubernetes. Air-Gap configuration: nodes: - address: 172.18.3.10 internal_address: 192.168.11.1 user: ubuntu role: [controlplane,worker,etcd] - address: 172.18.3.15 internal_address: 192.168.22.2 user: ubuntu role: [controlplane,worker,etcd] - address: 172.18.3.16 internal_address: 192.168.33.3 user: ubuntu role: [controlplane,worker,etcd] services: etcd: snapshot: true For Air-Gap HA you need to getting docker images(Version-2018): busybox minio/minio:RELEASE.2018-05-25T19-49-13Z rancher/alertmanager-helper:v0.0.2 rancher/calico-cni:v3.1.1 rancher/calico-cni:v3.1.3 rancher/calico-ctl:v2.0.0 rancher/calico-node:v3.1.1 rancher/calico-node:v3.1.3 rancher/cluster-proportional-autoscaler-amd64:1.0.0 rancher/coreos-etcd:v3.1.12 rancher/coreos-etcd:v3.2.18 rancher/coreos-etcd:v3.2.24 rancher/coreos-flannel-cni:v0.2.0 rancher/coreos-flannel-cni:v0.3.0 rancher/coreos-flannel:v0.10.0 rancher/coreos-flannel:v0.9.1 rancher/docker-elasticsearch-kubernetes:5.6.2 rancher/fluentd-helper:v0.1.2 rancher/fluentd:v0.1.10 rancher/hyperkube:v1.10.12-rancher1 rancher/hyperkube:v1.11.6-rancher1 rancher/hyperkube:v1.12.4-rancher1 rancher/hyperkube:v1.9.7-rancher2 rancher/jenkins-jnlp-slave:3.10-1-alpine rancher/jenkins-plugins-docker:17.12 rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.10 rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.13 rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.7 rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.8 rancher/k8s-dns-kube-dns-amd64:1.14.10 rancher/k8s-dns-kube-dns-amd64:1.14.13 rancher/k8s-dns-kube-dns-amd64:1.14.7 rancher/k8s-dns-kube-dns-amd64:1.14.8 rancher/k8s-dns-sidecar-amd64:1.14.10 rancher/k8s-dns-sidecar-amd64:1.14.13 rancher/k8s-dns-sidecar-amd64:1.14.7 rancher/k8s-dns-sidecar-amd64:1.14.8 rancher/kibana:5.6.4 rancher/log-aggregator:v0.1.3 rancher/metrics-server-amd64:v0.2.1 rancher/metrics-server-amd64:v0.3.1 rancher/nginx-ingress-controller:0.16.2-rancher1 rancher/nginx-ingress-controller-defaultbackend:1.4 rancher/pause-amd64:3.0 rancher/pause-amd64:3.1 rancher/pipeline-jenkins-server:v0.1.0 rancher/pipeline-tools:v0.1.0 rancher/prom-alertmanager:v0.15.2 rancher/rancher-agent:v2.1.5 rancher/rancher:v2.1.5 rancher/rke-tools:v0.1.13 rancher/rke-tools:v0.1.15 rancher/rke-tools:v0.1.16 rancher/coreos-etcd:v3.2.18 rancher/rke-tools:v0.1.15 rancher/k8s-dns-kube-dns-amd64:1.14.10 rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.10 rancher/k8s-dns-sidecar-amd64:1.14.10 rancher/cluster-proportional-autoscaler-amd64:1.0.0 rancher/hyperkube:v1.11.6-rancher1 rancher/coreos-flannel:v0.10.0 rancher/coreos-flannel-cni:v0.3.0 rancher/calico-node:v3.1.3 rancher/calico-cni:v3.1.3 rancher/calico-ctl:v2.0.0 weaveworks/weave-kube:2.1.2 weaveworks/weave-npc:2.1.2 rancher/pause-amd64:3.1 rancher/nginx-ingress-controller:0.16.2-rancher1 rancher/nginx-ingress-controller-defaultbackend:1.4 rancher/metrics-server-amd64:v0.2.1 I deployed Microservice .Netcore Ecommerce on Air-Gap as HA Info","title":"Rancher"},{"location":"public/devops/Rancher/#rancher","text":"One Platform for Kubernetes Management Rancher is a complete software stack for teams adopting containers. It addresses the operational and security challenges of managing multiple Kubernetes clusters, while providing DevOps teams with integrated tools for running containerized workloads. Rancher Kubernetes Engine (RKE) is a CNCF-certified #[[Kubernetes]] distribution that runs entirely within Docker containers. It works on bare-metal and virtualized servers. RKE solves the problem of installation complexity, a common issue in the Kubernetes community. With RKE, the installation and operation of Kubernetes is both simplified and easily automated, and it\u2019s entirely independent of the operating system and platform you\u2019re running. As long as you can run a supported version of Docker, you can deploy and run Kubernetes with RKE.Rancher has got [[CICD]] pipelines Quote Rancher is a CaaS platform and service provider that you can use it on cloud or #air-gap #high-avalibility. I deployed the Rancher via Helm and It was fascinated when I found kubernetes on rancher without trying to scratch. Rancher has got RKE-Cli like Google kubernetes and Amazon kubernetes. Air-Gap configuration: nodes: - address: 172.18.3.10 internal_address: 192.168.11.1 user: ubuntu role: [controlplane,worker,etcd] - address: 172.18.3.15 internal_address: 192.168.22.2 user: ubuntu role: [controlplane,worker,etcd] - address: 172.18.3.16 internal_address: 192.168.33.3 user: ubuntu role: [controlplane,worker,etcd] services: etcd: snapshot: true For Air-Gap HA you need to getting docker images(Version-2018): busybox minio/minio:RELEASE.2018-05-25T19-49-13Z rancher/alertmanager-helper:v0.0.2 rancher/calico-cni:v3.1.1 rancher/calico-cni:v3.1.3 rancher/calico-ctl:v2.0.0 rancher/calico-node:v3.1.1 rancher/calico-node:v3.1.3 rancher/cluster-proportional-autoscaler-amd64:1.0.0 rancher/coreos-etcd:v3.1.12 rancher/coreos-etcd:v3.2.18 rancher/coreos-etcd:v3.2.24 rancher/coreos-flannel-cni:v0.2.0 rancher/coreos-flannel-cni:v0.3.0 rancher/coreos-flannel:v0.10.0 rancher/coreos-flannel:v0.9.1 rancher/docker-elasticsearch-kubernetes:5.6.2 rancher/fluentd-helper:v0.1.2 rancher/fluentd:v0.1.10 rancher/hyperkube:v1.10.12-rancher1 rancher/hyperkube:v1.11.6-rancher1 rancher/hyperkube:v1.12.4-rancher1 rancher/hyperkube:v1.9.7-rancher2 rancher/jenkins-jnlp-slave:3.10-1-alpine rancher/jenkins-plugins-docker:17.12 rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.10 rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.13 rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.7 rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.8 rancher/k8s-dns-kube-dns-amd64:1.14.10 rancher/k8s-dns-kube-dns-amd64:1.14.13 rancher/k8s-dns-kube-dns-amd64:1.14.7 rancher/k8s-dns-kube-dns-amd64:1.14.8 rancher/k8s-dns-sidecar-amd64:1.14.10 rancher/k8s-dns-sidecar-amd64:1.14.13 rancher/k8s-dns-sidecar-amd64:1.14.7 rancher/k8s-dns-sidecar-amd64:1.14.8 rancher/kibana:5.6.4 rancher/log-aggregator:v0.1.3 rancher/metrics-server-amd64:v0.2.1 rancher/metrics-server-amd64:v0.3.1 rancher/nginx-ingress-controller:0.16.2-rancher1 rancher/nginx-ingress-controller-defaultbackend:1.4 rancher/pause-amd64:3.0 rancher/pause-amd64:3.1 rancher/pipeline-jenkins-server:v0.1.0 rancher/pipeline-tools:v0.1.0 rancher/prom-alertmanager:v0.15.2 rancher/rancher-agent:v2.1.5 rancher/rancher:v2.1.5 rancher/rke-tools:v0.1.13 rancher/rke-tools:v0.1.15 rancher/rke-tools:v0.1.16 rancher/coreos-etcd:v3.2.18 rancher/rke-tools:v0.1.15 rancher/k8s-dns-kube-dns-amd64:1.14.10 rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.10 rancher/k8s-dns-sidecar-amd64:1.14.10 rancher/cluster-proportional-autoscaler-amd64:1.0.0 rancher/hyperkube:v1.11.6-rancher1 rancher/coreos-flannel:v0.10.0 rancher/coreos-flannel-cni:v0.3.0 rancher/calico-node:v3.1.3 rancher/calico-cni:v3.1.3 rancher/calico-ctl:v2.0.0 weaveworks/weave-kube:2.1.2 weaveworks/weave-npc:2.1.2 rancher/pause-amd64:3.1 rancher/nginx-ingress-controller:0.16.2-rancher1 rancher/nginx-ingress-controller-defaultbackend:1.4 rancher/metrics-server-amd64:v0.2.1 I deployed Microservice .Netcore Ecommerce on Air-Gap as HA Info","title":"Rancher"},{"location":"public/devops/Virtualization/","tags":["vsphere","devops","cloud","esxi","virtualization"],"text":"Virualization \u00b6 [[VSphere]] 7.1- Features \u00b6 Server virtualization Optimal use of resources Reduce processing costs and power consumption To use the [[Kubernetes]] with high speed execution Remote communication to a server Run multiple operating systems simultaneously Info To know virtualization is obligate for blockchain developers. Senior full-stack developers have associated with it. My [[master]] thesis have being demonstrated cloud and virtualization. The virtualization concepts are simulated as kind of [[Container]] and virtual machine.","title":"Virualization"},{"location":"public/devops/Virtualization/#virualization","text":"","title":"Virualization"},{"location":"public/devops/Virtualization/#vsphere-71-features","text":"Server virtualization Optimal use of resources Reduce processing costs and power consumption To use the [[Kubernetes]] with high speed execution Remote communication to a server Run multiple operating systems simultaneously Info To know virtualization is obligate for blockchain developers. Senior full-stack developers have associated with it. My [[master]] thesis have being demonstrated cloud and virtualization. The virtualization concepts are simulated as kind of [[Container]] and virtual machine.","title":"[[VSphere]] 7.1- Features"},{"location":"public/fun/magazine/","tags":["magazine"],"text":"Magazine \u00b6 DC-Pride-2022-1-2022 How And why-Series Olaf-El-Vikingo SammaxSurfInTheHighWay SweetHeartPlayingCards-1935","title":"Magazine"},{"location":"public/fun/magazine/#magazine","text":"DC-Pride-2022-1-2022 How And why-Series Olaf-El-Vikingo SammaxSurfInTheHighWay SweetHeartPlayingCards-1935","title":"Magazine"},{"location":"public/fun/music/","tags":["music"],"text":"Music Videos \u00b6 Shadmehr Aghili - Love Celine Dion - The Best French AliReza Assar - Epic Darush - Fall in Deep","title":"Music Videos"},{"location":"public/fun/music/#music-videos","text":"Shadmehr Aghili - Love Celine Dion - The Best French AliReza Assar - Epic Darush - Fall in Deep","title":"Music Videos"},{"location":"public/fun/3d/3d-images/3d-image1/","text":"360\u00b0 Image","title":"3d image1"},{"location":"public/fun/3d/3d-images/3d-image2/","text":"360\u00b0 Image","title":"3d image2"},{"location":"public/fun/3d/3d-images/3d-images/","text":"3d-image1 3d-image2","title":"3d images"},{"location":"public/fun/3d/3d-videos/3D-videos/","text":"3d-360-Spaceflight to Andromeda Galaxy | 360\u00b0 Video VR 3d-360-Tomorrowland 2019 - IMMERSIVE VR EXPERIENCE - 20 Stages Live in 360\u00b0 3d-360-Virtual Nature 360\u00b0 - 5.7K Nature Meditation for Oculus Quest","title":"3D videos"},{"location":"public/fun/3d/3d-videos/3d-video1/","text":"","title":"3d video1"},{"location":"public/fun/3d/3d-videos/3d-video2/","text":"","title":"3d video2"},{"location":"public/fun/3d/3d-videos/3d-video3/","text":"","title":"3d video3"},{"location":"public/fun/magazine/magazine-dc-pride-2022-1-2022/","text":"","title":"Magazine dc pride 2022 1 2022"},{"location":"public/fun/magazine/magazine-howandwhy-series/","text":"","title":"Magazine howandwhy series"},{"location":"public/fun/magazine/magazine-olaf-el-vikingo/","text":"","title":"Magazine olaf el vikingo"},{"location":"public/fun/magazine/magazine-sammaxsurfinthehighway/","text":"","title":"Magazine sammaxsurfinthehighway"},{"location":"public/fun/magazine/magazine-sweetheartplayingcards1935/","text":"","title":"Magazine sweetheartplayingcards1935"},{"location":"public/issues/issues/","text":"issue-rust issue-substrate","title":"Issues"},{"location":"public/issues/nodejs/Issues-Nodejs/","text":"Failure: NodeJs AssertionError [ERR_ASSERTION]","title":"Issues Nodejs"},{"location":"public/issues/rust/issue-rust/","text":"issue-rust-libc-rust","title":"Issue rust"},{"location":"public/issues/rust/build/libc-rust/","tags":["libc","compile"],"text":"could not compile 'libc' due to previous error Info sudo apt install -y cmake pkg-config libssl-dev git gcc build-essential clang libclang-dev [[issue-rust]]","title":"Libc rust"},{"location":"public/issues/substrate/issue-substrate/","text":"issue-substrate-ocw-runtime","title":"Issue substrate"},{"location":"public/issues/substrate/recipes/runtime/ocw-runtime/","tags":["ocw","runtime","build"],"text":"failed to run custom build command for `ocw-runtime v3.0.0 Info First of all search nightly in explorer project and then find version used in that. rustup uninstall nightly rustup install nightly-2020-10-06 rustup target add wasm32-unknown-unknown --toolchain nightly-2020-10-06 export WASM_BUILD_TOOLCHAIN=nightly-2020-10-06 [[issue-substrate]] []","title":"Ocw runtime"},{"location":"public/mynotes/exp-2021cryprotrading/","text":"Experience loss of money because of trading crypto in 2021 \ud83e\udd15 \u00b6 I used to make a financial plan and I was responsible for paying 6% monthly Interest to investor and then I lost 73.000$ because in 2021 everybody said bitcoin will be 120.000-240.000$ but I decided to sell at the price of 70.000$ but It was not happening. I do not have any team for managing orders exactly and doing base on my good plan. This activity making psychological effects but I tried to get feel better by reading books, meditation, patience, recovery mind so on ... I wonder to let you know 73.000 $ is the value of 2.000.000.000 Rial.it was harmful in situations of unsuited economic in a country. Due to my interest and my experience with the Blockchain these things will still be worth something when I have finished paying off the debt \"To everyone who finds the current investment climate hard, diffcult, and somewhat confusing, I would say, 'Welcome to adult life.'\" - [[Charlie Munger]]","title":"Experience loss of money because of trading crypto in 2021 \ud83e\udd15"},{"location":"public/mynotes/exp-2021cryprotrading/#experience-loss-of-money-because-of-trading-crypto-in-2021","text":"I used to make a financial plan and I was responsible for paying 6% monthly Interest to investor and then I lost 73.000$ because in 2021 everybody said bitcoin will be 120.000-240.000$ but I decided to sell at the price of 70.000$ but It was not happening. I do not have any team for managing orders exactly and doing base on my good plan. This activity making psychological effects but I tried to get feel better by reading books, meditation, patience, recovery mind so on ... I wonder to let you know 73.000 $ is the value of 2.000.000.000 Rial.it was harmful in situations of unsuited economic in a country. Due to my interest and my experience with the Blockchain these things will still be worth something when I have finished paying off the debt \"To everyone who finds the current investment climate hard, diffcult, and somewhat confusing, I would say, 'Welcome to adult life.'\" - [[Charlie Munger]]","title":"Experience loss of money because of trading crypto in 2021 \ud83e\udd15"},{"location":"public/other/2021-year-review/","text":"Joe Previte See all posts 2021 Year in Review Last updated: 01/06/2022 2021 This year feels like a blur. I keep thinking 2021 and 2020 were actually the same year due to the pandemic. 2020 was a wild year because I joined Facebook/Meta, moved the entire family to Seattle, moved back to Arizona, left Facebook/Meta, bought a house and started at Coder. Even writing that last sentence feels tiring. There was a lot happening. But fast-forward to 2021 and it was actually a wonderful year. Working Full-Time on Open Source for Coder I joined Coder in December 2020 as an Open Source TypeScript Engineer. My responsibility was and still is to maintain an open source project called code-server, which is VS Code in the browser. I feel very grateful to have this job and work on open source every day. My work is all public on GitHub and anyone can go see it. And I get to interact with the community on a regular basis. Sometimes people help us debug issues. Other times they raise PRs and fix issues for us. It\u2019s amazing! And I\u2019ve really been enjoying my time at Coder. It\u2019s one of the first places where I look forward to going to work and I\u2019m learning new things everyday. I would say I looked forward to work 90% of the year. Yes, I had bad days. But I also have many many days where I am thinking about work on the weekend because I\u2019m so excited about this space. DevTools, specifically IDEs, is an exciting space. I do genuinely believe remote development is the future and I\u2019m happy I get to contribute to it. Becoming a Dad The other amazing part of the year was becoming a dad! In October, our first daughter (and first kid) was born. I really didn\u2019t know what to expect becoming a parent, but now I\u2019m starting to understand what it means. The biggest realization is how much attention I paid to things that don\u2019t matter before she was born. Now, I realize all I want is to take care of my family (wife, daughter and two dogs) and have a job that I enjoy. That\u2019s basically it. Everything else is icing on the cake. I also have a ton of respect for single parents. How do you do it?! I could never. It takes a village to raise a child. Thankfully we have lots of family here in Arizona to help us. 2021 Highlights Here are some of my other highlights for the year: attempted my first SaaS started livestreaming on Twitch 3,174 GitHub Contributions $36,942.02 in side income revenue 119 hours in the gym, 208 workouts, 1,774,602lbs lifted Goals for 2022 I try to practice systems over goals but I have 3 main things I\u2019m focusing on for 2022. Be the Best Dad and Husband I feel very fortunate that we had our first baby in 2021. Now I want to do everything I can to be the best dad for her and the best husband for my wife. I will be mindful when I\u2019m with them. Protect them, love them and take care of them. One of this biggest things I\u2019d like to do is generate wealth so they have long-term financial support. Since I\u2019m the breadwinner in the family, I\u2019d like to earn and save enough so that if something terrible happens, money isn\u2019t an issue for them. Launch TS Course I launched my first course - Vim for VSCode - in 2020. I started working on a TypeScript course in 2021. In 2022, I will partner with egghead and launch the TypeScript course. The goal is to have industry-level impact akin to Testing JavaScript or Epic React. Double Side-Project Income (> $50k) I\u2019d like to double my side-project income. On the low-end, it should be over $50k. To actually double it though, it should be closer to $75k. I plan to do this through my courses (Vim & TypeScript) and job board & job referrals. We\u2019ll see. It feels like I\u2019m shooting for the moon, but it can\u2019t hurt to try. Conclusion That\u2019s all! Thanks for reading. If you have questions or comments, or just want to say hey, shoot me a DM on Twitter! Join the Newsletter I send a monthly newsletter with 1 exciting thing, 1 helpful thing, and new jobs. Email* awesomeperson@gmail.com By subscribing, you agree with Revue\u2019s Terms of Service and Privacy Policy. \u00a9 2022 Joe Previte","title":"2021 year review"},{"location":"public/other/Charlie%20Munger/","text":"","title":"Charlie Munger"},{"location":"public/other/guide-website/","text":"","title":"Guide website"},{"location":"public/other/learn-quickly/","text":"How to Learn Quickly \u00b6 A few months back, I set out a goal to learn Language deeply in 3 months and I did it. Since then, others have asked how they can do the same. The outcome is a result of using something that I like to call the Fast Framework. This guide will teach you how you can use it to learn anything quickly. Imagine you\u2019re in racing a car. Your goal is to cross the finish line. Taking this analogy, we break the framework into three phases: Make your Map \u00b6 Stay on Track \u00b6 Cross the Finishline \u00b6 In each phase, I\u2019ll cover different aspects that will help you learn fast and reach your goal. I\u2019ll use learning Language as the example. The first phase will cover the foundation for your learning project. Think of this as vision, timeframe, timeline, and organization. In the phase after, the focus will be staying on track and I\u2019ll discuss aspects related to accountability, momentum, sharing, and focus. In the final phase of the journey, the goal is to finish strong and cross the finishline. There, I\u2019ll talk about practice, confidence, vocabulary, and depth. Make your Map \u00b6 The first step is to make your map. This will help answer questions like: What does it mean to \u201clearn [insert thing]\u201c? \u00b6 How long will the project take? \u00b6 What are the expected outcomes? \u00b6 How am I going to organize my learning project? \u00b6 Write a Clear Vision \u00b6 For the vision, define your project and use the Objective Key Results (OKRs) framework. If you aren\u2019t familiar, this was popularized by the book \u201dMeasure What Matters\u201d and is used at companies like Google and Intuit. First, define what you expect to achieve. In my Language learning project, I wrote: Learn Language deeply and become the [Company] \u201cin-house expert\u201d That will be your Objective. Next, figure out how you\u2019re going to measure it. We refer to these as the Key Results. Continuing with my previous project, I wrote: Read \u201cProgramming Language\u201d by Boris Cherny \u00b6 Read the Official Language Handbook \u00b6 Produce small code examples for all concepts \u00b6 Contribute to Language, the language \u00b6 Contribute to Language-cheatsheets/react-Language-cheatsheet \u00b6 Don\u2019t rush through this part. \u00b6 Spend some time thinking about your objective and what you need to achieve to get there. Completing your key results should allow you to confidently say you\u2019ve completed your objective. With this vision in mind, you now have clarity on it means when you say \u201clearn [X]\u201d and you know what you expect to achieve. Establish a Timeframe \u00b6 You don\u2019t want to be racing on this map forever. You need to be realistic and ask yourself how much time you have for this. Estimating time to complete tasks is hard. You can use what I like to call the Timeframe Formula: Take the length of months you want to work on this, multiple by 4 to give the amount in weeks. Then multiple it by the number of hours per week that you want to dedicate. For example, when I did a similar project, I gave myself 3 months with 8 hours per week. Using the Timeframe Formula, you get: 3 months x 4 weeks/month x 8 hours/week = 96 hours total. You now have your timeframe. Use this to set expectations on how much time you plan to dedicate each week. Build a Timeline \u00b6 The next thing you need to add to your map is a timeline. Think of this as a week by week calendar. The timeframe answers the question of how long and the timeline answers the what will I do each week. It helps you think less because you will already know what to do for that week. It won\u2019t be perfect. You may need to readjust, but you will have removed friction. An example \u00b6 Week 1 (June 1) Programming Language Chapter 1 - Introduction Chapter 2 - Language: a 10_000 foot view Book exercises Chapter 3 - All About Types Book exercises Official Language Handbook Basic Types Variable Declarations You know yourself best. Think back to the Timeframe Formula. The example estimated 8hrs/week and 12 weeks in total. Knowing how fast you work (i.e. read, code, etc.), you would adjust accordingly. A complete timeline would have all the weeks filled out. Two important tips: \u00b6 Leave ~10% buffer towards the end \u00b6 Give yourself some breathing room \u00b6 Life comes up and you may fall behind. That\u2019s where the buffer comes in! Some weeks, you may find that you complete everything in 6 hours. No need to fill those two other hours if you don\u2019t want to. Reward yourself with rest. \u00b6 With a timeline, you are good to go! Keep it Organized \u00b6 You want to stay organized on this journey. That means a place to keep track of your timeline, log any notes or things you learn, and have visual indicators for the progress you\u2019re making. I use Notion for this because it supports project management well. I make a place for the project. I add the timeline and use checkboxes. Then, I check them off as I go and take notes as I\u2019m learning. Here is a non-exhaustive list of tools you might want to check out: Notion \u00b6 Trello \u00b6 Asana \u00b6 GitHub Projects \u00b6 Basecamp \u00b6 You could also use an analog tool such as a pen and paper. Stay on Track \u00b6 Now that we have our map, we are ready for the next phase: stay on track. In this phase, the goal is to focus on developing the systems that will help you stay accountable, build momentum, share with others and, stay focused. Keep Yourself Accountable \u00b6 You always want to stay accountable for your project. Think of this as your race crew. They make sure you\u2019re fueled, your tires are rotated, you\u2019re hydrated, and you\u2019re ready to finish the race. We want a similar type of support and accountability. It could be: a group of friends a family member a friend online All you need is at least one person with whom you can share updates. They don\u2019t have to know Language or even know how to code. But they do need to be someone with whom you can check-in regularly. For Language, I recommend looking for 2-3 people who will join you in your Language journey. I would post: on Twitter, using the #100DaysOfCode or #CodeNewbie hashtags on Dev.to, using the #Language and #discuss tags to start a discussion and share your project on the Language Discord For your own project, come up with a similar list of options. Explore them all. See where you find the most success and stick with it. 2-3 people is ideal, but at least 1 other person works fine. Build Momentum \u00b6 You want momentum. Momentum will keep you going on the track and heading towards the finish line. Think small wins, milestones and success spirals. Small wins are the little accomplishments that we oftentimes take for granted. Examples are things like learning a new word or understanding a concept. Celebrate these. Milestones are the next step up. These can either be date-based or achievement-based. Date-based would be hitting the 1-month mark in your 3-month timeframe for your learning project. Achievement-based would be finishing one of your key results. Either way, these are things to be celebrated and help you sustain the momentum. Success spiral is a term I first heard in Motivation Hack by Nick Winter. It\u2019s the idea that you set yourself up for success for starting small and moving outwards, like a spiral. In this case with Language, maybe you say, \u201cI\u2019m going to write one line of Language a day.\u201d Sounds trivial, right? Good, it should. You start there, establish the habit, then build upwards and outwards. Upwards meaning you continue doing it every day. Outwards meaning you increase the lines of code (without losing the habit). Share with Others \u00b6 Yoda quote, \"Always pass on what you have learned.\" One of the most important parts of staying on track is sharing with others and Learning in Public. There are various mediums you can choose from for sharing: Tweets Blog Posts Podcasts Videos Tutorials Courses Any of these ways work - and there are probably more I didn\u2019t list. This will aid your project for a few reasons: Help you retain what you\u2019re learning Build expertise in the area Meet others who are learning When I was learning Language, I tweeted as I learned. Not only did I meet other Language community members, but people corrected me or taught me new things. Towards the end, people started tweeted me asking for Language help. I didn\u2019t always know the answer, but my sharing with others and learning in public helped me build reputation and credibility. I even ended up attracting the attention of an editor for a tech blog who paid me to write a few Language articles. As you can see, it pays to share with others. Keep Your Focus \u00b6 The last piece I want to touch on for staying on track is keeping your focus. To stay on track, you have to keep yourself focused. The first and foremost is limit your focus. Ideally, learning Language is your main focus. I wouldn\u2019t suggest doing this and learning Rust or another language or something else. Keeping your attention on one project increases the likelihood you\u2019ll stay on track. The other thing you might want to try is deep work. An idea by Cal Newport, it\u2019s where you create an environment that lets you focus on that project for a certain amount of time (such as 1 hour or more) without distractions. Figure out when you\u2019re most productive. For me, it\u2019s in the morning before work. I wake up early, go through my routine, and then spend some time learning. Lastly, find tools to help you stay focused. I am a big fan of the Pomodoro Technique. I have an app called Stretchly that reminds me to take a 20-second break every 20 minutes and a 5-minute break every 40 minutes. This allows me to focus for that period and then rest. It then repeats itself like a cycle. Cross the Finishline \u00b6 The last and final leg of this learning journey is cross the finishline. You should make it there and feel accomplished. Here, you want to use systems that will help you practice, build confidence, remember vocabulary, and go for depth. Practice \u00b6 Learning means nothing without practice. With your new Language knowledge, you can build projects or contribute to open source. This is where the application phase of the learning cycle appears. It doesn\u2019t matter what you build, but that the act of building happens. When I was learning, I followed a tutorial to build a tiny compiler. It was written in JavaScript, but I did it in Language. This forced me to figure out things on my own. If you\u2019re learning something related to code, another idea is contributing to open source. Practice is where you learn the most. Build Confidence \u00b6 You want to build confidence in whatever you\u2019re learning. This will make you feel comfortable using your new knowledge. In the case of Language, you want to build Language Confidence. There are various ways to do this including: teaching others \u00b6 sharing (as we said before) \u00b6 reviewing what you\u2019ve learned \u00b6 helping others \u00b6 Many of these things translate over to other topics as well. \u00b6 The main thing is to feel confident in using your new skills or knowledge. Don\u2019t Skip Vocab \u00b6 Vocabulary is often overlooked. Don\u2019t skip out on it! It helps build confidence and it will solidify what you know. It\u2019s also a great tool to fight imposter syndrome. Knowing the vocabulary will allow you to build expertise. To learn and remember vocabulary, use a spaced-repetition system such as Anki. I used it with my Language learning project. You can use it to remember things such as: terminology \u00b6 concepts \u00b6 patterns \u00b6 syntax \u00b6 Take the thing you\u2019re learning, break it down into pieces and then build a list of vocabulary or concepts around those. Study these. This will benefit you in the long-run. Go for Depth \u00b6 The last thing in this phase is going for depth. Deep learning leads to deep understanding. There are two techniques you can use to deepen what you learn. The first is called the Feynman Technique. Take a concept you are learning, such as type inference in Language and explain it as you would to a seven-year-old. The idea is that if you can\u2019t do that, you don\u2019t know the concept well enough. Note: the age of the person to whom you\u2019re explaining your learning concept can vary. Focus on being able to explain something you understand to someone with little knowledge or context. The second technique I want to point out is called Ultralearning. In his book, Scott Young explains Ultralearning as, a strategy for aggressive, self-directed learning. Scott Young Think of it as taking something, being aggressive with how much or how fast you can learn it, and diving deep. You can use this with your learning projects. While you\u2019re learning, take notes of questions you have or concepts you don\u2019t quite understand. Then at the end of your project, see if those questions remain. If they do, start a new learning project and focus on answering those questions. As you can imagine, if you do this with a topic, you\u2019ll have several learning projects and soon start to develop expertise in this subject. It\u2019s very powerful. Summary \u00b6 The most important takeaway is this: use systems to help you learn better and faster. They will serve as your map, keep you on track and help you cross the finishline. If you were to do this with a programming language like Language, you would develop a proficiency, hopefully even expertise in the language. The next steps are to go out and use your new knowledge in the world! See what you can build. Find ways to help other people. And if you\u2019re ambitious, I challenge you to go deeper after you finish your first learning project. Use this framework and do another round of it. See how much you can learn! You\u2019ll never know the opportunities that may show up as a result. Tweak this learning framework to your liking and try it out on other projects - even non-technical ones. Adjust as needed. See how it works. Special thanks to my friends Sean, swyx, and Prince for reviewing and giving feedback.","title":"How to Learn Quickly"},{"location":"public/other/learn-quickly/#how-to-learn-quickly","text":"A few months back, I set out a goal to learn Language deeply in 3 months and I did it. Since then, others have asked how they can do the same. The outcome is a result of using something that I like to call the Fast Framework. This guide will teach you how you can use it to learn anything quickly. Imagine you\u2019re in racing a car. Your goal is to cross the finish line. Taking this analogy, we break the framework into three phases:","title":"How to Learn Quickly"},{"location":"public/other/learn-quickly/#make-your-map","text":"","title":"Make your Map"},{"location":"public/other/learn-quickly/#stay-on-track","text":"","title":"Stay on Track"},{"location":"public/other/learn-quickly/#cross-the-finishline","text":"In each phase, I\u2019ll cover different aspects that will help you learn fast and reach your goal. I\u2019ll use learning Language as the example. The first phase will cover the foundation for your learning project. Think of this as vision, timeframe, timeline, and organization. In the phase after, the focus will be staying on track and I\u2019ll discuss aspects related to accountability, momentum, sharing, and focus. In the final phase of the journey, the goal is to finish strong and cross the finishline. There, I\u2019ll talk about practice, confidence, vocabulary, and depth.","title":"Cross the Finishline"},{"location":"public/other/learn-quickly/#make-your-map_1","text":"The first step is to make your map. This will help answer questions like:","title":"Make your Map"},{"location":"public/other/learn-quickly/#what-does-it-mean-to-learn-insert-thing","text":"","title":"What does it mean to \u201clearn [insert thing]\u201c?"},{"location":"public/other/learn-quickly/#how-long-will-the-project-take","text":"","title":"How long will the project take?"},{"location":"public/other/learn-quickly/#what-are-the-expected-outcomes","text":"","title":"What are the expected outcomes?"},{"location":"public/other/learn-quickly/#how-am-i-going-to-organize-my-learning-project","text":"","title":"How am I going to organize my learning project?"},{"location":"public/other/learn-quickly/#write-a-clear-vision","text":"For the vision, define your project and use the Objective Key Results (OKRs) framework. If you aren\u2019t familiar, this was popularized by the book \u201dMeasure What Matters\u201d and is used at companies like Google and Intuit. First, define what you expect to achieve. In my Language learning project, I wrote: Learn Language deeply and become the [Company] \u201cin-house expert\u201d That will be your Objective. Next, figure out how you\u2019re going to measure it. We refer to these as the Key Results. Continuing with my previous project, I wrote:","title":"Write a Clear Vision"},{"location":"public/other/learn-quickly/#read-programming-language-by-boris-cherny","text":"","title":"Read \u201cProgramming Language\u201d by Boris Cherny"},{"location":"public/other/learn-quickly/#read-the-official-language-handbook","text":"","title":"Read the Official Language Handbook"},{"location":"public/other/learn-quickly/#produce-small-code-examples-for-all-concepts","text":"","title":"Produce small code examples for all concepts"},{"location":"public/other/learn-quickly/#contribute-to-language-the-language","text":"","title":"Contribute to Language, the language"},{"location":"public/other/learn-quickly/#contribute-to-language-cheatsheetsreact-language-cheatsheet","text":"","title":"Contribute to Language-cheatsheets/react-Language-cheatsheet"},{"location":"public/other/learn-quickly/#dont-rush-through-this-part","text":"Spend some time thinking about your objective and what you need to achieve to get there. Completing your key results should allow you to confidently say you\u2019ve completed your objective. With this vision in mind, you now have clarity on it means when you say \u201clearn [X]\u201d and you know what you expect to achieve.","title":"Don\u2019t rush through this part."},{"location":"public/other/learn-quickly/#establish-a-timeframe","text":"You don\u2019t want to be racing on this map forever. You need to be realistic and ask yourself how much time you have for this. Estimating time to complete tasks is hard. You can use what I like to call the Timeframe Formula: Take the length of months you want to work on this, multiple by 4 to give the amount in weeks. Then multiple it by the number of hours per week that you want to dedicate. For example, when I did a similar project, I gave myself 3 months with 8 hours per week. Using the Timeframe Formula, you get: 3 months x 4 weeks/month x 8 hours/week = 96 hours total. You now have your timeframe. Use this to set expectations on how much time you plan to dedicate each week.","title":"Establish a Timeframe"},{"location":"public/other/learn-quickly/#build-a-timeline","text":"The next thing you need to add to your map is a timeline. Think of this as a week by week calendar. The timeframe answers the question of how long and the timeline answers the what will I do each week. It helps you think less because you will already know what to do for that week. It won\u2019t be perfect. You may need to readjust, but you will have removed friction.","title":"Build a Timeline"},{"location":"public/other/learn-quickly/#an-example","text":"Week 1 (June 1) Programming Language Chapter 1 - Introduction Chapter 2 - Language: a 10_000 foot view Book exercises Chapter 3 - All About Types Book exercises Official Language Handbook Basic Types Variable Declarations You know yourself best. Think back to the Timeframe Formula. The example estimated 8hrs/week and 12 weeks in total. Knowing how fast you work (i.e. read, code, etc.), you would adjust accordingly. A complete timeline would have all the weeks filled out.","title":"An example"},{"location":"public/other/learn-quickly/#two-important-tips","text":"","title":"Two important tips:"},{"location":"public/other/learn-quickly/#leave-10-buffer-towards-the-end","text":"","title":"Leave ~10% buffer towards the end"},{"location":"public/other/learn-quickly/#give-yourself-some-breathing-room","text":"","title":"Give yourself some breathing room"},{"location":"public/other/learn-quickly/#life-comes-up-and-you-may-fall-behind-thats-where-the-buffer-comes-in-some-weeks-you-may-find-that-you-complete-everything-in-6-hours-no-need-to-fill-those-two-other-hours-if-you-dont-want-to-reward-yourself-with-rest","text":"With a timeline, you are good to go!","title":"Life comes up and you may fall behind. That\u2019s where the buffer comes in! Some weeks, you may find that you complete everything in 6 hours. No need to fill those two other hours if you don\u2019t want to. Reward yourself with rest."},{"location":"public/other/learn-quickly/#keep-it-organized","text":"You want to stay organized on this journey. That means a place to keep track of your timeline, log any notes or things you learn, and have visual indicators for the progress you\u2019re making. I use Notion for this because it supports project management well. I make a place for the project. I add the timeline and use checkboxes. Then, I check them off as I go and take notes as I\u2019m learning. Here is a non-exhaustive list of tools you might want to check out:","title":"Keep it Organized"},{"location":"public/other/learn-quickly/#notion","text":"","title":"Notion"},{"location":"public/other/learn-quickly/#trello","text":"","title":"Trello"},{"location":"public/other/learn-quickly/#asana","text":"","title":"Asana"},{"location":"public/other/learn-quickly/#github-projects","text":"","title":"GitHub Projects"},{"location":"public/other/learn-quickly/#basecamp","text":"You could also use an analog tool such as a pen and paper.","title":"Basecamp"},{"location":"public/other/learn-quickly/#stay-on-track_1","text":"Now that we have our map, we are ready for the next phase: stay on track. In this phase, the goal is to focus on developing the systems that will help you stay accountable, build momentum, share with others and, stay focused.","title":"Stay on Track"},{"location":"public/other/learn-quickly/#keep-yourself-accountable","text":"You always want to stay accountable for your project. Think of this as your race crew. They make sure you\u2019re fueled, your tires are rotated, you\u2019re hydrated, and you\u2019re ready to finish the race. We want a similar type of support and accountability. It could be: a group of friends a family member a friend online All you need is at least one person with whom you can share updates. They don\u2019t have to know Language or even know how to code. But they do need to be someone with whom you can check-in regularly. For Language, I recommend looking for 2-3 people who will join you in your Language journey. I would post: on Twitter, using the #100DaysOfCode or #CodeNewbie hashtags on Dev.to, using the #Language and #discuss tags to start a discussion and share your project on the Language Discord For your own project, come up with a similar list of options. Explore them all. See where you find the most success and stick with it. 2-3 people is ideal, but at least 1 other person works fine.","title":"Keep Yourself Accountable"},{"location":"public/other/learn-quickly/#build-momentum","text":"You want momentum. Momentum will keep you going on the track and heading towards the finish line. Think small wins, milestones and success spirals. Small wins are the little accomplishments that we oftentimes take for granted. Examples are things like learning a new word or understanding a concept. Celebrate these. Milestones are the next step up. These can either be date-based or achievement-based. Date-based would be hitting the 1-month mark in your 3-month timeframe for your learning project. Achievement-based would be finishing one of your key results. Either way, these are things to be celebrated and help you sustain the momentum. Success spiral is a term I first heard in Motivation Hack by Nick Winter. It\u2019s the idea that you set yourself up for success for starting small and moving outwards, like a spiral. In this case with Language, maybe you say, \u201cI\u2019m going to write one line of Language a day.\u201d Sounds trivial, right? Good, it should. You start there, establish the habit, then build upwards and outwards. Upwards meaning you continue doing it every day. Outwards meaning you increase the lines of code (without losing the habit).","title":"Build Momentum"},{"location":"public/other/learn-quickly/#share-with-others","text":"Yoda quote, \"Always pass on what you have learned.\" One of the most important parts of staying on track is sharing with others and Learning in Public. There are various mediums you can choose from for sharing: Tweets Blog Posts Podcasts Videos Tutorials Courses Any of these ways work - and there are probably more I didn\u2019t list. This will aid your project for a few reasons: Help you retain what you\u2019re learning Build expertise in the area Meet others who are learning When I was learning Language, I tweeted as I learned. Not only did I meet other Language community members, but people corrected me or taught me new things. Towards the end, people started tweeted me asking for Language help. I didn\u2019t always know the answer, but my sharing with others and learning in public helped me build reputation and credibility. I even ended up attracting the attention of an editor for a tech blog who paid me to write a few Language articles. As you can see, it pays to share with others.","title":"Share with Others"},{"location":"public/other/learn-quickly/#keep-your-focus","text":"The last piece I want to touch on for staying on track is keeping your focus. To stay on track, you have to keep yourself focused. The first and foremost is limit your focus. Ideally, learning Language is your main focus. I wouldn\u2019t suggest doing this and learning Rust or another language or something else. Keeping your attention on one project increases the likelihood you\u2019ll stay on track. The other thing you might want to try is deep work. An idea by Cal Newport, it\u2019s where you create an environment that lets you focus on that project for a certain amount of time (such as 1 hour or more) without distractions. Figure out when you\u2019re most productive. For me, it\u2019s in the morning before work. I wake up early, go through my routine, and then spend some time learning. Lastly, find tools to help you stay focused. I am a big fan of the Pomodoro Technique. I have an app called Stretchly that reminds me to take a 20-second break every 20 minutes and a 5-minute break every 40 minutes. This allows me to focus for that period and then rest. It then repeats itself like a cycle.","title":"Keep Your Focus"},{"location":"public/other/learn-quickly/#cross-the-finishline_1","text":"The last and final leg of this learning journey is cross the finishline. You should make it there and feel accomplished. Here, you want to use systems that will help you practice, build confidence, remember vocabulary, and go for depth.","title":"Cross the Finishline"},{"location":"public/other/learn-quickly/#practice","text":"Learning means nothing without practice. With your new Language knowledge, you can build projects or contribute to open source. This is where the application phase of the learning cycle appears. It doesn\u2019t matter what you build, but that the act of building happens. When I was learning, I followed a tutorial to build a tiny compiler. It was written in JavaScript, but I did it in Language. This forced me to figure out things on my own. If you\u2019re learning something related to code, another idea is contributing to open source. Practice is where you learn the most.","title":"Practice"},{"location":"public/other/learn-quickly/#build-confidence","text":"You want to build confidence in whatever you\u2019re learning. This will make you feel comfortable using your new knowledge. In the case of Language, you want to build Language Confidence. There are various ways to do this including:","title":"Build Confidence"},{"location":"public/other/learn-quickly/#teaching-others","text":"","title":"teaching others"},{"location":"public/other/learn-quickly/#sharing-as-we-said-before","text":"","title":"sharing (as we said before)"},{"location":"public/other/learn-quickly/#reviewing-what-youve-learned","text":"","title":"reviewing what you\u2019ve learned"},{"location":"public/other/learn-quickly/#helping-others","text":"","title":"helping others"},{"location":"public/other/learn-quickly/#many-of-these-things-translate-over-to-other-topics-as-well","text":"The main thing is to feel confident in using your new skills or knowledge.","title":"Many of these things translate over to other topics as well."},{"location":"public/other/learn-quickly/#dont-skip-vocab","text":"Vocabulary is often overlooked. Don\u2019t skip out on it! It helps build confidence and it will solidify what you know. It\u2019s also a great tool to fight imposter syndrome. Knowing the vocabulary will allow you to build expertise. To learn and remember vocabulary, use a spaced-repetition system such as Anki. I used it with my Language learning project. You can use it to remember things such as:","title":"Don\u2019t Skip Vocab"},{"location":"public/other/learn-quickly/#terminology","text":"","title":"terminology"},{"location":"public/other/learn-quickly/#concepts","text":"","title":"concepts"},{"location":"public/other/learn-quickly/#patterns","text":"","title":"patterns"},{"location":"public/other/learn-quickly/#syntax","text":"Take the thing you\u2019re learning, break it down into pieces and then build a list of vocabulary or concepts around those. Study these. This will benefit you in the long-run.","title":"syntax"},{"location":"public/other/learn-quickly/#go-for-depth","text":"The last thing in this phase is going for depth. Deep learning leads to deep understanding. There are two techniques you can use to deepen what you learn. The first is called the Feynman Technique. Take a concept you are learning, such as type inference in Language and explain it as you would to a seven-year-old. The idea is that if you can\u2019t do that, you don\u2019t know the concept well enough. Note: the age of the person to whom you\u2019re explaining your learning concept can vary. Focus on being able to explain something you understand to someone with little knowledge or context. The second technique I want to point out is called Ultralearning. In his book, Scott Young explains Ultralearning as, a strategy for aggressive, self-directed learning. Scott Young Think of it as taking something, being aggressive with how much or how fast you can learn it, and diving deep. You can use this with your learning projects. While you\u2019re learning, take notes of questions you have or concepts you don\u2019t quite understand. Then at the end of your project, see if those questions remain. If they do, start a new learning project and focus on answering those questions. As you can imagine, if you do this with a topic, you\u2019ll have several learning projects and soon start to develop expertise in this subject. It\u2019s very powerful.","title":"Go for Depth"},{"location":"public/other/learn-quickly/#summary","text":"The most important takeaway is this: use systems to help you learn better and faster. They will serve as your map, keep you on track and help you cross the finishline. If you were to do this with a programming language like Language, you would develop a proficiency, hopefully even expertise in the language. The next steps are to go out and use your new knowledge in the world! See what you can build. Find ways to help other people. And if you\u2019re ambitious, I challenge you to go deeper after you finish your first learning project. Use this framework and do another round of it. See how much you can learn! You\u2019ll never know the opportunities that may show up as a result. Tweak this learning framework to your liking and try it out on other projects - even non-technical ones. Adjust as needed. See how it works. Special thanks to my friends Sean, swyx, and Prince for reviewing and giving feedback.","title":"Summary"},{"location":"public/other/main/","text":"Video Guide-Website roadmap 2021-year-review uses learn-quickly outer-links","title":"Main"},{"location":"public/other/no-included-uses/","text":"One of my favorite things to share with others is setups! It\u2019s fun to see what others use and share my own setup. To make things easier, I\u2019ve broken it into two categories: gear and software. Gear This is a mix of personal and work gear. Some I bought myself (new or used) and other parts were paid for by my company. Desk Setup Here is everything related to how my desk is set up at home. Desk I use a standing desk, specifically the Autonomous SmartDesk2 - Home Office. Chair With a work stipend, I purchased an Autonomous ErgoChair 2. Laptop For work, I have a MacBook Pro 16-inch and at home, I use an iMac or a 13-inch MacBook. Laptop Stand At home, I\u2019m usually working with one monitor (laptop) so I use a laptop stand to not have to bend over. I invested in the Roost a while back. It\u2019s a bit overpriced, but lightweight and does the job. Now, I might look at one of the competitors if I were to buy one today. Keyboard I switch between an Apple Magic Keyboard (personal) and a Kinesis Freestyle Edge (work). The Edge is a split keyboard and I am a huge fan! Mouse I switch between an Apple Magic Trackpad (personal) and an MX Logitech Vertical Mouse (work). Microphone I use Shure BETA 87A (thanks to my friends at egghead). Microphone Boom Arm I started streaming for work so I invested in a boom arm and went with the Rode PSA1. Big fan! Webcam Part of what I do for work is record videos so they let me buy a new webcam: Logitech BRIO. I am very happy with it! Works well for streaming and video meetings. Streamdeck Again, I stared streaming for work so they let me buy an Elegato Stream Deck 15-key. Software Most of this is software I use to work efficiently and productively. I\u2019ve switched back and forth between a lot of tools, but this is what I\u2019m using currently. Editor and Terminal IDE I switched from Sublime to VS Code years ago and I can\u2019t see myself going back. I used to use the Sublime keybindings in VS Code. However, last year I switched to the Vim keybindings. It took some time to reach the same speed, but I would say I\u2019ve surpassed my previous speed and added a few new tricks thanks to Vim. Terminal I use iTerm2. A friend told me about it a while ago. I switched to it and haven\u2019t looked back. Theme I switch between themes. Right now, I\u2019m using Noctis and happy with it. zsh and prezto I use zsh and prezto on top of that. Starship I found this by luck while exploring Rust. If anything, it lets you easily customize emojis used within your terminal for different programs. Productivity Random desktop apps that I use for productivity or other reasons. Notion I am HUGE Notion fan! I pay for the personal plan to get unlimited blocks and use it both for personal and work. I use it for task/project management and structure it using the P.A.R.A. method. Trello Trello has a special place in my heart. I have a few boards to keep track of project ideas and other personal stuff. ScreenFlow Similar to the microphone from egghead, I use ScreenFlow to record and edit my videos (mostly screencasts). Gifox 2 For PRs and showing things to friends or coworkers, I use Gifox 2. I paid for the pro version and use it on both my personal and work machine. Stretchly Stretchly is a handy app for reminding me to take breaks. Clippy or Flycut A coworker once told me about his clipboard history app. I thought it was genius and since then have used both Flycut and Clippy. Alfred As of writing this, I haven\u2019t caved to buy the Alfred Powerpack (though I may\u2026), I mainly use it because it\u2019s faster than Spotlight on macOS and does some cool things like let you shutdown your mac by typing \u201cshutdown.\u201d Rocket I like emojis a lot. I bought Rocket and am a huge fan. Flux Although maOS now has a built-in dimming feature, I don\u2019t find it to be as great as Flux so I use Flux to dim my screen/remove bluelight as the sunsets. Keeping You Awake Keeping You Awake is a fantastic app for preventing your mac from going to sleep. Spectacle and Rectangle For window management, I use Spectacle (personal) or Rectangle (work).","title":"No included uses"},{"location":"public/other/outer-links/","text":"Links Last updated: 09/19/2021 These are all the important links you should know about. Featured Streaming on Twitch - I stream about webdev, indie hacking and web3. Vim for VSCode - hands-on course that teaches you how to use Vim inside VSCode Joe\u2019s Jobs - my job board which has the best jobs in product, engineering, OSS and more. New roles drop every Tuesday. dip.chat - accountability groups for developers Basics of TypeScript - this is a weekly Telegram newsletter, but will eventually be a TypeScript course monthly newsletter - related to programming and learning. I also share goodies and deals here. I\u2019m also actively seeking out companies that are interested in collaborating. If that\u2019s you, DM me on Twitter or shoot me an email joe at this domain. Other Things I\u2019ve done in the past that may be of interest to you: The Beginner\u2019s Guide to Figma - pro course on egghead Shareable Custom Hooks in React - pro course on egghead","title":"Outer links"},{"location":"public/other/roadmap/","text":"RoadMap \u00b6 I had a lot of fun making this a challenge for myself! I feel more motivated to continue contributing to Rust OSS What\u2019s next? Next up in my Ultralerning Plan is to: build and ship a small project in Rust I already built a small temperature converter suggested by the Rust Lang Book at the end of Chapter 3. However, for this particular goal, I assigned myself the task to \u201cBuild a small web server app (bunny1 clone).\u201d I already started on the project and have made solid progress. I still need to refactor a few pieces and ship it. After, I\u2019ll share a blog post about how I built it and a link so you can check it out.","title":"RoadMap"},{"location":"public/other/roadmap/#roadmap","text":"I had a lot of fun making this a challenge for myself! I feel more motivated to continue contributing to Rust OSS What\u2019s next? Next up in my Ultralerning Plan is to: build and ship a small project in Rust I already built a small temperature converter suggested by the Rust Lang Book at the end of Chapter 3. However, for this particular goal, I assigned myself the task to \u201cBuild a small web server app (bunny1 clone).\u201d I already started on the project and have made solid progress. I still need to refactor a few pieces and ship it. After, I\u2019ll share a blog post about how I built it and a link so you can check it out.","title":"RoadMap"},{"location":"public/programming/armanriazi-movies-reactjs/","tags":["github","couchdb","ibm","reactjs","nodejs","expressjs","api","restapi","cloud","sample","cicd","devops"],"text":"armanriazi-movies-reactjs \u00b6 online: armanriazi-movies-reactjs.herokuapp Improved speed and performance. I developed a sample-project base on [[Reactjs]], [[Nodejs]], [[Couchdb]], [[IBM]] ,and [[Cloud]], on [[Heroku]] [[CICD]]. I wanted to start work on reactjs that I think it has a main components include grid, list, search, connected to db. I have got satisfied with mix of couchdb and reactjs! Why not! both of them are good choice for frontend and database with o/i json. Github Repository [[Github-ArmanRiazi]]","title":"armanriazi-movies-reactjs"},{"location":"public/programming/armanriazi-movies-reactjs/#armanriazi-movies-reactjs","text":"online: armanriazi-movies-reactjs.herokuapp Improved speed and performance. I developed a sample-project base on [[Reactjs]], [[Nodejs]], [[Couchdb]], [[IBM]] ,and [[Cloud]], on [[Heroku]] [[CICD]]. I wanted to start work on reactjs that I think it has a main components include grid, list, search, connected to db. I have got satisfied with mix of couchdb and reactjs! Why not! both of them are good choice for frontend and database with o/i json. Github Repository [[Github-ArmanRiazi]]","title":"armanriazi-movies-reactjs"},{"location":"public/programming/armanriazi-vidly-api/","tags":["github","couchdb","ibm","reactjs","nodejs","expressjs","api","restapi","cloud","sample","cicd","devops"],"text":"armanriazi-vidly-api \u00b6 online: armanriazi-vidly-api.herokuapp Improved speed and performance. I developed a sample-project base on #expressjs, [[Restapi]], [[Api]], [[Nodejs]], [[Couchdb]], [[IBM]] ,and [[Cloud]], on [[Heroku]] [[CICD]]. I wanted to start work on reactjs that I think it has a main components include grid, list, search, connected to db. I have got satisfied with mix of couchdb and reactjs! Why not! both of them are good choice for frontend and database with o/i json. Example APIs Query Genre: https://armanriazi-vidly-api.herokuapp.com/api/genres/name/comedy Token Generate: https://armanriazi-vidly-api.herokuapp.com/api/auth/yourRefToken Github Repository [[Github-ArmanRiazi]]","title":"armanriazi-vidly-api"},{"location":"public/programming/armanriazi-vidly-api/#armanriazi-vidly-api","text":"online: armanriazi-vidly-api.herokuapp Improved speed and performance. I developed a sample-project base on #expressjs, [[Restapi]], [[Api]], [[Nodejs]], [[Couchdb]], [[IBM]] ,and [[Cloud]], on [[Heroku]] [[CICD]]. I wanted to start work on reactjs that I think it has a main components include grid, list, search, connected to db. I have got satisfied with mix of couchdb and reactjs! Why not! both of them are good choice for frontend and database with o/i json. Example APIs Query Genre: https://armanriazi-vidly-api.herokuapp.com/api/genres/name/comedy Token Generate: https://armanriazi-vidly-api.herokuapp.com/api/auth/yourRefToken Github Repository [[Github-ArmanRiazi]]","title":"armanriazi-vidly-api"},{"location":"public/programming/commands/","text":"If you want to get Commands(Ubuntu, Devops, Blockchain CLIs) in a compact, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ Commands)","title":"Commands"},{"location":"public/programming/programming/","tags":["rust","programming","codebase","github"],"text":"Rust Rust Rust","title":"Programming"},{"location":"public/programming/rust/rust-lang-ecosystem/","text":"Understanding the Rust Ecosystem \u00b6 Last updated: 06/15/2020(Copied) Rust, a systems-programming language, which prides itself on being Stack Overflow\u2019s \u201c most loved language for five years in row \u201d and GitHub\u2019s second fastest growing (235% 2018-2019) has gained popularity both at companies like Amazon, FB, Discord and externally within the programming community. For part of my job, I have been focused on developing my own understanding of the space. I work within the DevTools pillar and focus primarily on programming languages. My main priority for H1 of 2020 has been Rust. The goal of this article is: To paint a high-level overview of the ecosystem The article covers various aspects of the ecosystem including community, companies using the language, selling points, etc. Overview \u00b6 One of the hardest parts of understanding a programming language is setting the boundaries for what you encapsulate as part of and not part of the ecosystem. I gathered input coworkers and mentors in order to set the criteria for this project. For our purposes, I choose to limit it to the following areas, which you\u2019ll see below. For each section, you can expect: A brief description of how I defined the section Key highlights from the ecosystem for that area of the ecosystem Academic Research \u00b6 Things that fall under this category might be research papers, academic presentations, and anything related. It was difficult to find much in this area, but here are a few highlights: Memory-Safety Challenge Considered Solved? An Empirical Study with All Rust CVEs What can the programming language Rust do for astrophysics? RustBelt: Securing the Foundations of the RustProgramming Language Rust-Like Borrowing with 2 nd -Class Values (Short Paper) Safe Systems Programming in Rust:The Promise and the Challenge Fearless Concurrency? Understanding Concurrent Programming Safety in Real-World Rust Software As you can tell from skimming the headings, researchers are looking at Rust\u2019s use cases, security, memory management, type-safety and concurrency. It\u2019s unfortunate there isn\u2019t an easy way to stay on top of academic research within Rust. Demographics \u00b6 When you look at the programming language, how do you know who is using it? What industries do they work in? Fortunately, the Rust Survey 2019 Results provides insight related to demographics. Based on the results, here are the key highlights: Respondents\u2019 top five languages: English, Chinese, German, French and Japanese Top five industries using Rust: Backend Web Applications, Distributed Systems, Embedded Devices, IT and Network Programming Top three titles for Rust users: Programmer/Software Engineer, Systems Architect, Web Developer/Front End Developer It\u2019s unfortunate that we do not have more information related to demographics such as gender, ethnicity, race, etc. There was an attempt to gather some of this information in the 2016 survey . Know that this section contains a small glimpse into the people of the Rust and is far from complete or representative of the ecosystem. Community \u00b6 Community itself is a huge category. I tried my best to break it into subcategories for things that might fit here. In general, think of this area as the various places where members of the community congregate (online and in-person), groups who write code, and foundations. These are a combination of chat platforms, but also places where updates are shared with the community. Here are some worth noting: Chat Platforms Discord (35,597 members total) The Rust Programming Language (25,135 members) Rust Programming Language Community Server (10,462 members) Rust lang Slack (3,046 people) Rust Team Zulip (655 people) (mainly focused on people who work on Rust itself) Conferences FOSDEM RustConf Rusty Days RustFest Netherlands Rust + GNOME Hackfest Rust Latam RustLab Oxidize List of 2020 events on the Rust lang blog Core contributors Governance - all the different core team members associated with each team GitHub Rustlang org members GitHub committers - over 2k people have contributed to /rust repo Rust team alumni - people who worked on a Rust team previously Forums Users forum (14.2k) Internals forum (6.8k) r/rust -Reddit (100k people) Meetups Stats (meetups with the topic \u201crust\u201d ) 73,706 members 1,749 interested 204 Meetups 145 cities 42 countries Groups (not all listed, some highlights) Desert Rust (Phoenix, AZ) Minneapolis Rust Meetup Rusty Bay Area Meetup Rust Bangalore Rust Berlin Rust in Blockchain Rust Los Angeles Rust London User Group Rust Dev in Mountain View Meetup Rust Denver Rust NYC Rust Nairobi Rust Paris San Diego Rust Seattle Rust Meetup Utah Rust Miscellaneous RFCs (2.9k stars) - where technical decisions are made in regards to Rust This Week in Rust - weekly newsletter Programs Rust\u2019s Reach (currently on hold due to lack of funding and people) - \u201cmentorship like program between participants from URGs and Rust team members\u201d Rust Bridge (1 chapter) - \u201ca workshop focused on getting underrepresented people with a background in another programming language to learn Rust and join the community.\u201d *These stats were taken on 5/19/2020 As you can see, the community category extends itself across many platforms and mediums online. It\u2019s easy to overwhelm oneself with all the places you can go to get involved. The beautiful part is that there is no shortage of finding ways to meet others within the community. *For the data in the \u201cMeetups > Stats\u201d category, you\u2019ll notice that it includes some meetups that are not specifically for Rust so take that number with a grain of salt. Companies \u00b6 It would be impossible to list all the companies that use Rust. This is a sub-selection of notable companies (more well-known) that are using or investing in Rust, ideally along with articles where they share how they\u2019re using it or helping the ecosystem: Amazon AWS is sponsoring the Rust programming language - AWS Open Source Blog (October 2019) \u201c\u2026 AWS staff open-sourced a virtualization technology named Firecracker that was coded primarily in Rust \u201d - zdnet.com article (October 2019) \u201c_As Rust starts to take up a larger chunk of Amazon\u2019s backend code, the company is making sure the project has the means to continue to evolve and fix security issues.\u201d _-_ _ zdnet.com article (October 2019) AWS sponsors RustConf - AWS Open Source Blog (2018 - 2020) Apple Rust for server-side Linux on Apple Cloud Traffic (March 2020) Atlassian (makers of Jira) Use Rust in the backend for analyzing terabytes of source code Cloudflare Cloudflare uses Rust in production for WebAssembly edge computing as well as a lot of foundational infrastructure (2018-2019) Discord \u201cWhy Discord is switching from Go to Rust\u201d - (February 2020) 11.9K claps \u201cUsing Rust to Scale Elixir for 11 Million Concurrent Users\u201d - (May 2019) 6.4K claps Dropbox Dropbox is highlighted on the /production page of the rust-lang.org website - (currently - March 2020) Go-ing to Rust: Optimizing Storage at Dropbox - (November 2017) Dropbox is mentioned on official Rust lang blog - (May 2017) \u201cThe Epic Story of Dropbox\u2019s Exodus From the Amazon Cloud Empire\u201d - (March 2016) Facebook Developers have named Rust their most-loved programming language five years in a row. Here\u2019s why developers at Facebook, Dropbox, and Amazon all adore it - (June 2020) The Relay Team is experimenting with a \u201crewrite of the Relay compiler in Rust\u201d (May 2020) Mononoke, the new Mercurial backend, was written from scratch in Rust GitHub GitHub donating VMs for GitHub Actions (April 2020) Google Rust makes up increasingly large parts of Google\u2019s Fuchsia operating system Chrome OS\u2019s virtualization infrastructure and several other components are in Rust Android uses Rust Chromium is beginning to adopt Rust Google released an \u201cunofficial\u201d project called [tarpc](https://github.com/google/tarpc) \u201cAn RPC framework for Rust\u201d Microsoft Microsoft featured on /sponsors page \u201cMicrosoft opens up Rust-inspired Project Verona programming language on GitHub\u201d - (Jan 2020) \u201cMicrosoft looks to Rust language to beat memory vulnerabilities\u201d - (Dec 2019) \u201cMicrosoft Exploring Rust as the Solution for Safe Software\u201d - (Nov 2019) Azure Pipelines sponsoring Rust - (Oct 2019) Microsoft looking into Rust for security reasons . - (July 2019) \u201cMicrosoft eyes Mozilla\u2019s Rust to obliterate C++ memory security flaws\u201d - (July 2019) Azure IoT Edge has been using Rust since at least 2018 Mozilla Rust is used in Firefox through a project called Oxidation Mozilla is writing a browser written in Rust called Servo \u201cRust 2018 is here\u2026 but what is it?\u201d - (Dec 2018) \u201cMozilla binds Firefox\u2019s fate to the Rust language\u201d - (Feb 2017) \u201cProject for porting C to Rust gains Mozilla\u2019s backing\u201d - (Oct 2016) npm Performance critical registry service architecture is Rust Reddit Uses Rust for comment processing Twitter Build team has been using Rust in production for ~3 years and intend for it to make up a large portion of their codebase going forward Yelp Yelp is featured under the \u201cRust in production\u201d section of rust-lang.org , they talk about how they use it in this talk - (Aug 2018) Honorable Mentions There is a list of production users on the rust-lang.org website \u201cA Snapshot of Rust\u2019s Popularity in July 2018\u201d Nike using Rust Language \u00b6 Think core library, compiler, type system. Basically all the code that makes up the language and some of the tools that help with writing code in Rust. Books & References Asynchronous Programming In Rust Book Command Line Applications in Rust The Rust Programming Language Book The Cargo Book - info about the rust package manager The Rustonomicon Book - the dark arts of unsafe Rust The Rust Reference Book Rust Compiler Error Index - book on all the rust compiler errors rustdoc Book - all about rustdoc and writing documentation in Rust std - standard library docs Code & DevTools Cargo the package manager + build system Core language Rust-clippy - official linter Rustfmt - official formatter rustc - the Rust compiler (inside the core language) Language Frameworks \u00b6 What would a programming language be without frameworks? Thankfully, the community resource rust-web-framework-comparison made this research easy. Here is a long list: Client frameworks actix-web ( homepage / repository / api docs ) reqwest (- / repository / documentation ) hyper ( homepage / repository / documentation ) jsonrpc (- / repository / documentation ) Frontend frameworks (WASM) stdweb ( - / repository / documentation ) A standard library for the client-side Web yew ( homepage / repository / documentation ) - A frontend framework inspired by Elm and React (based on stdweb) percy ( homepage / repository / - ) - A modular toolkit for building isomorphic web apps seed ( homepage / repository / - ) - A Rust framework for creating web apps draco ( - / repository / documentation ) - A frontend framework inspired by Redux and Elm smithy ( homepage - / repository / - documentation ) - A front-end framework squark ( - / repository / documentation ) - Rust frontend framework, for web browser and more. willow ( homepage - / repository / - ) - A frontend framework inspired by Elm dodrio ( - / repository / documentation ) - A fast, bump-allocated virtual DOM library. dominator ( - / repository / documentation - Zero cost declarative DOM library using FRP signals for Rust!. mika ( homepage / repository / - ) - A signal-based framework for building front-end app, it tries to help, but may cause annoyances. Server frameworks actix-web ( homepage / repository / documentation / user guide ) gotham ( homepage / repository / documentation / examples ) iron ( homepage / repository / documentation ) nickel ( homepage / repository / documentation ) rocket ( homepage / repository / documentation ) rouille ( - / repository / documentation ) Thruster ( - / repository / documentation / examples ) Tide ( - / repository / documentation / examples ) tower-web ( - / repository / documentation / examples ) warp ( - / repository / documentation / examples ) Static site generators zola ( homepage / repository / documentation ) Templating frameworks tera ( homepage / repository / documentation ) mustache (- / repository / documentation ) liquid (- / repository / - ) handlebars (- / repository / documentation ) horrorshow (- / repository / documentation ) maud ( homepage / repository / documentation ) askama (- / repository / documentation ) stpl (- / repository / - ) ructe (- / repository / documentation ) typed-html (- / repository / documentation ) Websocket frameworks websocket ( homepage / repository / documentation ) ws-rs ( homepage / repository / documentation ) tungstenite ( - / repository / documentation ) actix-web ( homepage / repository / documentation ) Again, this is a bit overwhelming for a new person learning Rust. It\u2019s difficult to know what to choose. However, it\u2019s also a benefit having the ability to try out various solutions and see what works best. Learning \u00b6 Similar to the Community category, learning can be quite difficult to narrow down. I have tried my best to highlight the main areas and a few examples for each category. Know that this list is non-exhaustive and more a brief survey into this area of the ecosystem. Articles A collection of notable Rust bloggers Each week, This Week in Rust shares articles Fearless Rust Bloggers Learning Rust - Pascal Precht Read Rust - Rust blog post aggregator Writing an OS in Rust Books Programming Rust - O\u2019Reilly Media Rust in Action - Manning Bootcamps No response on Rust users forum No response on Twitter NobleProg Rust microcourse Classes (specifically academic, in universities) Northwestern University Rust being taught at University of Maryland, College Park Stanford\u2019s Programming Languages course dedicates 3.5 weeks to Rust Stanford\u2019s Operating Systems course in Rust University of Pennsylvania University of Virginia (first class) Tutorials Rustlings - Small exercises to get you used to reading and writing Rust code rust-learning - detailed list of awesome learning materials Tour of Rust - Step by step guide through the features of the Rust programming language Courses Intro to Rust - YouTube Rust Crash Course - YouTube Rust Projects - YouTube The Rust Programming Language - Udemy Using Web Assembly with Rust - egghead Write your First Program with Rust - egghead Videos Learning Rust - two people pair-programming and going chapter by chapter through the Rust Lang Book Into_rust - screencast series Workshops Ferrous Systems - paid workshops for companies and teams RustBridge - an organization that is part of the official Rust group. Systems Programming with Rust (at a conference) Packages \u00b6 One of the most important aspects of a programming language ecosystem is a way to share code with others. In the Rust ecosystem, the most common way is through packages, more commonly referred to as \u201ccrates\u201d. Below are links to two places where you can share code (your own private registry or the public one): Cloudsmith - create your own private cargo registry crates.io - \u201cThe Rust community\u2019s crate registry\u201d libs.rs - \u201cFast, lightweight, opinionated, unofficial alternative to crates.io\u201d Platforms \u00b6 The objective for this section was to figure out where Rust code can run. What platforms or systems are people targeting or building for? We saw a few of these mentioned in the Frameworks section. Here are the most common ones I could find (and some examples): Browser WebAssembly Wasm-bindgem Rust to WASM + Next CLI Apps clap Build binaries for Linux, macOS and Windows Embedded Devices https://www.rust-lang.org/what/embedded Operating System Writing an OS in Rust Mobile Apps Building an iOS App in Rust, Part 1: Getting Started with Rust Example project for building a library for iOS + Android in Rust Server Deploying to Heroku Anywhere? Rust Once, Run Everywhere Selling Points \u00b6 Everyone will have their favorite reasons for using one language over another. I tried to select articles related to the selling points, but also highlight features of the language brought up by people who advocate for it. Articles How often does Rust change? Rust programming language: Seven reasons why you should learn it in 2019 What is Rust and why is it so popular? Why Rust? Why should I use Rust? Features Borrow checker (\u201c Rust has a static garbage collector \u201d) Community Ownership model Package manager Performance Productivity Excellent documentation Built-in tools (cargo, fmt, clippy) Smart memory-management Type system Other Used by big companies (talk about Facebook, Microsoft, Amazon, etc.) *Note: this section also piggybacks off the Use Cases section (coming up). Beyond this, I would encourage you to read the results from the Rust 2019 survey which asked \u201cWhy not use Rust\u201d . Not all points relate to selling points, but it may provide insight into what would sell people on using Rust if these things were fixed. Tools \u00b6 The tools used for writing and using the programming language is an aspect we sometimes forget. This affects the developer experience and can drive or hinder the ecosystem. Here are some highlights: Benchmarking criterion - Statistics-driven Microbenchmarking Built-in testing support Cargo Build (macOS, Windows, Linux) Clippy Rustdoc rustfmt IDE support https://www.rust-lang.org/tools Hover over documentation in editor Rust Playground - test code online, share with others Use Cases \u00b6 Deriving some of the tops results from the Rust Survey 2019 , here are the main industries/applications that responded in the survey and are using Rust: Top 10 from survey Backend Web Applications Distributed Systems Embedded Devices Enterprise Software Frontend Web Applications Internet of Things IT Network Programming Security Technology Other Blockchain ( Libra Move ) Solana Deno - uses JavaScript engine written in Rust 1.0 Announcement Summary \u00b6 Reflecting on what we have covered thus far, we can see that the Rust ecosystem is well-developed and growing. This is not a conclusive/comprehensive list of the ecosystem or the companies using it. From my knowledge, Rust is used at big companies such as Amazon, Apple, Microsoft and Google. They are all investing in the language. We\u2019ve covered the ecosystem from a bird\u2019s-eye view as we see it today. Here are the main things to walk away with: Overview The community is ubiquitous both online and in-person There is no shortage of books or references to read from the official Rust groups Rust can be used for writing web, mobile, and CLI apps, servers embedded devices, and OS\u2019s Rust is fast, well-documented, type-safe, manages memory efficiently, but has a steep learning curve What\u2019s next? \u00b6 We plan to use this information when making decisions and building strategies for us to get involved with the Rust ecosystem. If you\u2019d like to collaborate with us, please reach out to me over DMs on Twitter ! We would love to work with you. Thank you for reading! Thank you \u00b6 To close out, I\u2019d like to give thanks to the following people for their contributions and feedback. I appreciate all of you! David Tolnay Pedro Rittner Jk Jensen Joe Savona Nell Shamrell-Harrington Lauren Tan Kathy Kam Cami Williams Joel Marcey Join the Newsletter \u00b6 I send a monthly newsletter with 1 exciting thing, 1 helpful thing, and new jobs. Email* By subscribing, you agree with Revue\u2019s Terms of Service \u00a92022 Joe Previte","title":"Rust lang ecosystem"},{"location":"public/programming/rust/rust-lang-ecosystem/#understanding-the-rust-ecosystem","text":"Last updated: 06/15/2020(Copied) Rust, a systems-programming language, which prides itself on being Stack Overflow\u2019s \u201c most loved language for five years in row \u201d and GitHub\u2019s second fastest growing (235% 2018-2019) has gained popularity both at companies like Amazon, FB, Discord and externally within the programming community. For part of my job, I have been focused on developing my own understanding of the space. I work within the DevTools pillar and focus primarily on programming languages. My main priority for H1 of 2020 has been Rust. The goal of this article is: To paint a high-level overview of the ecosystem The article covers various aspects of the ecosystem including community, companies using the language, selling points, etc.","title":"Understanding the Rust Ecosystem"},{"location":"public/programming/rust/rust-lang-ecosystem/#overview","text":"One of the hardest parts of understanding a programming language is setting the boundaries for what you encapsulate as part of and not part of the ecosystem. I gathered input coworkers and mentors in order to set the criteria for this project. For our purposes, I choose to limit it to the following areas, which you\u2019ll see below. For each section, you can expect: A brief description of how I defined the section Key highlights from the ecosystem for that area of the ecosystem","title":"Overview"},{"location":"public/programming/rust/rust-lang-ecosystem/#academic-research","text":"Things that fall under this category might be research papers, academic presentations, and anything related. It was difficult to find much in this area, but here are a few highlights: Memory-Safety Challenge Considered Solved? An Empirical Study with All Rust CVEs What can the programming language Rust do for astrophysics? RustBelt: Securing the Foundations of the RustProgramming Language Rust-Like Borrowing with 2 nd -Class Values (Short Paper) Safe Systems Programming in Rust:The Promise and the Challenge Fearless Concurrency? Understanding Concurrent Programming Safety in Real-World Rust Software As you can tell from skimming the headings, researchers are looking at Rust\u2019s use cases, security, memory management, type-safety and concurrency. It\u2019s unfortunate there isn\u2019t an easy way to stay on top of academic research within Rust.","title":"Academic Research"},{"location":"public/programming/rust/rust-lang-ecosystem/#demographics","text":"When you look at the programming language, how do you know who is using it? What industries do they work in? Fortunately, the Rust Survey 2019 Results provides insight related to demographics. Based on the results, here are the key highlights: Respondents\u2019 top five languages: English, Chinese, German, French and Japanese Top five industries using Rust: Backend Web Applications, Distributed Systems, Embedded Devices, IT and Network Programming Top three titles for Rust users: Programmer/Software Engineer, Systems Architect, Web Developer/Front End Developer It\u2019s unfortunate that we do not have more information related to demographics such as gender, ethnicity, race, etc. There was an attempt to gather some of this information in the 2016 survey . Know that this section contains a small glimpse into the people of the Rust and is far from complete or representative of the ecosystem.","title":"Demographics"},{"location":"public/programming/rust/rust-lang-ecosystem/#community","text":"Community itself is a huge category. I tried my best to break it into subcategories for things that might fit here. In general, think of this area as the various places where members of the community congregate (online and in-person), groups who write code, and foundations. These are a combination of chat platforms, but also places where updates are shared with the community. Here are some worth noting: Chat Platforms Discord (35,597 members total) The Rust Programming Language (25,135 members) Rust Programming Language Community Server (10,462 members) Rust lang Slack (3,046 people) Rust Team Zulip (655 people) (mainly focused on people who work on Rust itself) Conferences FOSDEM RustConf Rusty Days RustFest Netherlands Rust + GNOME Hackfest Rust Latam RustLab Oxidize List of 2020 events on the Rust lang blog Core contributors Governance - all the different core team members associated with each team GitHub Rustlang org members GitHub committers - over 2k people have contributed to /rust repo Rust team alumni - people who worked on a Rust team previously Forums Users forum (14.2k) Internals forum (6.8k) r/rust -Reddit (100k people) Meetups Stats (meetups with the topic \u201crust\u201d ) 73,706 members 1,749 interested 204 Meetups 145 cities 42 countries Groups (not all listed, some highlights) Desert Rust (Phoenix, AZ) Minneapolis Rust Meetup Rusty Bay Area Meetup Rust Bangalore Rust Berlin Rust in Blockchain Rust Los Angeles Rust London User Group Rust Dev in Mountain View Meetup Rust Denver Rust NYC Rust Nairobi Rust Paris San Diego Rust Seattle Rust Meetup Utah Rust Miscellaneous RFCs (2.9k stars) - where technical decisions are made in regards to Rust This Week in Rust - weekly newsletter Programs Rust\u2019s Reach (currently on hold due to lack of funding and people) - \u201cmentorship like program between participants from URGs and Rust team members\u201d Rust Bridge (1 chapter) - \u201ca workshop focused on getting underrepresented people with a background in another programming language to learn Rust and join the community.\u201d *These stats were taken on 5/19/2020 As you can see, the community category extends itself across many platforms and mediums online. It\u2019s easy to overwhelm oneself with all the places you can go to get involved. The beautiful part is that there is no shortage of finding ways to meet others within the community. *For the data in the \u201cMeetups > Stats\u201d category, you\u2019ll notice that it includes some meetups that are not specifically for Rust so take that number with a grain of salt.","title":"Community"},{"location":"public/programming/rust/rust-lang-ecosystem/#companies","text":"It would be impossible to list all the companies that use Rust. This is a sub-selection of notable companies (more well-known) that are using or investing in Rust, ideally along with articles where they share how they\u2019re using it or helping the ecosystem: Amazon AWS is sponsoring the Rust programming language - AWS Open Source Blog (October 2019) \u201c\u2026 AWS staff open-sourced a virtualization technology named Firecracker that was coded primarily in Rust \u201d - zdnet.com article (October 2019) \u201c_As Rust starts to take up a larger chunk of Amazon\u2019s backend code, the company is making sure the project has the means to continue to evolve and fix security issues.\u201d _-_ _ zdnet.com article (October 2019) AWS sponsors RustConf - AWS Open Source Blog (2018 - 2020) Apple Rust for server-side Linux on Apple Cloud Traffic (March 2020) Atlassian (makers of Jira) Use Rust in the backend for analyzing terabytes of source code Cloudflare Cloudflare uses Rust in production for WebAssembly edge computing as well as a lot of foundational infrastructure (2018-2019) Discord \u201cWhy Discord is switching from Go to Rust\u201d - (February 2020) 11.9K claps \u201cUsing Rust to Scale Elixir for 11 Million Concurrent Users\u201d - (May 2019) 6.4K claps Dropbox Dropbox is highlighted on the /production page of the rust-lang.org website - (currently - March 2020) Go-ing to Rust: Optimizing Storage at Dropbox - (November 2017) Dropbox is mentioned on official Rust lang blog - (May 2017) \u201cThe Epic Story of Dropbox\u2019s Exodus From the Amazon Cloud Empire\u201d - (March 2016) Facebook Developers have named Rust their most-loved programming language five years in a row. Here\u2019s why developers at Facebook, Dropbox, and Amazon all adore it - (June 2020) The Relay Team is experimenting with a \u201crewrite of the Relay compiler in Rust\u201d (May 2020) Mononoke, the new Mercurial backend, was written from scratch in Rust GitHub GitHub donating VMs for GitHub Actions (April 2020) Google Rust makes up increasingly large parts of Google\u2019s Fuchsia operating system Chrome OS\u2019s virtualization infrastructure and several other components are in Rust Android uses Rust Chromium is beginning to adopt Rust Google released an \u201cunofficial\u201d project called [tarpc](https://github.com/google/tarpc) \u201cAn RPC framework for Rust\u201d Microsoft Microsoft featured on /sponsors page \u201cMicrosoft opens up Rust-inspired Project Verona programming language on GitHub\u201d - (Jan 2020) \u201cMicrosoft looks to Rust language to beat memory vulnerabilities\u201d - (Dec 2019) \u201cMicrosoft Exploring Rust as the Solution for Safe Software\u201d - (Nov 2019) Azure Pipelines sponsoring Rust - (Oct 2019) Microsoft looking into Rust for security reasons . - (July 2019) \u201cMicrosoft eyes Mozilla\u2019s Rust to obliterate C++ memory security flaws\u201d - (July 2019) Azure IoT Edge has been using Rust since at least 2018 Mozilla Rust is used in Firefox through a project called Oxidation Mozilla is writing a browser written in Rust called Servo \u201cRust 2018 is here\u2026 but what is it?\u201d - (Dec 2018) \u201cMozilla binds Firefox\u2019s fate to the Rust language\u201d - (Feb 2017) \u201cProject for porting C to Rust gains Mozilla\u2019s backing\u201d - (Oct 2016) npm Performance critical registry service architecture is Rust Reddit Uses Rust for comment processing Twitter Build team has been using Rust in production for ~3 years and intend for it to make up a large portion of their codebase going forward Yelp Yelp is featured under the \u201cRust in production\u201d section of rust-lang.org , they talk about how they use it in this talk - (Aug 2018) Honorable Mentions There is a list of production users on the rust-lang.org website \u201cA Snapshot of Rust\u2019s Popularity in July 2018\u201d Nike using Rust","title":"Companies"},{"location":"public/programming/rust/rust-lang-ecosystem/#language","text":"Think core library, compiler, type system. Basically all the code that makes up the language and some of the tools that help with writing code in Rust. Books & References Asynchronous Programming In Rust Book Command Line Applications in Rust The Rust Programming Language Book The Cargo Book - info about the rust package manager The Rustonomicon Book - the dark arts of unsafe Rust The Rust Reference Book Rust Compiler Error Index - book on all the rust compiler errors rustdoc Book - all about rustdoc and writing documentation in Rust std - standard library docs Code & DevTools Cargo the package manager + build system Core language Rust-clippy - official linter Rustfmt - official formatter rustc - the Rust compiler (inside the core language)","title":"Language"},{"location":"public/programming/rust/rust-lang-ecosystem/#language-frameworks","text":"What would a programming language be without frameworks? Thankfully, the community resource rust-web-framework-comparison made this research easy. Here is a long list: Client frameworks actix-web ( homepage / repository / api docs ) reqwest (- / repository / documentation ) hyper ( homepage / repository / documentation ) jsonrpc (- / repository / documentation ) Frontend frameworks (WASM) stdweb ( - / repository / documentation ) A standard library for the client-side Web yew ( homepage / repository / documentation ) - A frontend framework inspired by Elm and React (based on stdweb) percy ( homepage / repository / - ) - A modular toolkit for building isomorphic web apps seed ( homepage / repository / - ) - A Rust framework for creating web apps draco ( - / repository / documentation ) - A frontend framework inspired by Redux and Elm smithy ( homepage - / repository / - documentation ) - A front-end framework squark ( - / repository / documentation ) - Rust frontend framework, for web browser and more. willow ( homepage - / repository / - ) - A frontend framework inspired by Elm dodrio ( - / repository / documentation ) - A fast, bump-allocated virtual DOM library. dominator ( - / repository / documentation - Zero cost declarative DOM library using FRP signals for Rust!. mika ( homepage / repository / - ) - A signal-based framework for building front-end app, it tries to help, but may cause annoyances. Server frameworks actix-web ( homepage / repository / documentation / user guide ) gotham ( homepage / repository / documentation / examples ) iron ( homepage / repository / documentation ) nickel ( homepage / repository / documentation ) rocket ( homepage / repository / documentation ) rouille ( - / repository / documentation ) Thruster ( - / repository / documentation / examples ) Tide ( - / repository / documentation / examples ) tower-web ( - / repository / documentation / examples ) warp ( - / repository / documentation / examples ) Static site generators zola ( homepage / repository / documentation ) Templating frameworks tera ( homepage / repository / documentation ) mustache (- / repository / documentation ) liquid (- / repository / - ) handlebars (- / repository / documentation ) horrorshow (- / repository / documentation ) maud ( homepage / repository / documentation ) askama (- / repository / documentation ) stpl (- / repository / - ) ructe (- / repository / documentation ) typed-html (- / repository / documentation ) Websocket frameworks websocket ( homepage / repository / documentation ) ws-rs ( homepage / repository / documentation ) tungstenite ( - / repository / documentation ) actix-web ( homepage / repository / documentation ) Again, this is a bit overwhelming for a new person learning Rust. It\u2019s difficult to know what to choose. However, it\u2019s also a benefit having the ability to try out various solutions and see what works best.","title":"Language Frameworks"},{"location":"public/programming/rust/rust-lang-ecosystem/#learning","text":"Similar to the Community category, learning can be quite difficult to narrow down. I have tried my best to highlight the main areas and a few examples for each category. Know that this list is non-exhaustive and more a brief survey into this area of the ecosystem. Articles A collection of notable Rust bloggers Each week, This Week in Rust shares articles Fearless Rust Bloggers Learning Rust - Pascal Precht Read Rust - Rust blog post aggregator Writing an OS in Rust Books Programming Rust - O\u2019Reilly Media Rust in Action - Manning Bootcamps No response on Rust users forum No response on Twitter NobleProg Rust microcourse Classes (specifically academic, in universities) Northwestern University Rust being taught at University of Maryland, College Park Stanford\u2019s Programming Languages course dedicates 3.5 weeks to Rust Stanford\u2019s Operating Systems course in Rust University of Pennsylvania University of Virginia (first class) Tutorials Rustlings - Small exercises to get you used to reading and writing Rust code rust-learning - detailed list of awesome learning materials Tour of Rust - Step by step guide through the features of the Rust programming language Courses Intro to Rust - YouTube Rust Crash Course - YouTube Rust Projects - YouTube The Rust Programming Language - Udemy Using Web Assembly with Rust - egghead Write your First Program with Rust - egghead Videos Learning Rust - two people pair-programming and going chapter by chapter through the Rust Lang Book Into_rust - screencast series Workshops Ferrous Systems - paid workshops for companies and teams RustBridge - an organization that is part of the official Rust group. Systems Programming with Rust (at a conference)","title":"Learning"},{"location":"public/programming/rust/rust-lang-ecosystem/#packages","text":"One of the most important aspects of a programming language ecosystem is a way to share code with others. In the Rust ecosystem, the most common way is through packages, more commonly referred to as \u201ccrates\u201d. Below are links to two places where you can share code (your own private registry or the public one): Cloudsmith - create your own private cargo registry crates.io - \u201cThe Rust community\u2019s crate registry\u201d libs.rs - \u201cFast, lightweight, opinionated, unofficial alternative to crates.io\u201d","title":"Packages"},{"location":"public/programming/rust/rust-lang-ecosystem/#platforms","text":"The objective for this section was to figure out where Rust code can run. What platforms or systems are people targeting or building for? We saw a few of these mentioned in the Frameworks section. Here are the most common ones I could find (and some examples): Browser WebAssembly Wasm-bindgem Rust to WASM + Next CLI Apps clap Build binaries for Linux, macOS and Windows Embedded Devices https://www.rust-lang.org/what/embedded Operating System Writing an OS in Rust Mobile Apps Building an iOS App in Rust, Part 1: Getting Started with Rust Example project for building a library for iOS + Android in Rust Server Deploying to Heroku Anywhere? Rust Once, Run Everywhere","title":"Platforms"},{"location":"public/programming/rust/rust-lang-ecosystem/#selling-points","text":"Everyone will have their favorite reasons for using one language over another. I tried to select articles related to the selling points, but also highlight features of the language brought up by people who advocate for it. Articles How often does Rust change? Rust programming language: Seven reasons why you should learn it in 2019 What is Rust and why is it so popular? Why Rust? Why should I use Rust? Features Borrow checker (\u201c Rust has a static garbage collector \u201d) Community Ownership model Package manager Performance Productivity Excellent documentation Built-in tools (cargo, fmt, clippy) Smart memory-management Type system Other Used by big companies (talk about Facebook, Microsoft, Amazon, etc.) *Note: this section also piggybacks off the Use Cases section (coming up). Beyond this, I would encourage you to read the results from the Rust 2019 survey which asked \u201cWhy not use Rust\u201d . Not all points relate to selling points, but it may provide insight into what would sell people on using Rust if these things were fixed.","title":"Selling Points"},{"location":"public/programming/rust/rust-lang-ecosystem/#tools","text":"The tools used for writing and using the programming language is an aspect we sometimes forget. This affects the developer experience and can drive or hinder the ecosystem. Here are some highlights: Benchmarking criterion - Statistics-driven Microbenchmarking Built-in testing support Cargo Build (macOS, Windows, Linux) Clippy Rustdoc rustfmt IDE support https://www.rust-lang.org/tools Hover over documentation in editor Rust Playground - test code online, share with others","title":"Tools"},{"location":"public/programming/rust/rust-lang-ecosystem/#use-cases","text":"Deriving some of the tops results from the Rust Survey 2019 , here are the main industries/applications that responded in the survey and are using Rust: Top 10 from survey Backend Web Applications Distributed Systems Embedded Devices Enterprise Software Frontend Web Applications Internet of Things IT Network Programming Security Technology Other Blockchain ( Libra Move ) Solana Deno - uses JavaScript engine written in Rust 1.0 Announcement","title":"Use Cases"},{"location":"public/programming/rust/rust-lang-ecosystem/#summary","text":"Reflecting on what we have covered thus far, we can see that the Rust ecosystem is well-developed and growing. This is not a conclusive/comprehensive list of the ecosystem or the companies using it. From my knowledge, Rust is used at big companies such as Amazon, Apple, Microsoft and Google. They are all investing in the language. We\u2019ve covered the ecosystem from a bird\u2019s-eye view as we see it today. Here are the main things to walk away with: Overview The community is ubiquitous both online and in-person There is no shortage of books or references to read from the official Rust groups Rust can be used for writing web, mobile, and CLI apps, servers embedded devices, and OS\u2019s Rust is fast, well-documented, type-safe, manages memory efficiently, but has a steep learning curve","title":"Summary"},{"location":"public/programming/rust/rust-lang-ecosystem/#whats-next","text":"We plan to use this information when making decisions and building strategies for us to get involved with the Rust ecosystem. If you\u2019d like to collaborate with us, please reach out to me over DMs on Twitter ! We would love to work with you. Thank you for reading!","title":"What\u2019s next?"},{"location":"public/programming/rust/rust-lang-ecosystem/#thank-you","text":"To close out, I\u2019d like to give thanks to the following people for their contributions and feedback. I appreciate all of you! David Tolnay Pedro Rittner Jk Jensen Joe Savona Nell Shamrell-Harrington Lauren Tan Kathy Kam Cami Williams Joel Marcey","title":"Thank you"},{"location":"public/programming/rust/rust-lang-ecosystem/#join-the-newsletter","text":"I send a monthly newsletter with 1 exciting thing, 1 helpful thing, and new jobs. Email* By subscribing, you agree with Revue\u2019s Terms of Service \u00a92022 Joe Previte","title":"Join the Newsletter"},{"location":"public/programming/rust/rust-lang-research-intro/","text":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Rust-Lang/Part(7) \u00b6 Dr.Gavin-Wood #Polkadot#kusama#ParaState#Substrate#Rust-Lang \ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb 1 Features \u00b6 \ud83d\udc46\ud83d\udc46\ud83d\udc46 Crates \u00b6 Alloc \u00b6 The Rust core allocation and collections library This library provides smart pointers and collections for managing heap-allocated values. This library, like libcore, normally doesn\u2019t need to be used directly since its contents are re-exported in the std crate. Crates that use the #![no_std] attribute however will typically not depend on std, so they\u2019d use this crate instead. https://doc.rust-lang.org/alloc/index.html Core \u00b6 The Rust Core Library The Rust Core Library is the dependency-free1 foundation of The Rust Standard Library. It is the portable glue between the language and its libraries, defining the intrinsic and primitive building blocks of all Rust code. It links to no upstream libraries, no system libraries, and no libc. The core library is minimal: it isn\u2019t even aware of heap allocation, nor does it provide concurrency or I/O. These things require platform integration, and this library is platform-agnostic. https://doc.rust-lang.org/core/index.html Crate proc_macroCopy \u00b6 A support library for macro authors when defining new macros. This library, provided by the standard distribution, provides the types consumed in the interfaces of procedurally defined macro definitions such as function-like macros #[proc_macro], macro attributes #[proc_macro_attribute] and custom derive attributes#[proc_macro_derive]. https://doc.rust-lang.org/proc_macro/index.html Std(The Rust Standard Library) \u00b6 The Rust Standard Library is the foundation of portable Rust software, a set of minimal and battle-tested shared abstractions for the broader Rust ecosystem. It offers core types, like Vec and Option , library-defined operations on language primitives, standard macros, I/O and multithreading, among many other things. std is available to all Rust crates by default. Therefore, the standard library can be accessed in use statements through the path std, as in use std::env. https://doc.rust-lang.org/std/index.html Test \u00b6 Support code for rustc\u2019s built in unit-test and micro-benchmarking framework. Almost all user code will only be interested in Bencher and black_box . All other interactions (such as writing tests and benchmarks themselves) should be done via the #[test] and #[bench] attributes. See the Testing Chapter of the book for more details. https://doc.rust-lang.org/test/index.html \ud83d\udc46\ud83d\udc46\ud83d\udc46 Memory \u00b6 Rust programs have 3 memory regions where data is stored: Data memory - For data that is fixed in size and static (i.e. always available through life of program). Consider the text in your program (e.g. \"Hello World!\"): This text's bytes are only ever read from one place and therefore can be stored in this region. Compilers make lots of optimizations with this kind of data, and they are generally considered very fast to use since locations are known and fixed. Stack memory - For data that is declared as variables within a function. The location of this memory never changes for the duration of a function call; because of this compilers can optimize code so stack data is very fast to access. Heap memory - For data that is created while the application is running. Data in this region may be added, moved, removed, resized, etc. Because of its dynamic nature it's generally considered slower to use, but it allows for much more creative usages of memory. When data is added to this region we call it an allocation . When data is removed from this section we call it a deallocation . Thread \u00b6 LifeTime \u00b6 @Static A static variable is a memory resource created at compile-time that exists through a program start to finish . They must have their types explicitly specified so special lifetime lasting the entire program execution. A static lifetime is a memory resource that lasts indefinitely to the end of a program. Note that by this definition some static lifetime resources can be created at runtime. Lifetime specifiers always start with a ' (e.g. 'a, 'b, 'c). Resources with static lifetimes have a special lifetime specifier 'static. 'static resources will never drop. If static lifetime resources contain references they must all be 'static (anything less would not live long enough). fn main() { let mut foo = Foo { x: 42 }; let x = &mut foo.x; *x = 13; // x is dropped here, allowing us to create a non-mutable reference let y = do_something(&foo); println!(\"{} {}\", y, foo.x); // y is dropped here // foo is dropped here } /* Standard Output 42 */ Memory detail: Modifying static variables is inherently dangerous because they are globally accessable to be read from by anyone introducing the possibility of a data race. static X: T = T(); Global variable with 'static lifetime, single memory location. T: 'static Same; does esp. not mean value t will live 'static, only that it could. Language Sugar: Rvalue Static Promotion Makes references to constants 'static, e.g., &42, &None, &mut []. Promote constexpr rvalues to values in static memory instead of stack slots, and expose those in the language by being able to directly create 'static references to them. This would allow code like let x: &'static u32 = &42 to work. static PI: f64 = 3.1415; fn main() { // static variables can also be scoped to a function static mut SECRET: &'static str = \"swordfish\"; // string literals have a 'static lifetime let msg: &'static str = \"Hello World!\"; let p: &'static f64 = &PI; println!(\"{} {}\", msg, p); // You can break some rules, but you must be explicit unsafe { // we can set SECRET to a string literal because it is also `static SECRET = \"abracadabra\"; println!(\"{}\", SECRET); } } /* Standard Output Hello World! 3.1415 abracadabra */ @Unsafe If you still had access to (via unsafe) they might still look like valid S, but any attempt to use them as valid S is undefined behavior. \u2193 https://cheats.rs/#unsafe-unsound-undefined-dark side of force Try to avoid \"unsafe {}\", often safer, faster solution without it. Exception: FFI. Arc \u00b6 @Safe Arc presents us with a couple of use statements that include threads and something called Arc. Arc represents a thread-safe reference-counting pointer, and Arc stands for Atomically Reference Counted. You may know of this idea from old iOS Objective-C code or something like that. // arc1.rs // Make this code compile by filling in a value for `shared_numbers` where the // TODO comment is and create an initial binding for `child_numbers` // somewhere. Try not to create any copies of the `numbers` Vec! // Execute `rustlings hint arc1` for hints :) use std::sync::Arc; use std::thread; fn main() { let numbers: Vec<_> = (0..100u32).collect(); let shared_numbers = Arc::new(numbers); let mut joinhandles = Vec::new(); for offset in 0..8 { let child_numbers = shared_numbers.clone(); joinhandles.push(thread::spawn(move || { let mut i = offset; let mut sum = 0; while i < child_numbers.len() { sum += child_numbers[i]; i += 5; } println!(\"Sum of offset {} is {}\", offset, sum); })); } for handle in joinhandles.into_iter() { handle.join().unwrap(); } } What Arc does is provides shared ownership of a value allocated in the heap. Invoking clone on Arc gives you a new Arc instance, which points to the same allocation on the heap as the original source Arc. What Arc will do is then increase the reference count, and it will not drop the value inside of the Arc until the last reference has dropped. In this code, what we need to do is set a value for shared_numbers and then also create an initial binding for child_numbers such that we can use the value inside of the multiple threads that are spawned for the range zero to eight. Note that numbers here is a Vec which we've told the Rust compiler to infer the type of with this <_>, and also told that the type by using a range of to 100 as u32. For shared_numbers, what we'll do is create a new Arc . Note that we also need to use new binding for child_numbers. We have a number of places we could put it, including right below shared_numbers or inside of this loop. We're going to do this inside of the loop so that we create a new clone and increase the Arc reference counter for every offset that we spawn a new thread for. Note that shared_numbers is a new Arc that contains the Vec for each offset in the range zero to eight, which we spawn a thread for child_numbers, clones shared_numbers, which increments the Arc counter and allows child_numbers to access the same data \ud83d\udc46\ud83d\udc46\ud83d\udc46 \u270d\ufe0f\u270d\ufe0f\u270d\ufe0f Let's Start - to setup in 5min https://www.gitpod.io/docs/languages/rust#rust-in-gitpod Getting started with Toturial Introduction - Rust By Example Learn Rust - Rust Programming Language Tour of Rust - Let's go on an adventure! In-Depth Rust Tutorials for 2022 | egghead.io https://rust-lang.github.io/rustup/examples.html \ud83d\udcda\ud83d\udcda\ud83d\udcda Literature \u00b6 https://doc.rust-lang.org/error-index.html Cargo Getting Start \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f If you liked this article or if it helped you please clap on this post to help the Read.Cash algorithm recommend it to more people. If you have any questions or remarks please feel free to leave a comment below. Alternatively, please feel free to send donations 0xde5D732a5AB44832E1c69b18be30834639F44A2c \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4f#Arman-Riazi\ud83e\udd1d","title":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Rust-Lang/Part(7)"},{"location":"public/programming/rust/rust-lang-research-intro/#highlighted-deep-dive-into-polkadotsubstratekusamarust-langpart7","text":"Dr.Gavin-Wood #Polkadot#kusama#ParaState#Substrate#Rust-Lang \ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb\ud83d\udc69\u200d\ud83c\udfeb 1","title":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Rust-Lang/Part(7)"},{"location":"public/programming/rust/rust-lang-research-intro/#features","text":"\ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Features"},{"location":"public/programming/rust/rust-lang-research-intro/#crates","text":"","title":"Crates"},{"location":"public/programming/rust/rust-lang-research-intro/#alloc","text":"The Rust core allocation and collections library This library provides smart pointers and collections for managing heap-allocated values. This library, like libcore, normally doesn\u2019t need to be used directly since its contents are re-exported in the std crate. Crates that use the #![no_std] attribute however will typically not depend on std, so they\u2019d use this crate instead. https://doc.rust-lang.org/alloc/index.html","title":"Alloc"},{"location":"public/programming/rust/rust-lang-research-intro/#core","text":"The Rust Core Library The Rust Core Library is the dependency-free1 foundation of The Rust Standard Library. It is the portable glue between the language and its libraries, defining the intrinsic and primitive building blocks of all Rust code. It links to no upstream libraries, no system libraries, and no libc. The core library is minimal: it isn\u2019t even aware of heap allocation, nor does it provide concurrency or I/O. These things require platform integration, and this library is platform-agnostic. https://doc.rust-lang.org/core/index.html","title":"Core"},{"location":"public/programming/rust/rust-lang-research-intro/#crate-proc_macrocopy","text":"A support library for macro authors when defining new macros. This library, provided by the standard distribution, provides the types consumed in the interfaces of procedurally defined macro definitions such as function-like macros #[proc_macro], macro attributes #[proc_macro_attribute] and custom derive attributes#[proc_macro_derive]. https://doc.rust-lang.org/proc_macro/index.html","title":"Crate proc_macroCopy"},{"location":"public/programming/rust/rust-lang-research-intro/#stdthe-rust-standard-library","text":"The Rust Standard Library is the foundation of portable Rust software, a set of minimal and battle-tested shared abstractions for the broader Rust ecosystem. It offers core types, like Vec and Option , library-defined operations on language primitives, standard macros, I/O and multithreading, among many other things. std is available to all Rust crates by default. Therefore, the standard library can be accessed in use statements through the path std, as in use std::env. https://doc.rust-lang.org/std/index.html","title":"Std(The Rust Standard Library)"},{"location":"public/programming/rust/rust-lang-research-intro/#test","text":"Support code for rustc\u2019s built in unit-test and micro-benchmarking framework. Almost all user code will only be interested in Bencher and black_box . All other interactions (such as writing tests and benchmarks themselves) should be done via the #[test] and #[bench] attributes. See the Testing Chapter of the book for more details. https://doc.rust-lang.org/test/index.html \ud83d\udc46\ud83d\udc46\ud83d\udc46","title":"Test"},{"location":"public/programming/rust/rust-lang-research-intro/#memory","text":"Rust programs have 3 memory regions where data is stored: Data memory - For data that is fixed in size and static (i.e. always available through life of program). Consider the text in your program (e.g. \"Hello World!\"): This text's bytes are only ever read from one place and therefore can be stored in this region. Compilers make lots of optimizations with this kind of data, and they are generally considered very fast to use since locations are known and fixed. Stack memory - For data that is declared as variables within a function. The location of this memory never changes for the duration of a function call; because of this compilers can optimize code so stack data is very fast to access. Heap memory - For data that is created while the application is running. Data in this region may be added, moved, removed, resized, etc. Because of its dynamic nature it's generally considered slower to use, but it allows for much more creative usages of memory. When data is added to this region we call it an allocation . When data is removed from this section we call it a deallocation .","title":"Memory"},{"location":"public/programming/rust/rust-lang-research-intro/#thread","text":"","title":"Thread"},{"location":"public/programming/rust/rust-lang-research-intro/#lifetime","text":"@Static A static variable is a memory resource created at compile-time that exists through a program start to finish . They must have their types explicitly specified so special lifetime lasting the entire program execution. A static lifetime is a memory resource that lasts indefinitely to the end of a program. Note that by this definition some static lifetime resources can be created at runtime. Lifetime specifiers always start with a ' (e.g. 'a, 'b, 'c). Resources with static lifetimes have a special lifetime specifier 'static. 'static resources will never drop. If static lifetime resources contain references they must all be 'static (anything less would not live long enough). fn main() { let mut foo = Foo { x: 42 }; let x = &mut foo.x; *x = 13; // x is dropped here, allowing us to create a non-mutable reference let y = do_something(&foo); println!(\"{} {}\", y, foo.x); // y is dropped here // foo is dropped here } /* Standard Output 42 */ Memory detail: Modifying static variables is inherently dangerous because they are globally accessable to be read from by anyone introducing the possibility of a data race. static X: T = T(); Global variable with 'static lifetime, single memory location. T: 'static Same; does esp. not mean value t will live 'static, only that it could. Language Sugar: Rvalue Static Promotion Makes references to constants 'static, e.g., &42, &None, &mut []. Promote constexpr rvalues to values in static memory instead of stack slots, and expose those in the language by being able to directly create 'static references to them. This would allow code like let x: &'static u32 = &42 to work. static PI: f64 = 3.1415; fn main() { // static variables can also be scoped to a function static mut SECRET: &'static str = \"swordfish\"; // string literals have a 'static lifetime let msg: &'static str = \"Hello World!\"; let p: &'static f64 = &PI; println!(\"{} {}\", msg, p); // You can break some rules, but you must be explicit unsafe { // we can set SECRET to a string literal because it is also `static SECRET = \"abracadabra\"; println!(\"{}\", SECRET); } } /* Standard Output Hello World! 3.1415 abracadabra */ @Unsafe If you still had access to (via unsafe) they might still look like valid S, but any attempt to use them as valid S is undefined behavior. \u2193 https://cheats.rs/#unsafe-unsound-undefined-dark side of force Try to avoid \"unsafe {}\", often safer, faster solution without it. Exception: FFI.","title":"LifeTime"},{"location":"public/programming/rust/rust-lang-research-intro/#arc","text":"@Safe Arc presents us with a couple of use statements that include threads and something called Arc. Arc represents a thread-safe reference-counting pointer, and Arc stands for Atomically Reference Counted. You may know of this idea from old iOS Objective-C code or something like that. // arc1.rs // Make this code compile by filling in a value for `shared_numbers` where the // TODO comment is and create an initial binding for `child_numbers` // somewhere. Try not to create any copies of the `numbers` Vec! // Execute `rustlings hint arc1` for hints :) use std::sync::Arc; use std::thread; fn main() { let numbers: Vec<_> = (0..100u32).collect(); let shared_numbers = Arc::new(numbers); let mut joinhandles = Vec::new(); for offset in 0..8 { let child_numbers = shared_numbers.clone(); joinhandles.push(thread::spawn(move || { let mut i = offset; let mut sum = 0; while i < child_numbers.len() { sum += child_numbers[i]; i += 5; } println!(\"Sum of offset {} is {}\", offset, sum); })); } for handle in joinhandles.into_iter() { handle.join().unwrap(); } } What Arc does is provides shared ownership of a value allocated in the heap. Invoking clone on Arc gives you a new Arc instance, which points to the same allocation on the heap as the original source Arc. What Arc will do is then increase the reference count, and it will not drop the value inside of the Arc until the last reference has dropped. In this code, what we need to do is set a value for shared_numbers and then also create an initial binding for child_numbers such that we can use the value inside of the multiple threads that are spawned for the range zero to eight. Note that numbers here is a Vec which we've told the Rust compiler to infer the type of with this <_>, and also told that the type by using a range of to 100 as u32. For shared_numbers, what we'll do is create a new Arc . Note that we also need to use new binding for child_numbers. We have a number of places we could put it, including right below shared_numbers or inside of this loop. We're going to do this inside of the loop so that we create a new clone and increase the Arc reference counter for every offset that we spawn a new thread for. Note that shared_numbers is a new Arc that contains the Vec for each offset in the range zero to eight, which we spawn a thread for child_numbers, clones shared_numbers, which increments the Arc counter and allows child_numbers to access the same data \ud83d\udc46\ud83d\udc46\ud83d\udc46 \u270d\ufe0f\u270d\ufe0f\u270d\ufe0f Let's Start - to setup in 5min https://www.gitpod.io/docs/languages/rust#rust-in-gitpod Getting started with Toturial Introduction - Rust By Example Learn Rust - Rust Programming Language Tour of Rust - Let's go on an adventure! In-Depth Rust Tutorials for 2022 | egghead.io https://rust-lang.github.io/rustup/examples.html \ud83d\udcda\ud83d\udcda\ud83d\udcda","title":"Arc"},{"location":"public/programming/rust/rust-lang-research-intro/#literature","text":"https://doc.rust-lang.org/error-index.html Cargo Getting Start \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f If you liked this article or if it helped you please clap on this post to help the Read.Cash algorithm recommend it to more people. If you have any questions or remarks please feel free to leave a comment below. Alternatively, please feel free to send donations 0xde5D732a5AB44832E1c69b18be30834639F44A2c \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f Reseacher & Organized by: \ud83d\ude4f#Arman-Riazi\ud83e\udd1d","title":"Literature"},{"location":"public/programming/rust/rust-learning-plan-chapter-1-notes/","text":"Rust Learning Plan & Chapter 1 Notes Last updated: 03/06/2020 Hello and welcome! This might be the first time we meet so I thought I\u2019d start this post off with a short introduction. I\u2019m Joe and previously I worked with JavaScript building web apps and mobile apps. Now, I\u2019m learning Rust both for personal reasons and work-related reasons. One of my primary focuses for this half of the year is Rust! Beyond that though, I am personally excited about Rust because: it\u2019s exciting it\u2019s type-safe (Yay, coming from TypeScript!) it\u2019s performant it has excellent documentation it has a strong community I dabbled a bit about a year ago doing some exercises on exercism but now learning Rust is a high priority. You might be interested in Rust because you can build: CLI tools Web apps (compile to WASM, or Web Assembly) Web servers And many other exciting things! For March, I decided to put together a plan to learn a little bit of Rust. The purpose is to start building projects with Rust and get involved in the community. Here\u2019s what the plan looks like: Learn enough Rust to be dangerous, measured by: ability to understand and explain basic concepts in Rust ability to contribute code to an open source project in the Rust community ability to build and ship a small project in Rust I\u2019ve taken these objectives and broken them out into actionable tasks. They are as follows: Read Chapters 1-3 of the Rust Lang Book (by Steve Klabnik and Carol Nichols, with contributions from the Rust Community) Write 3 blog posts Contribute to an open source project (bug fix or docs) Build a small web server app (bunny1 clone) This is the first blog post in the series, which covers my notes and thoughts on Chapter 1 of the Rust Lang Book. If you read Chapter 1 and would like to discuss, let\u2019s have a conversation! Tweet @ me or shoot me a DM on Twitter. Notes on Chapter 1 The first chapter in the Rust Lang Book is a friendly introduction to Rust. It covers enough of the basics to get started. You download Rust and then write your first program, which prints \u201cHello, World!\u201d Here are things I wrote down while reading the first chapter online: rustup is the preferred version manager Coming from the JavaScript world, I\u2019m used to scouring the internet for a decent node version manager. The common goto is nvm. Lucky for us, the Rust team supplies an official version manager and it\u2019s called rustup. Free, offline docs - out-of-the-box I noted this after rereading some of Chapter 1. rustup comes with a version of the docs that you can launch and read offline \ud83d\ude31 How genius is that?! rustup doc cargo commands are like npm commands Similar to how we use npm in the JS world for packaging and building our projects, cargo serves a similar purpose for Rust. Rust leans towards snake_case In JS, I used camelCase when naming things. It seems like the Rust community leans towards snake_case. This was evident during the hello world exercise. We named the project directory hello_world. My assumption may be premature. semicolons have meaning There is a great debate in JS - semicolons or no semicolons? While the choice is mainly conventional in JavaScript, Rust is a bit different. Most of the time, you\u2019ll use them to declare the end of an expression. Here\u2019s an example: // Rust example println!(\"Hello, world!\"); Like all good rules in programming languages, there is an exception! If you don\u2019t include it in a code block, it returns the last line. Here\u2019s what that looks like: // Rust if x < 5 { x + 1 } There is no semicolon but this will still return x plus 1. Reminds me of the arrow function implicit return in JavaScript: // JavaScript const firstName = () => 'Rusty' Rust has an official code formatter If you\u2019re not familiar with the Prettier, it\u2019s an opinionated code formatter. It supports a lot of different languages. I believe it\u2019s the most used one in JavaScript. A positive note about Rust is that they have an official formatter called rustfmt. And even better, the Rust book says, The Rust team plans to eventually include this tool with the standard Rust distribution Official formatting - hooray! Another thing we don\u2019t have to worry about. Rust uses macros I wasn\u2019t familiar with this because JavaScript does not have them. They look like functions, but according to Computer Hope, macros are \u201ca tool that allows a developer to re-use code.\u201d I thought it was like a function, but they have a note saying, A macro is not the same as a function. Functions require special instructions and computational overhead to safely pass arguments and return values. A macro is a way to repeat frequently-used lines of code. Here is an example using the println! macro in Rust: // Rust println!(\"Howdy, friend!\"); The \u201c!\u201d in \u201cprintln!\u201d means it\u2019s a macro After learning about macros, I asked myself, \u201cBut how do you know if it\u2019s a local function vs. macro?\u201d Then I realized, it\u2019s the !. That\u2019s the pattern to look for. \u201cBinary executable\u201d is fancy terms for \u201ccomputer-ready-file\u201d I\u2019ve heard the term \u201cbinary executable.\u201d I know what \u201cbinary\u201d means and I know what \u201cexecutable\u201d means, but I highlighted this anyway. In layperson terms, it means the computer can read and execute it without anyone\u2019s help. Compile before you run, you must When I learned JavaScript, I never fully understood the whole compiled vs interpreted lingo. Well, now I have a basic understanding. In most cases, a JavaScript engine (like V8) \u201ccompiles JavaScript code into machine code at execution by implementing a JIT (Just-In-Time) compiler.\u201d Notice though, the JS engine does this, not the developer. In Rust (and many other languages), there is a compile step that you, the developer, must do. So you must compile your code before you can run it. Ahead-of-time compilation is awesome I hadn\u2019t previously heard this phrase \u201cahead-of-time compilation\u201d but now I get what it is and why it\u2019s awesome. You compile your program and it outputs a file. Because you compiled \u201cahead of time\u201d \ud83d\ude09 you can send it to a friend who can then run it on their machine without having Rust. That\u2019s amazing! At least coming from JS/Python. With Rust, it\u2019s already ready to go! cargo new, what it do? Going back to our npm comparison, it is like npm init and creates a new Rust project. What makes it even better though is that it includes a .gitignore file for you. It\u2019s fantastic. crates are like npm packages Crates are bundled up pieces of code. Similar to the JS world, you install a package from npm, you do the same with Rust, but with crates. I love the term \u201ccrate.\u201d It\u2019s kind of fun to say and isn\u2019t an everyday term like \u201cpackages\u201d. The official crates registry is crates.io. The other differentiating factor is that crates.io is \u201cmanaged by members of the Crates.io and Rust core teams.\u201d I hope this means it\u2019s more sustainable and community-driven. Rust encourages project folder structure Coming from the JS world, you can put your files in any directory you want (most of the time). You then tell your bundler where to look. What I like about Rust is that it encourages a project folder structure out the gate. According to the book, \u201cCargo expects your source files to live inside the src directory.\u201d This is great! One less thing for us to think about. You can, of course, override this by setting the path value in your cargo.toml (I googled out of curiosity). cargo check - \u201cAm I doing this right?\u201d cargo check will check your source code without building it. This is a good way to iterate quickly. cargo build \u2014release - \u201cShip it!\u201d This one is more of a reminder for me. When you\u2019re ready to ship your code to production, add the release flag to your build step: cargo build --release fn: function keyword is only two letters In JavaScript, we have to use seven keystrokes to declare a function. That\u2019s a lot! But in Rust, we only need to write two: fn. How cool is that? We\u2019re five keystrokes richer in Rust. What\u2019s next? As previously mentioned, next up for me is Chapter 2 of the Rust Lang Book. Here, they\u2019ll walk us through programming a guessing game - hooray! I\u2019m excited about this. The next blog post in this series will cover my notes on building my first real project in Rust. Until then, happy coding my fellow Rustaceans! \ud83e\udd80 P.S. - I included a glossary and cheatsheet at the end here. Enjoy! Glossary I covered a decent number of new words (at least for me) in this post. I find it helpful to remind myself what they each mean. Here are they are described in my own words: ahead-of-time compilation - compiling beforehand binary executable - a file that a computer already understands Cargo - Rust\u2019s official build system and package manager crate - a bundle of code that you can use in your project crates.io - the official Rust package registry developer advocate - someone who can talk about and write code and works with the dev community macro - it\u2019s like a global function Rustacean - a Rust community member rustup - the official Rust version manager WASM - Web Assembly Cheatsheet Most of the commands that were covered in Chapter 1: Install Rust with rustup curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh Update to the latest version of Rust rustup update Check your version of Rust rustc --version Open the docs for Rust locally (available offline too) rustup doc Manually compile a file rustc main.rs Check your version of cargo cargo --version Create a new Rust program cargo new Example for a project named hello_world \u00b6 cargo new hello_world Check that Rust program compiles cargo check Build a Rust program cargo build Run a Rust program cargo run Build a Rust program for production cargo build --release","title":"Rust learning plan chapter 1 notes"},{"location":"public/programming/rust/rust-learning-plan-chapter-1-notes/#example-for-a-project-named-hello_world","text":"cargo new hello_world Check that Rust program compiles cargo check Build a Rust program cargo build Run a Rust program cargo run Build a Rust program for production cargo build --release","title":"Example for a project named hello_world"},{"location":"public/programming/rust/rust-scratch-blockchain/","text":"Welcome To The Home Blockchain Of \ud83e\udd80Rustaceans \u00b6 The repo is a prerequisite of the Substrate-Framework and it would be nicer to practice too. The repo is included Rust syntax, configuration and the goal of creating scratch codes like one is becuase of providing testbed environment of Blockchain . The Next reason is to using some features of Rust-Lang that I had wanted to implement it after learning Rust. Used json in the main runner of the project so that consume json transactions as a offchain blockchain. As you follow materials you can see (future work) which means you can add these concepts to the project. I have some idea that you can affort on it to completing future works. Smart Contracts, MultiSignature, RPC, Make A Better CLI, and something that you can implementing (Do not worry sice most of your works will merge to main branch. We will not create a framework or complete Blockchain because we just need to learning more and used it use-cases) The difference between the current work and the prev works \u00b6 I have tried to use fundamental concepts correctly, for example, all of us know any block have not any copy so because of it we are calling blockchain! Unlike many repositories on GitHub(testbed/scratched projects-non productive) that almost use Copy/Clone features of Rust-Lang. In the following, there are some features that cause a different project. Currently Status: Under Refactoring How To Contribute Easy \u00b6 [Rust 2021 A Scratch Blockchain-1] Youtube-Rust 2021 A Scratch Blockchain-1 Rust 2021 A Scratch Blockchain-2 Youtube-Rust 2021 A Scratch Blockchain-2 Instructions for working with \u00b6 DIFFICULTY={difficulty} cargo {mode} {file name} {difficulty}: (optional-key-env) value default 0x00ffffffffffffffffffffffffffffff.It must be 32 byte. {mode}: macro, string, file/ default mode is on the macrojson mode. {macro, string} there is in project and you can not access or manipulate except by getting the project. serde_json support string and macro based on called library. {file} json file is external .json file that you can set it for command line {file name} index directory of the project sample-bolocks.json Example: cargo build DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run file sample-bolocks.json DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run macrojson DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run stringjson time cargo run cargo watch -x run Using time and watch is optional and depends on your purpose Features \u00b6 [\u2713] Modular [\u2713] UnitTest(semi:future work) [\u2713] Customized Error Handling [\u2713] Json & String Data Deserialized [\u2713] Closure(Functional Programming) [\u2713] Cryptography-Hashing Alogrithm SHA-256 [\u2713] Configuration Files(semi- devOps) Used Concepts \u00b6 - [\u2713] Memoization\u2022Lazy\u2022Evaluation \u00b6 We can create a struct that will hold the closure and the resulting value of calling the closure. The struct will execute the closure only if we need the resulting value, and it will cache the resulting value so the rest of our code doesn\u2019t have to be responsible for saving and reusing the result. FnOnce consumes the variables it captures from its enclosing scope, known as the closure\u2019s environment. To consume the captured variables, the closure must take ownership of these variables and move them into the closure when it is defined. The Once part of the name represents the fact that the closure can\u2019t take ownership of the same variables more than once, so it can be called only once. FnMut can change the environment because it mutably borrows values. Fn borrows values from the environment immutably. FnOnce: takes the whole value. FnMut: takes a mutable reference. Fn: takes a regular reference. - [\u2713] Coercion \u00b6 Deref coercion is a convenience that Rust performs on arguments to functions and methods. Deref coercion works only on types that implement the Deref trait. Deref coercion converts such a type into a reference to another type. For example, deref coercion can convert &String to &str because String implements the Deref trait such that it returns &str. The number of times that Deref::deref needs to be inserted is resolved at compile time, so there is no runtime penalty for taking advantage of deref coercion! Similar to how you use the Deref trait to override the * operator on immutable references, you can use the DerefMut trait to override the * operator on mutable references.the Drop trait is almost always used when implementing a smart pointer. For example, when a Box is dropped it will deallocate the space on the heap that the box points to. Note that we didn\u2019t need to call the drop method explicitly. - [\u2713] DST\u2022Or\u2022Unsizedtype \u00b6 DSTs or unsized types': str(but not &str-So although a &T is a single value that stores the memory address of where the T is located, a &str is two values: the address of the str and its length. Rust has a particular trait called the Sized trait to determine whether or not a type\u2019s size is known at compile time. This trait is automatically implemented for everything whose size is known at compile time. In addition, Rust implicitly adds a bound on Sized to every generic function. - [\u2713] Operation \u00b6 -> Methods are functions that are coupled to some object. From a syntactic point of view, these are just functions that don\u2019t need to specify one of their arguments. Rather than calling open() and passing a File object in as an argument (read(f, buffer)), methods allow the main object to be implicit in the function call (f.read(buffer)) using the dot operator. There are a number of theoretical differences between methods and functions, but a detailed discussion of those computer science topics is available in other books. Briefly, functions are regarded as pure, meaning their behavior is determined solely by their arguments. Methods are inherently impure, given that one of their arguments is effectively a side effect. These are muddy waters, though. Functions are perfectly capable of acting on side effects themselves. Moreover, methods are implemented with functions. And, to add an exception to an exception, objects sometimes implement static methods, which do not include implicit arguments. To define methods, Rust programmers use an impl block - [\u2713] Borrowchecker \u00b6 The borrow checker checks that all access to data is legal, which allows Rust to prevent safety issues. Learning how this works will, at the very least, speed up your development time by helping you avoid run-ins with the compiler. More significantly though, learning to work with the borrow checker allows you to build larger software systems with confidence. It underpins the term fearless concurrency. - [\u2713] Borrowchecker\u2022Lifetime \u00b6 -> Lifetime=Timetolive=Subset of their scope Make hypotheses about whether or not your experiments will pass the borrow checker before you compile reference in Rust has a lifetime, which is the scope for which that reference is valid. Most of the time, lifetimes are implicit and inferred, just like most of the time, types are inferred. We must annotate types when multiple types are possible. In a similar way, we must annotate lifetimes when the lifetimes of references could be related in a few different ways. The main aim of lifetimes is to prevent dangling references, which cause a program to reference data other than the data it\u2019s intended to reference. All references in Rust have a lifetime, even if they are not explicitly annotated. The compiler is capable of implicitly assigning lifetimes. A value\u2019s lifetime is the period when accessing that value is valid behavior. A function\u2019s local variables live until the function returns, while global variables might live for the life of the program. The notion of ownership is rather limited. An owner cleans up when its values\u2019 lifetimes end. Although every parameter has a lifetime, these checks are typically invisible as the compiler can infer most lifetimes by itself. All values bound to a given lifetime must live as long as the last access to any value bound to that lifetime. No lifetime annotations are required when calling a function. Lifetime annotations don\u2019t change how long any of the references live. Just as functions can accept any type when the signature specifies a generic type parameter, functions can accept references with any lifetime by specifying a generic lifetime parameter. Lifetime annotations describe the relationships of the lifetimes of multiple references to each other without affecting the lifetimes. The lifetime annotations indicate that the references first and second must both live as long as that generic lifetime. Lifetimes on function or method parameters are called input lifetimes, and lifetimes on return values are called output lifetimes. Although every parameter has a lifetime, these checks are typically invisible as the compiler can infer most lifetimes by itself All values bound to a given lifetime must live as long as the last access to any value bound to that lifetime. No lifetime annotations are required when calling a function. Using two lifetime parameters (a and b) indicates that the lifetimes of i and j are decoupled. fn add_with_lifetimes<'a, 'b>(i: &'a i32, j: &'b i32) -> i32 {} Lifetime of that usage: the LOC('existence time' or Line of code) between when a location is first used in a certain way, and when that usage stops. Lifetime of that value: the LOC (or actual time) between when a value is created, and when that value is dropped. Might be useful when discussing open file descriptors, but also irrelevant here. Ultimately, lifetime syntax is about connecting the lifetimes of various parameters and return values of functions. Once they\u2019re connected, Rust has enough information to allow memory-safe operations and disallow operations that would create dangling pointers or otherwise violate memory safety. - [\u2713] Dangle \u00b6 The main aim of lifetimes is to prevent dangling references.which has an outer scope and an inner scope. In return section of a function primitive types need to define as (&'a or &'static) - [\u2713] Generic \u00b6 You might be wondering whether there is a runtime cost when using generic type parameters. The good news is that using generic types won't make your run any slower than it would with concrete types. Rust accomplishes this by performing monomorphization of the code using generics at compile time. Monomorphization is the process of turning generic code into specific code by filling in the concrete types that are used when compile. Every programming language has tools for effectively handling the duplication of concepts. In Rust, one such tool is generics. Generics are abstract stand-ins for concrete types or other properties. When we\u2019re writing code, we can express the behavior of generics or how they relate to other generics without knowing what will be in their place when compiling and running the code. Static\u2022Dispatch(Passed) \u00b6 -> Monomorphization Dispatch is the mechanism to determine which specific version of code is actually run when it involves polymorphism. Two major forms of dispatch are static dispatch and dynamic dispatch. While Rust favors static dispatch, it also supports dynamic dispatch through a mechanism called \u2018trait objects\u2019. When Rust compiles this code, it performs monomorphization. The monomorphized version of the code looks like the following. The generic Option is replaced with the specific definitions created by the compiler: versions of a polymorphic function (or any polymorphic entity) during compilation is called Monomorphization. Because Rust compiles generic code into code that specifies the type in each instance, we pay no runtime cost for using generics. When the code runs, it performs just as it would if we had duplicated each definition by hand. The process of monomorphization makes Rust\u2019s generics extremely efficient at runtime. This is opposed to dynamic dispatch - [\u2713] Dynamic\u2022Dispatch \u00b6 The code that results from monomorphization is doing static dispatch, which is when the compiler knows what method you\u2019re calling at compile time. This is opposed to dynamic dispatch, which is when the compiler can\u2019t tell at compile time which method you\u2019re calling. In dynamic dispatch cases, the compiler emits code that at runtime will figure out which method to call. When we use trait objects, Rust must use dynamic dispatch. The compiler doesn\u2019t know all the types that might be used with the code that is using trait objects, so it doesn\u2019t know which method implemented on which type to call. Instead, at runtime, Rust uses the pointers inside the trait object to know which method to call. There is a runtime cost when this lookup happens that doesn\u2019t occur with static dispatch. Dynamic dispatch also prevents the compiler from choosing to inline a method\u2019s code, which in turn prevents some optimizations. - [-] Blanket\u2022Implementation \u00b6 Any implementation where a type appears uncovered. impl Foo for T, impl Bar for T, impl Bar > for T, and impl Bar for Vec are considered blanket impls. We can also conditionally implement a trait for any type that implements another trait. Implementations of a trait on any type that satisfies the trait bounds are called blanket implementations and are extensively used in the Rust standard library. For example, the standard library implements the ToString trait on any type that implements the Display trait. - [\u2713] Bound(syntax) \u00b6 Bounds are constraints on a type or trait. For example, if a bound is placed on the argument a function takes, types passed to that function must abide by that constraint. - [\u2713] Trait \u00b6 We can use traits to define shared behavior in an abstract way. We can use trait bounds to specify that a generic type can be any type that has certain behavior. Traits are similar to a feature often called interfaces in other languages, although with some differences. What is a trait? A trait is a language feature that is analogous to an interface, protocol, or contract. If you have a background in object-oriented programming, consider a trait to be an abstract base class. If you have a background in functional programming, Rust\u2019s traits are close to Haskell\u2019s type classes these also support a form of inheritance that\u2019s common in most object oriented languages. For now, though, the thing to remember is that traits represent common behavior (Or reusable codes like println!)that types opt into via the syntax impl Trait for Type. After the method signature, instead of providing an implementation within curly brackets, we use a semicolon. This interface consists of associated items, which come in three varieties: functions, types, constants. All traits define an implicit type parameter Self that refers to \"the type that is implementing this interface\". Trait functions may omit the function body by replacing it with a semicolon. This indicates that the implementation must define the function. If the trait function defines a body, this definition acts as a default for any implementation which does not override it. Similarly, associated constants may omit the equals sign and expression to indicate implementations must define the constant value. Associated types must never define the type, the type may only be specified in an implementation. - [\u2713] Polymorphism \u00b6 In a struct or enum, the data in the struct fields and the behavior in impl blocks are separated, whereas in other languages, the data and behavior combined into one concept is often labeled an object.However, trait objects are more like objects in other languages in the sense that they combine data and behavior. - [\u2713] Unrolling \u00b6 It is an optimization that removes the overhead of the loop controlling code and instead generates repetitive code for each iteration of the loop. - [\u2713] Binding\u2022Match \u00b6 The compiler automatically references the Some, and since we're borrowing, name is bound as ref name automatically as well. If we were mutating: //https://blog.rust-lang.org/2018/05/10/Rust-1.26.html#nicer-match-bindings // `self` has type `&List`, and `*self` has type `List`, matching on a // concrete type `T` is preferred over a match on a reference `&T` // after Rust 2018 you can use self here and tail (with no ref) below as well, // rust will infer &s and ref tail. - [\u2717] Datarace\u2022Rustaceans \u00b6 Note: The opposite of referencing by using & is dereferencing, which is accomplished with the dereference operator, *. [-] Nan(philosophy) \u00b6 Floating-point types include \u201cnot a number\u201d values (represented in Rust syntax as NAN values) to handle these cases. NAN values poison other numbers. Almost all operations interacting with NAN return NAN. Another thing to be mindful of is that, by definition, NAN values are never equal. Programming language design is often thought of in terms of which features you include, but the features you exclude are important too. Rust doesn\u2019t have the null feature that many other languages have. Null is a value that means there is no value there. In languages with null, variables can always be in one of two states: null or not-null. In his 2009 presentation \u201cNull References: The Billion Dollar Mistake,\u201d Tony Hoare, the inventor of null, has this to say: I call it my billion-dollar mistake. At that time, I was designing the first comprehensive type system for references in an object-oriented language. My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn\u2019t resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years. To program defensively, make use of the is_nan() and is_finite() methods. Inducing a crash, rather than silently proceeding with a mathematical error, allows you to debug close to what has caused the problem. The following illustrates using the is_finite() - [\u2713] Duplication((literal) \u00b6 Concept of copying the pointer, length, and capacity without copying the data probably sounds like making a shallow copy. If we do want to deeply copy the heap data of the String, not just the stack data, we can use a common method called clone - [\u2713] Semantic(literal) \u00b6 Primitive types are said to possess copy semantics, whereas all other types have move semantics. Adding more functionality (e.g., reference-counting semantics rather than move semantics) to types by wrapping these in other types typically reduces their run-time performance. - [\u2713] Zero\u2022Cost\u2022Abstractions(literal) \u00b6 One of the ways this manifests is by not adding extra data around values within structs. - [\u2713] Coherence(literal) \u00b6 -> Orphan = Trait\u2022External\u2022Implement But we can\u2019t implement external traits on external types. For example, we can\u2019t implement the Display trait on Vec within our aggregator crate, because Display and Vec are defined in the standard library and aren\u2019t local to our aggregator crate. This restriction is part of a property of programs called coherence, and more specifically the orphan rule, so named because the parent type is not present. This rule ensures that other people\u2019s code can\u2019t break your code and vice versa. Without the rule, two crates could implement the same trait for the same type, and Rust wouldn\u2019t know which implementation to use. Preserves contextual coherence of trace data from tasks/function/methods when logging. For example new instance of a struct of course, as you probably already know, struct then you can just summerize your struct in a method. - [\u2713] Jargon(literal) \u00b6 Functional programming jargon: \u201cto cons x onto y\u201d informally means to construct a new container instance by putting the element x at the start of this new container, followed by the container y.Other, more complex recursive data types are useful in various situations, but by starting with the cons list, we can explore how boxes let us define a recursive data type without much distraction. - [\u2713] Refactor(literal) \u00b6 One alternative to refactoring is to simply copy values. Doing this often is typically frowned upon, however, but it can be useful in a pinch. Primitive types like integers are a good example of that. Primitive types are cheap for a CPU to duplicate\u2014so cheap, in fact, that Rust always copies these if it would otherwise worry about ownership being moved. Types can opt into two modes of duplication: cloning and copying. - [\u2713] Pattern\u2022Newtype \u00b6 Using the Newtype Pattern to Implement External Traits on External Types 'thin wrapper around the type' : part of Vec is noticed. We can make a Wrapper struct that holds an instance of Vec ; then we can implement Display on Wrapper and use the Vec value The downside of using this technique is that Wrapper is a new type, so it doesn\u2019t have the methods of the value it\u2019s holding. We would have to implement all the methods of Vec directly on Wrapper such that the methods delegate to self.0, which would allow us to treat Wrapper exactly like a Vec . If we wanted the new type to have every method the inner type has, implementing the Deref trait (If we don\u2019t want the Wrapper type to have all the methods of the inner type\u2014for example, to restrict the Wrapper type\u2019s behavior\u2014we would have to implement just the methods we do want manually.) - [\u2717] Pattern\u2022Design\u2022Interior(future work) \u00b6 Interior mutability is a design pattern in Rust that allows you to mutate data even when there are immutable references to that data; normally, this action is disallowed by the borrowing rules. To mutate data, the pattern uses unsafe code inside a data structure to bend Rust\u2019s usual rules that govern mutation and borrowing. RefCell type that follows the interior mutability pattern. Unlike Rc , the RefCell type represents single ownership over the data it holds. So, what makes RefCell different from a type like Box ? Recall the borrowing rules... Similar to Rc , RefCell is only for use in single-threaded scenarios and will give you a compile-time error if you try using it in a multithreaded context. At any given time, you can have either (but not both of) one mutable reference or any number of immutable references.References must always be valid. - [\u2717] Type\u2022Wraper(future work) \u00b6 -> Wrapper type = Reference-Counted Value = Shared Ownership = Track valid references Use wrapper types, which allow more flexibility than what is available by default. These, however, incur costs at runtime to ensure that Rust\u2019s safety guarantees are maintained. Another way to phrase this is that Rust allows programmers to opt in to garbage collection. - [\u2717] Mem\u2022Leak(future work) \u00b6 -> Managing Memory Leak Rust\u2019s memory safety guarantees make it difficult, but not impossible, to accidentally create memory that is never cleaned up (known as a memory leak). Preventing memory leaks entirely is not one of Rust\u2019s guarantees in the same way that disallowing data races at compile time is, meaning memory leaks are memory safe in Rust. We can see that Rust allows memory leaks by using Rc and RefCell : it\u2019s possible to create references where items refer to each other in a cycle. This creates memory leaks because the reference count of each item in the cycle will never reach 0, and the values will never be dropped. - [\u2717] Mem\u2022Doublefree(future work) \u00b6 This is a problem: when s2 and s1 (s2 is copied s1 means 2different pointer and the same data) go out of scope, they will both try to free the same memory. This is known as a double free error and is one of the memory safety bugs we mentioned previously. Freeing memory twice can lead to memory corruption, which can potentially lead to security vulnerabilities. - [\u2717] Mem\u2022Deallocating\u2022or\u2022RAII(future work) \u00b6 Note: In C++, this pattern of deallocating resources at the end of an item\u2019s lifetime is sometimes called Resource Acquisition Is Initialization (RAII). The drop function in Rust will be familiar to you if you\u2019ve used RAII patterns. - [\u2717] Thread(future work) \u00b6 Which parts of your code on different threads will run. This can lead to problems, such as: Race conditions, where threads are accessing data or resources in an inconsistent order Deadlocks, where two threads are waiting for each other to finish using a resource the other thread has, preventing both threads from continuing Bugs that happen only in certain situations and are hard to reproduce and fix reliably. - [\u2717] Thread\u2022Strateges(future work) \u00b6 -> Priority Performance Stealing_Join: execute code in parallel when there are idle CPUs to handle it. When join is called from outside the thread pool, the calling thread will block while the closures execute in the pool. When join is called within the pool, the calling thread still actively participates in the thread pool. It will begin by executing closure A (on the current thread). While it is doing that, it will advertise closure B as being available for other threads to execute. Once closure A has completed, the current thread will try to execute closure B; if however closure B has been stolen, then it will look for other work while waiting for the thief to fully execute closure B. (This is the typical work-stealing strategy). Send is require because we have jump from quick func(thread a) to part func(thread b) frequently. Atomic: types provide primitive shared-memory communication between threads, and are the building blocks of other concurrent types. This module defines atomic versions of a select number of primitive types, including AtomicBool, AtomicIsize, AtomicUsize, AtomicI8, AtomicU16, etc. Atomic types present operations that, when used correctly, synchronize updates between threads. Each method takes an Ordering which represents the strength of the memory barrier for that operation. These orderings are the same as the C++20 atomic orderings. For more information see the nomicon. Atomic variables are safe to share between threads (they implement Sync) but they do not themselves provide the mechanism for sharing and follow the threading model of Rust. The most common way to share an atomic variable is to put it into an Arc (an atomically-reference-counted shared pointer). Atomic types may be stored in static variables, initialized using the constant initializers like AtomicBool::new. Atomic statics are often used for lazy global initialization. Spin_Loop_Yeild also known as busy loop and spin loop-If you want to sleep pause a thread for short amounts of time, or if your application is sensitive to timing, use a spin loop - [\u2717] Unsafe\u2022Extern\u2022Mangling(future work) \u00b6 > Mangling is when a compiler changes the name we\u2019ve given a function to a different name that contains more information for other parts of the compilation process to consume but is less human readable. Every programming language compiler mangles names slightly differently, so for a Rust function to be nameable by other languages, we must disable the Rust compiler\u2019s name mangling. - [\u2713] Interior\u2022Mutability\u2022Pattern \u00b6 RefCell : Lets us have many immutable borrows or one mutable borrow at any point in time. Mutating the value inside an immutable value is the interior mutability pattern. Interior mutability is a design pattern in Rust that allows you to mutate data even when there are immutable references to that data; normally, this action is disallowed by the borrowing rules. To mutate data, the pattern uses unsafe code inside a data structure to bend Rust\u2019s usual rules that govern mutation and borrowing. RefCell type that follows the interior mutability pattern. Unlike Rc , the RefCell type represents single ownership over the data it holds. So, what makes RefCell different from a type like Box ? Recall the borrowing rules, Similar to Rc , RefCell is only for use in single-threaded scenarios and will give you a compile-time error if you try using it in a multithreaded context. At any given time, you can have either (but not both of) one mutable reference or any number of immutable references.References must always be valid. - [\u2717] OOP\u2022State\u2022DesignPattern(future work) \u00b6 -> We can used it for smart contracts so we will need to implemented smart contracts Using the state pattern means when the business requirements of the program change, we won\u2019t need to change the code of the value holding the state or the code that uses the value. We\u2019ll only need to update the code inside one of the state objects to change its rules or perhaps add more state objects. e.g Post type. This type will use the state pattern and will hold a value that will be one of three state objects representing the various states a post can be in\u2014draft, waiting for review, or published. Changing from one state to another will be managed internally within the Post type. The states change in response to the methods called by our library\u2019s users on the Post instance, but they don\u2019t have to manage the state changes directly. Also, users can\u2019t make a mistake with the states, like publishing a post before it\u2019s reviewed. - [\u2717] Superpower(future work) \u00b6 if the Rust compiler doesn\u2019t have enough information to be confident, it will reject the code. In these cases, you can use unsafe code to tell the compiler, \u201cTrust me, I know what I\u2019m doing.\u201d The downside is that you use it at your own risk: if you use unsafe code incorrectly, problems due to memory unsafety, such as null pointer dereferencing, can occur. You can take five actions in unsafe Rust, called unsafe superpowers, that you can\u2019t in safe Rust. Those superpowers include the ability to: Dereference a raw pointer Call an unsafe function or method Access or modify a mutable static variable Implement an unsafe trait Access fields of unions Calling unsafe() would crash the program. consider unsafe to be a warning sign rather than an indicator that you\u2019re embarking on anything illegal. Unsafe means \u201cthe same level of safety offered by C at all times.\u201d If you still had access to (via unsafe) they might still look like valid S, but any attempt to use them as valid S is undefined behavior. \u2193 https://cheats.rs/#unsafe-unsound-undefined-dark side of force Try to avoid \"unsafe {}\", often safer, faster solution without it. Exception: FFI. People are fallible, and mistakes will happen, but by requiring these five unsafe operations to be inside blocks annotated with unsafe you\u2019ll know that any errors related to memory safety must be within an unsafe block. Keep unsafe blocks small; you\u2019ll be thankful later when you investigate memory bugs. To isolate unsafe code as much as possible, it\u2019s best to enclose unsafe code within a safe abstraction and provide a safe API, which we\u2019ll discuss later in the chapter when we examine unsafe functions and methods. Parts of the standard library are implemented as safe abstractions over unsafe code that has been audited. Wrapping unsafe code in a safe abstraction prevents uses of unsafe from leaking out into all the places that you or your users might want to use the functionality implemented with unsafe code, because using a safe abstraction is safe. Contributors \u00b6 nom is the fruit of the work of many contributors over the years, many thanks for your help! Contributors Welcome To The Home Blockchain Of \ud83e\udd80Rustaceans \u00b6 The repo is a prerequisite of the Substrate-Framework and it would be nicer to practice too. The repo is included Rust syntax, configuration and the goal of creating scratch codes like one is becuase of providing testbed environment of Blockchain . The Next reason is to using some features of Rust-Lang that I had wanted to implement it after learning Rust. Used json in the main runner of the project so that consume json transactions as a offchain blockchain. As you follow materials you can see (future work) which means you can add these concepts to the project. I have some idea that you can affort on it to completing future works. Smart Contracts, MultiSignature, RPC, Make A Better CLI, and something that you can implementing (Do not worry sice most of your works will merge to main branch. We will not create a framework or complete Blockchain because we just need to learning more and used it use-cases) The difference between the current work and the prev works \u00b6 I have tried to use fundamental concepts correctly, for example, all of us know any block have not any copy so because of it we are calling blockchain! Unlike many repositories on GitHub(testbed/scratched projects-non productive) that almost use Copy/Clone attributes of Rust-Lang for creating block. In the following, there are some features that cause a different project. Currently Status: Under refactoring with contributors How To Contribute Easy \u00b6 [Rust 2021 A Scratch Blockchain-1] Youtube-Rust 2021 A Scratch Blockchain-1 Rust 2021 A Scratch Blockchain-2 Youtube-Rust 2021 A Scratch Blockchain-2 Documents Crate \u00b6 Docs.rs Package Manager crates.io Features \u00b6 [\u2713] Modular [\u2713] Customized Error Handling [\u2713] Json & String Data Deserialized [\u2713] Functional Programming(Closure) [\u2713] Cryptography-Hashing Alogrithm SHA-256 [-] WebAssembly(Next future video) [-] Unit & Integration Testing(structure-need more time in the future) [-] Configuration Files(devOps-need more time in the future) Instructions for working with \u00b6 DIFFICULTY={difficulty} cargo {mode} {file name} {difficulty}: (optional-key-env) value default 0x00ffffffffffffffffffffffffffffff.It must be 32 byte. {mode}: macro, string, file/ default mode is on the macrojson mode. {macro, string} there is in project and you can not access or manipulate except by getting the project. serde_json support string and macro based on called library. {file} json file is external .json file that you can set it for command line {file name} index directory of the project sample-bolocks.json Example: cargo build cargo run RUST_LOG=INFO DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run file sample-bolocks.json DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run macrojson DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run stringjson time cargo run cargo watch -x run cargo test Using time and watch is optional and depends on your purpose Instructions for installing-bin \u00b6 curl -LSfs https://github.com/armanriazi/armanriazi/blob/main/install-0.sh | sh -s -- --git armanriazi/rust-scratch-blockchain How to consume the library \u00b6 1. cargo new yourprojectname 2. Add new dependency [dependencies] blockchain-scratch-rust = \"0.3.0\" 3. To update dependencies cargo update 4. Your main.rs of the program use library_blockchain::*; fn main() { println!(\"Hello, world!\"); library_blockchain::blockchain_executive::main(); } 5. Due to the file sample-three-block-noerror.json in the repo you might copy it and manipulate it, in spite of that you can use generators of your database or ORMs for producing a file.json as the same as following content. Get attention to keys in the file for example we must have transaction{number} and if we write 'mytransaction 1' and run it we will get error. Json File { \"blocks\":[{ \"block1\":[{ \"transactions\":[{ \"transaction1\":[{ \"inputs\":[{ }], \"outputs\":[{ \"to_addr\": \"Alice\", \"value\": \"50\" },{ \"to_addr\": \"Bob\", \"value\": \"7\" }] }] }] }] , \"block2\":[{ \"transactions\":[{ \"transaction1\":[{ \"inputs\":[{ }], \"outputs\":[{ \"to_addr\": \"Chris\", \"value\": \"536\" }] }], \"transaction2\":[{ \"inputs\":[{ \"to_addr\": \"Alice\", \"value\": \"50\" },{ \"to_addr\": \"Bob\", \"value\": \"7\" }], \"outputs\":[{ \"to_addr\": \"Alice\", \"value\": \"49\" },{ \"to_addr\": \"Bob\", \"value\": \"6\" }] }] }] }], \"block3\":[{ \"transactions\":[{ \"transaction1\":[{ \"inputs\":[{ }], \"outputs\":[{ \"to_addr\": \"Alice\", \"value\": \"49\" },{ \"to_addr\": \"Bob\", \"value\": \"6\" }] }] }] }] }] } Run of one of above commands. RUST_LOG=info DIFFICULTY=0x0000ffffffffffffffffffffffffffff time cargo run file sample-three-block-noerror.json 7. Everything is Ok and it is working fine. Console Log Finished dev [unoptimized + debuginfo] target(s) in 0.07s Running `target/debug/consume-rust-scratch-blockchain file sample-three-block-noerror.json` Hello, world! [2022-07-06T13:30:22Z INFO library_blockchain::blockchain_executive] ------------Welcome to env_logger------------ [2022-07-06T13:30:22Z INFO library_blockchain::blockchain_executive] Starting Up... ************************************************************** Selected mode is file! **BlOcKcHaIn SiGnAls:** Block[0]: 17b9180cd95fef6c0e8ab81702ab9cfd835b4af373fdc7ee45d13cba69c40000 at: 1657114222903 with: 1 trx, nonce: 131263 [2022-07-06T13:30:24Z INFO library_blockchain::factory] Success updated With the block 1. **BlOcKcHaIn SiGnAls:** Block[1]: eeb73730eb18ef3efbadbe7b5f3cc1a07c0d97b6c97e7df8945e61089b280000 at: 1657114224538 with: 2 trx, nonce: 257740 [2022-07-06T13:30:30Z INFO library_blockchain::factory] Success updated With the block 2. **BlOcKcHaIn SiGnAls:** Block[2]: 3674f23d58002856c17816590f7e2ff195005ad477c67e704d61eead25710000 at: 1657114230226 with: 1 trx, nonce: 37407 [2022-07-06T13:30:30Z INFO library_blockchain::factory] Success updated With the block 3. 7.67user 0.16system 0:08.03elapsed 97%CPU (0avgtext+0avgdata 25300maxresident)k 2280inputs+0outputs (13major+6505minor)pagefaults 0swaps WASM(future work) \u00b6 For consume the library we used some WASM compiling strategy: Bindgen Wasmer-LLVM Wasmer-Wasi Binary of rust-scratch-blockchain Used Concepts \u00b6 - [\u2713] Memoization\u2022Lazy\u2022Evaluation \u00b6 We can create a struct that will hold the closure and the resulting value of calling the closure. The struct will execute the closure only if we need the resulting value, and it will cache the resulting value so the rest of our code doesn\u2019t have to be responsible for saving and reusing the result. FnOnce consumes the variables it captures from its enclosing scope, known as the closure\u2019s environment. To consume the captured variables, the closure must take ownership of these variables and move them into the closure when it is defined. The Once part of the name represents the fact that the closure can\u2019t take ownership of the same variables more than once, so it can be called only once. FnMut can change the environment because it mutably borrows values. Fn borrows values from the environment immutably. FnOnce: takes the whole value. FnMut: takes a mutable reference. Fn: takes a regular reference. - [\u2713] Coercion \u00b6 Deref coercion is a convenience that Rust performs on arguments to functions and methods. Deref coercion works only on types that implement the Deref trait. Deref coercion converts such a type into a reference to another type. For example, deref coercion can convert &String to &str because String implements the Deref trait such that it returns &str. The number of times that Deref::deref needs to be inserted is resolved at compile time, so there is no runtime penalty for taking advantage of deref coercion! Similar to how you use the Deref trait to override the * operator on immutable references, you can use the DerefMut trait to override the * operator on mutable references.the Drop trait is almost always used when implementing a smart pointer. For example, when a Box is dropped it will deallocate the space on the heap that the box points to. Note that we didn\u2019t need to call the drop method explicitly. - [\u2713] DST\u2022Or\u2022Unsizedtype \u00b6 DSTs or unsized types': str(but not &str-So although a &T is a single value that stores the memory address of where the T is located, a &str is two values: the address of the str and its length. Rust has a particular trait called the Sized trait to determine whether or not a type\u2019s size is known at compile time. This trait is automatically implemented for everything whose size is known at compile time. In addition, Rust implicitly adds a bound on Sized to every generic function. - [\u2713] Operation \u00b6 -> Methods are functions that are coupled to some object. From a syntactic point of view, these are just functions that don\u2019t need to specify one of their arguments. Rather than calling open() and passing a File object in as an argument (read(f, buffer)), methods allow the main object to be implicit in the function call (f.read(buffer)) using the dot operator. There are a number of theoretical differences between methods and functions, but a detailed discussion of those computer science topics is available in other books. Briefly, functions are regarded as pure, meaning their behavior is determined solely by their arguments. Methods are inherently impure, given that one of their arguments is effectively a side effect. These are muddy waters, though. Functions are perfectly capable of acting on side effects themselves. Moreover, methods are implemented with functions. And, to add an exception to an exception, objects sometimes implement static methods, which do not include implicit arguments. To define methods, Rust programmers use an impl block - [\u2713] Borrowchecker \u00b6 The borrow checker checks that all access to data is legal, which allows Rust to prevent safety issues. Learning how this works will, at the very least, speed up your development time by helping you avoid run-ins with the compiler. More significantly though, learning to work with the borrow checker allows you to build larger software systems with confidence. It underpins the term fearless concurrency. - [\u2713] Borrowchecker\u2022Lifetime \u00b6 -> Lifetime=Timetolive=Subset of their scope Make hypotheses about whether or not your experiments will pass the borrow checker before you compile reference in Rust has a lifetime, which is the scope for which that reference is valid. Most of the time, lifetimes are implicit and inferred, just like most of the time, types are inferred. We must annotate types when multiple types are possible. In a similar way, we must annotate lifetimes when the lifetimes of references could be related in a few different ways. The main aim of lifetimes is to prevent dangling references, which cause a program to reference data other than the data it\u2019s intended to reference. All references in Rust have a lifetime, even if they are not explicitly annotated. The compiler is capable of implicitly assigning lifetimes. A value\u2019s lifetime is the period when accessing that value is valid behavior. A function\u2019s local variables live until the function returns, while global variables might live for the life of the program. The notion of ownership is rather limited. An owner cleans up when its values\u2019 lifetimes end. Although every parameter has a lifetime, these checks are typically invisible as the compiler can infer most lifetimes by itself. All values bound to a given lifetime must live as long as the last access to any value bound to that lifetime. No lifetime annotations are required when calling a function. Lifetime annotations don\u2019t change how long any of the references live. Just as functions can accept any type when the signature specifies a generic type parameter, functions can accept references with any lifetime by specifying a generic lifetime parameter. Lifetime annotations describe the relationships of the lifetimes of multiple references to each other without affecting the lifetimes. The lifetime annotations indicate that the references first and second must both live as long as that generic lifetime. Lifetimes on function or method parameters are called input lifetimes, and lifetimes on return values are called output lifetimes. Although every parameter has a lifetime, these checks are typically invisible as the compiler can infer most lifetimes by itself All values bound to a given lifetime must live as long as the last access to any value bound to that lifetime. No lifetime annotations are required when calling a function. Using two lifetime parameters (a and b) indicates that the lifetimes of i and j are decoupled. fn add_with_lifetimes<'a, 'b>(i: &'a i32, j: &'b i32) -> i32 {} Lifetime of that usage: the LOC('existence time' or Line of code) between when a location is first used in a certain way, and when that usage stops. Lifetime of that value: the LOC (or actual time) between when a value is created, and when that value is dropped. Might be useful when discussing open file descriptors, but also irrelevant here. Ultimately, lifetime syntax is about connecting the lifetimes of various parameters and return values of functions. Once they\u2019re connected, Rust has enough information to allow memory-safe operations and disallow operations that would create dangling pointers or otherwise violate memory safety. - [\u2713] Dangle \u00b6 The main aim of lifetimes is to prevent dangling references.which has an outer scope and an inner scope. In return section of a function primitive types need to define as (&'a or &'static) - [\u2713] Generic \u00b6 You might be wondering whether there is a runtime cost when using generic type parameters. The good news is that using generic types won't make your run any slower than it would with concrete types. Rust accomplishes this by performing monomorphization of the code using generics at compile time. Monomorphization is the process of turning generic code into specific code by filling in the concrete types that are used when compile. Every programming language has tools for effectively handling the duplication of concepts. In Rust, one such tool is generics. Generics are abstract stand-ins for concrete types or other properties. When we\u2019re writing code, we can express the behavior of generics or how they relate to other generics without knowing what will be in their place when compiling and running the code. Static\u2022Dispatch(Passed) \u00b6 -> Monomorphization Dispatch is the mechanism to determine which specific version of code is actually run when it involves polymorphism. Two major forms of dispatch are static dispatch and dynamic dispatch. While Rust favors static dispatch, it also supports dynamic dispatch through a mechanism called \u2018trait objects\u2019. When Rust compiles this code, it performs monomorphization. The monomorphized version of the code looks like the following. The generic Option is replaced with the specific definitions created by the compiler: versions of a polymorphic function (or any polymorphic entity) during compilation is called Monomorphization. Because Rust compiles generic code into code that specifies the type in each instance, we pay no runtime cost for using generics. When the code runs, it performs just as it would if we had duplicated each definition by hand. The process of monomorphization makes Rust\u2019s generics extremely efficient at runtime. This is opposed to dynamic dispatch - [\u2713] Dynamic\u2022Dispatch \u00b6 The code that results from monomorphization is doing static dispatch, which is when the compiler knows what method you\u2019re calling at compile time. This is opposed to dynamic dispatch, which is when the compiler can\u2019t tell at compile time which method you\u2019re calling. In dynamic dispatch cases, the compiler emits code that at runtime will figure out which method to call. When we use trait objects, Rust must use dynamic dispatch. The compiler doesn\u2019t know all the types that might be used with the code that is using trait objects, so it doesn\u2019t know which method implemented on which type to call. Instead, at runtime, Rust uses the pointers inside the trait object to know which method to call. There is a runtime cost when this lookup happens that doesn\u2019t occur with static dispatch. Dynamic dispatch also prevents the compiler from choosing to inline a method\u2019s code, which in turn prevents some optimizations. - [-] Blanket\u2022Implementation \u00b6 Any implementation where a type appears uncovered. impl Foo for T, impl Bar for T, impl Bar > for T, and impl Bar for Vec are considered blanket impls. We can also conditionally implement a trait for any type that implements another trait. Implementations of a trait on any type that satisfies the trait bounds are called blanket implementations and are extensively used in the Rust standard library. For example, the standard library implements the ToString trait on any type that implements the Display trait. - [\u2713] Bound(syntax) \u00b6 Bounds are constraints on a type or trait. For example, if a bound is placed on the argument a function takes, types passed to that function must abide by that constraint. - [\u2713] Trait \u00b6 We can use traits to define shared behavior in an abstract way. We can use trait bounds to specify that a generic type can be any type that has certain behavior. Traits are similar to a feature often called interfaces in other languages, although with some differences. What is a trait? A trait is a language feature that is analogous to an interface, protocol, or contract. If you have a background in object-oriented programming, consider a trait to be an abstract base class. If you have a background in functional programming, Rust\u2019s traits are close to Haskell\u2019s type classes these also support a form of inheritance that\u2019s common in most object oriented languages. For now, though, the thing to remember is that traits represent common behavior (Or reusable codes like println!)that types opt into via the syntax impl Trait for Type. After the method signature, instead of providing an implementation within curly brackets, we use a semicolon. This interface consists of associated items, which come in three varieties: functions, types, constants. All traits define an implicit type parameter Self that refers to \"the type that is implementing this interface\". Trait functions may omit the function body by replacing it with a semicolon. This indicates that the implementation must define the function. If the trait function defines a body, this definition acts as a default for any implementation which does not override it. Similarly, associated constants may omit the equals sign and expression to indicate implementations must define the constant value. Associated types must never define the type, the type may only be specified in an implementation. - [\u2713] Polymorphism \u00b6 In a struct or enum, the data in the struct fields and the behavior in impl blocks are separated, whereas in other languages, the data and behavior combined into one concept is often labeled an object.However, trait objects are more like objects in other languages in the sense that they combine data and behavior. - [\u2713] Unrolling \u00b6 It is an optimization that removes the overhead of the loop controlling code and instead generates repetitive code for each iteration of the loop. - [\u2713] Binding\u2022Match \u00b6 The compiler automatically references the Some, and since we're borrowing, name is bound as ref name automatically as well. If we were mutating: //https://blog.rust-lang.org/2018/05/10/Rust-1.26.html#nicer-match-bindings // `self` has type `&List`, and `*self` has type `List`, matching on a // concrete type `T` is preferred over a match on a reference `&T` // after Rust 2018 you can use self here and tail (with no ref) below as well, // rust will infer &s and ref tail. - [\u2717] Datarace\u2022Rustaceans \u00b6 Note: The opposite of referencing by using & is dereferencing, which is accomplished with the dereference operator, *. [-] Nan(philosophy) \u00b6 Floating-point types include \u201cnot a number\u201d values (represented in Rust syntax as NAN values) to handle these cases. NAN values poison other numbers. Almost all operations interacting with NAN return NAN. Another thing to be mindful of is that, by definition, NAN values are never equal. Programming language design is often thought of in terms of which features you include, but the features you exclude are important too. Rust doesn\u2019t have the null feature that many other languages have. Null is a value that means there is no value there. In languages with null, variables can always be in one of two states: null or not-null. In his 2009 presentation \u201cNull References: The Billion Dollar Mistake,\u201d Tony Hoare, the inventor of null, has this to say: I call it my billion-dollar mistake. At that time, I was designing the first comprehensive type system for references in an object-oriented language. My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn\u2019t resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years. To program defensively, make use of the is_nan() and is_finite() methods. Inducing a crash, rather than silently proceeding with a mathematical error, allows you to debug close to what has caused the problem. The following illustrates using the is_finite() - [\u2713] Duplication((literal) \u00b6 Concept of copying the pointer, length, and capacity without copying the data probably sounds like making a shallow copy. If we do want to deeply copy the heap data of the String, not just the stack data, we can use a common method called clone - [\u2713] Semantic(literal) \u00b6 Primitive types are said to possess copy semantics, whereas all other types have move semantics. Adding more functionality (e.g., reference-counting semantics rather than move semantics) to types by wrapping these in other types typically reduces their run-time performance. - [\u2713] Zero\u2022Cost\u2022Abstractions(literal) \u00b6 One of the ways this manifests is by not adding extra data around values within structs. - [\u2713] Coherence(literal) \u00b6 -> Orphan = Trait\u2022External\u2022Implement But we can\u2019t implement external traits on external types. For example, we can\u2019t implement the Display trait on Vec within our aggregator crate, because Display and Vec are defined in the standard library and aren\u2019t local to our aggregator crate. This restriction is part of a property of programs called coherence, and more specifically the orphan rule, so named because the parent type is not present. This rule ensures that other people\u2019s code can\u2019t break your code and vice versa. Without the rule, two crates could implement the same trait for the same type, and Rust wouldn\u2019t know which implementation to use. Preserves contextual coherence of trace data from tasks/function/methods when logging. For example new instance of a struct of course, as you probably already know, struct then you can just summerize your struct in a method. - [\u2713] Jargon(literal) \u00b6 Functional programming jargon: \u201cto cons x onto y\u201d informally means to construct a new container instance by putting the element x at the start of this new container, followed by the container y.Other, more complex recursive data types are useful in various situations, but by starting with the cons list, we can explore how boxes let us define a recursive data type without much distraction. - [\u2713] Refactor(literal) \u00b6 One alternative to refactoring is to simply copy values. Doing this often is typically frowned upon, however, but it can be useful in a pinch. Primitive types like integers are a good example of that. Primitive types are cheap for a CPU to duplicate\u2014so cheap, in fact, that Rust always copies these if it would otherwise worry about ownership being moved. Types can opt into two modes of duplication: cloning and copying. - [\u2713] Pattern\u2022Newtype \u00b6 Using the Newtype Pattern to Implement External Traits on External Types 'thin wrapper around the type' : part of Vec is noticed. We can make a Wrapper struct that holds an instance of Vec ; then we can implement Display on Wrapper and use the Vec value The downside of using this technique is that Wrapper is a new type, so it doesn\u2019t have the methods of the value it\u2019s holding. We would have to implement all the methods of Vec directly on Wrapper such that the methods delegate to self.0, which would allow us to treat Wrapper exactly like a Vec . If we wanted the new type to have every method the inner type has, implementing the Deref trait (If we don\u2019t want the Wrapper type to have all the methods of the inner type\u2014for example, to restrict the Wrapper type\u2019s behavior\u2014we would have to implement just the methods we do want manually.) - [\u2717] Pattern\u2022Design\u2022Interior(future work) \u00b6 Interior mutability is a design pattern in Rust that allows you to mutate data even when there are immutable references to that data; normally, this action is disallowed by the borrowing rules. To mutate data, the pattern uses unsafe code inside a data structure to bend Rust\u2019s usual rules that govern mutation and borrowing. RefCell type that follows the interior mutability pattern. Unlike Rc , the RefCell type represents single ownership over the data it holds. So, what makes RefCell different from a type like Box ? Recall the borrowing rules... Similar to Rc , RefCell is only for use in single-threaded scenarios and will give you a compile-time error if you try using it in a multithreaded context. At any given time, you can have either (but not both of) one mutable reference or any number of immutable references.References must always be valid. - [\u2717] Type\u2022Wraper(future work) \u00b6 -> Wrapper type = Reference-Counted Value = Shared Ownership = Track valid references Use wrapper types, which allow more flexibility than what is available by default. These, however, incur costs at runtime to ensure that Rust\u2019s safety guarantees are maintained. Another way to phrase this is that Rust allows programmers to opt in to garbage collection. - [\u2717] Mem\u2022Leak(future work) \u00b6 -> Managing Memory Leak Rust\u2019s memory safety guarantees make it difficult, but not impossible, to accidentally create memory that is never cleaned up (known as a memory leak). Preventing memory leaks entirely is not one of Rust\u2019s guarantees in the same way that disallowing data races at compile time is, meaning memory leaks are memory safe in Rust. We can see that Rust allows memory leaks by using Rc and RefCell : it\u2019s possible to create references where items refer to each other in a cycle. This creates memory leaks because the reference count of each item in the cycle will never reach 0, and the values will never be dropped. - [\u2717] Mem\u2022Doublefree(future work) \u00b6 This is a problem: when s2 and s1 (s2 is copied s1 means 2different pointer and the same data) go out of scope, they will both try to free the same memory. This is known as a double free error and is one of the memory safety bugs we mentioned previously. Freeing memory twice can lead to memory corruption, which can potentially lead to security vulnerabilities. - [\u2717] Mem\u2022Deallocating\u2022or\u2022RAII(future work) \u00b6 Note: In C++, this pattern of deallocating resources at the end of an item\u2019s lifetime is sometimes called Resource Acquisition Is Initialization (RAII). The drop function in Rust will be familiar to you if you\u2019ve used RAII patterns. - [\u2717] Thread(future work) \u00b6 Which parts of your code on different threads will run. This can lead to problems, such as: Race conditions, where threads are accessing data or resources in an inconsistent order Deadlocks, where two threads are waiting for each other to finish using a resource the other thread has, preventing both threads from continuing Bugs that happen only in certain situations and are hard to reproduce and fix reliably. - [\u2717] Thread\u2022Strateges(future work) \u00b6 -> Priority Performance Stealing_Join: execute code in parallel when there are idle CPUs to handle it. When join is called from outside the thread pool, the calling thread will block while the closures execute in the pool. When join is called within the pool, the calling thread still actively participates in the thread pool. It will begin by executing closure A (on the current thread). While it is doing that, it will advertise closure B as being available for other threads to execute. Once closure A has completed, the current thread will try to execute closure B; if however closure B has been stolen, then it will look for other work while waiting for the thief to fully execute closure B. (This is the typical work-stealing strategy). Send is require because we have jump from quick func(thread a) to part func(thread b) frequently. Atomic: types provide primitive shared-memory communication between threads, and are the building blocks of other concurrent types. This module defines atomic versions of a select number of primitive types, including AtomicBool, AtomicIsize, AtomicUsize, AtomicI8, AtomicU16, etc. Atomic types present operations that, when used correctly, synchronize updates between threads. Each method takes an Ordering which represents the strength of the memory barrier for that operation. These orderings are the same as the C++20 atomic orderings. For more information see the nomicon. Atomic variables are safe to share between threads (they implement Sync) but they do not themselves provide the mechanism for sharing and follow the threading model of Rust. The most common way to share an atomic variable is to put it into an Arc (an atomically-reference-counted shared pointer). Atomic types may be stored in static variables, initialized using the constant initializers like AtomicBool::new. Atomic statics are often used for lazy global initialization. Spin_Loop_Yeild also known as busy loop and spin loop-If you want to sleep pause a thread for short amounts of time, or if your application is sensitive to timing, use a spin loop - [\u2717] Unsafe\u2022Extern\u2022Mangling(future work) \u00b6 > Mangling is when a compiler changes the name we\u2019ve given a function to a different name that contains more information for other parts of the compilation process to consume but is less human readable. Every programming language compiler mangles names slightly differently, so for a Rust function to be nameable by other languages, we must disable the Rust compiler\u2019s name mangling. - [\u2713] Interior\u2022Mutability\u2022Pattern \u00b6 RefCell : Lets us have many immutable borrows or one mutable borrow at any point in time. Mutating the value inside an immutable value is the interior mutability pattern. Interior mutability is a design pattern in Rust that allows you to mutate data even when there are immutable references to that data; normally, this action is disallowed by the borrowing rules. To mutate data, the pattern uses unsafe code inside a data structure to bend Rust\u2019s usual rules that govern mutation and borrowing. RefCell type that follows the interior mutability pattern. Unlike Rc , the RefCell type represents single ownership over the data it holds. So, what makes RefCell different from a type like Box ? Recall the borrowing rules, Similar to Rc , RefCell is only for use in single-threaded scenarios and will give you a compile-time error if you try using it in a multithreaded context. At any given time, you can have either (but not both of) one mutable reference or any number of immutable references.References must always be valid. - [\u2717] OOP\u2022State\u2022DesignPattern(future work) \u00b6 -> We can used it for smart contracts so we will need to implemented smart contracts Using the state pattern means when the business requirements of the program change, we won\u2019t need to change the code of the value holding the state or the code that uses the value. We\u2019ll only need to update the code inside one of the state objects to change its rules or perhaps add more state objects. e.g Post type. This type will use the state pattern and will hold a value that will be one of three state objects representing the various states a post can be in\u2014draft, waiting for review, or published. Changing from one state to another will be managed internally within the Post type. The states change in response to the methods called by our library\u2019s users on the Post instance, but they don\u2019t have to manage the state changes directly. Also, users can\u2019t make a mistake with the states, like publishing a post before it\u2019s reviewed. - [\u2717] Superpower(future work) \u00b6 if the Rust compiler doesn\u2019t have enough information to be confident, it will reject the code. In these cases, you can use unsafe code to tell the compiler, \u201cTrust me, I know what I\u2019m doing.\u201d The downside is that you use it at your own risk: if you use unsafe code incorrectly, problems due to memory unsafety, such as null pointer dereferencing, can occur. You can take five actions in unsafe Rust, called unsafe superpowers, that you can\u2019t in safe Rust. Those superpowers include the ability to: Dereference a raw pointer Call an unsafe function or method Access or modify a mutable static variable Implement an unsafe trait Access fields of unions Calling unsafe() would crash the program. consider unsafe to be a warning sign rather than an indicator that you\u2019re embarking on anything illegal. Unsafe means \u201cthe same level of safety offered by C at all times.\u201d If you still had access to (via unsafe) they might still look like valid S, but any attempt to use them as valid S is undefined behavior. \u2193 https://cheats.rs/#unsafe-unsound-undefined-dark side of force Try to avoid \"unsafe {}\", often safer, faster solution without it. Exception: FFI. People are fallible, and mistakes will happen, but by requiring these five unsafe operations to be inside blocks annotated with unsafe you\u2019ll know that any errors related to memory safety must be within an unsafe block. Keep unsafe blocks small; you\u2019ll be thankful later when you investigate memory bugs. To isolate unsafe code as much as possible, it\u2019s best to enclose unsafe code within a safe abstraction and provide a safe API, which we\u2019ll discuss later in the chapter when we examine unsafe functions and methods. Parts of the standard library are implemented as safe abstractions over unsafe code that has been audited. Wrapping unsafe code in a safe abstraction prevents uses of unsafe from leaking out into all the places that you or your users might want to use the functionality implemented with unsafe code, because using a safe abstraction is safe. Contributors \u00b6 nom is the fruit of the work of many contributors over the years, many thanks for your help! Contributors Thanks \u00b6 Convert string to u128 Solved Issues \u00b6 Convert-string-to-u128","title":"Rust scratch blockchain"},{"location":"public/programming/rust/rust-scratch-blockchain/#welcome-to-the-home-blockchain-of-rustaceans","text":"The repo is a prerequisite of the Substrate-Framework and it would be nicer to practice too. The repo is included Rust syntax, configuration and the goal of creating scratch codes like one is becuase of providing testbed environment of Blockchain . The Next reason is to using some features of Rust-Lang that I had wanted to implement it after learning Rust. Used json in the main runner of the project so that consume json transactions as a offchain blockchain. As you follow materials you can see (future work) which means you can add these concepts to the project. I have some idea that you can affort on it to completing future works. Smart Contracts, MultiSignature, RPC, Make A Better CLI, and something that you can implementing (Do not worry sice most of your works will merge to main branch. We will not create a framework or complete Blockchain because we just need to learning more and used it use-cases)","title":"Welcome To The Home Blockchain Of \ud83e\udd80Rustaceans"},{"location":"public/programming/rust/rust-scratch-blockchain/#the-difference-between-the-current-work-and-the-prev-works","text":"I have tried to use fundamental concepts correctly, for example, all of us know any block have not any copy so because of it we are calling blockchain! Unlike many repositories on GitHub(testbed/scratched projects-non productive) that almost use Copy/Clone features of Rust-Lang. In the following, there are some features that cause a different project. Currently Status: Under Refactoring","title":"The difference between the current work and the prev works"},{"location":"public/programming/rust/rust-scratch-blockchain/#how-to-contribute-easy","text":"[Rust 2021 A Scratch Blockchain-1] Youtube-Rust 2021 A Scratch Blockchain-1 Rust 2021 A Scratch Blockchain-2 Youtube-Rust 2021 A Scratch Blockchain-2","title":"How To Contribute Easy"},{"location":"public/programming/rust/rust-scratch-blockchain/#instructions-for-working-with","text":"DIFFICULTY={difficulty} cargo {mode} {file name} {difficulty}: (optional-key-env) value default 0x00ffffffffffffffffffffffffffffff.It must be 32 byte. {mode}: macro, string, file/ default mode is on the macrojson mode. {macro, string} there is in project and you can not access or manipulate except by getting the project. serde_json support string and macro based on called library. {file} json file is external .json file that you can set it for command line {file name} index directory of the project sample-bolocks.json Example: cargo build DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run file sample-bolocks.json DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run macrojson DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run stringjson time cargo run cargo watch -x run Using time and watch is optional and depends on your purpose","title":"Instructions for working with"},{"location":"public/programming/rust/rust-scratch-blockchain/#features","text":"[\u2713] Modular [\u2713] UnitTest(semi:future work) [\u2713] Customized Error Handling [\u2713] Json & String Data Deserialized [\u2713] Closure(Functional Programming) [\u2713] Cryptography-Hashing Alogrithm SHA-256 [\u2713] Configuration Files(semi- devOps)","title":"Features"},{"location":"public/programming/rust/rust-scratch-blockchain/#used-concepts","text":"","title":"Used Concepts"},{"location":"public/programming/rust/rust-scratch-blockchain/#-memoizationlazyevaluation","text":"We can create a struct that will hold the closure and the resulting value of calling the closure. The struct will execute the closure only if we need the resulting value, and it will cache the resulting value so the rest of our code doesn\u2019t have to be responsible for saving and reusing the result. FnOnce consumes the variables it captures from its enclosing scope, known as the closure\u2019s environment. To consume the captured variables, the closure must take ownership of these variables and move them into the closure when it is defined. The Once part of the name represents the fact that the closure can\u2019t take ownership of the same variables more than once, so it can be called only once. FnMut can change the environment because it mutably borrows values. Fn borrows values from the environment immutably. FnOnce: takes the whole value. FnMut: takes a mutable reference. Fn: takes a regular reference.","title":"- [\u2713] Memoization\u2022Lazy\u2022Evaluation"},{"location":"public/programming/rust/rust-scratch-blockchain/#-coercion","text":"Deref coercion is a convenience that Rust performs on arguments to functions and methods. Deref coercion works only on types that implement the Deref trait. Deref coercion converts such a type into a reference to another type. For example, deref coercion can convert &String to &str because String implements the Deref trait such that it returns &str. The number of times that Deref::deref needs to be inserted is resolved at compile time, so there is no runtime penalty for taking advantage of deref coercion! Similar to how you use the Deref trait to override the * operator on immutable references, you can use the DerefMut trait to override the * operator on mutable references.the Drop trait is almost always used when implementing a smart pointer. For example, when a Box is dropped it will deallocate the space on the heap that the box points to. Note that we didn\u2019t need to call the drop method explicitly.","title":"- [\u2713] Coercion"},{"location":"public/programming/rust/rust-scratch-blockchain/#-dstorunsizedtype","text":"DSTs or unsized types': str(but not &str-So although a &T is a single value that stores the memory address of where the T is located, a &str is two values: the address of the str and its length. Rust has a particular trait called the Sized trait to determine whether or not a type\u2019s size is known at compile time. This trait is automatically implemented for everything whose size is known at compile time. In addition, Rust implicitly adds a bound on Sized to every generic function.","title":"- [\u2713] DST\u2022Or\u2022Unsizedtype"},{"location":"public/programming/rust/rust-scratch-blockchain/#-operation","text":"-> Methods are functions that are coupled to some object. From a syntactic point of view, these are just functions that don\u2019t need to specify one of their arguments. Rather than calling open() and passing a File object in as an argument (read(f, buffer)), methods allow the main object to be implicit in the function call (f.read(buffer)) using the dot operator. There are a number of theoretical differences between methods and functions, but a detailed discussion of those computer science topics is available in other books. Briefly, functions are regarded as pure, meaning their behavior is determined solely by their arguments. Methods are inherently impure, given that one of their arguments is effectively a side effect. These are muddy waters, though. Functions are perfectly capable of acting on side effects themselves. Moreover, methods are implemented with functions. And, to add an exception to an exception, objects sometimes implement static methods, which do not include implicit arguments. To define methods, Rust programmers use an impl block","title":"- [\u2713] Operation"},{"location":"public/programming/rust/rust-scratch-blockchain/#-borrowchecker","text":"The borrow checker checks that all access to data is legal, which allows Rust to prevent safety issues. Learning how this works will, at the very least, speed up your development time by helping you avoid run-ins with the compiler. More significantly though, learning to work with the borrow checker allows you to build larger software systems with confidence. It underpins the term fearless concurrency.","title":"- [\u2713] Borrowchecker"},{"location":"public/programming/rust/rust-scratch-blockchain/#-borrowcheckerlifetime","text":"-> Lifetime=Timetolive=Subset of their scope Make hypotheses about whether or not your experiments will pass the borrow checker before you compile reference in Rust has a lifetime, which is the scope for which that reference is valid. Most of the time, lifetimes are implicit and inferred, just like most of the time, types are inferred. We must annotate types when multiple types are possible. In a similar way, we must annotate lifetimes when the lifetimes of references could be related in a few different ways. The main aim of lifetimes is to prevent dangling references, which cause a program to reference data other than the data it\u2019s intended to reference. All references in Rust have a lifetime, even if they are not explicitly annotated. The compiler is capable of implicitly assigning lifetimes. A value\u2019s lifetime is the period when accessing that value is valid behavior. A function\u2019s local variables live until the function returns, while global variables might live for the life of the program. The notion of ownership is rather limited. An owner cleans up when its values\u2019 lifetimes end. Although every parameter has a lifetime, these checks are typically invisible as the compiler can infer most lifetimes by itself. All values bound to a given lifetime must live as long as the last access to any value bound to that lifetime. No lifetime annotations are required when calling a function. Lifetime annotations don\u2019t change how long any of the references live. Just as functions can accept any type when the signature specifies a generic type parameter, functions can accept references with any lifetime by specifying a generic lifetime parameter. Lifetime annotations describe the relationships of the lifetimes of multiple references to each other without affecting the lifetimes. The lifetime annotations indicate that the references first and second must both live as long as that generic lifetime. Lifetimes on function or method parameters are called input lifetimes, and lifetimes on return values are called output lifetimes. Although every parameter has a lifetime, these checks are typically invisible as the compiler can infer most lifetimes by itself All values bound to a given lifetime must live as long as the last access to any value bound to that lifetime. No lifetime annotations are required when calling a function. Using two lifetime parameters (a and b) indicates that the lifetimes of i and j are decoupled. fn add_with_lifetimes<'a, 'b>(i: &'a i32, j: &'b i32) -> i32 {} Lifetime of that usage: the LOC('existence time' or Line of code) between when a location is first used in a certain way, and when that usage stops. Lifetime of that value: the LOC (or actual time) between when a value is created, and when that value is dropped. Might be useful when discussing open file descriptors, but also irrelevant here. Ultimately, lifetime syntax is about connecting the lifetimes of various parameters and return values of functions. Once they\u2019re connected, Rust has enough information to allow memory-safe operations and disallow operations that would create dangling pointers or otherwise violate memory safety.","title":"- [\u2713] Borrowchecker\u2022Lifetime"},{"location":"public/programming/rust/rust-scratch-blockchain/#-dangle","text":"The main aim of lifetimes is to prevent dangling references.which has an outer scope and an inner scope. In return section of a function primitive types need to define as (&'a or &'static)","title":"- [\u2713] Dangle"},{"location":"public/programming/rust/rust-scratch-blockchain/#-generic","text":"You might be wondering whether there is a runtime cost when using generic type parameters. The good news is that using generic types won't make your run any slower than it would with concrete types. Rust accomplishes this by performing monomorphization of the code using generics at compile time. Monomorphization is the process of turning generic code into specific code by filling in the concrete types that are used when compile. Every programming language has tools for effectively handling the duplication of concepts. In Rust, one such tool is generics. Generics are abstract stand-ins for concrete types or other properties. When we\u2019re writing code, we can express the behavior of generics or how they relate to other generics without knowing what will be in their place when compiling and running the code.","title":"- [\u2713] Generic"},{"location":"public/programming/rust/rust-scratch-blockchain/#staticdispatchpassed","text":"-> Monomorphization Dispatch is the mechanism to determine which specific version of code is actually run when it involves polymorphism. Two major forms of dispatch are static dispatch and dynamic dispatch. While Rust favors static dispatch, it also supports dynamic dispatch through a mechanism called \u2018trait objects\u2019. When Rust compiles this code, it performs monomorphization. The monomorphized version of the code looks like the following. The generic Option is replaced with the specific definitions created by the compiler: versions of a polymorphic function (or any polymorphic entity) during compilation is called Monomorphization. Because Rust compiles generic code into code that specifies the type in each instance, we pay no runtime cost for using generics. When the code runs, it performs just as it would if we had duplicated each definition by hand. The process of monomorphization makes Rust\u2019s generics extremely efficient at runtime. This is opposed to dynamic dispatch","title":"Static\u2022Dispatch(Passed)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-dynamicdispatch","text":"The code that results from monomorphization is doing static dispatch, which is when the compiler knows what method you\u2019re calling at compile time. This is opposed to dynamic dispatch, which is when the compiler can\u2019t tell at compile time which method you\u2019re calling. In dynamic dispatch cases, the compiler emits code that at runtime will figure out which method to call. When we use trait objects, Rust must use dynamic dispatch. The compiler doesn\u2019t know all the types that might be used with the code that is using trait objects, so it doesn\u2019t know which method implemented on which type to call. Instead, at runtime, Rust uses the pointers inside the trait object to know which method to call. There is a runtime cost when this lookup happens that doesn\u2019t occur with static dispatch. Dynamic dispatch also prevents the compiler from choosing to inline a method\u2019s code, which in turn prevents some optimizations.","title":"- [\u2713] Dynamic\u2022Dispatch"},{"location":"public/programming/rust/rust-scratch-blockchain/#-blanketimplementation","text":"Any implementation where a type appears uncovered. impl Foo for T, impl Bar for T, impl Bar > for T, and impl Bar for Vec are considered blanket impls. We can also conditionally implement a trait for any type that implements another trait. Implementations of a trait on any type that satisfies the trait bounds are called blanket implementations and are extensively used in the Rust standard library. For example, the standard library implements the ToString trait on any type that implements the Display trait.","title":"- [-] Blanket\u2022Implementation"},{"location":"public/programming/rust/rust-scratch-blockchain/#-boundsyntax","text":"Bounds are constraints on a type or trait. For example, if a bound is placed on the argument a function takes, types passed to that function must abide by that constraint.","title":"- [\u2713] Bound(syntax)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-trait","text":"We can use traits to define shared behavior in an abstract way. We can use trait bounds to specify that a generic type can be any type that has certain behavior. Traits are similar to a feature often called interfaces in other languages, although with some differences. What is a trait? A trait is a language feature that is analogous to an interface, protocol, or contract. If you have a background in object-oriented programming, consider a trait to be an abstract base class. If you have a background in functional programming, Rust\u2019s traits are close to Haskell\u2019s type classes these also support a form of inheritance that\u2019s common in most object oriented languages. For now, though, the thing to remember is that traits represent common behavior (Or reusable codes like println!)that types opt into via the syntax impl Trait for Type. After the method signature, instead of providing an implementation within curly brackets, we use a semicolon. This interface consists of associated items, which come in three varieties: functions, types, constants. All traits define an implicit type parameter Self that refers to \"the type that is implementing this interface\". Trait functions may omit the function body by replacing it with a semicolon. This indicates that the implementation must define the function. If the trait function defines a body, this definition acts as a default for any implementation which does not override it. Similarly, associated constants may omit the equals sign and expression to indicate implementations must define the constant value. Associated types must never define the type, the type may only be specified in an implementation.","title":"- [\u2713] Trait"},{"location":"public/programming/rust/rust-scratch-blockchain/#-polymorphism","text":"In a struct or enum, the data in the struct fields and the behavior in impl blocks are separated, whereas in other languages, the data and behavior combined into one concept is often labeled an object.However, trait objects are more like objects in other languages in the sense that they combine data and behavior.","title":"- [\u2713] Polymorphism"},{"location":"public/programming/rust/rust-scratch-blockchain/#-unrolling","text":"It is an optimization that removes the overhead of the loop controlling code and instead generates repetitive code for each iteration of the loop.","title":"- [\u2713] Unrolling"},{"location":"public/programming/rust/rust-scratch-blockchain/#-bindingmatch","text":"The compiler automatically references the Some, and since we're borrowing, name is bound as ref name automatically as well. If we were mutating: //https://blog.rust-lang.org/2018/05/10/Rust-1.26.html#nicer-match-bindings // `self` has type `&List`, and `*self` has type `List`, matching on a // concrete type `T` is preferred over a match on a reference `&T` // after Rust 2018 you can use self here and tail (with no ref) below as well, // rust will infer &s and ref tail.","title":"- [\u2713] Binding\u2022Match"},{"location":"public/programming/rust/rust-scratch-blockchain/#-dataracerustaceans","text":"Note: The opposite of referencing by using & is dereferencing, which is accomplished with the dereference operator, *.","title":"- [\u2717] Datarace\u2022Rustaceans"},{"location":"public/programming/rust/rust-scratch-blockchain/#-nanphilosophy","text":"Floating-point types include \u201cnot a number\u201d values (represented in Rust syntax as NAN values) to handle these cases. NAN values poison other numbers. Almost all operations interacting with NAN return NAN. Another thing to be mindful of is that, by definition, NAN values are never equal. Programming language design is often thought of in terms of which features you include, but the features you exclude are important too. Rust doesn\u2019t have the null feature that many other languages have. Null is a value that means there is no value there. In languages with null, variables can always be in one of two states: null or not-null. In his 2009 presentation \u201cNull References: The Billion Dollar Mistake,\u201d Tony Hoare, the inventor of null, has this to say: I call it my billion-dollar mistake. At that time, I was designing the first comprehensive type system for references in an object-oriented language. My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn\u2019t resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years. To program defensively, make use of the is_nan() and is_finite() methods. Inducing a crash, rather than silently proceeding with a mathematical error, allows you to debug close to what has caused the problem. The following illustrates using the is_finite()","title":"[-] Nan(philosophy)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-duplicationliteral","text":"Concept of copying the pointer, length, and capacity without copying the data probably sounds like making a shallow copy. If we do want to deeply copy the heap data of the String, not just the stack data, we can use a common method called clone","title":"- [\u2713] Duplication((literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-semanticliteral","text":"Primitive types are said to possess copy semantics, whereas all other types have move semantics. Adding more functionality (e.g., reference-counting semantics rather than move semantics) to types by wrapping these in other types typically reduces their run-time performance.","title":"- [\u2713] Semantic(literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-zerocostabstractionsliteral","text":"One of the ways this manifests is by not adding extra data around values within structs.","title":"- [\u2713] Zero\u2022Cost\u2022Abstractions(literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-coherenceliteral","text":"-> Orphan = Trait\u2022External\u2022Implement But we can\u2019t implement external traits on external types. For example, we can\u2019t implement the Display trait on Vec within our aggregator crate, because Display and Vec are defined in the standard library and aren\u2019t local to our aggregator crate. This restriction is part of a property of programs called coherence, and more specifically the orphan rule, so named because the parent type is not present. This rule ensures that other people\u2019s code can\u2019t break your code and vice versa. Without the rule, two crates could implement the same trait for the same type, and Rust wouldn\u2019t know which implementation to use. Preserves contextual coherence of trace data from tasks/function/methods when logging. For example new instance of a struct of course, as you probably already know, struct then you can just summerize your struct in a method.","title":"- [\u2713] Coherence(literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-jargonliteral","text":"Functional programming jargon: \u201cto cons x onto y\u201d informally means to construct a new container instance by putting the element x at the start of this new container, followed by the container y.Other, more complex recursive data types are useful in various situations, but by starting with the cons list, we can explore how boxes let us define a recursive data type without much distraction.","title":"- [\u2713] Jargon(literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-refactorliteral","text":"One alternative to refactoring is to simply copy values. Doing this often is typically frowned upon, however, but it can be useful in a pinch. Primitive types like integers are a good example of that. Primitive types are cheap for a CPU to duplicate\u2014so cheap, in fact, that Rust always copies these if it would otherwise worry about ownership being moved. Types can opt into two modes of duplication: cloning and copying.","title":"- [\u2713] Refactor(literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-patternnewtype","text":"Using the Newtype Pattern to Implement External Traits on External Types 'thin wrapper around the type' : part of Vec is noticed. We can make a Wrapper struct that holds an instance of Vec ; then we can implement Display on Wrapper and use the Vec value The downside of using this technique is that Wrapper is a new type, so it doesn\u2019t have the methods of the value it\u2019s holding. We would have to implement all the methods of Vec directly on Wrapper such that the methods delegate to self.0, which would allow us to treat Wrapper exactly like a Vec . If we wanted the new type to have every method the inner type has, implementing the Deref trait (If we don\u2019t want the Wrapper type to have all the methods of the inner type\u2014for example, to restrict the Wrapper type\u2019s behavior\u2014we would have to implement just the methods we do want manually.)","title":"- [\u2713] Pattern\u2022Newtype"},{"location":"public/programming/rust/rust-scratch-blockchain/#-patterndesigninteriorfuture-work","text":"Interior mutability is a design pattern in Rust that allows you to mutate data even when there are immutable references to that data; normally, this action is disallowed by the borrowing rules. To mutate data, the pattern uses unsafe code inside a data structure to bend Rust\u2019s usual rules that govern mutation and borrowing. RefCell type that follows the interior mutability pattern. Unlike Rc , the RefCell type represents single ownership over the data it holds. So, what makes RefCell different from a type like Box ? Recall the borrowing rules... Similar to Rc , RefCell is only for use in single-threaded scenarios and will give you a compile-time error if you try using it in a multithreaded context. At any given time, you can have either (but not both of) one mutable reference or any number of immutable references.References must always be valid.","title":"- [\u2717] Pattern\u2022Design\u2022Interior(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-typewraperfuture-work","text":"-> Wrapper type = Reference-Counted Value = Shared Ownership = Track valid references Use wrapper types, which allow more flexibility than what is available by default. These, however, incur costs at runtime to ensure that Rust\u2019s safety guarantees are maintained. Another way to phrase this is that Rust allows programmers to opt in to garbage collection.","title":"- [\u2717] Type\u2022Wraper(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-memleakfuture-work","text":"-> Managing Memory Leak Rust\u2019s memory safety guarantees make it difficult, but not impossible, to accidentally create memory that is never cleaned up (known as a memory leak). Preventing memory leaks entirely is not one of Rust\u2019s guarantees in the same way that disallowing data races at compile time is, meaning memory leaks are memory safe in Rust. We can see that Rust allows memory leaks by using Rc and RefCell : it\u2019s possible to create references where items refer to each other in a cycle. This creates memory leaks because the reference count of each item in the cycle will never reach 0, and the values will never be dropped.","title":"- [\u2717] Mem\u2022Leak(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-memdoublefreefuture-work","text":"This is a problem: when s2 and s1 (s2 is copied s1 means 2different pointer and the same data) go out of scope, they will both try to free the same memory. This is known as a double free error and is one of the memory safety bugs we mentioned previously. Freeing memory twice can lead to memory corruption, which can potentially lead to security vulnerabilities.","title":"- [\u2717] Mem\u2022Doublefree(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-memdeallocatingorraiifuture-work","text":"Note: In C++, this pattern of deallocating resources at the end of an item\u2019s lifetime is sometimes called Resource Acquisition Is Initialization (RAII). The drop function in Rust will be familiar to you if you\u2019ve used RAII patterns.","title":"- [\u2717] Mem\u2022Deallocating\u2022or\u2022RAII(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-threadfuture-work","text":"Which parts of your code on different threads will run. This can lead to problems, such as: Race conditions, where threads are accessing data or resources in an inconsistent order Deadlocks, where two threads are waiting for each other to finish using a resource the other thread has, preventing both threads from continuing Bugs that happen only in certain situations and are hard to reproduce and fix reliably.","title":"- [\u2717] Thread(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-threadstrategesfuture-work","text":"-> Priority Performance Stealing_Join: execute code in parallel when there are idle CPUs to handle it. When join is called from outside the thread pool, the calling thread will block while the closures execute in the pool. When join is called within the pool, the calling thread still actively participates in the thread pool. It will begin by executing closure A (on the current thread). While it is doing that, it will advertise closure B as being available for other threads to execute. Once closure A has completed, the current thread will try to execute closure B; if however closure B has been stolen, then it will look for other work while waiting for the thief to fully execute closure B. (This is the typical work-stealing strategy). Send is require because we have jump from quick func(thread a) to part func(thread b) frequently. Atomic: types provide primitive shared-memory communication between threads, and are the building blocks of other concurrent types. This module defines atomic versions of a select number of primitive types, including AtomicBool, AtomicIsize, AtomicUsize, AtomicI8, AtomicU16, etc. Atomic types present operations that, when used correctly, synchronize updates between threads. Each method takes an Ordering which represents the strength of the memory barrier for that operation. These orderings are the same as the C++20 atomic orderings. For more information see the nomicon. Atomic variables are safe to share between threads (they implement Sync) but they do not themselves provide the mechanism for sharing and follow the threading model of Rust. The most common way to share an atomic variable is to put it into an Arc (an atomically-reference-counted shared pointer). Atomic types may be stored in static variables, initialized using the constant initializers like AtomicBool::new. Atomic statics are often used for lazy global initialization. Spin_Loop_Yeild also known as busy loop and spin loop-If you want to sleep pause a thread for short amounts of time, or if your application is sensitive to timing, use a spin loop","title":"- [\u2717] Thread\u2022Strateges(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-unsafeexternmanglingfuture-work","text":"> Mangling is when a compiler changes the name we\u2019ve given a function to a different name that contains more information for other parts of the compilation process to consume but is less human readable. Every programming language compiler mangles names slightly differently, so for a Rust function to be nameable by other languages, we must disable the Rust compiler\u2019s name mangling.","title":"- [\u2717] Unsafe\u2022Extern\u2022Mangling(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-interiormutabilitypattern","text":"RefCell : Lets us have many immutable borrows or one mutable borrow at any point in time. Mutating the value inside an immutable value is the interior mutability pattern. Interior mutability is a design pattern in Rust that allows you to mutate data even when there are immutable references to that data; normally, this action is disallowed by the borrowing rules. To mutate data, the pattern uses unsafe code inside a data structure to bend Rust\u2019s usual rules that govern mutation and borrowing. RefCell type that follows the interior mutability pattern. Unlike Rc , the RefCell type represents single ownership over the data it holds. So, what makes RefCell different from a type like Box ? Recall the borrowing rules, Similar to Rc , RefCell is only for use in single-threaded scenarios and will give you a compile-time error if you try using it in a multithreaded context. At any given time, you can have either (but not both of) one mutable reference or any number of immutable references.References must always be valid.","title":"- [\u2713] Interior\u2022Mutability\u2022Pattern"},{"location":"public/programming/rust/rust-scratch-blockchain/#-oopstatedesignpatternfuture-work","text":"-> We can used it for smart contracts so we will need to implemented smart contracts Using the state pattern means when the business requirements of the program change, we won\u2019t need to change the code of the value holding the state or the code that uses the value. We\u2019ll only need to update the code inside one of the state objects to change its rules or perhaps add more state objects. e.g Post type. This type will use the state pattern and will hold a value that will be one of three state objects representing the various states a post can be in\u2014draft, waiting for review, or published. Changing from one state to another will be managed internally within the Post type. The states change in response to the methods called by our library\u2019s users on the Post instance, but they don\u2019t have to manage the state changes directly. Also, users can\u2019t make a mistake with the states, like publishing a post before it\u2019s reviewed.","title":"- [\u2717] OOP\u2022State\u2022DesignPattern(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-superpowerfuture-work","text":"if the Rust compiler doesn\u2019t have enough information to be confident, it will reject the code. In these cases, you can use unsafe code to tell the compiler, \u201cTrust me, I know what I\u2019m doing.\u201d The downside is that you use it at your own risk: if you use unsafe code incorrectly, problems due to memory unsafety, such as null pointer dereferencing, can occur. You can take five actions in unsafe Rust, called unsafe superpowers, that you can\u2019t in safe Rust. Those superpowers include the ability to: Dereference a raw pointer Call an unsafe function or method Access or modify a mutable static variable Implement an unsafe trait Access fields of unions Calling unsafe() would crash the program. consider unsafe to be a warning sign rather than an indicator that you\u2019re embarking on anything illegal. Unsafe means \u201cthe same level of safety offered by C at all times.\u201d If you still had access to (via unsafe) they might still look like valid S, but any attempt to use them as valid S is undefined behavior. \u2193 https://cheats.rs/#unsafe-unsound-undefined-dark side of force Try to avoid \"unsafe {}\", often safer, faster solution without it. Exception: FFI. People are fallible, and mistakes will happen, but by requiring these five unsafe operations to be inside blocks annotated with unsafe you\u2019ll know that any errors related to memory safety must be within an unsafe block. Keep unsafe blocks small; you\u2019ll be thankful later when you investigate memory bugs. To isolate unsafe code as much as possible, it\u2019s best to enclose unsafe code within a safe abstraction and provide a safe API, which we\u2019ll discuss later in the chapter when we examine unsafe functions and methods. Parts of the standard library are implemented as safe abstractions over unsafe code that has been audited. Wrapping unsafe code in a safe abstraction prevents uses of unsafe from leaking out into all the places that you or your users might want to use the functionality implemented with unsafe code, because using a safe abstraction is safe.","title":"- [\u2717] Superpower(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#contributors","text":"nom is the fruit of the work of many contributors over the years, many thanks for your help! Contributors","title":"Contributors"},{"location":"public/programming/rust/rust-scratch-blockchain/#welcome-to-the-home-blockchain-of-rustaceans_1","text":"The repo is a prerequisite of the Substrate-Framework and it would be nicer to practice too. The repo is included Rust syntax, configuration and the goal of creating scratch codes like one is becuase of providing testbed environment of Blockchain . The Next reason is to using some features of Rust-Lang that I had wanted to implement it after learning Rust. Used json in the main runner of the project so that consume json transactions as a offchain blockchain. As you follow materials you can see (future work) which means you can add these concepts to the project. I have some idea that you can affort on it to completing future works. Smart Contracts, MultiSignature, RPC, Make A Better CLI, and something that you can implementing (Do not worry sice most of your works will merge to main branch. We will not create a framework or complete Blockchain because we just need to learning more and used it use-cases)","title":"Welcome To The Home Blockchain Of \ud83e\udd80Rustaceans"},{"location":"public/programming/rust/rust-scratch-blockchain/#the-difference-between-the-current-work-and-the-prev-works_1","text":"I have tried to use fundamental concepts correctly, for example, all of us know any block have not any copy so because of it we are calling blockchain! Unlike many repositories on GitHub(testbed/scratched projects-non productive) that almost use Copy/Clone attributes of Rust-Lang for creating block. In the following, there are some features that cause a different project. Currently Status: Under refactoring with contributors","title":"The difference between the current work and the prev works"},{"location":"public/programming/rust/rust-scratch-blockchain/#how-to-contribute-easy_1","text":"[Rust 2021 A Scratch Blockchain-1] Youtube-Rust 2021 A Scratch Blockchain-1 Rust 2021 A Scratch Blockchain-2 Youtube-Rust 2021 A Scratch Blockchain-2","title":"How To Contribute Easy"},{"location":"public/programming/rust/rust-scratch-blockchain/#documents-crate","text":"Docs.rs Package Manager crates.io","title":"Documents Crate"},{"location":"public/programming/rust/rust-scratch-blockchain/#features_1","text":"[\u2713] Modular [\u2713] Customized Error Handling [\u2713] Json & String Data Deserialized [\u2713] Functional Programming(Closure) [\u2713] Cryptography-Hashing Alogrithm SHA-256 [-] WebAssembly(Next future video) [-] Unit & Integration Testing(structure-need more time in the future) [-] Configuration Files(devOps-need more time in the future)","title":"Features"},{"location":"public/programming/rust/rust-scratch-blockchain/#instructions-for-working-with_1","text":"DIFFICULTY={difficulty} cargo {mode} {file name} {difficulty}: (optional-key-env) value default 0x00ffffffffffffffffffffffffffffff.It must be 32 byte. {mode}: macro, string, file/ default mode is on the macrojson mode. {macro, string} there is in project and you can not access or manipulate except by getting the project. serde_json support string and macro based on called library. {file} json file is external .json file that you can set it for command line {file name} index directory of the project sample-bolocks.json Example: cargo build cargo run RUST_LOG=INFO DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run file sample-bolocks.json DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run macrojson DIFFICULTY=0x00000fffffffffffffffffffffffffff time cargo run stringjson time cargo run cargo watch -x run cargo test Using time and watch is optional and depends on your purpose","title":"Instructions for working with"},{"location":"public/programming/rust/rust-scratch-blockchain/#instructions-for-installing-bin","text":"curl -LSfs https://github.com/armanriazi/armanriazi/blob/main/install-0.sh | sh -s -- --git armanriazi/rust-scratch-blockchain","title":"Instructions for installing-bin"},{"location":"public/programming/rust/rust-scratch-blockchain/#how-to-consume-the-library","text":"1. cargo new yourprojectname 2. Add new dependency [dependencies] blockchain-scratch-rust = \"0.3.0\" 3. To update dependencies cargo update 4. Your main.rs of the program use library_blockchain::*; fn main() { println!(\"Hello, world!\"); library_blockchain::blockchain_executive::main(); } 5. Due to the file sample-three-block-noerror.json in the repo you might copy it and manipulate it, in spite of that you can use generators of your database or ORMs for producing a file.json as the same as following content. Get attention to keys in the file for example we must have transaction{number} and if we write 'mytransaction 1' and run it we will get error. Json File { \"blocks\":[{ \"block1\":[{ \"transactions\":[{ \"transaction1\":[{ \"inputs\":[{ }], \"outputs\":[{ \"to_addr\": \"Alice\", \"value\": \"50\" },{ \"to_addr\": \"Bob\", \"value\": \"7\" }] }] }] }] , \"block2\":[{ \"transactions\":[{ \"transaction1\":[{ \"inputs\":[{ }], \"outputs\":[{ \"to_addr\": \"Chris\", \"value\": \"536\" }] }], \"transaction2\":[{ \"inputs\":[{ \"to_addr\": \"Alice\", \"value\": \"50\" },{ \"to_addr\": \"Bob\", \"value\": \"7\" }], \"outputs\":[{ \"to_addr\": \"Alice\", \"value\": \"49\" },{ \"to_addr\": \"Bob\", \"value\": \"6\" }] }] }] }], \"block3\":[{ \"transactions\":[{ \"transaction1\":[{ \"inputs\":[{ }], \"outputs\":[{ \"to_addr\": \"Alice\", \"value\": \"49\" },{ \"to_addr\": \"Bob\", \"value\": \"6\" }] }] }] }] }] } Run of one of above commands. RUST_LOG=info DIFFICULTY=0x0000ffffffffffffffffffffffffffff time cargo run file sample-three-block-noerror.json 7. Everything is Ok and it is working fine. Console Log Finished dev [unoptimized + debuginfo] target(s) in 0.07s Running `target/debug/consume-rust-scratch-blockchain file sample-three-block-noerror.json` Hello, world! [2022-07-06T13:30:22Z INFO library_blockchain::blockchain_executive] ------------Welcome to env_logger------------ [2022-07-06T13:30:22Z INFO library_blockchain::blockchain_executive] Starting Up... ************************************************************** Selected mode is file! **BlOcKcHaIn SiGnAls:** Block[0]: 17b9180cd95fef6c0e8ab81702ab9cfd835b4af373fdc7ee45d13cba69c40000 at: 1657114222903 with: 1 trx, nonce: 131263 [2022-07-06T13:30:24Z INFO library_blockchain::factory] Success updated With the block 1. **BlOcKcHaIn SiGnAls:** Block[1]: eeb73730eb18ef3efbadbe7b5f3cc1a07c0d97b6c97e7df8945e61089b280000 at: 1657114224538 with: 2 trx, nonce: 257740 [2022-07-06T13:30:30Z INFO library_blockchain::factory] Success updated With the block 2. **BlOcKcHaIn SiGnAls:** Block[2]: 3674f23d58002856c17816590f7e2ff195005ad477c67e704d61eead25710000 at: 1657114230226 with: 1 trx, nonce: 37407 [2022-07-06T13:30:30Z INFO library_blockchain::factory] Success updated With the block 3. 7.67user 0.16system 0:08.03elapsed 97%CPU (0avgtext+0avgdata 25300maxresident)k 2280inputs+0outputs (13major+6505minor)pagefaults 0swaps","title":"How to consume the library"},{"location":"public/programming/rust/rust-scratch-blockchain/#wasmfuture-work","text":"For consume the library we used some WASM compiling strategy: Bindgen Wasmer-LLVM Wasmer-Wasi Binary of rust-scratch-blockchain","title":"WASM(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#used-concepts_1","text":"","title":"Used Concepts"},{"location":"public/programming/rust/rust-scratch-blockchain/#-memoizationlazyevaluation_1","text":"We can create a struct that will hold the closure and the resulting value of calling the closure. The struct will execute the closure only if we need the resulting value, and it will cache the resulting value so the rest of our code doesn\u2019t have to be responsible for saving and reusing the result. FnOnce consumes the variables it captures from its enclosing scope, known as the closure\u2019s environment. To consume the captured variables, the closure must take ownership of these variables and move them into the closure when it is defined. The Once part of the name represents the fact that the closure can\u2019t take ownership of the same variables more than once, so it can be called only once. FnMut can change the environment because it mutably borrows values. Fn borrows values from the environment immutably. FnOnce: takes the whole value. FnMut: takes a mutable reference. Fn: takes a regular reference.","title":"- [\u2713] Memoization\u2022Lazy\u2022Evaluation"},{"location":"public/programming/rust/rust-scratch-blockchain/#-coercion_1","text":"Deref coercion is a convenience that Rust performs on arguments to functions and methods. Deref coercion works only on types that implement the Deref trait. Deref coercion converts such a type into a reference to another type. For example, deref coercion can convert &String to &str because String implements the Deref trait such that it returns &str. The number of times that Deref::deref needs to be inserted is resolved at compile time, so there is no runtime penalty for taking advantage of deref coercion! Similar to how you use the Deref trait to override the * operator on immutable references, you can use the DerefMut trait to override the * operator on mutable references.the Drop trait is almost always used when implementing a smart pointer. For example, when a Box is dropped it will deallocate the space on the heap that the box points to. Note that we didn\u2019t need to call the drop method explicitly.","title":"- [\u2713] Coercion"},{"location":"public/programming/rust/rust-scratch-blockchain/#-dstorunsizedtype_1","text":"DSTs or unsized types': str(but not &str-So although a &T is a single value that stores the memory address of where the T is located, a &str is two values: the address of the str and its length. Rust has a particular trait called the Sized trait to determine whether or not a type\u2019s size is known at compile time. This trait is automatically implemented for everything whose size is known at compile time. In addition, Rust implicitly adds a bound on Sized to every generic function.","title":"- [\u2713] DST\u2022Or\u2022Unsizedtype"},{"location":"public/programming/rust/rust-scratch-blockchain/#-operation_1","text":"-> Methods are functions that are coupled to some object. From a syntactic point of view, these are just functions that don\u2019t need to specify one of their arguments. Rather than calling open() and passing a File object in as an argument (read(f, buffer)), methods allow the main object to be implicit in the function call (f.read(buffer)) using the dot operator. There are a number of theoretical differences between methods and functions, but a detailed discussion of those computer science topics is available in other books. Briefly, functions are regarded as pure, meaning their behavior is determined solely by their arguments. Methods are inherently impure, given that one of their arguments is effectively a side effect. These are muddy waters, though. Functions are perfectly capable of acting on side effects themselves. Moreover, methods are implemented with functions. And, to add an exception to an exception, objects sometimes implement static methods, which do not include implicit arguments. To define methods, Rust programmers use an impl block","title":"- [\u2713] Operation"},{"location":"public/programming/rust/rust-scratch-blockchain/#-borrowchecker_1","text":"The borrow checker checks that all access to data is legal, which allows Rust to prevent safety issues. Learning how this works will, at the very least, speed up your development time by helping you avoid run-ins with the compiler. More significantly though, learning to work with the borrow checker allows you to build larger software systems with confidence. It underpins the term fearless concurrency.","title":"- [\u2713] Borrowchecker"},{"location":"public/programming/rust/rust-scratch-blockchain/#-borrowcheckerlifetime_1","text":"-> Lifetime=Timetolive=Subset of their scope Make hypotheses about whether or not your experiments will pass the borrow checker before you compile reference in Rust has a lifetime, which is the scope for which that reference is valid. Most of the time, lifetimes are implicit and inferred, just like most of the time, types are inferred. We must annotate types when multiple types are possible. In a similar way, we must annotate lifetimes when the lifetimes of references could be related in a few different ways. The main aim of lifetimes is to prevent dangling references, which cause a program to reference data other than the data it\u2019s intended to reference. All references in Rust have a lifetime, even if they are not explicitly annotated. The compiler is capable of implicitly assigning lifetimes. A value\u2019s lifetime is the period when accessing that value is valid behavior. A function\u2019s local variables live until the function returns, while global variables might live for the life of the program. The notion of ownership is rather limited. An owner cleans up when its values\u2019 lifetimes end. Although every parameter has a lifetime, these checks are typically invisible as the compiler can infer most lifetimes by itself. All values bound to a given lifetime must live as long as the last access to any value bound to that lifetime. No lifetime annotations are required when calling a function. Lifetime annotations don\u2019t change how long any of the references live. Just as functions can accept any type when the signature specifies a generic type parameter, functions can accept references with any lifetime by specifying a generic lifetime parameter. Lifetime annotations describe the relationships of the lifetimes of multiple references to each other without affecting the lifetimes. The lifetime annotations indicate that the references first and second must both live as long as that generic lifetime. Lifetimes on function or method parameters are called input lifetimes, and lifetimes on return values are called output lifetimes. Although every parameter has a lifetime, these checks are typically invisible as the compiler can infer most lifetimes by itself All values bound to a given lifetime must live as long as the last access to any value bound to that lifetime. No lifetime annotations are required when calling a function. Using two lifetime parameters (a and b) indicates that the lifetimes of i and j are decoupled. fn add_with_lifetimes<'a, 'b>(i: &'a i32, j: &'b i32) -> i32 {} Lifetime of that usage: the LOC('existence time' or Line of code) between when a location is first used in a certain way, and when that usage stops. Lifetime of that value: the LOC (or actual time) between when a value is created, and when that value is dropped. Might be useful when discussing open file descriptors, but also irrelevant here. Ultimately, lifetime syntax is about connecting the lifetimes of various parameters and return values of functions. Once they\u2019re connected, Rust has enough information to allow memory-safe operations and disallow operations that would create dangling pointers or otherwise violate memory safety.","title":"- [\u2713] Borrowchecker\u2022Lifetime"},{"location":"public/programming/rust/rust-scratch-blockchain/#-dangle_1","text":"The main aim of lifetimes is to prevent dangling references.which has an outer scope and an inner scope. In return section of a function primitive types need to define as (&'a or &'static)","title":"- [\u2713] Dangle"},{"location":"public/programming/rust/rust-scratch-blockchain/#-generic_1","text":"You might be wondering whether there is a runtime cost when using generic type parameters. The good news is that using generic types won't make your run any slower than it would with concrete types. Rust accomplishes this by performing monomorphization of the code using generics at compile time. Monomorphization is the process of turning generic code into specific code by filling in the concrete types that are used when compile. Every programming language has tools for effectively handling the duplication of concepts. In Rust, one such tool is generics. Generics are abstract stand-ins for concrete types or other properties. When we\u2019re writing code, we can express the behavior of generics or how they relate to other generics without knowing what will be in their place when compiling and running the code.","title":"- [\u2713] Generic"},{"location":"public/programming/rust/rust-scratch-blockchain/#staticdispatchpassed_1","text":"-> Monomorphization Dispatch is the mechanism to determine which specific version of code is actually run when it involves polymorphism. Two major forms of dispatch are static dispatch and dynamic dispatch. While Rust favors static dispatch, it also supports dynamic dispatch through a mechanism called \u2018trait objects\u2019. When Rust compiles this code, it performs monomorphization. The monomorphized version of the code looks like the following. The generic Option is replaced with the specific definitions created by the compiler: versions of a polymorphic function (or any polymorphic entity) during compilation is called Monomorphization. Because Rust compiles generic code into code that specifies the type in each instance, we pay no runtime cost for using generics. When the code runs, it performs just as it would if we had duplicated each definition by hand. The process of monomorphization makes Rust\u2019s generics extremely efficient at runtime. This is opposed to dynamic dispatch","title":"Static\u2022Dispatch(Passed)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-dynamicdispatch_1","text":"The code that results from monomorphization is doing static dispatch, which is when the compiler knows what method you\u2019re calling at compile time. This is opposed to dynamic dispatch, which is when the compiler can\u2019t tell at compile time which method you\u2019re calling. In dynamic dispatch cases, the compiler emits code that at runtime will figure out which method to call. When we use trait objects, Rust must use dynamic dispatch. The compiler doesn\u2019t know all the types that might be used with the code that is using trait objects, so it doesn\u2019t know which method implemented on which type to call. Instead, at runtime, Rust uses the pointers inside the trait object to know which method to call. There is a runtime cost when this lookup happens that doesn\u2019t occur with static dispatch. Dynamic dispatch also prevents the compiler from choosing to inline a method\u2019s code, which in turn prevents some optimizations.","title":"- [\u2713] Dynamic\u2022Dispatch"},{"location":"public/programming/rust/rust-scratch-blockchain/#-blanketimplementation_1","text":"Any implementation where a type appears uncovered. impl Foo for T, impl Bar for T, impl Bar > for T, and impl Bar for Vec are considered blanket impls. We can also conditionally implement a trait for any type that implements another trait. Implementations of a trait on any type that satisfies the trait bounds are called blanket implementations and are extensively used in the Rust standard library. For example, the standard library implements the ToString trait on any type that implements the Display trait.","title":"- [-] Blanket\u2022Implementation"},{"location":"public/programming/rust/rust-scratch-blockchain/#-boundsyntax_1","text":"Bounds are constraints on a type or trait. For example, if a bound is placed on the argument a function takes, types passed to that function must abide by that constraint.","title":"- [\u2713] Bound(syntax)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-trait_1","text":"We can use traits to define shared behavior in an abstract way. We can use trait bounds to specify that a generic type can be any type that has certain behavior. Traits are similar to a feature often called interfaces in other languages, although with some differences. What is a trait? A trait is a language feature that is analogous to an interface, protocol, or contract. If you have a background in object-oriented programming, consider a trait to be an abstract base class. If you have a background in functional programming, Rust\u2019s traits are close to Haskell\u2019s type classes these also support a form of inheritance that\u2019s common in most object oriented languages. For now, though, the thing to remember is that traits represent common behavior (Or reusable codes like println!)that types opt into via the syntax impl Trait for Type. After the method signature, instead of providing an implementation within curly brackets, we use a semicolon. This interface consists of associated items, which come in three varieties: functions, types, constants. All traits define an implicit type parameter Self that refers to \"the type that is implementing this interface\". Trait functions may omit the function body by replacing it with a semicolon. This indicates that the implementation must define the function. If the trait function defines a body, this definition acts as a default for any implementation which does not override it. Similarly, associated constants may omit the equals sign and expression to indicate implementations must define the constant value. Associated types must never define the type, the type may only be specified in an implementation.","title":"- [\u2713] Trait"},{"location":"public/programming/rust/rust-scratch-blockchain/#-polymorphism_1","text":"In a struct or enum, the data in the struct fields and the behavior in impl blocks are separated, whereas in other languages, the data and behavior combined into one concept is often labeled an object.However, trait objects are more like objects in other languages in the sense that they combine data and behavior.","title":"- [\u2713] Polymorphism"},{"location":"public/programming/rust/rust-scratch-blockchain/#-unrolling_1","text":"It is an optimization that removes the overhead of the loop controlling code and instead generates repetitive code for each iteration of the loop.","title":"- [\u2713] Unrolling"},{"location":"public/programming/rust/rust-scratch-blockchain/#-bindingmatch_1","text":"The compiler automatically references the Some, and since we're borrowing, name is bound as ref name automatically as well. If we were mutating: //https://blog.rust-lang.org/2018/05/10/Rust-1.26.html#nicer-match-bindings // `self` has type `&List`, and `*self` has type `List`, matching on a // concrete type `T` is preferred over a match on a reference `&T` // after Rust 2018 you can use self here and tail (with no ref) below as well, // rust will infer &s and ref tail.","title":"- [\u2713] Binding\u2022Match"},{"location":"public/programming/rust/rust-scratch-blockchain/#-dataracerustaceans_1","text":"Note: The opposite of referencing by using & is dereferencing, which is accomplished with the dereference operator, *.","title":"- [\u2717] Datarace\u2022Rustaceans"},{"location":"public/programming/rust/rust-scratch-blockchain/#-nanphilosophy_1","text":"Floating-point types include \u201cnot a number\u201d values (represented in Rust syntax as NAN values) to handle these cases. NAN values poison other numbers. Almost all operations interacting with NAN return NAN. Another thing to be mindful of is that, by definition, NAN values are never equal. Programming language design is often thought of in terms of which features you include, but the features you exclude are important too. Rust doesn\u2019t have the null feature that many other languages have. Null is a value that means there is no value there. In languages with null, variables can always be in one of two states: null or not-null. In his 2009 presentation \u201cNull References: The Billion Dollar Mistake,\u201d Tony Hoare, the inventor of null, has this to say: I call it my billion-dollar mistake. At that time, I was designing the first comprehensive type system for references in an object-oriented language. My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn\u2019t resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years. To program defensively, make use of the is_nan() and is_finite() methods. Inducing a crash, rather than silently proceeding with a mathematical error, allows you to debug close to what has caused the problem. The following illustrates using the is_finite()","title":"[-] Nan(philosophy)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-duplicationliteral_1","text":"Concept of copying the pointer, length, and capacity without copying the data probably sounds like making a shallow copy. If we do want to deeply copy the heap data of the String, not just the stack data, we can use a common method called clone","title":"- [\u2713] Duplication((literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-semanticliteral_1","text":"Primitive types are said to possess copy semantics, whereas all other types have move semantics. Adding more functionality (e.g., reference-counting semantics rather than move semantics) to types by wrapping these in other types typically reduces their run-time performance.","title":"- [\u2713] Semantic(literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-zerocostabstractionsliteral_1","text":"One of the ways this manifests is by not adding extra data around values within structs.","title":"- [\u2713] Zero\u2022Cost\u2022Abstractions(literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-coherenceliteral_1","text":"-> Orphan = Trait\u2022External\u2022Implement But we can\u2019t implement external traits on external types. For example, we can\u2019t implement the Display trait on Vec within our aggregator crate, because Display and Vec are defined in the standard library and aren\u2019t local to our aggregator crate. This restriction is part of a property of programs called coherence, and more specifically the orphan rule, so named because the parent type is not present. This rule ensures that other people\u2019s code can\u2019t break your code and vice versa. Without the rule, two crates could implement the same trait for the same type, and Rust wouldn\u2019t know which implementation to use. Preserves contextual coherence of trace data from tasks/function/methods when logging. For example new instance of a struct of course, as you probably already know, struct then you can just summerize your struct in a method.","title":"- [\u2713] Coherence(literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-jargonliteral_1","text":"Functional programming jargon: \u201cto cons x onto y\u201d informally means to construct a new container instance by putting the element x at the start of this new container, followed by the container y.Other, more complex recursive data types are useful in various situations, but by starting with the cons list, we can explore how boxes let us define a recursive data type without much distraction.","title":"- [\u2713] Jargon(literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-refactorliteral_1","text":"One alternative to refactoring is to simply copy values. Doing this often is typically frowned upon, however, but it can be useful in a pinch. Primitive types like integers are a good example of that. Primitive types are cheap for a CPU to duplicate\u2014so cheap, in fact, that Rust always copies these if it would otherwise worry about ownership being moved. Types can opt into two modes of duplication: cloning and copying.","title":"- [\u2713] Refactor(literal)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-patternnewtype_1","text":"Using the Newtype Pattern to Implement External Traits on External Types 'thin wrapper around the type' : part of Vec is noticed. We can make a Wrapper struct that holds an instance of Vec ; then we can implement Display on Wrapper and use the Vec value The downside of using this technique is that Wrapper is a new type, so it doesn\u2019t have the methods of the value it\u2019s holding. We would have to implement all the methods of Vec directly on Wrapper such that the methods delegate to self.0, which would allow us to treat Wrapper exactly like a Vec . If we wanted the new type to have every method the inner type has, implementing the Deref trait (If we don\u2019t want the Wrapper type to have all the methods of the inner type\u2014for example, to restrict the Wrapper type\u2019s behavior\u2014we would have to implement just the methods we do want manually.)","title":"- [\u2713] Pattern\u2022Newtype"},{"location":"public/programming/rust/rust-scratch-blockchain/#-patterndesigninteriorfuture-work_1","text":"Interior mutability is a design pattern in Rust that allows you to mutate data even when there are immutable references to that data; normally, this action is disallowed by the borrowing rules. To mutate data, the pattern uses unsafe code inside a data structure to bend Rust\u2019s usual rules that govern mutation and borrowing. RefCell type that follows the interior mutability pattern. Unlike Rc , the RefCell type represents single ownership over the data it holds. So, what makes RefCell different from a type like Box ? Recall the borrowing rules... Similar to Rc , RefCell is only for use in single-threaded scenarios and will give you a compile-time error if you try using it in a multithreaded context. At any given time, you can have either (but not both of) one mutable reference or any number of immutable references.References must always be valid.","title":"- [\u2717] Pattern\u2022Design\u2022Interior(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-typewraperfuture-work_1","text":"-> Wrapper type = Reference-Counted Value = Shared Ownership = Track valid references Use wrapper types, which allow more flexibility than what is available by default. These, however, incur costs at runtime to ensure that Rust\u2019s safety guarantees are maintained. Another way to phrase this is that Rust allows programmers to opt in to garbage collection.","title":"- [\u2717] Type\u2022Wraper(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-memleakfuture-work_1","text":"-> Managing Memory Leak Rust\u2019s memory safety guarantees make it difficult, but not impossible, to accidentally create memory that is never cleaned up (known as a memory leak). Preventing memory leaks entirely is not one of Rust\u2019s guarantees in the same way that disallowing data races at compile time is, meaning memory leaks are memory safe in Rust. We can see that Rust allows memory leaks by using Rc and RefCell : it\u2019s possible to create references where items refer to each other in a cycle. This creates memory leaks because the reference count of each item in the cycle will never reach 0, and the values will never be dropped.","title":"- [\u2717] Mem\u2022Leak(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-memdoublefreefuture-work_1","text":"This is a problem: when s2 and s1 (s2 is copied s1 means 2different pointer and the same data) go out of scope, they will both try to free the same memory. This is known as a double free error and is one of the memory safety bugs we mentioned previously. Freeing memory twice can lead to memory corruption, which can potentially lead to security vulnerabilities.","title":"- [\u2717] Mem\u2022Doublefree(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-memdeallocatingorraiifuture-work_1","text":"Note: In C++, this pattern of deallocating resources at the end of an item\u2019s lifetime is sometimes called Resource Acquisition Is Initialization (RAII). The drop function in Rust will be familiar to you if you\u2019ve used RAII patterns.","title":"- [\u2717] Mem\u2022Deallocating\u2022or\u2022RAII(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-threadfuture-work_1","text":"Which parts of your code on different threads will run. This can lead to problems, such as: Race conditions, where threads are accessing data or resources in an inconsistent order Deadlocks, where two threads are waiting for each other to finish using a resource the other thread has, preventing both threads from continuing Bugs that happen only in certain situations and are hard to reproduce and fix reliably.","title":"- [\u2717] Thread(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-threadstrategesfuture-work_1","text":"-> Priority Performance Stealing_Join: execute code in parallel when there are idle CPUs to handle it. When join is called from outside the thread pool, the calling thread will block while the closures execute in the pool. When join is called within the pool, the calling thread still actively participates in the thread pool. It will begin by executing closure A (on the current thread). While it is doing that, it will advertise closure B as being available for other threads to execute. Once closure A has completed, the current thread will try to execute closure B; if however closure B has been stolen, then it will look for other work while waiting for the thief to fully execute closure B. (This is the typical work-stealing strategy). Send is require because we have jump from quick func(thread a) to part func(thread b) frequently. Atomic: types provide primitive shared-memory communication between threads, and are the building blocks of other concurrent types. This module defines atomic versions of a select number of primitive types, including AtomicBool, AtomicIsize, AtomicUsize, AtomicI8, AtomicU16, etc. Atomic types present operations that, when used correctly, synchronize updates between threads. Each method takes an Ordering which represents the strength of the memory barrier for that operation. These orderings are the same as the C++20 atomic orderings. For more information see the nomicon. Atomic variables are safe to share between threads (they implement Sync) but they do not themselves provide the mechanism for sharing and follow the threading model of Rust. The most common way to share an atomic variable is to put it into an Arc (an atomically-reference-counted shared pointer). Atomic types may be stored in static variables, initialized using the constant initializers like AtomicBool::new. Atomic statics are often used for lazy global initialization. Spin_Loop_Yeild also known as busy loop and spin loop-If you want to sleep pause a thread for short amounts of time, or if your application is sensitive to timing, use a spin loop","title":"- [\u2717] Thread\u2022Strateges(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-unsafeexternmanglingfuture-work_1","text":"> Mangling is when a compiler changes the name we\u2019ve given a function to a different name that contains more information for other parts of the compilation process to consume but is less human readable. Every programming language compiler mangles names slightly differently, so for a Rust function to be nameable by other languages, we must disable the Rust compiler\u2019s name mangling.","title":"- [\u2717] Unsafe\u2022Extern\u2022Mangling(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-interiormutabilitypattern_1","text":"RefCell : Lets us have many immutable borrows or one mutable borrow at any point in time. Mutating the value inside an immutable value is the interior mutability pattern. Interior mutability is a design pattern in Rust that allows you to mutate data even when there are immutable references to that data; normally, this action is disallowed by the borrowing rules. To mutate data, the pattern uses unsafe code inside a data structure to bend Rust\u2019s usual rules that govern mutation and borrowing. RefCell type that follows the interior mutability pattern. Unlike Rc , the RefCell type represents single ownership over the data it holds. So, what makes RefCell different from a type like Box ? Recall the borrowing rules, Similar to Rc , RefCell is only for use in single-threaded scenarios and will give you a compile-time error if you try using it in a multithreaded context. At any given time, you can have either (but not both of) one mutable reference or any number of immutable references.References must always be valid.","title":"- [\u2713] Interior\u2022Mutability\u2022Pattern"},{"location":"public/programming/rust/rust-scratch-blockchain/#-oopstatedesignpatternfuture-work_1","text":"-> We can used it for smart contracts so we will need to implemented smart contracts Using the state pattern means when the business requirements of the program change, we won\u2019t need to change the code of the value holding the state or the code that uses the value. We\u2019ll only need to update the code inside one of the state objects to change its rules or perhaps add more state objects. e.g Post type. This type will use the state pattern and will hold a value that will be one of three state objects representing the various states a post can be in\u2014draft, waiting for review, or published. Changing from one state to another will be managed internally within the Post type. The states change in response to the methods called by our library\u2019s users on the Post instance, but they don\u2019t have to manage the state changes directly. Also, users can\u2019t make a mistake with the states, like publishing a post before it\u2019s reviewed.","title":"- [\u2717] OOP\u2022State\u2022DesignPattern(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#-superpowerfuture-work_1","text":"if the Rust compiler doesn\u2019t have enough information to be confident, it will reject the code. In these cases, you can use unsafe code to tell the compiler, \u201cTrust me, I know what I\u2019m doing.\u201d The downside is that you use it at your own risk: if you use unsafe code incorrectly, problems due to memory unsafety, such as null pointer dereferencing, can occur. You can take five actions in unsafe Rust, called unsafe superpowers, that you can\u2019t in safe Rust. Those superpowers include the ability to: Dereference a raw pointer Call an unsafe function or method Access or modify a mutable static variable Implement an unsafe trait Access fields of unions Calling unsafe() would crash the program. consider unsafe to be a warning sign rather than an indicator that you\u2019re embarking on anything illegal. Unsafe means \u201cthe same level of safety offered by C at all times.\u201d If you still had access to (via unsafe) they might still look like valid S, but any attempt to use them as valid S is undefined behavior. \u2193 https://cheats.rs/#unsafe-unsound-undefined-dark side of force Try to avoid \"unsafe {}\", often safer, faster solution without it. Exception: FFI. People are fallible, and mistakes will happen, but by requiring these five unsafe operations to be inside blocks annotated with unsafe you\u2019ll know that any errors related to memory safety must be within an unsafe block. Keep unsafe blocks small; you\u2019ll be thankful later when you investigate memory bugs. To isolate unsafe code as much as possible, it\u2019s best to enclose unsafe code within a safe abstraction and provide a safe API, which we\u2019ll discuss later in the chapter when we examine unsafe functions and methods. Parts of the standard library are implemented as safe abstractions over unsafe code that has been audited. Wrapping unsafe code in a safe abstraction prevents uses of unsafe from leaking out into all the places that you or your users might want to use the functionality implemented with unsafe code, because using a safe abstraction is safe.","title":"- [\u2717] Superpower(future work)"},{"location":"public/programming/rust/rust-scratch-blockchain/#contributors_1","text":"nom is the fruit of the work of many contributors over the years, many thanks for your help! Contributors","title":"Contributors"},{"location":"public/programming/rust/rust-scratch-blockchain/#thanks","text":"Convert string to u128","title":"Thanks"},{"location":"public/programming/rust/rust-scratch-blockchain/#solved-issues","text":"Convert-string-to-u128","title":"Solved Issues"},{"location":"public/programming/rust/rust/","text":"Rust-Language \u00b6 SourceCode(Rust-All-In-One) \u00b6 SourceCode(Rust-Scratch-Blockchain) \u00b6 [[Rust 2021 A Scratch Blockchain-1]] [[Rust 2021 A Scratch Blockchain-2]] ( ReadMe ) Research \u00b6 Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Rust-Lang Rust-Lang-Ecosystem Rust-lang-Hello-World","title":"Rust"},{"location":"public/programming/rust/rust/#rust-language","text":"","title":"Rust-Language"},{"location":"public/programming/rust/rust/#sourcecoderust-all-in-one","text":"","title":"SourceCode(Rust-All-In-One)"},{"location":"public/programming/rust/rust/#sourcecoderust-scratch-blockchain","text":"[[Rust 2021 A Scratch Blockchain-1]] [[Rust 2021 A Scratch Blockchain-2]] ( ReadMe )","title":"SourceCode(Rust-Scratch-Blockchain)"},{"location":"public/programming/rust/rust/#research","text":"Highlighted Deep Dive Into Polkadot/Substrate/Kusama/Rust-Lang Rust-Lang-Ecosystem Rust-lang-Hello-World","title":"Research"},{"location":"public/university/master/","tags":["cloud","container","caas","virtualization","devops","master","science","armanriazi","java","university","github"],"text":"Master Thesis--Arman Riazi \u00b6 Abstract \u00b6 Nowadays with the development of technology, we observe an increase in the number of users using Cloud Computing services. The process of increasing demand, the need for intelligent supply and demand cycle, better resource management, better utilization of resources is necessary. The results indicate competition from the cycle leads to a complex challenge for selecting and scheduling tasks to provide composite services in the Cloud. One of the most important issues in this field is Load Balancing. How to choose idle resources from a set of resources, overcoming compositional constraints, determines the importance of scheduling and resource allocation. These are NP-Hard issues. State-of-the-art architecture in the field of Cloud Computing for the implementation of Scientific Workflows that can be implemented in a distributed manner is becoming increasingly considered in other sciences related to Cloud Computing. The distinction and competition of Cloud Service Providers to publish services with more profit and better quality to customers are summarized in features such as \"Scalability, Stability, High availability, Fault tolerance.\" By providing new solutions and services for using specialists in other sciences, we can see the utilization of Cloud Computing Infrastructure and services in the fields of industry, commerce, health, and emergency applications. The possibility of conducting Scientific Workflows using Virtual Machines\" and Containers is a goal that has been addressed in the proposed architecture. The Load Balancing in the form of Containers at the level of Virtual Machines using the Ant Colony Optimization(ACO) algorithm is one of the important goals and issues that have been covered and solutions for utilization as much as possible has been explained. According to previous studies, there is no comprehensive or stable architecture that can balance Scientific Workflows using the algorithm ACO at the container virtualization level. By providing a simulator environment and testing several samples with different parameters then estimated the efficiency of the ACO and default algorithm of [[Cloudsim]], ie First-Come-First-Serve(FCFS). In the case of fifty, hundred Samples of Montage Scientific Workflow, which is considered as the average load rate, balancing the workload of the Containers on the Virtual Machine with the ACO has better results than the FCFS. If the value of the beta parameter of the ACO is assigned by zero, the algorithm will be trapped to the local optimal. In the case of a thousand sample, which is interpreted as a large amount of workload, if a Cybershake Workflow is used finally the results will be the same in all performance evaluation indicators. Keywords: [[Cloud]]Computing, #ContainerAllocation, [[Workflow]], #ACO Info Getting Project-OpenSource Experimental Research: CloudSim-Workflow-Function-Container-Plus (Toward ServerMix) ArmanRiazi(AramisIT)Modeling And Simulation Of running containers on the host without needing a virtual machine. Pros: Simulation of cost and performance Scalability: Container is very scalable than the virtual machines Elasticity: with separating logical code and data Decrease overhead Decrease the start time of tasks Fixed data dependency Resource management Workflow Engine management Resource Management Cons: Lack of clean code and more refactoring. exclude of design patterns, modular Not using Maven and Unit Test Concepts: Workflow: correspond with Function Composition on the simulation environment. Function as a Service(FaaS): Lambda or Cloud Function on the production environment. Cloudlet : the task of the client or job of workflow ACO Scheduler: Ant colony optimization Serverfull: include virtual machine/on-premises Serverless: no server, Event-driven, Provisioning, Scalability, FaaS ServerMix: The proposed model included both of them. In implementing simulation we did not use FaaS or Lambda functions but we have some situations and marks of the Serverless as a kind of theoretical because we implemented with the capability of elasticity that is one of the Serverless features. on the other hand, we are going to need event-driven and arrow functions in this java program. Target: Running Montage workflow base on the container. We have two repo for implementing: Container base on Vm: ( Cloudsim-Workflow-Function-Container ),( Cloudsim-Workflow-Function-Container-ACO ) Container base on host:( CloudSim-Workflow-Function-Container-Plus ), ( Cloudsim-Workflow-Function-Container-ACO ) Part of class diagram: ContainerCloudsim class diagram Sequential diagram of WFC architecture: Proposed Architecture: WFC has transparency and clarity on architecture and implemented java code. Prerequisites: Resolve project libraries include: commons-math3\u20133.2 | 3\u20136.1, flanagan, jdom-2.0.0, opencsv-2.3 (maybe) Results with montage Num.X: Season 6 Contact me: Let me know how can I help you with developing and researching. I am eager to your suggestion References \u00b6 [1] Malawski, M., Gajek, A., Zima, A., Balis, B., & Figiela, K. (2020). Serverless execution of scientific workflows: Experiments with hyperflow, aws lambda and google cloud functions. Future Generation Computer Systems, 110, 502-514. [2] Kavitha, Kadarla, and S. C. Sharma. \"Performance analysis of ACO\u2010based improved virtual machine allocation in cloud for IoT\u2010enabled healthcare.\" Concurrency and Computation: Practice and Experience 32, nov. 21 (2020): e5613. [3] Leitner, Philipp, Erik Wittern, Josef Spillner, and Waldemar Hummer. \"A mixed-method empirical study of Function-as-a-Service software development in industrial practice.\" Journal of Systems and Software 149 (2019): 340-359. [4] Shafiei, Hossein, Ahmad Khonsari, and Payam Mousavi. \"Serverless computing: A survey of opportunities, challenges and applications.\" arXiv preprint arXiv:1911.01296 (2019). [5] Garc\u00eda-L\u00f3pez, Pedro, Marc S\u00e1nchez-Artigas, Simon Shillaker, Peter Pietzuch, David Breitgand, Gil Vernik, Pierre Sutra, Tristan Tarrant, and Ana Juan Ferrer. \"Servermix: Tradeoffs and challenges of serverless data analytics.\" arXiv preprint arXiv:1907.11465 (2019). [6] P\u00e9rez A, Molt\u00f3 G, Caballer M, Calatrava A. Serverless computing for container-based architectures. Future Generation Computer Systems. 2018 Jun 1;83:50-9. [7] Spillner, Josef. \"Snafu: Function-as-a-service (faas) runtime design and implementation.\" arXiv preprint arXiv:1703.07562 (2017). [8] Jiang, Qingye, Young Choon Lee, and Albert Y. Zomaya. \"Serverless execution of scientific workflows.\" In International Conference on Service-Oriented Computing, pp. 706-721. Springer, Cham, 2017. [9] Chen, Weiwei, and Ewa Deelman. \"Workflowsim: A toolkit for simulating scientific workflows in distributed environments.\" In 2012 IEEE 8 th international conference on E-science, pp. 1-8. IEEE, 2012. [10] Piraghaj, Sareh Fotuhi, Amir Vahid Dastjerdi, Rodrigo N. Calheiros, and Rajkumar Buyya. \"ContainerCloudSim: An environment for modeling and simulation of containers in cloud data centers.\" Software: Practice and Experience 47, no. 4 (2017): 505-521. [11] He, Zhenxiang, Jiankang Dong, Zhengjiang Li, and Wenjuan Guo. \"Research on Task Scheduling Strategy Optimization Based onACO in Cloud Computing Environment.\" In 2020 IEEE 5 th Information Technology and Mechatronics Engineering Conference (ITOEC), pp. 1615-1619. IEEE, 2020. [12] Balis, Bartosz. \"HyperFlow: A model of computation, programming approach and enactment engine for complex distributed workflows.\" Future Generation Computer Systems 55 (2016): 147-162. [13] Kacsuk, Peter, J\u00f3zsef Kov\u00e1cs, and Zolt\u00e1n Farkas. \"The flowbster cloud-oriented workflow system to process large scientific data sets.\" Journal of Grid Computing 16, no. 1 (2018): 55-83. [14] Jonas, Eric, Johann Schleier-Smith, Vikram Sreekanti, Chia-Che Tsai, Anurag Khandelwal, Qifan Pu, Vaishaal Shankar et al. \"Cloud programming simplified: A berkeley view on serverless computing.\" arXiv preprint arXiv:1902.03383 (2019). [15] Wickremasinghe, B., Calheiros, R. N., & Buyya, R. (2010, April). Cloudanalyst: A cloudsim-based visual modeller for analysing cloud computing environments and applications. In 2010 24 th IEEE international conference on advanced information networking and applications (pp. 446-452). IEEE. [16] Soltani, Boubaker, Afifa Ghenai, and Nadia Zeghib. \"Towards distributed containerized serverless architecture in multi cloud environment.\" Procedia computer science 134 (2018): 121-128. [17] Sturm, Rick, Carol Pollard, and Julie Craig. \"The NIST definition of cloud computing.\" In Proc. Appl. Perform. Manage.(APM) Digit. Enterprise, pp. 267-269. 2017. [18] Karmel, Anil, Ramaswamy Chandramouli, and Michaela Iorga. Nist definition of microservices, application containers and system virtual machines. No. NIST Special Publication (SP) 800-180 (Draft). National Institute of Standards and Technology, 2016. [19] Casalicchio, Emiliano. \"Autonomic Orchestration of Containers: Problem Definition and Research Challenges.\" In VALUETOOLS. 2016. [20] Cord\u00f3n Garc\u00eda, Oscar, Francisco Herrera Triguero, and Thomas St\u00fctzle. \"A review on the ant colony optimization metaheuristic: Basis, models and new trends.\" Mathware & soft computing. 2002 Vol. 9 N\u00fam. 2 [-3] (2002). [21] Choe, Tae-Young. \"Dynamic Task Scheduling Algorithm based on Ant Colony Scheme.\" (2015). [22] Fl\u00f3rez, Edson, Wilfredo G\u00f3mez, and Lola Bautista. \"An ant colony optimization algorithm for job shop scheduling problem.\" arXiv preprint arXiv:1309.5110 (2013). [23] Katiyar, Sapna, N. Ibraheem, and Abdul Quaiyum Ansari. \"Ant colony optimization: a tutorial review.\" In National Conference on Advances in Power and Control, pp. 99-110. 2015. [24] Lin, Miao, Jianqing Xi, Weihua Bai, and Jiayin Wu. \"Ant colony algorithm for multi-objective optimization of container-based microservice scheduling in cloud.\" IEEE Access 7 (2019): 83088-83100. [25] Rani, Rama, and Ritu Garg. \"Power and temperature-aware workflow scheduling considering deadline constraint in cloud.\" Arabian Journal for Science and Engineering 45, no. 12 (2020): 10775-10791. [26] Gutjahr, Walter J. \"ACO algorithms with guaranteed convergence to the optimal solution.\" Information processing letters 82, no. 3 (2002): 145-153.","title":"Master Thesis--Arman Riazi"},{"location":"public/university/master/#master-thesis-arman-riazi","text":"","title":"Master Thesis--Arman Riazi"},{"location":"public/university/master/#abstract","text":"Nowadays with the development of technology, we observe an increase in the number of users using Cloud Computing services. The process of increasing demand, the need for intelligent supply and demand cycle, better resource management, better utilization of resources is necessary. The results indicate competition from the cycle leads to a complex challenge for selecting and scheduling tasks to provide composite services in the Cloud. One of the most important issues in this field is Load Balancing. How to choose idle resources from a set of resources, overcoming compositional constraints, determines the importance of scheduling and resource allocation. These are NP-Hard issues. State-of-the-art architecture in the field of Cloud Computing for the implementation of Scientific Workflows that can be implemented in a distributed manner is becoming increasingly considered in other sciences related to Cloud Computing. The distinction and competition of Cloud Service Providers to publish services with more profit and better quality to customers are summarized in features such as \"Scalability, Stability, High availability, Fault tolerance.\" By providing new solutions and services for using specialists in other sciences, we can see the utilization of Cloud Computing Infrastructure and services in the fields of industry, commerce, health, and emergency applications. The possibility of conducting Scientific Workflows using Virtual Machines\" and Containers is a goal that has been addressed in the proposed architecture. The Load Balancing in the form of Containers at the level of Virtual Machines using the Ant Colony Optimization(ACO) algorithm is one of the important goals and issues that have been covered and solutions for utilization as much as possible has been explained. According to previous studies, there is no comprehensive or stable architecture that can balance Scientific Workflows using the algorithm ACO at the container virtualization level. By providing a simulator environment and testing several samples with different parameters then estimated the efficiency of the ACO and default algorithm of [[Cloudsim]], ie First-Come-First-Serve(FCFS). In the case of fifty, hundred Samples of Montage Scientific Workflow, which is considered as the average load rate, balancing the workload of the Containers on the Virtual Machine with the ACO has better results than the FCFS. If the value of the beta parameter of the ACO is assigned by zero, the algorithm will be trapped to the local optimal. In the case of a thousand sample, which is interpreted as a large amount of workload, if a Cybershake Workflow is used finally the results will be the same in all performance evaluation indicators. Keywords: [[Cloud]]Computing, #ContainerAllocation, [[Workflow]], #ACO Info Getting Project-OpenSource Experimental Research: CloudSim-Workflow-Function-Container-Plus (Toward ServerMix) ArmanRiazi(AramisIT)Modeling And Simulation Of running containers on the host without needing a virtual machine. Pros: Simulation of cost and performance Scalability: Container is very scalable than the virtual machines Elasticity: with separating logical code and data Decrease overhead Decrease the start time of tasks Fixed data dependency Resource management Workflow Engine management Resource Management Cons: Lack of clean code and more refactoring. exclude of design patterns, modular Not using Maven and Unit Test Concepts: Workflow: correspond with Function Composition on the simulation environment. Function as a Service(FaaS): Lambda or Cloud Function on the production environment. Cloudlet : the task of the client or job of workflow ACO Scheduler: Ant colony optimization Serverfull: include virtual machine/on-premises Serverless: no server, Event-driven, Provisioning, Scalability, FaaS ServerMix: The proposed model included both of them. In implementing simulation we did not use FaaS or Lambda functions but we have some situations and marks of the Serverless as a kind of theoretical because we implemented with the capability of elasticity that is one of the Serverless features. on the other hand, we are going to need event-driven and arrow functions in this java program. Target: Running Montage workflow base on the container. We have two repo for implementing: Container base on Vm: ( Cloudsim-Workflow-Function-Container ),( Cloudsim-Workflow-Function-Container-ACO ) Container base on host:( CloudSim-Workflow-Function-Container-Plus ), ( Cloudsim-Workflow-Function-Container-ACO ) Part of class diagram: ContainerCloudsim class diagram Sequential diagram of WFC architecture: Proposed Architecture: WFC has transparency and clarity on architecture and implemented java code. Prerequisites: Resolve project libraries include: commons-math3\u20133.2 | 3\u20136.1, flanagan, jdom-2.0.0, opencsv-2.3 (maybe) Results with montage Num.X: Season 6 Contact me: Let me know how can I help you with developing and researching. I am eager to your suggestion","title":"Abstract"},{"location":"public/university/master/#references","text":"[1] Malawski, M., Gajek, A., Zima, A., Balis, B., & Figiela, K. (2020). Serverless execution of scientific workflows: Experiments with hyperflow, aws lambda and google cloud functions. Future Generation Computer Systems, 110, 502-514. [2] Kavitha, Kadarla, and S. C. Sharma. \"Performance analysis of ACO\u2010based improved virtual machine allocation in cloud for IoT\u2010enabled healthcare.\" Concurrency and Computation: Practice and Experience 32, nov. 21 (2020): e5613. [3] Leitner, Philipp, Erik Wittern, Josef Spillner, and Waldemar Hummer. \"A mixed-method empirical study of Function-as-a-Service software development in industrial practice.\" Journal of Systems and Software 149 (2019): 340-359. [4] Shafiei, Hossein, Ahmad Khonsari, and Payam Mousavi. \"Serverless computing: A survey of opportunities, challenges and applications.\" arXiv preprint arXiv:1911.01296 (2019). [5] Garc\u00eda-L\u00f3pez, Pedro, Marc S\u00e1nchez-Artigas, Simon Shillaker, Peter Pietzuch, David Breitgand, Gil Vernik, Pierre Sutra, Tristan Tarrant, and Ana Juan Ferrer. \"Servermix: Tradeoffs and challenges of serverless data analytics.\" arXiv preprint arXiv:1907.11465 (2019). [6] P\u00e9rez A, Molt\u00f3 G, Caballer M, Calatrava A. Serverless computing for container-based architectures. Future Generation Computer Systems. 2018 Jun 1;83:50-9. [7] Spillner, Josef. \"Snafu: Function-as-a-service (faas) runtime design and implementation.\" arXiv preprint arXiv:1703.07562 (2017). [8] Jiang, Qingye, Young Choon Lee, and Albert Y. Zomaya. \"Serverless execution of scientific workflows.\" In International Conference on Service-Oriented Computing, pp. 706-721. Springer, Cham, 2017. [9] Chen, Weiwei, and Ewa Deelman. \"Workflowsim: A toolkit for simulating scientific workflows in distributed environments.\" In 2012 IEEE 8 th international conference on E-science, pp. 1-8. IEEE, 2012. [10] Piraghaj, Sareh Fotuhi, Amir Vahid Dastjerdi, Rodrigo N. Calheiros, and Rajkumar Buyya. \"ContainerCloudSim: An environment for modeling and simulation of containers in cloud data centers.\" Software: Practice and Experience 47, no. 4 (2017): 505-521. [11] He, Zhenxiang, Jiankang Dong, Zhengjiang Li, and Wenjuan Guo. \"Research on Task Scheduling Strategy Optimization Based onACO in Cloud Computing Environment.\" In 2020 IEEE 5 th Information Technology and Mechatronics Engineering Conference (ITOEC), pp. 1615-1619. IEEE, 2020. [12] Balis, Bartosz. \"HyperFlow: A model of computation, programming approach and enactment engine for complex distributed workflows.\" Future Generation Computer Systems 55 (2016): 147-162. [13] Kacsuk, Peter, J\u00f3zsef Kov\u00e1cs, and Zolt\u00e1n Farkas. \"The flowbster cloud-oriented workflow system to process large scientific data sets.\" Journal of Grid Computing 16, no. 1 (2018): 55-83. [14] Jonas, Eric, Johann Schleier-Smith, Vikram Sreekanti, Chia-Che Tsai, Anurag Khandelwal, Qifan Pu, Vaishaal Shankar et al. \"Cloud programming simplified: A berkeley view on serverless computing.\" arXiv preprint arXiv:1902.03383 (2019). [15] Wickremasinghe, B., Calheiros, R. N., & Buyya, R. (2010, April). Cloudanalyst: A cloudsim-based visual modeller for analysing cloud computing environments and applications. In 2010 24 th IEEE international conference on advanced information networking and applications (pp. 446-452). IEEE. [16] Soltani, Boubaker, Afifa Ghenai, and Nadia Zeghib. \"Towards distributed containerized serverless architecture in multi cloud environment.\" Procedia computer science 134 (2018): 121-128. [17] Sturm, Rick, Carol Pollard, and Julie Craig. \"The NIST definition of cloud computing.\" In Proc. Appl. Perform. Manage.(APM) Digit. Enterprise, pp. 267-269. 2017. [18] Karmel, Anil, Ramaswamy Chandramouli, and Michaela Iorga. Nist definition of microservices, application containers and system virtual machines. No. NIST Special Publication (SP) 800-180 (Draft). National Institute of Standards and Technology, 2016. [19] Casalicchio, Emiliano. \"Autonomic Orchestration of Containers: Problem Definition and Research Challenges.\" In VALUETOOLS. 2016. [20] Cord\u00f3n Garc\u00eda, Oscar, Francisco Herrera Triguero, and Thomas St\u00fctzle. \"A review on the ant colony optimization metaheuristic: Basis, models and new trends.\" Mathware & soft computing. 2002 Vol. 9 N\u00fam. 2 [-3] (2002). [21] Choe, Tae-Young. \"Dynamic Task Scheduling Algorithm based on Ant Colony Scheme.\" (2015). [22] Fl\u00f3rez, Edson, Wilfredo G\u00f3mez, and Lola Bautista. \"An ant colony optimization algorithm for job shop scheduling problem.\" arXiv preprint arXiv:1309.5110 (2013). [23] Katiyar, Sapna, N. Ibraheem, and Abdul Quaiyum Ansari. \"Ant colony optimization: a tutorial review.\" In National Conference on Advances in Power and Control, pp. 99-110. 2015. [24] Lin, Miao, Jianqing Xi, Weihua Bai, and Jiayin Wu. \"Ant colony algorithm for multi-objective optimization of container-based microservice scheduling in cloud.\" IEEE Access 7 (2019): 83088-83100. [25] Rani, Rama, and Ritu Garg. \"Power and temperature-aware workflow scheduling considering deadline constraint in cloud.\" Arabian Journal for Science and Engineering 45, no. 12 (2020): 10775-10791. [26] Gutjahr, Walter J. \"ACO algorithms with guaranteed convergence to the optimal solution.\" Information processing letters 82, no. 3 (2002): 145-153.","title":"References"},{"location":"reference/","text":"Reference \u00b6 Material for MkDocs is packed with many great features that make technical writing a joyful activity. This section of the documentation explains how to set up a page, and showcases all available specimen that can be used directly from within Markdown files. Configuration \u00b6 Built-in meta plugin \u00b6 Sponsors only \u00b7 insiders-4.21.0 \u00b7 Plugin \u00b7 Experimental The built-in meta plugin allows to set front matter per folder , which is especially handy to ensure that all pages in a folder use specific templates or tags. Add the following lines to mkdocs.yml : plugins : - meta If you need to be able to build your documentation with and without Insiders , please refer to the built-in plugins section to learn how shared configurations help to achieve this. The following configuration options are available: meta_file Default: **/.meta.yml \u2013 This option specifies the name of the meta files that the plugin should look for. The default setting assumes that meta files are called .meta.yml : plugins : - meta : meta_file : '**/.meta.yml' # (1)! Note that it's strongly recommended to prefix meta files with a . , since otherwise they would be included in the build output. Usage \u00b6 Setting the page title \u00b6 Each page has a designated title, which is used in the navigation sidebar, for social cards and in other places. While MkDocs attempts to automatically determine the title of a page in a four step process , the title can also be explicitly set with the front matter title property: --- title : Lorem ipsum dolor sit amet # (1)! --- # Document title ... This line sets the title inside the HTML document's head for the generated page to the given value. Note that the site title, which is set via site_name , is appended with a dash. Setting the page description \u00b6 A Markdown file can include a description that is added to the meta tags of a page, and is also used for social cards . It's a good idea to set a site_description in mkdocs.yml as a fallback value if the author does not explicitly define a description for a Markdown file: --- description : Nullam urna elit, malesuada eget finibus ut, ac tortor. # (1)! --- # Document title ... This line sets the meta tag containing the description inside the document head for the current page to the provided value. Setting the page icon \u00b6 Sponsors only \u00b7 insiders-4.5.0 \u00b7 Experimental An icon can be assigned to each page, which is then rendered as part of the navigation sidebar, as well as navigation tabs , if enabled. Use the front matter icon property to reference an icon, adding the following lines at the top of a Markdown file: --- icon : material/emoticon-happy # (1)! --- # Document title ... Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: Setting the page status \u00b6 Sponsors only \u00b7 insiders-4.22.0 \u00b7 Experimental A status can be assigned to each page, which is then displayed as part of the navigation sidebar. First, associate a status identifier with a description by adding the following to mkdocs.yml : extra : status : <identifier> : <description> # (1)! The identifier can only include alphanumeric characters, as well as dashes and underscores. For example, if you have a status Recently added , you can set new as an identifier: extra : status : new : Recently added The page status can now be set with the front matter status property. For example, you can mark a page as new with the following lines at the top of a Markdown file: --- status : new --- # Document title ... The following status identifiers are currently supported: \u2013 new \u2013 deprecated Setting the page subtitle \u00b6 Sponsors only \u00b7 insiders-4.25.0 \u00b7 Experimental Each page can define a subtitle, which is then rendered below the title as part of the navigation sidebar by using the front matter subtitle property, and adding the following lines: --- subtitle : Nullam urna elit, malesuada eget finibus ut, ac tortor --- # Document title ... Setting the page template \u00b6 If you're using theme extension and created a new page template in the overrides directory, you can enable it for a specific page. Add the following lines at the top of a Markdown file: --- template : custom.html --- # Document title ... How to set a page template for an entire folder? With the help of the built-in meta plugin , you can set a custom template for an entire section and all nested pages, by creating a .meta.yml file in the corresponding folder with the following content: template : custom.html Customization \u00b6 Using metadata in templates \u00b6 on all pages \u00b6 In order to add custom meta tags to your document, you can extend the theme and override the extrahead block , e.g. to add indexing policies for search engines via the robots property: {% extends \"base.html\" %} {% block extrahead %} < meta property = \"robots\" content = \"noindex, nofollow\" /> {% endblock %} on a single page \u00b6 If you want to set a meta tag on a single page, or want to set different values for different pages, you can use the page.meta object inside your template override, e.g.: {% extends \"base.html\" %} {% block extrahead %} {% if page and page.meta and page.meta.robots %} < meta property = \"robots\" content = \"{{ page.meta.robots }}\" /> {% else %} < meta property = \"robots\" content = \"index, follow\" /> {% endif %} {% endblock %} You can now use robots exactly like title and description to set values. Note that in this case, the template defines an else branch, which would set a default if none was given.","title":"Reference"},{"location":"reference/#reference","text":"Material for MkDocs is packed with many great features that make technical writing a joyful activity. This section of the documentation explains how to set up a page, and showcases all available specimen that can be used directly from within Markdown files.","title":"Reference"},{"location":"reference/#configuration","text":"","title":"Configuration"},{"location":"reference/#built-in-meta-plugin","text":"Sponsors only \u00b7 insiders-4.21.0 \u00b7 Plugin \u00b7 Experimental The built-in meta plugin allows to set front matter per folder , which is especially handy to ensure that all pages in a folder use specific templates or tags. Add the following lines to mkdocs.yml : plugins : - meta If you need to be able to build your documentation with and without Insiders , please refer to the built-in plugins section to learn how shared configurations help to achieve this. The following configuration options are available: meta_file Default: **/.meta.yml \u2013 This option specifies the name of the meta files that the plugin should look for. The default setting assumes that meta files are called .meta.yml : plugins : - meta : meta_file : '**/.meta.yml' # (1)! Note that it's strongly recommended to prefix meta files with a . , since otherwise they would be included in the build output.","title":"Built-in meta plugin"},{"location":"reference/#usage","text":"","title":"Usage"},{"location":"reference/#setting-the-page-title","text":"Each page has a designated title, which is used in the navigation sidebar, for social cards and in other places. While MkDocs attempts to automatically determine the title of a page in a four step process , the title can also be explicitly set with the front matter title property: --- title : Lorem ipsum dolor sit amet # (1)! --- # Document title ... This line sets the title inside the HTML document's head for the generated page to the given value. Note that the site title, which is set via site_name , is appended with a dash.","title":"Setting the page title"},{"location":"reference/#setting-the-page-description","text":"A Markdown file can include a description that is added to the meta tags of a page, and is also used for social cards . It's a good idea to set a site_description in mkdocs.yml as a fallback value if the author does not explicitly define a description for a Markdown file: --- description : Nullam urna elit, malesuada eget finibus ut, ac tortor. # (1)! --- # Document title ... This line sets the meta tag containing the description inside the document head for the current page to the provided value.","title":"Setting the page description"},{"location":"reference/#setting-the-page-icon","text":"Sponsors only \u00b7 insiders-4.5.0 \u00b7 Experimental An icon can be assigned to each page, which is then rendered as part of the navigation sidebar, as well as navigation tabs , if enabled. Use the front matter icon property to reference an icon, adding the following lines at the top of a Markdown file: --- icon : material/emoticon-happy # (1)! --- # Document title ... Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard:","title":"Setting the page icon"},{"location":"reference/#setting-the-page-status","text":"Sponsors only \u00b7 insiders-4.22.0 \u00b7 Experimental A status can be assigned to each page, which is then displayed as part of the navigation sidebar. First, associate a status identifier with a description by adding the following to mkdocs.yml : extra : status : <identifier> : <description> # (1)! The identifier can only include alphanumeric characters, as well as dashes and underscores. For example, if you have a status Recently added , you can set new as an identifier: extra : status : new : Recently added The page status can now be set with the front matter status property. For example, you can mark a page as new with the following lines at the top of a Markdown file: --- status : new --- # Document title ... The following status identifiers are currently supported: \u2013 new \u2013 deprecated","title":"Setting the page status"},{"location":"reference/#setting-the-page-subtitle","text":"Sponsors only \u00b7 insiders-4.25.0 \u00b7 Experimental Each page can define a subtitle, which is then rendered below the title as part of the navigation sidebar by using the front matter subtitle property, and adding the following lines: --- subtitle : Nullam urna elit, malesuada eget finibus ut, ac tortor --- # Document title ...","title":"Setting the page subtitle"},{"location":"reference/#setting-the-page-template","text":"If you're using theme extension and created a new page template in the overrides directory, you can enable it for a specific page. Add the following lines at the top of a Markdown file: --- template : custom.html --- # Document title ... How to set a page template for an entire folder? With the help of the built-in meta plugin , you can set a custom template for an entire section and all nested pages, by creating a .meta.yml file in the corresponding folder with the following content: template : custom.html","title":"Setting the page template"},{"location":"reference/#customization","text":"","title":"Customization"},{"location":"reference/#using-metadata-in-templates","text":"","title":"Using metadata in templates"},{"location":"reference/#on-all-pages","text":"In order to add custom meta tags to your document, you can extend the theme and override the extrahead block , e.g. to add indexing policies for search engines via the robots property: {% extends \"base.html\" %} {% block extrahead %} < meta property = \"robots\" content = \"noindex, nofollow\" /> {% endblock %}","title":"on all pages"},{"location":"reference/#on-a-single-page","text":"If you want to set a meta tag on a single page, or want to set different values for different pages, you can use the page.meta object inside your template override, e.g.: {% extends \"base.html\" %} {% block extrahead %} {% if page and page.meta and page.meta.robots %} < meta property = \"robots\" content = \"{{ page.meta.robots }}\" /> {% else %} < meta property = \"robots\" content = \"index, follow\" /> {% endif %} {% endblock %} You can now use robots exactly like title and description to set values. Note that in this case, the template defines an else branch, which would set a default if none was given.","title":"on a single page"},{"location":"reference/admonitions/","text":"Admonitions \u00b6 Admonitions, also known as call-outs , are an excellent choice for including side content without significantly interrupting the document flow. Material for MkDocs provides several different types of admonitions and allows for the inclusion and nesting of arbitrary content. Configuration \u00b6 This configuration enables admonitions, allows to make them collapsible and to nest arbitrary content inside admonitions. Add the following lines to mkdocs.yml : markdown_extensions : - admonition - pymdownx.details - pymdownx.superfences See additional configuration options: Admonition Details SuperFences Admonition icons \u00b6 8.3.0 \u00b7 Experimental Each of the supported admonition types has a distinct icon, which can be changed to any icon bundled with the theme, or even a custom icon . Add the following lines to mkdocs.yml : theme : icon : admonition : <type> : <icon> # (1)! Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: Expand to show alternate icon sets Octicons FontAwesome theme : icon : admonition : note : octicons/tag-16 abstract : octicons/checklist-16 info : octicons/info-16 tip : octicons/squirrel-16 success : octicons/check-16 question : octicons/question-16 warning : octicons/alert-16 failure : octicons/x-circle-16 danger : octicons/zap-16 bug : octicons/bug-16 example : octicons/beaker-16 quote : octicons/quote-16 theme : icon : admonition : note : fontawesome/solid/note-sticky abstract : fontawesome/solid/book info : fontawesome/solid/circle-info tip : fontawesome/solid/bullhorn success : fontawesome/solid/check question : fontawesome/solid/circle-question warning : fontawesome/solid/triangle-exclamation failure : fontawesome/solid/bomb danger : fontawesome/solid/skull bug : fontawesome/solid/robot example : fontawesome/solid/flask quote : fontawesome/solid/quote-left Usage \u00b6 Admonitions follow a simple syntax: a block starts with !!! , followed by a single keyword used as a type qualifier . The content of the block follows on the next line, indented by four spaces: Admonition !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Changing the title \u00b6 By default, the title will equal the type qualifier in titlecase. However, it can be changed by adding a quoted string containing valid Markdown (including links, formatting, ...) after the type qualifier: Admonition with custom title !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Removing the title \u00b6 Similar to changing the title , the icon and title can be omitted entirely by adding an empty string directly after the type qualifier. Note that this will not work for collapsible blocks : Admonition without title !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Collapsible blocks \u00b6 When Details is enabled and an admonition block is started with ??? instead of !!! , the admonition is rendered as a collapsible block with a small toggle on the right side: Admonition, collapsible ??? note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Adding a + after the ??? token renders the block expanded: Admonition, collapsible and initially expanded ???+ note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Inline blocks \u00b6 7.0.0 \u00b7 Experimental Admonitions can also be rendered as inline blocks (i.e. for sidebars), placing them to the right using the inline + end modifiers, or to the left using only the inline modifier: inline end inline Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. !!! info inline end Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Use inline end to align to the right (left for rtl languages). Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. !!! info inline Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Use inline to align to the left (right for rtl languages). Important : admonitions that use the inline modifiers must be declared prior to the content block you want to place them beside. If there's insufficient space to render the admonition next to the block, the admonition will stretch to the full width of the viewport, e.g. on mobile viewports. Supported types \u00b6 Following is a list of type qualifiers provided by Material for MkDocs, whereas the default type, and thus fallback for unknown type qualifiers, is note 1 : note Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. abstract Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. info Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. tip Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. success Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. question Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. warning Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. failure Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. danger Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. bug Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. example Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. quote Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Customization \u00b6 Classic admonitions \u00b6 Prior to version 8.5.6 , admonitions had a slightly different appearance: Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. If you want to restore this appearance, add the following CSS to an additional style sheet : .md-typeset .admonition.classic { border-width: 0; border-left-width: 4px; } docs/stylesheets/extra.css mkdocs.yml . md-typeset . admonition , . md-typeset details { border-width : 0 ; border-left-width : 4 px ; } extra_css : - stylesheets/extra.css Custom admonitions \u00b6 If you want to add a custom admonition type, all you need is a color and an *.svg icon. Copy the icon's code from the .icons folder and add the following CSS to an additional style sheet : :root { --md-admonition-icon--pied-piper: url('data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 576 512\"><path d=\"M244 246c-3.2-2-6.3-2.9-10.1-2.9-6.6 0-12.6 3.2-19.3 3.7l1.7 4.9zm135.9 197.9c-19 0-64.1 9.5-79.9 19.8l6.9 45.1c35.7 6.1 70.1 3.6 106-9.8-4.8-10-23.5-55.1-33-55.1zM340.8 177c6.6 2.8 11.5 9.2 22.7 22.1 2-1.4 7.5-5.2 7.5-8.6 0-4.9-11.8-13.2-13.2-23 11.2-5.7 25.2-6 37.6-8.9 68.1-16.4 116.3-52.9 146.8-116.7C548.3 29.3 554 16.1 554.6 2l-2 2.6c-28.4 50-33 63.2-81.3 100-31.9 24.4-69.2 40.2-106.6 54.6l-6.3-.3v-21.8c-19.6 1.6-19.7-14.6-31.6-23-18.7 20.6-31.6 40.8-58.9 51.1-12.7 4.8-19.6 10-25.9 21.8 34.9-16.4 91.2-13.5 98.8-10zM555.5 0l-.6 1.1-.3.9.6-.6zm-59.2 382.1c-33.9-56.9-75.3-118.4-150-115.5l-.3-6c-1.1-13.5 32.8 3.2 35.1-31l-14.4 7.2c-19.8-45.7-8.6-54.3-65.5-54.3-14.7 0-26.7 1.7-41.4 4.6 2.9 18.6 2.2 36.7-10.9 50.3l19.5 5.5c-1.7 3.2-2.9 6.3-2.9 9.8 0 21 42.8 2.9 42.8 33.6 0 18.4-36.8 60.1-54.9 60.1-8 0-53.7-50-53.4-60.1l.3-4.6 52.3-11.5c13-2.6 12.3-22.7-2.9-22.7-3.7 0-43.1 9.2-49.4 10.6-2-5.2-7.5-14.1-13.8-14.1-3.2 0-6.3 3.2-9.5 4-9.2 2.6-31 2.9-21.5 20.1L15.9 298.5c-5.5 1.1-8.9 6.3-8.9 11.8 0 6 5.5 10.9 11.5 10.9 8 0 131.3-28.4 147.4-32.2 2.6 3.2 4.6 6.3 7.8 8.6 20.1 14.4 59.8 85.9 76.4 85.9 24.1 0 58-22.4 71.3-41.9 3.2-4.3 6.9-7.5 12.4-6.9.6 13.8-31.6 34.2-33 43.7-1.4 10.2-1 35.2-.3 41.1 26.7 8.1 52-3.6 77.9-2.9 4.3-21 10.6-41.9 9.8-63.5l-.3-9.5c-1.4-34.2-10.9-38.5-34.8-58.6-1.1-1.1-2.6-2.6-3.7-4 2.2-1.4 1.1-1 4.6-1.7 88.5 0 56.3 183.6 111.5 229.9 33.1-15 72.5-27.9 103.5-47.2-29-25.6-52.6-45.7-72.7-79.9zm-196.2 46.1v27.2l11.8-3.4-2.9-23.8zm-68.7-150.4l24.1 61.2 21-13.8-31.3-50.9zm84.4 154.9l2 12.4c9-1.5 58.4-6.6 58.4-14.1 0-1.4-.6-3.2-.9-4.6-26.8 0-36.9 3.8-59.5 6.3z\"/></svg>') } .md-typeset .admonition.pied-piper, .md-typeset details.pied-piper { border-color: rgb(43, 155, 70); } .md-typeset .pied-piper > .admonition-title, .md-typeset .pied-piper > summary { background-color: rgba(43, 155, 70, 0.1); } .md-typeset .pied-piper > .admonition-title::before, .md-typeset .pied-piper > summary::before { background-color: rgb(43, 155, 70); -webkit-mask-image: var(--md-admonition-icon--pied-piper); mask-image: var(--md-admonition-icon--pied-piper); } docs/stylesheets/extra.css mkdocs.yml : root { --md-admonition-icon--pied-piper : url ( 'data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 576 512\"><path d=\"M244 246c-3.2-2-6.3-2.9-10.1-2.9-6.6 0-12.6 3.2-19.3 3.7l1.7 4.9zm135.9 197.9c-19 0-64.1 9.5-79.9 19.8l6.9 45.1c35.7 6.1 70.1 3.6 106-9.8-4.8-10-23.5-55.1-33-55.1zM340.8 177c6.6 2.8 11.5 9.2 22.7 22.1 2-1.4 7.5-5.2 7.5-8.6 0-4.9-11.8-13.2-13.2-23 11.2-5.7 25.2-6 37.6-8.9 68.1-16.4 116.3-52.9 146.8-116.7C548.3 29.3 554 16.1 554.6 2l-2 2.6c-28.4 50-33 63.2-81.3 100-31.9 24.4-69.2 40.2-106.6 54.6l-6.3-.3v-21.8c-19.6 1.6-19.7-14.6-31.6-23-18.7 20.6-31.6 40.8-58.9 51.1-12.7 4.8-19.6 10-25.9 21.8 34.9-16.4 91.2-13.5 98.8-10zM555.5 0l-.6 1.1-.3.9.6-.6zm-59.2 382.1c-33.9-56.9-75.3-118.4-150-115.5l-.3-6c-1.1-13.5 32.8 3.2 35.1-31l-14.4 7.2c-19.8-45.7-8.6-54.3-65.5-54.3-14.7 0-26.7 1.7-41.4 4.6 2.9 18.6 2.2 36.7-10.9 50.3l19.5 5.5c-1.7 3.2-2.9 6.3-2.9 9.8 0 21 42.8 2.9 42.8 33.6 0 18.4-36.8 60.1-54.9 60.1-8 0-53.7-50-53.4-60.1l.3-4.6 52.3-11.5c13-2.6 12.3-22.7-2.9-22.7-3.7 0-43.1 9.2-49.4 10.6-2-5.2-7.5-14.1-13.8-14.1-3.2 0-6.3 3.2-9.5 4-9.2 2.6-31 2.9-21.5 20.1L15.9 298.5c-5.5 1.1-8.9 6.3-8.9 11.8 0 6 5.5 10.9 11.5 10.9 8 0 131.3-28.4 147.4-32.2 2.6 3.2 4.6 6.3 7.8 8.6 20.1 14.4 59.8 85.9 76.4 85.9 24.1 0 58-22.4 71.3-41.9 3.2-4.3 6.9-7.5 12.4-6.9.6 13.8-31.6 34.2-33 43.7-1.4 10.2-1 35.2-.3 41.1 26.7 8.1 52-3.6 77.9-2.9 4.3-21 10.6-41.9 9.8-63.5l-.3-9.5c-1.4-34.2-10.9-38.5-34.8-58.6-1.1-1.1-2.6-2.6-3.7-4 2.2-1.4 1.1-1 4.6-1.7 88.5 0 56.3 183.6 111.5 229.9 33.1-15 72.5-27.9 103.5-47.2-29-25.6-52.6-45.7-72.7-79.9zm-196.2 46.1v27.2l11.8-3.4-2.9-23.8zm-68.7-150.4l24.1 61.2 21-13.8-31.3-50.9zm84.4 154.9l2 12.4c9-1.5 58.4-6.6 58.4-14.1 0-1.4-.6-3.2-.9-4.6-26.8 0-36.9 3.8-59.5 6.3z\"/></svg>' ) } . md-typeset . admonition . pied-piper , . md-typeset details . pied-piper { border-color : rgb ( 43 , 155 , 70 ); } . md-typeset . pied-piper > . admonition-title , . md-typeset . pied-piper > summary { background-color : rgba ( 43 , 155 , 70 , 0.1 ); } . md-typeset . pied-piper > . admonition-title :: before , . md-typeset . pied-piper > summary :: before { background-color : rgb ( 43 , 155 , 70 ); -webkit- mask-image : var ( --md-admonition-icon--pied-piper ); mask-image : var ( --md-admonition-icon--pied-piper ); } extra_css : - stylesheets/extra.css After applying the customization, you can use the custom admonition type: Admonition with custom type !!! pied-piper \"Pied Piper\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Pied Piper Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Previously, some of the supported types defined more than one qualifier. For example, authors could use summary or tldr as alternative qualifiers to render an abstract admonition. As this increased the size of the CSS that is shipped with Material for MkDocs, the additional type qualifiers are now all deprecated and will be removed in the next major version. This will also be mentioned in the upgrade guide. \u21a9","title":"Admonitions"},{"location":"reference/admonitions/#admonitions","text":"Admonitions, also known as call-outs , are an excellent choice for including side content without significantly interrupting the document flow. Material for MkDocs provides several different types of admonitions and allows for the inclusion and nesting of arbitrary content.","title":"Admonitions"},{"location":"reference/admonitions/#configuration","text":"This configuration enables admonitions, allows to make them collapsible and to nest arbitrary content inside admonitions. Add the following lines to mkdocs.yml : markdown_extensions : - admonition - pymdownx.details - pymdownx.superfences See additional configuration options: Admonition Details SuperFences","title":"Configuration"},{"location":"reference/admonitions/#admonition-icons","text":"8.3.0 \u00b7 Experimental Each of the supported admonition types has a distinct icon, which can be changed to any icon bundled with the theme, or even a custom icon . Add the following lines to mkdocs.yml : theme : icon : admonition : <type> : <icon> # (1)! Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: Expand to show alternate icon sets Octicons FontAwesome theme : icon : admonition : note : octicons/tag-16 abstract : octicons/checklist-16 info : octicons/info-16 tip : octicons/squirrel-16 success : octicons/check-16 question : octicons/question-16 warning : octicons/alert-16 failure : octicons/x-circle-16 danger : octicons/zap-16 bug : octicons/bug-16 example : octicons/beaker-16 quote : octicons/quote-16 theme : icon : admonition : note : fontawesome/solid/note-sticky abstract : fontawesome/solid/book info : fontawesome/solid/circle-info tip : fontawesome/solid/bullhorn success : fontawesome/solid/check question : fontawesome/solid/circle-question warning : fontawesome/solid/triangle-exclamation failure : fontawesome/solid/bomb danger : fontawesome/solid/skull bug : fontawesome/solid/robot example : fontawesome/solid/flask quote : fontawesome/solid/quote-left","title":"Admonition icons"},{"location":"reference/admonitions/#usage","text":"Admonitions follow a simple syntax: a block starts with !!! , followed by a single keyword used as a type qualifier . The content of the block follows on the next line, indented by four spaces: Admonition !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Usage"},{"location":"reference/admonitions/#changing-the-title","text":"By default, the title will equal the type qualifier in titlecase. However, it can be changed by adding a quoted string containing valid Markdown (including links, formatting, ...) after the type qualifier: Admonition with custom title !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Phasellus posuere in sem ut cursus Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Changing the title"},{"location":"reference/admonitions/#removing-the-title","text":"Similar to changing the title , the icon and title can be omitted entirely by adding an empty string directly after the type qualifier. Note that this will not work for collapsible blocks : Admonition without title !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Removing the title"},{"location":"reference/admonitions/#collapsible-blocks","text":"When Details is enabled and an admonition block is started with ??? instead of !!! , the admonition is rendered as a collapsible block with a small toggle on the right side: Admonition, collapsible ??? note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Adding a + after the ??? token renders the block expanded: Admonition, collapsible and initially expanded ???+ note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Collapsible blocks"},{"location":"reference/admonitions/#inline-blocks","text":"7.0.0 \u00b7 Experimental Admonitions can also be rendered as inline blocks (i.e. for sidebars), placing them to the right using the inline + end modifiers, or to the left using only the inline modifier: inline end inline Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. !!! info inline end Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Use inline end to align to the right (left for rtl languages). Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. !!! info inline Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Use inline to align to the left (right for rtl languages). Important : admonitions that use the inline modifiers must be declared prior to the content block you want to place them beside. If there's insufficient space to render the admonition next to the block, the admonition will stretch to the full width of the viewport, e.g. on mobile viewports.","title":"Inline blocks"},{"location":"reference/admonitions/#supported-types","text":"Following is a list of type qualifiers provided by Material for MkDocs, whereas the default type, and thus fallback for unknown type qualifiers, is note 1 : note Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. abstract Abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. info Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. tip Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. success Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. question Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. warning Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. failure Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. danger Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. bug Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. example Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. quote Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Supported types"},{"location":"reference/admonitions/#customization","text":"","title":"Customization"},{"location":"reference/admonitions/#classic-admonitions","text":"Prior to version 8.5.6 , admonitions had a slightly different appearance: Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. If you want to restore this appearance, add the following CSS to an additional style sheet : .md-typeset .admonition.classic { border-width: 0; border-left-width: 4px; } docs/stylesheets/extra.css mkdocs.yml . md-typeset . admonition , . md-typeset details { border-width : 0 ; border-left-width : 4 px ; } extra_css : - stylesheets/extra.css","title":"Classic admonitions"},{"location":"reference/admonitions/#custom-admonitions","text":"If you want to add a custom admonition type, all you need is a color and an *.svg icon. Copy the icon's code from the .icons folder and add the following CSS to an additional style sheet : :root { --md-admonition-icon--pied-piper: url('data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 576 512\"><path d=\"M244 246c-3.2-2-6.3-2.9-10.1-2.9-6.6 0-12.6 3.2-19.3 3.7l1.7 4.9zm135.9 197.9c-19 0-64.1 9.5-79.9 19.8l6.9 45.1c35.7 6.1 70.1 3.6 106-9.8-4.8-10-23.5-55.1-33-55.1zM340.8 177c6.6 2.8 11.5 9.2 22.7 22.1 2-1.4 7.5-5.2 7.5-8.6 0-4.9-11.8-13.2-13.2-23 11.2-5.7 25.2-6 37.6-8.9 68.1-16.4 116.3-52.9 146.8-116.7C548.3 29.3 554 16.1 554.6 2l-2 2.6c-28.4 50-33 63.2-81.3 100-31.9 24.4-69.2 40.2-106.6 54.6l-6.3-.3v-21.8c-19.6 1.6-19.7-14.6-31.6-23-18.7 20.6-31.6 40.8-58.9 51.1-12.7 4.8-19.6 10-25.9 21.8 34.9-16.4 91.2-13.5 98.8-10zM555.5 0l-.6 1.1-.3.9.6-.6zm-59.2 382.1c-33.9-56.9-75.3-118.4-150-115.5l-.3-6c-1.1-13.5 32.8 3.2 35.1-31l-14.4 7.2c-19.8-45.7-8.6-54.3-65.5-54.3-14.7 0-26.7 1.7-41.4 4.6 2.9 18.6 2.2 36.7-10.9 50.3l19.5 5.5c-1.7 3.2-2.9 6.3-2.9 9.8 0 21 42.8 2.9 42.8 33.6 0 18.4-36.8 60.1-54.9 60.1-8 0-53.7-50-53.4-60.1l.3-4.6 52.3-11.5c13-2.6 12.3-22.7-2.9-22.7-3.7 0-43.1 9.2-49.4 10.6-2-5.2-7.5-14.1-13.8-14.1-3.2 0-6.3 3.2-9.5 4-9.2 2.6-31 2.9-21.5 20.1L15.9 298.5c-5.5 1.1-8.9 6.3-8.9 11.8 0 6 5.5 10.9 11.5 10.9 8 0 131.3-28.4 147.4-32.2 2.6 3.2 4.6 6.3 7.8 8.6 20.1 14.4 59.8 85.9 76.4 85.9 24.1 0 58-22.4 71.3-41.9 3.2-4.3 6.9-7.5 12.4-6.9.6 13.8-31.6 34.2-33 43.7-1.4 10.2-1 35.2-.3 41.1 26.7 8.1 52-3.6 77.9-2.9 4.3-21 10.6-41.9 9.8-63.5l-.3-9.5c-1.4-34.2-10.9-38.5-34.8-58.6-1.1-1.1-2.6-2.6-3.7-4 2.2-1.4 1.1-1 4.6-1.7 88.5 0 56.3 183.6 111.5 229.9 33.1-15 72.5-27.9 103.5-47.2-29-25.6-52.6-45.7-72.7-79.9zm-196.2 46.1v27.2l11.8-3.4-2.9-23.8zm-68.7-150.4l24.1 61.2 21-13.8-31.3-50.9zm84.4 154.9l2 12.4c9-1.5 58.4-6.6 58.4-14.1 0-1.4-.6-3.2-.9-4.6-26.8 0-36.9 3.8-59.5 6.3z\"/></svg>') } .md-typeset .admonition.pied-piper, .md-typeset details.pied-piper { border-color: rgb(43, 155, 70); } .md-typeset .pied-piper > .admonition-title, .md-typeset .pied-piper > summary { background-color: rgba(43, 155, 70, 0.1); } .md-typeset .pied-piper > .admonition-title::before, .md-typeset .pied-piper > summary::before { background-color: rgb(43, 155, 70); -webkit-mask-image: var(--md-admonition-icon--pied-piper); mask-image: var(--md-admonition-icon--pied-piper); } docs/stylesheets/extra.css mkdocs.yml : root { --md-admonition-icon--pied-piper : url ( 'data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 576 512\"><path d=\"M244 246c-3.2-2-6.3-2.9-10.1-2.9-6.6 0-12.6 3.2-19.3 3.7l1.7 4.9zm135.9 197.9c-19 0-64.1 9.5-79.9 19.8l6.9 45.1c35.7 6.1 70.1 3.6 106-9.8-4.8-10-23.5-55.1-33-55.1zM340.8 177c6.6 2.8 11.5 9.2 22.7 22.1 2-1.4 7.5-5.2 7.5-8.6 0-4.9-11.8-13.2-13.2-23 11.2-5.7 25.2-6 37.6-8.9 68.1-16.4 116.3-52.9 146.8-116.7C548.3 29.3 554 16.1 554.6 2l-2 2.6c-28.4 50-33 63.2-81.3 100-31.9 24.4-69.2 40.2-106.6 54.6l-6.3-.3v-21.8c-19.6 1.6-19.7-14.6-31.6-23-18.7 20.6-31.6 40.8-58.9 51.1-12.7 4.8-19.6 10-25.9 21.8 34.9-16.4 91.2-13.5 98.8-10zM555.5 0l-.6 1.1-.3.9.6-.6zm-59.2 382.1c-33.9-56.9-75.3-118.4-150-115.5l-.3-6c-1.1-13.5 32.8 3.2 35.1-31l-14.4 7.2c-19.8-45.7-8.6-54.3-65.5-54.3-14.7 0-26.7 1.7-41.4 4.6 2.9 18.6 2.2 36.7-10.9 50.3l19.5 5.5c-1.7 3.2-2.9 6.3-2.9 9.8 0 21 42.8 2.9 42.8 33.6 0 18.4-36.8 60.1-54.9 60.1-8 0-53.7-50-53.4-60.1l.3-4.6 52.3-11.5c13-2.6 12.3-22.7-2.9-22.7-3.7 0-43.1 9.2-49.4 10.6-2-5.2-7.5-14.1-13.8-14.1-3.2 0-6.3 3.2-9.5 4-9.2 2.6-31 2.9-21.5 20.1L15.9 298.5c-5.5 1.1-8.9 6.3-8.9 11.8 0 6 5.5 10.9 11.5 10.9 8 0 131.3-28.4 147.4-32.2 2.6 3.2 4.6 6.3 7.8 8.6 20.1 14.4 59.8 85.9 76.4 85.9 24.1 0 58-22.4 71.3-41.9 3.2-4.3 6.9-7.5 12.4-6.9.6 13.8-31.6 34.2-33 43.7-1.4 10.2-1 35.2-.3 41.1 26.7 8.1 52-3.6 77.9-2.9 4.3-21 10.6-41.9 9.8-63.5l-.3-9.5c-1.4-34.2-10.9-38.5-34.8-58.6-1.1-1.1-2.6-2.6-3.7-4 2.2-1.4 1.1-1 4.6-1.7 88.5 0 56.3 183.6 111.5 229.9 33.1-15 72.5-27.9 103.5-47.2-29-25.6-52.6-45.7-72.7-79.9zm-196.2 46.1v27.2l11.8-3.4-2.9-23.8zm-68.7-150.4l24.1 61.2 21-13.8-31.3-50.9zm84.4 154.9l2 12.4c9-1.5 58.4-6.6 58.4-14.1 0-1.4-.6-3.2-.9-4.6-26.8 0-36.9 3.8-59.5 6.3z\"/></svg>' ) } . md-typeset . admonition . pied-piper , . md-typeset details . pied-piper { border-color : rgb ( 43 , 155 , 70 ); } . md-typeset . pied-piper > . admonition-title , . md-typeset . pied-piper > summary { background-color : rgba ( 43 , 155 , 70 , 0.1 ); } . md-typeset . pied-piper > . admonition-title :: before , . md-typeset . pied-piper > summary :: before { background-color : rgb ( 43 , 155 , 70 ); -webkit- mask-image : var ( --md-admonition-icon--pied-piper ); mask-image : var ( --md-admonition-icon--pied-piper ); } extra_css : - stylesheets/extra.css After applying the customization, you can use the custom admonition type: Admonition with custom type !!! pied-piper \"Pied Piper\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Pied Piper Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Previously, some of the supported types defined more than one qualifier. For example, authors could use summary or tldr as alternative qualifiers to render an abstract admonition. As this increased the size of the CSS that is shipped with Material for MkDocs, the additional type qualifiers are now all deprecated and will be removed in the next major version. This will also be mentioned in the upgrade guide. \u21a9","title":"Custom admonitions"},{"location":"reference/annotations/","text":"Annotations \u00b6 One of the flagship features of Material for MkDocs is the ability to inject annotations \u2013 little markers that can be added almost anywhere in a document and expand a tooltip containing arbitrary Markdown on click or keyboard focus. Configuration \u00b6 This configuration allows to add annotations to all inline- and block-level elements, as well as code blocks, and nest annotations inside each other. Add the following lines to mkdocs.yml : markdown_extensions : - attr_list - md_in_html - pymdownx.superfences See additional configuration options: Attribute Lists Markdown in HTML SuperFences Usage \u00b6 Using annotations \u00b6 Sponsors only \u00b7 insiders-4.6.0 \u00b7 Experimental Annotations consist of two parts: a marker, which can be placed anywhere in a block marked with the annotate class, and content located in a list below the block containing the marker: Text with annotations Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. { .annotate } 1. :man_raising_hand: I'm an annotation! I can contain `code` , __formatted text__, images, ... basically anything that can be expressed in Markdown. Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. I'm an annotation! I can contain code , formatted text , images, ... basically anything that can be written in Markdown. Note that the annotate class must only be added to the outermost block. All nested elements can use the same list to define annotations, except when annotations are nested themselves. in annotations \u00b6 When SuperFences is enabled, annotations can be nested inside annotations by adding the annotate class to the list item hosting the annotation content, repeating the process: Text with nested annotations Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. { .annotate } 1. :man_raising_hand: I'm an annotation! (1) { .annotate } 1. :woman_raising_hand: I'm an annotation as well! Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. I'm an annotation! (1) I'm an annotation as well! in admonitions \u00b6 The titles and bodies of admonitions can also host annotations by adding the annotate modifier after the type qualifier, which is similar to how inline blocks work: Admonition with annotations !!! note annotate \"Phasellus posuere in sem ut cursus (1)\" Lorem ipsum dolor sit amet, (2) consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. 1. :man_raising_hand: I'm an annotation! 2. :woman_raising_hand: I'm an annotation as well! Phasellus posuere in sem ut cursus (1) Lorem ipsum dolor sit amet, (2) consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. I'm an annotation! I'm an annotation as well! in content tabs \u00b6 Content tabs can host annotations by adding the annotate class to the block of a dedicated content tab (and not to the container, which is not supported): Content tabs with annotations === \"Tab 1\" Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. { .annotate } 1. :man_raising_hand: I'm an annotation! === \"Tab 2\" Phasellus posuere in sem ut cursus (1) { .annotate } 1. :woman_raising_hand: I'm an annotation as well! Tab 1 Tab 2 Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. I'm an annotation! Phasellus posuere in sem ut cursus (1) I'm an annotation as well! in everything else \u00b6 The Attribute Lists extension is the key ingredient for adding annotations to most elements, but it has some limitations . However, it's always possible to leverage the Markdown in HTML extension to wrap arbitrary elements with a div with the annotate class: HTML with annotations < div class = \"annotate\" markdown > > Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. </ div > 1. :man_raising_hand: I'm an annotation! Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. I'm an annotation! With this trick, annotations can also be added to blockquotes, lists, and many other elements that are not supported by the Attribute Lists extension. Furthermore, note that code blocks follow different semantics . Known limitations Please note that annotations currently don't work in data tables as reported in #3453 , as data tables are scrollable elements and positioning is very tricky to get right. This might be fixed in the future.","title":"Annotations"},{"location":"reference/annotations/#annotations","text":"One of the flagship features of Material for MkDocs is the ability to inject annotations \u2013 little markers that can be added almost anywhere in a document and expand a tooltip containing arbitrary Markdown on click or keyboard focus.","title":"Annotations"},{"location":"reference/annotations/#configuration","text":"This configuration allows to add annotations to all inline- and block-level elements, as well as code blocks, and nest annotations inside each other. Add the following lines to mkdocs.yml : markdown_extensions : - attr_list - md_in_html - pymdownx.superfences See additional configuration options: Attribute Lists Markdown in HTML SuperFences","title":"Configuration"},{"location":"reference/annotations/#usage","text":"","title":"Usage"},{"location":"reference/annotations/#using-annotations","text":"Sponsors only \u00b7 insiders-4.6.0 \u00b7 Experimental Annotations consist of two parts: a marker, which can be placed anywhere in a block marked with the annotate class, and content located in a list below the block containing the marker: Text with annotations Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. { .annotate } 1. :man_raising_hand: I'm an annotation! I can contain `code` , __formatted text__, images, ... basically anything that can be expressed in Markdown. Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. I'm an annotation! I can contain code , formatted text , images, ... basically anything that can be written in Markdown. Note that the annotate class must only be added to the outermost block. All nested elements can use the same list to define annotations, except when annotations are nested themselves.","title":"Using annotations"},{"location":"reference/annotations/#in-annotations","text":"When SuperFences is enabled, annotations can be nested inside annotations by adding the annotate class to the list item hosting the annotation content, repeating the process: Text with nested annotations Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. { .annotate } 1. :man_raising_hand: I'm an annotation! (1) { .annotate } 1. :woman_raising_hand: I'm an annotation as well! Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. I'm an annotation! (1) I'm an annotation as well!","title":"in annotations"},{"location":"reference/annotations/#in-admonitions","text":"The titles and bodies of admonitions can also host annotations by adding the annotate modifier after the type qualifier, which is similar to how inline blocks work: Admonition with annotations !!! note annotate \"Phasellus posuere in sem ut cursus (1)\" Lorem ipsum dolor sit amet, (2) consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. 1. :man_raising_hand: I'm an annotation! 2. :woman_raising_hand: I'm an annotation as well! Phasellus posuere in sem ut cursus (1) Lorem ipsum dolor sit amet, (2) consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. I'm an annotation! I'm an annotation as well!","title":"in admonitions"},{"location":"reference/annotations/#in-content-tabs","text":"Content tabs can host annotations by adding the annotate class to the block of a dedicated content tab (and not to the container, which is not supported): Content tabs with annotations === \"Tab 1\" Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. { .annotate } 1. :man_raising_hand: I'm an annotation! === \"Tab 2\" Phasellus posuere in sem ut cursus (1) { .annotate } 1. :woman_raising_hand: I'm an annotation as well! Tab 1 Tab 2 Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. I'm an annotation! Phasellus posuere in sem ut cursus (1) I'm an annotation as well!","title":"in content tabs"},{"location":"reference/annotations/#in-everything-else","text":"The Attribute Lists extension is the key ingredient for adding annotations to most elements, but it has some limitations . However, it's always possible to leverage the Markdown in HTML extension to wrap arbitrary elements with a div with the annotate class: HTML with annotations < div class = \"annotate\" markdown > > Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. </ div > 1. :man_raising_hand: I'm an annotation! Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit. I'm an annotation! With this trick, annotations can also be added to blockquotes, lists, and many other elements that are not supported by the Attribute Lists extension. Furthermore, note that code blocks follow different semantics . Known limitations Please note that annotations currently don't work in data tables as reported in #3453 , as data tables are scrollable elements and positioning is very tricky to get right. This might be fixed in the future.","title":"in everything else"},{"location":"reference/buttons/","text":"Buttons \u00b6 Material for MkDocs provides dedicated styles for primary and secondary buttons that can be added to any link, label or button element. This is especially useful for documents or landing pages with dedicated call-to-actions . Configuration \u00b6 This configuration allows to add attributes to all inline- and block-level elements with a simple syntax, turning any link into a button. Add the following lines to mkdocs.yml : markdown_extensions : - attr_list See additional configuration options: Attribute Lists Usage \u00b6 Adding buttons \u00b6 In order to render a link as a button, suffix it with curly braces and add the .md-button class selector to it. The button will receive the selected primary color and accent color if active. Button [ Subscribe to our newsletter ]( # ){ .md-button } Subscribe to our newsletter Adding primary buttons \u00b6 If you want to display a filled, primary button (like on the landing page of Material for MkDocs), add both, the .md-button and .md-button--primary CSS class selectors. Button, primary [ Subscribe to our newsletter ]( # ){ .md-button .md-button--primary } Subscribe to our newsletter Adding icon buttons \u00b6 Of course, icons can be added to all types of buttons by using the icon syntax together with any valid icon shortcode, which can be easily found with a few keystrokes through our icon search . Button with icon [ Send :fontawesome-solid-paper-plane: ]( # ){ .md-button } Send","title":"Buttons"},{"location":"reference/buttons/#buttons","text":"Material for MkDocs provides dedicated styles for primary and secondary buttons that can be added to any link, label or button element. This is especially useful for documents or landing pages with dedicated call-to-actions .","title":"Buttons"},{"location":"reference/buttons/#configuration","text":"This configuration allows to add attributes to all inline- and block-level elements with a simple syntax, turning any link into a button. Add the following lines to mkdocs.yml : markdown_extensions : - attr_list See additional configuration options: Attribute Lists","title":"Configuration"},{"location":"reference/buttons/#usage","text":"","title":"Usage"},{"location":"reference/buttons/#adding-buttons","text":"In order to render a link as a button, suffix it with curly braces and add the .md-button class selector to it. The button will receive the selected primary color and accent color if active. Button [ Subscribe to our newsletter ]( # ){ .md-button } Subscribe to our newsletter","title":"Adding buttons"},{"location":"reference/buttons/#adding-primary-buttons","text":"If you want to display a filled, primary button (like on the landing page of Material for MkDocs), add both, the .md-button and .md-button--primary CSS class selectors. Button, primary [ Subscribe to our newsletter ]( # ){ .md-button .md-button--primary } Subscribe to our newsletter","title":"Adding primary buttons"},{"location":"reference/buttons/#adding-icon-buttons","text":"Of course, icons can be added to all types of buttons by using the icon syntax together with any valid icon shortcode, which can be easily found with a few keystrokes through our icon search . Button with icon [ Send :fontawesome-solid-paper-plane: ]( # ){ .md-button } Send","title":"Adding icon buttons"},{"location":"reference/code-blocks/","text":"Code blocks \u00b6 Code blocks and examples are an essential part of technical project documentation. Material for MkDocs provides different ways to set up syntax highlighting for code blocks, either during build time using Pygments or during runtime using a JavaScript syntax highlighter. Configuration \u00b6 This configuration enables syntax highlighting on code blocks and inline code blocks, and allows to include source code directly from other files. Add the following lines to mkdocs.yml : markdown_extensions : - pymdownx.highlight : anchor_linenums : true - pymdownx.inlinehilite - pymdownx.snippets - pymdownx.superfences The following sections discuss how to use different syntax highlighting features with Pygments , the recommended highlighter, so they don't apply when using a JavaScript syntax highlighter. See additional configuration options: Highlight InlineHilite SuperFences Snippets Code annotations \u00b6 8.0.0 \u00b7 Feature flag Code annotations offer a comfortable and friendly way to attach arbitrary content to specific sections of code blocks by adding numeric markers in block and inline comments in the language of the code block. Add the following to mkdocs.yml to enable them globally: theme : features : - content.code.annotate # (1)! I'm a code annotation! I can contain code , formatted text , images, ... basically anything that can be written in Markdown. Enabling code annotations for a specific code block If you don't want to enable code annotations globally, because you don't like the automatic inlining behavior, you can enable them for a specific code block by using a slightly different syntax based on the Attribute Lists extension: ``` { .yaml .annotate } # Code block content ``` Note that the language shortcode which has to come first must now also be prefixed by a . . Anchor links \u00b6 8.5.0 \u00b7 Experimental In order to be able to link to code annotations and share them more easily, an anchor link is automatically added to each annotation, which you can copy via right click or open in a new tab: # (1)! If you Cmd me, I'm rendered open in a new tab. You can also right-click me to copy link address to share me with others. Usage \u00b6 Code blocks must be enclosed with two separate lines containing three backticks. To add syntax highlighting to those blocks, add the language shortcode directly after the opening block. See the list of available lexers to find the shortcode for a given language: Code block ``` py import tensorflow as tf ``` import tensorflow as tf Adding a title \u00b6 In order to provide additional context, a custom title can be added to a code block by using the title=\"<custom title>\" option directly after the shortcode, e.g. to display the name of a file: Code block with title ``` py title=\"bubble_sort.py\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` bubble_sort.py def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Adding annotations \u00b6 Code annotations can be placed anywhere in a code block where a comment for the language of the block can be placed, e.g. for JavaScript in // ... and /* ... */ , for YAML in # ... , etc. 1 : Code block with annotation ``` yaml theme: features: - content.code.annotate # (1) ``` 1. :man_raising_hand: I'm a code annotation! I can contain `code` , __formatted text__, images, ... basically anything that can be written in Markdown. theme : features : - content.code.annotate # (1) I'm a code annotation! I can contain code , formatted text , images, ... basically anything that can be written in Markdown. Stripping comments \u00b6 8.5.0 \u00b7 Experimental If you wish to strip the comment characters surrounding a code annotation, simply add an ! after the closing parenthesis of the code annotation: Code block with annotation, stripped ``` yaml # (1)! ``` 1. Look ma, less line noise! # (1)! Look ma, less line noise! Note that this only allows for a single code annotation to be rendered per comment. If you want to add multiple code annotations, comments cannot be stripped for technical reasons. Adding line numbers \u00b6 Line numbers can be added to a code block by using the linenums=\"<start>\" option directly after the shortcode, whereas <start> represents the starting line number. A code block can start from a line number other than 1 , which allows to split large code blocks for readability: Code block with line numbers ``` py linenums=\"1\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Highlighting specific lines \u00b6 Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language shortcode. Note that line counts start at 1 , regardless of the starting line number specified as part of linenums : Code block with highlighted lines ``` py hl_lines=\"2 3\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Highlighting inline code blocks \u00b6 When InlineHilite is enabled, syntax highlighting can be applied to inline code blocks by prefixing them with a shebang, i.e. #! , directly followed by the corresponding language shortcode . Inline code block The `#!python range()` function is used to generate a sequence of numbers. The range () function is used to generate a sequence of numbers. Embedding external files \u00b6 When Snippets is enabled, content from other files (including source files) can be embedded by using the --8<-- notation directly from within a code block: Code block with external content ``` title=\".browserslistrc\" --8<-- \".browserslistrc\" ``` .browserslistrc last 4 years Customization \u00b6 Custom syntax theme \u00b6 If Pygments is used, Material for MkDocs provides the styles for code blocks , which are built with a custom and well-balanced palette that works equally well for both color schemes : --md-code-hl-number-color --md-code-hl-special-color --md-code-hl-function-color --md-code-hl-constant-color --md-code-hl-keyword-color --md-code-hl-string-color --md-code-hl-name-color --md-code-hl-operator-color --md-code-hl-punctuation-color --md-code-hl-comment-color --md-code-hl-generic-color --md-code-hl-variable-color Code block foreground, background and line highlight colors are defined via: --md-code-fg-color --md-code-bg-color --md-code-hl-color Let's say you want to change the color of \"strings\" . While there are several types of string tokens , they use the same color. You can assign a new color by using an additional style sheet : docs/stylesheets/extra.css mkdocs.yml : root > * { --md-code-hl-string-color : #0FF1CE ; } extra_css : - stylesheets/extra.css If you want to tweak a specific type of string, e.g. `backticks` , you can lookup the specific CSS class name in the syntax theme definition , and override it as part of your additional style sheet : docs/stylesheets/extra.css mkdocs.yml . highlight . sb { color : #0FF1CE ; } extra_css : - stylesheets/extra.css Annotation tooltip width \u00b6 If you have a lot of content hosted inside your code annotations, it can be a good idea to increase the width of the tooltip by adding the following as part of an additional style sheet : docs/stylesheets/extra.css mkdocs.yml : root { --md-tooltip-width : 600 px ; } extra_css : - stylesheets/extra.css This will render annotations with a larger width: # (1)! Muuuuuuuuuuuuuuuch more space for content Annotations with numbers \u00b6 Prior to 8.1.0 , code annotations were rendered with markers showing the original number as used by the author. However, for technical reasons code annotation numbers restart each code block, which might lead to confusion. For this reason, code annotations now render as + signs which are rotated if they're open to denote that clicking them again will close them. If you wish to revert to the prior behavior and display code annotation numbers, you can add an additional style sheet and copy and paste the following CSS: docs/stylesheets/extra.css mkdocs.yml . md-typeset . md-annotation__index > :: before { content : attr ( data -md-annotation-id ); } . md-typeset : focus-within > . md-annotation__index > :: before { transform : none ; } extra_css : - stylesheets/extra.css Code annotations require syntax highlighting with Pygments \u2013 they're currently not compatible with JavaScript syntax highlighters, or languages that do not have comments in their grammar. However, we're actively working on supporting alternate ways of defining code annotations, allowing to always place code annotations at the end of lines. \u21a9","title":"Code blocks"},{"location":"reference/code-blocks/#code-blocks","text":"Code blocks and examples are an essential part of technical project documentation. Material for MkDocs provides different ways to set up syntax highlighting for code blocks, either during build time using Pygments or during runtime using a JavaScript syntax highlighter.","title":"Code blocks"},{"location":"reference/code-blocks/#configuration","text":"This configuration enables syntax highlighting on code blocks and inline code blocks, and allows to include source code directly from other files. Add the following lines to mkdocs.yml : markdown_extensions : - pymdownx.highlight : anchor_linenums : true - pymdownx.inlinehilite - pymdownx.snippets - pymdownx.superfences The following sections discuss how to use different syntax highlighting features with Pygments , the recommended highlighter, so they don't apply when using a JavaScript syntax highlighter. See additional configuration options: Highlight InlineHilite SuperFences Snippets","title":"Configuration"},{"location":"reference/code-blocks/#code-annotations","text":"8.0.0 \u00b7 Feature flag Code annotations offer a comfortable and friendly way to attach arbitrary content to specific sections of code blocks by adding numeric markers in block and inline comments in the language of the code block. Add the following to mkdocs.yml to enable them globally: theme : features : - content.code.annotate # (1)! I'm a code annotation! I can contain code , formatted text , images, ... basically anything that can be written in Markdown. Enabling code annotations for a specific code block If you don't want to enable code annotations globally, because you don't like the automatic inlining behavior, you can enable them for a specific code block by using a slightly different syntax based on the Attribute Lists extension: ``` { .yaml .annotate } # Code block content ``` Note that the language shortcode which has to come first must now also be prefixed by a . .","title":"Code annotations"},{"location":"reference/code-blocks/#anchor-links","text":"8.5.0 \u00b7 Experimental In order to be able to link to code annotations and share them more easily, an anchor link is automatically added to each annotation, which you can copy via right click or open in a new tab: # (1)! If you Cmd me, I'm rendered open in a new tab. You can also right-click me to copy link address to share me with others.","title":"Anchor links"},{"location":"reference/code-blocks/#usage","text":"Code blocks must be enclosed with two separate lines containing three backticks. To add syntax highlighting to those blocks, add the language shortcode directly after the opening block. See the list of available lexers to find the shortcode for a given language: Code block ``` py import tensorflow as tf ``` import tensorflow as tf","title":"Usage"},{"location":"reference/code-blocks/#adding-a-title","text":"In order to provide additional context, a custom title can be added to a code block by using the title=\"<custom title>\" option directly after the shortcode, e.g. to display the name of a file: Code block with title ``` py title=\"bubble_sort.py\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` bubble_sort.py def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ]","title":"Adding a title"},{"location":"reference/code-blocks/#adding-annotations","text":"Code annotations can be placed anywhere in a code block where a comment for the language of the block can be placed, e.g. for JavaScript in // ... and /* ... */ , for YAML in # ... , etc. 1 : Code block with annotation ``` yaml theme: features: - content.code.annotate # (1) ``` 1. :man_raising_hand: I'm a code annotation! I can contain `code` , __formatted text__, images, ... basically anything that can be written in Markdown. theme : features : - content.code.annotate # (1) I'm a code annotation! I can contain code , formatted text , images, ... basically anything that can be written in Markdown.","title":"Adding annotations"},{"location":"reference/code-blocks/#stripping-comments","text":"8.5.0 \u00b7 Experimental If you wish to strip the comment characters surrounding a code annotation, simply add an ! after the closing parenthesis of the code annotation: Code block with annotation, stripped ``` yaml # (1)! ``` 1. Look ma, less line noise! # (1)! Look ma, less line noise! Note that this only allows for a single code annotation to be rendered per comment. If you want to add multiple code annotations, comments cannot be stripped for technical reasons.","title":"Stripping comments"},{"location":"reference/code-blocks/#adding-line-numbers","text":"Line numbers can be added to a code block by using the linenums=\"<start>\" option directly after the shortcode, whereas <start> represents the starting line number. A code block can start from a line number other than 1 , which allows to split large code blocks for readability: Code block with line numbers ``` py linenums=\"1\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ]","title":"Adding line numbers"},{"location":"reference/code-blocks/#highlighting-specific-lines","text":"Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language shortcode. Note that line counts start at 1 , regardless of the starting line number specified as part of linenums : Code block with highlighted lines ``` py hl_lines=\"2 3\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ]","title":"Highlighting specific lines"},{"location":"reference/code-blocks/#highlighting-inline-code-blocks","text":"When InlineHilite is enabled, syntax highlighting can be applied to inline code blocks by prefixing them with a shebang, i.e. #! , directly followed by the corresponding language shortcode . Inline code block The `#!python range()` function is used to generate a sequence of numbers. The range () function is used to generate a sequence of numbers.","title":"Highlighting inline code blocks"},{"location":"reference/code-blocks/#embedding-external-files","text":"When Snippets is enabled, content from other files (including source files) can be embedded by using the --8<-- notation directly from within a code block: Code block with external content ``` title=\".browserslistrc\" --8<-- \".browserslistrc\" ``` .browserslistrc last 4 years","title":"Embedding external files"},{"location":"reference/code-blocks/#customization","text":"","title":"Customization"},{"location":"reference/code-blocks/#custom-syntax-theme","text":"If Pygments is used, Material for MkDocs provides the styles for code blocks , which are built with a custom and well-balanced palette that works equally well for both color schemes : --md-code-hl-number-color --md-code-hl-special-color --md-code-hl-function-color --md-code-hl-constant-color --md-code-hl-keyword-color --md-code-hl-string-color --md-code-hl-name-color --md-code-hl-operator-color --md-code-hl-punctuation-color --md-code-hl-comment-color --md-code-hl-generic-color --md-code-hl-variable-color Code block foreground, background and line highlight colors are defined via: --md-code-fg-color --md-code-bg-color --md-code-hl-color Let's say you want to change the color of \"strings\" . While there are several types of string tokens , they use the same color. You can assign a new color by using an additional style sheet : docs/stylesheets/extra.css mkdocs.yml : root > * { --md-code-hl-string-color : #0FF1CE ; } extra_css : - stylesheets/extra.css If you want to tweak a specific type of string, e.g. `backticks` , you can lookup the specific CSS class name in the syntax theme definition , and override it as part of your additional style sheet : docs/stylesheets/extra.css mkdocs.yml . highlight . sb { color : #0FF1CE ; } extra_css : - stylesheets/extra.css","title":"Custom syntax theme"},{"location":"reference/code-blocks/#annotation-tooltip-width","text":"If you have a lot of content hosted inside your code annotations, it can be a good idea to increase the width of the tooltip by adding the following as part of an additional style sheet : docs/stylesheets/extra.css mkdocs.yml : root { --md-tooltip-width : 600 px ; } extra_css : - stylesheets/extra.css This will render annotations with a larger width: # (1)! Muuuuuuuuuuuuuuuch more space for content","title":"Annotation tooltip width"},{"location":"reference/code-blocks/#annotations-with-numbers","text":"Prior to 8.1.0 , code annotations were rendered with markers showing the original number as used by the author. However, for technical reasons code annotation numbers restart each code block, which might lead to confusion. For this reason, code annotations now render as + signs which are rotated if they're open to denote that clicking them again will close them. If you wish to revert to the prior behavior and display code annotation numbers, you can add an additional style sheet and copy and paste the following CSS: docs/stylesheets/extra.css mkdocs.yml . md-typeset . md-annotation__index > :: before { content : attr ( data -md-annotation-id ); } . md-typeset : focus-within > . md-annotation__index > :: before { transform : none ; } extra_css : - stylesheets/extra.css Code annotations require syntax highlighting with Pygments \u2013 they're currently not compatible with JavaScript syntax highlighters, or languages that do not have comments in their grammar. However, we're actively working on supporting alternate ways of defining code annotations, allowing to always place code annotations at the end of lines. \u21a9","title":"Annotations with numbers"},{"location":"reference/content-tabs/","text":"Content tabs \u00b6 Sometimes, it's desirable to group alternative content under different tabs, e.g. when describing how to access an API from different languages or environments. Material for MkDocs allows for beautiful and functional tabs, grouping code blocks and other content. Configuration \u00b6 This configuration enables content tabs, and allows to nest arbitrary content inside content tabs, including code blocks and ... more content tabs! Add the following lines to mkdocs.yml : markdown_extensions : - pymdownx.superfences - pymdownx.tabbed : alternate_style : true See additional configuration options: SuperFences Tabbed Anchor links \u00b6 Sponsors only \u00b7 insiders-4.17.0 \u00b7 Experimental In order to link to content tabs and share them more easily, Insiders adds an anchor link to each content tab automatically, which you can copy via right click or open in a new tab: Open me in a new tab ... ... or me ... ... or even me You can copy the link of the tab and create a link on the same or any other page. For example, you can jump to the third tab above this paragraph or to the publishing guide for Insiders . Readable anchor links Python Markdown Extensions 9.6 adds support for slugification of content tabs, which produces nicer looking and more readable anchor links. Enable the slugify function with the following lines: markdown_extensions : - pymdownx.tabbed : slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower Fore more information, please see the extension guide . Linked content tabs \u00b6 8.3.0 \u00b7 Feature flag \u00b7 Experimental When enabled, all content tabs across the whole documentation site will be linked and switch to the same label when the user clicks on a tab. Add the following lines to mkdocs.yml : theme : features : - content.tabs.link Content tabs are linked based on their label, not offset. This means that all tabs with the same label will be activated when a user clicks a content tab regardless of order inside a container. Furthermore, this feature is fully integrated with instant loading and persisted across page loads. Feature enabled Feature disabled Usage \u00b6 Grouping code blocks \u00b6 Code blocks are one of the primary targets to be grouped, and can be considered a special case of content tabs, as tabs with a single code block are always rendered without horizontal spacing: Content tabs with code blocks === \"C\" ``` c #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); return 0; } ``` === \"C++\" ``` c++ #include <iostream> int main(void) { std::cout << \"Hello world!\" << std::endl; return 0; } ``` C C++ #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } Grouping other content \u00b6 When a content tab contains more than one code block, it is rendered with horizontal spacing. Vertical spacing is never added, but can be achieved by nesting tabs in other blocks: Content tabs === \"Unordered list\" * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered list\" 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci Unordered list Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Embedded content \u00b6 When SuperFences is enabled, content tabs can contain arbitrary nested content, including further content tabs, and can be nested in other blocks like admonitions or blockquotes: Content tabs in admonition !!! example === \"Unordered List\" ``` markdown * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci ``` === \"Ordered List\" ``` markdown 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci ``` Example Unordered List Ordered List * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci","title":"Content tabs"},{"location":"reference/content-tabs/#content-tabs","text":"Sometimes, it's desirable to group alternative content under different tabs, e.g. when describing how to access an API from different languages or environments. Material for MkDocs allows for beautiful and functional tabs, grouping code blocks and other content.","title":"Content tabs"},{"location":"reference/content-tabs/#configuration","text":"This configuration enables content tabs, and allows to nest arbitrary content inside content tabs, including code blocks and ... more content tabs! Add the following lines to mkdocs.yml : markdown_extensions : - pymdownx.superfences - pymdownx.tabbed : alternate_style : true See additional configuration options: SuperFences Tabbed","title":"Configuration"},{"location":"reference/content-tabs/#anchor-links","text":"Sponsors only \u00b7 insiders-4.17.0 \u00b7 Experimental In order to link to content tabs and share them more easily, Insiders adds an anchor link to each content tab automatically, which you can copy via right click or open in a new tab: Open me in a new tab ... ... or me ... ... or even me You can copy the link of the tab and create a link on the same or any other page. For example, you can jump to the third tab above this paragraph or to the publishing guide for Insiders . Readable anchor links Python Markdown Extensions 9.6 adds support for slugification of content tabs, which produces nicer looking and more readable anchor links. Enable the slugify function with the following lines: markdown_extensions : - pymdownx.tabbed : slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower Fore more information, please see the extension guide .","title":"Anchor links"},{"location":"reference/content-tabs/#linked-content-tabs","text":"8.3.0 \u00b7 Feature flag \u00b7 Experimental When enabled, all content tabs across the whole documentation site will be linked and switch to the same label when the user clicks on a tab. Add the following lines to mkdocs.yml : theme : features : - content.tabs.link Content tabs are linked based on their label, not offset. This means that all tabs with the same label will be activated when a user clicks a content tab regardless of order inside a container. Furthermore, this feature is fully integrated with instant loading and persisted across page loads. Feature enabled Feature disabled","title":"Linked content tabs"},{"location":"reference/content-tabs/#usage","text":"","title":"Usage"},{"location":"reference/content-tabs/#grouping-code-blocks","text":"Code blocks are one of the primary targets to be grouped, and can be considered a special case of content tabs, as tabs with a single code block are always rendered without horizontal spacing: Content tabs with code blocks === \"C\" ``` c #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); return 0; } ``` === \"C++\" ``` c++ #include <iostream> int main(void) { std::cout << \"Hello world!\" << std::endl; return 0; } ``` C C++ #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Grouping code blocks"},{"location":"reference/content-tabs/#grouping-other-content","text":"When a content tab contains more than one code block, it is rendered with horizontal spacing. Vertical spacing is never added, but can be achieved by nesting tabs in other blocks: Content tabs === \"Unordered list\" * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered list\" 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci Unordered list Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci","title":"Grouping other content"},{"location":"reference/content-tabs/#embedded-content","text":"When SuperFences is enabled, content tabs can contain arbitrary nested content, including further content tabs, and can be nested in other blocks like admonitions or blockquotes: Content tabs in admonition !!! example === \"Unordered List\" ``` markdown * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci ``` === \"Ordered List\" ``` markdown 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci ``` Example Unordered List Ordered List * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci","title":"Embedded content"},{"location":"reference/data-tables/","text":"Data tables \u00b6 Material for MkDocs defines default styles for data tables \u2013 an excellent way of rendering tabular data in project documentation. Furthermore, customizations like sortable tables can be achieved with a third-party library and some additional JavaScript . Configuration \u00b6 This configuration enables Markdown table support, which should normally be enabled by default, but to be sure, add the following lines to mkdocs.yml : markdown_extensions : - tables See additional configuration options: Tables Usage \u00b6 Data tables can be used at any position in your project documentation and can contain arbitrary Markdown, including inline code blocks, as well as icons and emojis : Data table | Method | Description | | ----------- | ------------------------------------ | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Method Description GET Fetch resource PUT Update resource DELETE Delete resource Column alignment \u00b6 If you want to align a specific column to the left , center or right , you can use the regular Markdown syntax placing : characters at the beginning and/or end of the divider. Left Center Right Data table, columns aligned to left | Method | Description | | :---------- | :----------------------------------- | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Method Description GET Fetch resource PUT Update resource DELETE Delete resource Data table, columns centered | Method | Description | | :---------: | :----------------------------------: | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Method Description GET Fetch resource PUT Update resource DELETE Delete resource Data table, columns aligned to right | Method | Description | | ----------: | -----------------------------------: | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Method Description GET Fetch resource PUT Update resource DELETE Delete resource Customization \u00b6 Sortable tables \u00b6 If you want to make data tables sortable, you can add tablesort , which is natively integrated with Material for MkDocs and will also work with instant loading via additional JavaScript : docs/javascripts/tablesort.js mkdocs.yml document $ . subscribe ( function () { var tables = document . querySelectorAll ( \"article table:not([class])\" ) tables . forEach ( function ( table ) { new Tablesort ( table ) }) }) extra_javascript : - https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js - javascripts/tablesort.js After applying the customization, data tables can be sorted by clicking on a column: Data table, columns sortable | Method | Description | | ----------- | ------------------------------------ | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Method Description GET Fetch resource PUT Update resource DELETE Delete resource Note that tablesort provides alternative comparison implementations like numbers, filesizes, dates and month names. See the tablesort documentation for more information. var tables = document.querySelectorAll(\"article table\") new Tablesort(tables.item(tables.length - 1));","title":"Data tables"},{"location":"reference/data-tables/#data-tables","text":"Material for MkDocs defines default styles for data tables \u2013 an excellent way of rendering tabular data in project documentation. Furthermore, customizations like sortable tables can be achieved with a third-party library and some additional JavaScript .","title":"Data tables"},{"location":"reference/data-tables/#configuration","text":"This configuration enables Markdown table support, which should normally be enabled by default, but to be sure, add the following lines to mkdocs.yml : markdown_extensions : - tables See additional configuration options: Tables","title":"Configuration"},{"location":"reference/data-tables/#usage","text":"Data tables can be used at any position in your project documentation and can contain arbitrary Markdown, including inline code blocks, as well as icons and emojis : Data table | Method | Description | | ----------- | ------------------------------------ | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Method Description GET Fetch resource PUT Update resource DELETE Delete resource","title":"Usage"},{"location":"reference/data-tables/#column-alignment","text":"If you want to align a specific column to the left , center or right , you can use the regular Markdown syntax placing : characters at the beginning and/or end of the divider. Left Center Right Data table, columns aligned to left | Method | Description | | :---------- | :----------------------------------- | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Method Description GET Fetch resource PUT Update resource DELETE Delete resource Data table, columns centered | Method | Description | | :---------: | :----------------------------------: | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Method Description GET Fetch resource PUT Update resource DELETE Delete resource Data table, columns aligned to right | Method | Description | | ----------: | -----------------------------------: | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Method Description GET Fetch resource PUT Update resource DELETE Delete resource","title":"Column alignment"},{"location":"reference/data-tables/#customization","text":"","title":"Customization"},{"location":"reference/data-tables/#sortable-tables","text":"If you want to make data tables sortable, you can add tablesort , which is natively integrated with Material for MkDocs and will also work with instant loading via additional JavaScript : docs/javascripts/tablesort.js mkdocs.yml document $ . subscribe ( function () { var tables = document . querySelectorAll ( \"article table:not([class])\" ) tables . forEach ( function ( table ) { new Tablesort ( table ) }) }) extra_javascript : - https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js - javascripts/tablesort.js After applying the customization, data tables can be sorted by clicking on a column: Data table, columns sortable | Method | Description | | ----------- | ------------------------------------ | | `GET` | :material-check: Fetch resource | | `PUT` | :material-check-all: Update resource | | `DELETE` | :material-close: Delete resource | Method Description GET Fetch resource PUT Update resource DELETE Delete resource Note that tablesort provides alternative comparison implementations like numbers, filesizes, dates and month names. See the tablesort documentation for more information. var tables = document.querySelectorAll(\"article table\") new Tablesort(tables.item(tables.length - 1));","title":"Sortable tables"},{"location":"reference/diagrams/","text":"Diagrams \u00b6 Diagrams help to communicate complex relationships and interconnections between different technical components, and are a great addition to project documentation. Material for MkDocs integrates with Mermaid.js , a very popular and flexible solution for drawing diagrams. Configuration \u00b6 8.2.0 \u00b7 Experimental This configuration enables native support for Mermaid.js diagrams. Material for MkDocs will automatically initialize the JavaScript runtime when a page includes a mermaid code block: markdown_extensions : - pymdownx.superfences : custom_fences : - name : mermaid class : mermaid format : !!python/name:pymdownx.superfences.fence_code_format No further configuration is necessary. Advantages over a custom integration: Works with instant loading without any additional effort Diagrams automatically use fonts and colors defined in mkdocs.yml 1 Fonts and colors can be customized with additional style sheets Support for both, light and dark color schemes \u2013 try it on this page! Usage \u00b6 Using flowcharts \u00b6 Flowcharts are diagrams that represent workflows or processes. The steps are rendered as nodes of various kinds and are connected by edges, describing the necessary order of steps: Flow chart ``` mermaid graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; ``` graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; Using sequence diagrams \u00b6 Sequence diagrams describe a specific scenario as sequential interactions between multiple objects or actors, including the messages that are exchanged between those actors: Sequence diagram ``` mermaid sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! ``` sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! Using state diagrams \u00b6 State diagrams are a great tool to describe the behavior of a system, decomposing it into a finite number of states, and transitions between those states: State diagram ``` mermaid stateDiagram-v2 state fork_state <<fork>> [*] --> fork_state fork_state --> State2 fork_state --> State3 state join_state <<join>> State2 --> join_state State3 --> join_state join_state --> State4 State4 --> [*] ``` stateDiagram-v2 state fork_state <<fork>> [*] --> fork_state fork_state --> State2 fork_state --> State3 state join_state <<join>> State2 --> join_state State3 --> join_state join_state --> State4 State4 --> [*] Using class diagrams \u00b6 Class diagrams are central to object oriented programing, describing the structure of a system by modelling entities as classes and relationships between them: Class diagram ``` mermaid classDiagram Person <|-- Student Person <|-- Professor Person : +String name Person : +String phoneNumber Person : +String emailAddress Person: +purchaseParkingPass() Address \"1\" <-- \"0..1\" Person:lives at class Student{ +int studentNumber +int averageMark +isEligibleToEnrol() +getSeminarsTaken() } class Professor{ +int salary } class Address{ +String street +String city +String state +int postalCode +String country -validate() +outputAsLabel() } ``` classDiagram Person <|-- Student Person <|-- Professor Person : +String name Person : +String phoneNumber Person : +String emailAddress Person: +purchaseParkingPass() Address \"1\" <-- \"0..1\" Person:lives at class Student{ +int studentNumber +int averageMark +isEligibleToEnrol() +getSeminarsTaken() } class Professor{ +int salary } class Address{ +String street +String city +String state +int postalCode +String country -validate() +outputAsLabel() } Using entity-relationship diagrams \u00b6 An entity-relationship diagram is composed of entity types and specifies relationships that exist between entities. It describes inter-related things in a specific domain of knowledge: Entity-relationship diagram ``` mermaid erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses ``` erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses Other diagram types \u00b6 Besides the diagram types listed above, Mermaid.js provides support for pie charts , gantt charts , user journeys , git graphs and requirement diagrams , all of which are not officially supported by Material for MkDocs. Those diagrams should still work as advertised by Mermaid.js , but we don't consider them a good choice, mostly as they don't work well on mobile. While all Mermaid.js features should work out-of-the-box, Material for MkDocs will currently only adjust the fonts and colors for flowcharts, sequence diagrams, class diagams, state diagrams and entity relationship diagrams. See the section on other diagrams for more informaton why this is currently not implemented for all diagrams. \u21a9","title":"Diagrams"},{"location":"reference/diagrams/#diagrams","text":"Diagrams help to communicate complex relationships and interconnections between different technical components, and are a great addition to project documentation. Material for MkDocs integrates with Mermaid.js , a very popular and flexible solution for drawing diagrams.","title":"Diagrams"},{"location":"reference/diagrams/#configuration","text":"8.2.0 \u00b7 Experimental This configuration enables native support for Mermaid.js diagrams. Material for MkDocs will automatically initialize the JavaScript runtime when a page includes a mermaid code block: markdown_extensions : - pymdownx.superfences : custom_fences : - name : mermaid class : mermaid format : !!python/name:pymdownx.superfences.fence_code_format No further configuration is necessary. Advantages over a custom integration: Works with instant loading without any additional effort Diagrams automatically use fonts and colors defined in mkdocs.yml 1 Fonts and colors can be customized with additional style sheets Support for both, light and dark color schemes \u2013 try it on this page!","title":"Configuration"},{"location":"reference/diagrams/#usage","text":"","title":"Usage"},{"location":"reference/diagrams/#using-flowcharts","text":"Flowcharts are diagrams that represent workflows or processes. The steps are rendered as nodes of various kinds and are connected by edges, describing the necessary order of steps: Flow chart ``` mermaid graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; ``` graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!];","title":"Using flowcharts"},{"location":"reference/diagrams/#using-sequence-diagrams","text":"Sequence diagrams describe a specific scenario as sequential interactions between multiple objects or actors, including the messages that are exchanged between those actors: Sequence diagram ``` mermaid sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! ``` sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good!","title":"Using sequence diagrams"},{"location":"reference/diagrams/#using-state-diagrams","text":"State diagrams are a great tool to describe the behavior of a system, decomposing it into a finite number of states, and transitions between those states: State diagram ``` mermaid stateDiagram-v2 state fork_state <<fork>> [*] --> fork_state fork_state --> State2 fork_state --> State3 state join_state <<join>> State2 --> join_state State3 --> join_state join_state --> State4 State4 --> [*] ``` stateDiagram-v2 state fork_state <<fork>> [*] --> fork_state fork_state --> State2 fork_state --> State3 state join_state <<join>> State2 --> join_state State3 --> join_state join_state --> State4 State4 --> [*]","title":"Using state diagrams"},{"location":"reference/diagrams/#using-class-diagrams","text":"Class diagrams are central to object oriented programing, describing the structure of a system by modelling entities as classes and relationships between them: Class diagram ``` mermaid classDiagram Person <|-- Student Person <|-- Professor Person : +String name Person : +String phoneNumber Person : +String emailAddress Person: +purchaseParkingPass() Address \"1\" <-- \"0..1\" Person:lives at class Student{ +int studentNumber +int averageMark +isEligibleToEnrol() +getSeminarsTaken() } class Professor{ +int salary } class Address{ +String street +String city +String state +int postalCode +String country -validate() +outputAsLabel() } ``` classDiagram Person <|-- Student Person <|-- Professor Person : +String name Person : +String phoneNumber Person : +String emailAddress Person: +purchaseParkingPass() Address \"1\" <-- \"0..1\" Person:lives at class Student{ +int studentNumber +int averageMark +isEligibleToEnrol() +getSeminarsTaken() } class Professor{ +int salary } class Address{ +String street +String city +String state +int postalCode +String country -validate() +outputAsLabel() }","title":"Using class diagrams"},{"location":"reference/diagrams/#using-entity-relationship-diagrams","text":"An entity-relationship diagram is composed of entity types and specifies relationships that exist between entities. It describes inter-related things in a specific domain of knowledge: Entity-relationship diagram ``` mermaid erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses ``` erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses","title":"Using entity-relationship diagrams"},{"location":"reference/diagrams/#other-diagram-types","text":"Besides the diagram types listed above, Mermaid.js provides support for pie charts , gantt charts , user journeys , git graphs and requirement diagrams , all of which are not officially supported by Material for MkDocs. Those diagrams should still work as advertised by Mermaid.js , but we don't consider them a good choice, mostly as they don't work well on mobile. While all Mermaid.js features should work out-of-the-box, Material for MkDocs will currently only adjust the fonts and colors for flowcharts, sequence diagrams, class diagams, state diagrams and entity relationship diagrams. See the section on other diagrams for more informaton why this is currently not implemented for all diagrams. \u21a9","title":"Other diagram types"},{"location":"reference/footnotes/","text":"Footnotes \u00b6 Footnotes are a great way to add supplemental or additional information to a specific word, phrase or sentence without interrupting the flow of a document. Material for MkDocs provides the ability to define, reference and render footnotes. Configuration \u00b6 This configuration adds the ability to define inline footnotes, which are then rendered below all Markdown content of a document. Add the following lines to mkdocs.yml : markdown_extensions : - footnotes See additional configuration options: Footnotes Usage \u00b6 Adding footnote references \u00b6 A footnote reference must be enclosed in square brackets and must start with a caret ^ , directly followed by an arbitrary identifier, which is similar to the standard Markdown link syntax. Text with footnote references Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2 Adding footnote content \u00b6 The footnote content must be declared with the same identifier as the reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink to the footnote reference is automatically added. on a single line \u00b6 Short footnotes can be written on the same line: Footnote [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Jump to footnote on multiple lines \u00b6 Paragraphs can be written on the next line and must be indented by four spaces: Footnote [^2]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Jump to footnote Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. \u21a9","title":"Footnotes"},{"location":"reference/footnotes/#footnotes","text":"Footnotes are a great way to add supplemental or additional information to a specific word, phrase or sentence without interrupting the flow of a document. Material for MkDocs provides the ability to define, reference and render footnotes.","title":"Footnotes"},{"location":"reference/footnotes/#configuration","text":"This configuration adds the ability to define inline footnotes, which are then rendered below all Markdown content of a document. Add the following lines to mkdocs.yml : markdown_extensions : - footnotes See additional configuration options: Footnotes","title":"Configuration"},{"location":"reference/footnotes/#usage","text":"","title":"Usage"},{"location":"reference/footnotes/#adding-footnote-references","text":"A footnote reference must be enclosed in square brackets and must start with a caret ^ , directly followed by an arbitrary identifier, which is similar to the standard Markdown link syntax. Text with footnote references Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2","title":"Adding footnote references"},{"location":"reference/footnotes/#adding-footnote-content","text":"The footnote content must be declared with the same identifier as the reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink to the footnote reference is automatically added.","title":"Adding footnote content"},{"location":"reference/footnotes/#on-a-single-line","text":"Short footnotes can be written on the same line: Footnote [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Jump to footnote","title":"on a single line"},{"location":"reference/footnotes/#on-multiple-lines","text":"Paragraphs can be written on the next line and must be indented by four spaces: Footnote [^2]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Jump to footnote Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. \u21a9","title":"on multiple lines"},{"location":"reference/formatting/","text":"Formatting \u00b6 Material for MkDocs provides support for several HTML elements that can be used to highlight sections of a document or apply specific formatting. Additionally, Critic Markup is supported, adding the ability to display suggested changes for a document. Configuration \u00b6 This configuration enables support for keyboard keys, tracking changes in documents, defining sub- and superscript and highlighting text. Add the following lines to mkdocs.yml : markdown_extensions : - pymdownx.critic - pymdownx.caret - pymdownx.keys - pymdownx.mark - pymdownx.tilde See additional configuration options: Critic Caret, Mark & Tilde Keys Usage \u00b6 Highlighting changes \u00b6 When Critic is enabled, Critic Markup can be used, which adds the ability to highlight suggested changes, as well as add inline comments to a document: Text with suggested changes Text can be {--deleted--} and replacement text {++added++}. This can also be combined into {~~one~>a single~~} operation. {==Highlighting==} is also possible {>>and comments can be added inline<<}. {== Formatting can also be applied to blocks by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==} Text can be deleted and replacement text added . This can also be combined into one a single operation. Highlighting is also possible and comments can be added inline . Formatting can also be applied to blocks by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. Highlighting text \u00b6 When Caret, Mark & Tilde are enabled, text can be highlighted with a simple syntax, which is more convenient that directly using the corresponding mark , ins and del HTML tags: Text with highlighting - ==This was marked== - ^^This was inserted^^ - ~~This was deleted~~ This was marked This was inserted This was deleted Sub- and superscripts \u00b6 When Caret & Tilde are enabled, text can be sub- and superscripted with a simple syntax, which is more convenient than directly using the corresponding sub and sup HTML tags: Text with sub- und superscripts - H~2~O - A^T^A H 2 O A T A Adding keyboard keys \u00b6 When Keys is enabled, keyboard keys can be rendered with a simple syntax. Consult the Python Markdown Extensions documentation to learn about all available shortcodes: Keyboard keys ++ctrl+alt+del++ Ctrl + Alt + Del","title":"Formatting"},{"location":"reference/formatting/#formatting","text":"Material for MkDocs provides support for several HTML elements that can be used to highlight sections of a document or apply specific formatting. Additionally, Critic Markup is supported, adding the ability to display suggested changes for a document.","title":"Formatting"},{"location":"reference/formatting/#configuration","text":"This configuration enables support for keyboard keys, tracking changes in documents, defining sub- and superscript and highlighting text. Add the following lines to mkdocs.yml : markdown_extensions : - pymdownx.critic - pymdownx.caret - pymdownx.keys - pymdownx.mark - pymdownx.tilde See additional configuration options: Critic Caret, Mark & Tilde Keys","title":"Configuration"},{"location":"reference/formatting/#usage","text":"","title":"Usage"},{"location":"reference/formatting/#highlighting-changes","text":"When Critic is enabled, Critic Markup can be used, which adds the ability to highlight suggested changes, as well as add inline comments to a document: Text with suggested changes Text can be {--deleted--} and replacement text {++added++}. This can also be combined into {~~one~>a single~~} operation. {==Highlighting==} is also possible {>>and comments can be added inline<<}. {== Formatting can also be applied to blocks by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==} Text can be deleted and replacement text added . This can also be combined into one a single operation. Highlighting is also possible and comments can be added inline . Formatting can also be applied to blocks by putting the opening and closing tags on separate lines and adding new lines between the tags and the content.","title":"Highlighting changes"},{"location":"reference/formatting/#highlighting-text","text":"When Caret, Mark & Tilde are enabled, text can be highlighted with a simple syntax, which is more convenient that directly using the corresponding mark , ins and del HTML tags: Text with highlighting - ==This was marked== - ^^This was inserted^^ - ~~This was deleted~~ This was marked This was inserted This was deleted","title":"Highlighting text"},{"location":"reference/formatting/#sub-and-superscripts","text":"When Caret & Tilde are enabled, text can be sub- and superscripted with a simple syntax, which is more convenient than directly using the corresponding sub and sup HTML tags: Text with sub- und superscripts - H~2~O - A^T^A H 2 O A T A","title":"Sub- and superscripts"},{"location":"reference/formatting/#adding-keyboard-keys","text":"When Keys is enabled, keyboard keys can be rendered with a simple syntax. Consult the Python Markdown Extensions documentation to learn about all available shortcodes: Keyboard keys ++ctrl+alt+del++ Ctrl + Alt + Del","title":"Adding keyboard keys"},{"location":"reference/grids/","text":"Grids \u00b6 Material for MkDocs makes it easy to arrange sections into grids, grouping blocks that convey similar meaning or are of equal importance. Grids are just perfect for building index pages that show a brief overview of a large section of your documentation. Configuration \u00b6 This configuration enables the use of grids, allowing to bring blocks of identical or different types into a rectangular shape. Add the following lines to mkdocs.yml : markdown_extensions : # (1)! - attr_list - md_in_html Note that some of the examples listed below use icons and emojis , which have to be configured separately . See additional configuration options: Attribute Lists Markdown in HTML Usage \u00b6 Grids come in two flavors: card grids , which wrap each element in a card that levitates on hover, and generic grids , which allow to arrange arbitrary block elements in a rectangular shape. Using card grids \u00b6 Sponsors only \u00b7 insiders-4.12.0 \u00b7 Experimental Card grids wrap each grid item with a beautiful hover card that levitates on hover. They come in two slightly different syntaxes: list and block syntax , adding support for distinct use cases. List syntax \u00b6 The list syntax is essentially a shortcut for card grids , and consists of an unordered (or ordered) list wrapped by a div with both, the grid and cards classes: Card grid < div class = \"grid cards\" markdown > - :fontawesome-brands-html5: __HTML__ for content and structure - :fontawesome-brands-js: __JavaScript__ for interactivity - :fontawesome-brands-css3: __CSS__ for text running out of boxes - :fontawesome-brands-internet-explorer: __Internet Explorer__ ... huh? </ div > HTML for content and structure JavaScript for interactivity CSS for text running out of boxes Internet Explorer ... huh? List elements can contain arbitrary Markdown, as long as the surrounding div defines the markdown attribute. Following is a more complex example, which includes icons and links: Card grid, complex example < div class = \"grid cards\" markdown > - :material-clock-fast:{ .lg .middle } __Set up in 5 minutes__ --- Install [`mkdocs-material`](#) with [`pip`](#) and get up and running in minutes [:octicons-arrow-right-24: Getting started](#) - :fontawesome-brands-markdown:{ .lg .middle } __It's just Markdown__ --- Focus on your content and generate a responsive and searchable static site [:octicons-arrow-right-24: Reference](#) - :material-format-font:{ .lg .middle } __Made to measure__ --- Change the colors, fonts, language, icons, logo and more with a few lines [:octicons-arrow-right-24: Customization](#) - :material-scale-balance:{ .lg .middle } __Open Source, MIT__ --- Material for MkDocs is licensed under MIT and available on [GitHub] [:octicons-arrow-right-24: License](#) </ div > Set up in 5 minutes Install mkdocs-material with pip and get up and running in minutes Getting started It's just Markdown Focus on your content and generate a responsive and searchable static site Reference Made to measure Change the colors, fonts, language, icons, logo and more with a few lines Customization Open Source, MIT Material for MkDocs is licensed under MIT and available on GitHub License If there's insufficient space to render grid items next to each other, the items will stretch to the full width of the viewport, e.g. on mobile viewports. If there's more space available, grids will render in items of 3 and more, e.g. when hiding both sidebars . Block syntax \u00b6 The block syntax allows for arranging cards in grids together with other elements , as explained in the section on generic grids . Just add the card class to any block element inside a grid : Card grid, blocks < div class = \"grid\" markdown > :fontawesome-brands-html5: __HTML__ for content and structure { .card } :fontawesome-brands-js: __JavaScript__ for interactivity { .card } :fontawesome-brands-css3: __CSS__ for text running out of boxes { .card } > :fontawesome-brands-internet-explorer: __Internet Explorer__ ... huh? </ div > HTML for content and structure JavaScript for interactivity CSS for text running out of boxes Internet Explorer ... huh? While this syntax may seem unnecessarily verbose at first, the previous example shows how card grids can now be mixed with other elements that will also stretch to the grid. Using generic grids \u00b6 Sponsors only \u00b7 insiders-4.12.0 \u00b7 Experimental Generic grids allow for arranging arbitrary block elements in a grid, including admonitions , code blocks , content tabs and more. Just wrap a set of blocks by using a div with the grid class: Generic grid < div class = \"grid\" markdown > === \"Unordered list\" * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered list\" 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci ``` title=\"Content tabs\" === \"Unordered list\" * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered list\" 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci ``` </ div > Unordered list Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Content tabs === \"Unordered list\" * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered list\" 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci","title":"Grids"},{"location":"reference/grids/#grids","text":"Material for MkDocs makes it easy to arrange sections into grids, grouping blocks that convey similar meaning or are of equal importance. Grids are just perfect for building index pages that show a brief overview of a large section of your documentation.","title":"Grids"},{"location":"reference/grids/#configuration","text":"This configuration enables the use of grids, allowing to bring blocks of identical or different types into a rectangular shape. Add the following lines to mkdocs.yml : markdown_extensions : # (1)! - attr_list - md_in_html Note that some of the examples listed below use icons and emojis , which have to be configured separately . See additional configuration options: Attribute Lists Markdown in HTML","title":"Configuration"},{"location":"reference/grids/#usage","text":"Grids come in two flavors: card grids , which wrap each element in a card that levitates on hover, and generic grids , which allow to arrange arbitrary block elements in a rectangular shape.","title":"Usage"},{"location":"reference/grids/#using-card-grids","text":"Sponsors only \u00b7 insiders-4.12.0 \u00b7 Experimental Card grids wrap each grid item with a beautiful hover card that levitates on hover. They come in two slightly different syntaxes: list and block syntax , adding support for distinct use cases.","title":"Using card grids"},{"location":"reference/grids/#list-syntax","text":"The list syntax is essentially a shortcut for card grids , and consists of an unordered (or ordered) list wrapped by a div with both, the grid and cards classes: Card grid < div class = \"grid cards\" markdown > - :fontawesome-brands-html5: __HTML__ for content and structure - :fontawesome-brands-js: __JavaScript__ for interactivity - :fontawesome-brands-css3: __CSS__ for text running out of boxes - :fontawesome-brands-internet-explorer: __Internet Explorer__ ... huh? </ div > HTML for content and structure JavaScript for interactivity CSS for text running out of boxes Internet Explorer ... huh? List elements can contain arbitrary Markdown, as long as the surrounding div defines the markdown attribute. Following is a more complex example, which includes icons and links: Card grid, complex example < div class = \"grid cards\" markdown > - :material-clock-fast:{ .lg .middle } __Set up in 5 minutes__ --- Install [`mkdocs-material`](#) with [`pip`](#) and get up and running in minutes [:octicons-arrow-right-24: Getting started](#) - :fontawesome-brands-markdown:{ .lg .middle } __It's just Markdown__ --- Focus on your content and generate a responsive and searchable static site [:octicons-arrow-right-24: Reference](#) - :material-format-font:{ .lg .middle } __Made to measure__ --- Change the colors, fonts, language, icons, logo and more with a few lines [:octicons-arrow-right-24: Customization](#) - :material-scale-balance:{ .lg .middle } __Open Source, MIT__ --- Material for MkDocs is licensed under MIT and available on [GitHub] [:octicons-arrow-right-24: License](#) </ div > Set up in 5 minutes Install mkdocs-material with pip and get up and running in minutes Getting started It's just Markdown Focus on your content and generate a responsive and searchable static site Reference Made to measure Change the colors, fonts, language, icons, logo and more with a few lines Customization Open Source, MIT Material for MkDocs is licensed under MIT and available on GitHub License If there's insufficient space to render grid items next to each other, the items will stretch to the full width of the viewport, e.g. on mobile viewports. If there's more space available, grids will render in items of 3 and more, e.g. when hiding both sidebars .","title":"List syntax"},{"location":"reference/grids/#block-syntax","text":"The block syntax allows for arranging cards in grids together with other elements , as explained in the section on generic grids . Just add the card class to any block element inside a grid : Card grid, blocks < div class = \"grid\" markdown > :fontawesome-brands-html5: __HTML__ for content and structure { .card } :fontawesome-brands-js: __JavaScript__ for interactivity { .card } :fontawesome-brands-css3: __CSS__ for text running out of boxes { .card } > :fontawesome-brands-internet-explorer: __Internet Explorer__ ... huh? </ div > HTML for content and structure JavaScript for interactivity CSS for text running out of boxes Internet Explorer ... huh? While this syntax may seem unnecessarily verbose at first, the previous example shows how card grids can now be mixed with other elements that will also stretch to the grid.","title":"Block syntax"},{"location":"reference/grids/#using-generic-grids","text":"Sponsors only \u00b7 insiders-4.12.0 \u00b7 Experimental Generic grids allow for arranging arbitrary block elements in a grid, including admonitions , code blocks , content tabs and more. Just wrap a set of blocks by using a div with the grid class: Generic grid < div class = \"grid\" markdown > === \"Unordered list\" * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered list\" 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci ``` title=\"Content tabs\" === \"Unordered list\" * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered list\" 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci ``` </ div > Unordered list Ordered list Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Sed sagittis eleifend rutrum Donec vitae suscipit est Nulla tempor lobortis orci Content tabs === \"Unordered list\" * Sed sagittis eleifend rutrum * Donec vitae suscipit est * Nulla tempor lobortis orci === \"Ordered list\" 1. Sed sagittis eleifend rutrum 2. Donec vitae suscipit est 3. Nulla tempor lobortis orci","title":"Using generic grids"},{"location":"reference/icons-emojis/","text":"Icons, Emojis \u00b6 One of the best features of Material for MkDocs is the possibility to use more than 10,000 icons and thousands of emojis in your project documentation with practically zero additional effort. Moreover, custom icons can be added and used in mkdocs.yml , documents and templates. Search \u00b6 Tip: Enter some keywords to find icons and emojis and click on the shortcode to copy it to your clipboard. Configuration \u00b6 This configuration enables the use of icons and emojis by using simple shortcodes which can be discovered through the icon search . Add the following lines to mkdocs.yml : markdown_extensions : - attr_list - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator : !!python/name:materialx.emoji.to_svg The following icon sets are bundled with Material for MkDocs: \u2013 Material Design \u2013 FontAwesome \u2013 Octicons :simple-simpleicons: \u2013 Simple Icons See additional configuration options: Attribute Lists Emoji Emoji with custom icons Usage \u00b6 Using emojis \u00b6 Emojis can be integrated in Markdown by putting the shortcode of the emoji between two colons. If you're using Twemoji (recommended), you can look up the shortcodes at Emojipedia : Emoji :smile: Using icons \u00b6 When Emoji is enabled, icons can be used similar to emojis, by referencing a valid path to any icon bundled with the theme, which are located in the .icons directory, and replacing / with - : Icon :fontawesome-regular-face-laugh-wink: with colors \u00b6 When Attribute Lists is enabled, custom CSS classes can be added to icons by suffixing the icon with a special syntax. While HTML allows to use inline styles , it's always recommended to add an additional style sheet and move declarations into dedicated CSS classes: .twitter { color: #1DA1F2; } docs/stylesheets/extra.css mkdocs.yml . twitter { color : #1DA1F2 ; } extra_css : - stylesheets/extra.css After applying the customization, add the CSS class to the icon shortcode: Icon with color :fontawesome-brands-twitter:{ .twitter } with animations \u00b6 Similar to adding colors , it's just as easy to add animations to icons by using an additional style sheet , defining a @keyframes rule and adding a dedicated CSS class to the icon: docs/stylesheets/extra.css mkdocs.yml @ keyframes heart { 0 %, 40 %, 80 %, 100 % { transform : scale ( 1 ); } 20 %, 60 % { transform : scale ( 1.15 ); } } . heart { animation : heart 1000 ms infinite ; } extra_css : - stylesheets/extra.css After applying the customization, add the CSS class to the icon shortcode: Icon with animation :octicons-heart-fill-24:{ .heart } Customization \u00b6 Using icons in templates \u00b6 When you're extending the theme with partials or blocks, you can simply reference any icon that's bundled with the theme with Jinja's include function and wrap it with the .twemoji CSS class: < span class = \"twemoji\" > {% include \".icons/fontawesome/brands/twitter.svg\" %} <!-- (1)! --> </ span > Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: This is exactly what Material for MkDocs does in its templates.","title":"Icons, Emojis"},{"location":"reference/icons-emojis/#icons-emojis","text":"One of the best features of Material for MkDocs is the possibility to use more than 10,000 icons and thousands of emojis in your project documentation with practically zero additional effort. Moreover, custom icons can be added and used in mkdocs.yml , documents and templates.","title":"Icons, Emojis"},{"location":"reference/icons-emojis/#search","text":"Tip: Enter some keywords to find icons and emojis and click on the shortcode to copy it to your clipboard.","title":"Search"},{"location":"reference/icons-emojis/#configuration","text":"This configuration enables the use of icons and emojis by using simple shortcodes which can be discovered through the icon search . Add the following lines to mkdocs.yml : markdown_extensions : - attr_list - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator : !!python/name:materialx.emoji.to_svg The following icon sets are bundled with Material for MkDocs: \u2013 Material Design \u2013 FontAwesome \u2013 Octicons :simple-simpleicons: \u2013 Simple Icons See additional configuration options: Attribute Lists Emoji Emoji with custom icons","title":"Configuration"},{"location":"reference/icons-emojis/#usage","text":"","title":"Usage"},{"location":"reference/icons-emojis/#using-emojis","text":"Emojis can be integrated in Markdown by putting the shortcode of the emoji between two colons. If you're using Twemoji (recommended), you can look up the shortcodes at Emojipedia : Emoji :smile:","title":"Using emojis"},{"location":"reference/icons-emojis/#using-icons","text":"When Emoji is enabled, icons can be used similar to emojis, by referencing a valid path to any icon bundled with the theme, which are located in the .icons directory, and replacing / with - : Icon :fontawesome-regular-face-laugh-wink:","title":"Using icons"},{"location":"reference/icons-emojis/#with-colors","text":"When Attribute Lists is enabled, custom CSS classes can be added to icons by suffixing the icon with a special syntax. While HTML allows to use inline styles , it's always recommended to add an additional style sheet and move declarations into dedicated CSS classes: .twitter { color: #1DA1F2; } docs/stylesheets/extra.css mkdocs.yml . twitter { color : #1DA1F2 ; } extra_css : - stylesheets/extra.css After applying the customization, add the CSS class to the icon shortcode: Icon with color :fontawesome-brands-twitter:{ .twitter }","title":"with colors"},{"location":"reference/icons-emojis/#with-animations","text":"Similar to adding colors , it's just as easy to add animations to icons by using an additional style sheet , defining a @keyframes rule and adding a dedicated CSS class to the icon: docs/stylesheets/extra.css mkdocs.yml @ keyframes heart { 0 %, 40 %, 80 %, 100 % { transform : scale ( 1 ); } 20 %, 60 % { transform : scale ( 1.15 ); } } . heart { animation : heart 1000 ms infinite ; } extra_css : - stylesheets/extra.css After applying the customization, add the CSS class to the icon shortcode: Icon with animation :octicons-heart-fill-24:{ .heart }","title":"with animations"},{"location":"reference/icons-emojis/#customization","text":"","title":"Customization"},{"location":"reference/icons-emojis/#using-icons-in-templates","text":"When you're extending the theme with partials or blocks, you can simply reference any icon that's bundled with the theme with Jinja's include function and wrap it with the .twemoji CSS class: < span class = \"twemoji\" > {% include \".icons/fontawesome/brands/twitter.svg\" %} <!-- (1)! --> </ span > Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: This is exactly what Material for MkDocs does in its templates.","title":"Using icons in templates"},{"location":"reference/images/","text":"Images \u00b6 While images are first-class citizens of Markdown and part of the core syntax, it can be difficult to work with them. Material for MkDocs makes working with images more comfortable, providing styles for image alignment and image captions. Configuration \u00b6 This configuration adds the ability to align images, add captions to images (rendering them as figures), and mark large images for lazy-loading. Add the following lines to mkdocs.yml : markdown_extensions : - attr_list - md_in_html See additional configuration options: Attribute Lists Markdown in HTML Lightbox \u00b6 0.1.0 \u00b7 Plugin If you want to add image zoom functionality to your documentation, the glightbox plugin is an excellent choice, as it integrates perfectly with Material for MkDocs. Install it with pip : pip install mkdocs-glightbox Then, add the following lines to mkdocs.yml : plugins : - glightbox We recommend checking out the available configuration options . Usage \u00b6 Image alignment \u00b6 When Attribute Lists is enabled, images can be aligned by adding the respective alignment directions via the align attribute, i.e. align=left or align=right : Left Right Image, aligned to left ![ Image title ]( https://dummyimage.com/600x400/eee/aaa ){ align=left } Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Image, aligned to right ![ Image title ]( https://dummyimage.com/600x400/eee/aaa ){ align=right } Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. If there's insufficient space to render the text next to the image, the image will stretch to the full width of the viewport, e.g. on mobile viewports. Why is there no centered alignment? The align attribute doesn't allow for centered alignment, which is why this option is not supported by Material for MkDocs. 1 Instead, the image captions syntax can be used, as captions are optional. Image captions \u00b6 Sadly, the Markdown syntax doesn't provide native support for image captions, but it's always possible to use the Markdown in HTML extension with literal figure and figcaption tags: Image with caption < figure markdown > ![Image title](https://dummyimage.com/600x400/){ width=\"300\" } < figcaption > Image caption </ figcaption > </ figure > Image caption Image lazy-loading \u00b6 Modern browsers provide native support for lazy-loading images through the loading=lazy directive, which degrades to eager-loading in browsers without support: Image, lazy-loaded ![ Image title ]( https://dummyimage.com/600x400/ ){ loading=lazy } Light and dark mode \u00b6 8.1.1 \u00b7 Experimental If you added a color palette toggle and want to show different images for light and dark color schemes, you can append a #only-light or #only-dark hash fragment to the image URL: Image, different for light and dark mode ![ Image title ]( https://dummyimage.com/600x400/f5f5f5/aaaaaa#only-light ) ![ Image title ]( https://dummyimage.com/600x400/21222c/d5d7e2#only-dark ) You might also realize that the align attribute has been deprecated as of HTML5, so why use it anyways? The main reason is portability \u2013 it's still supported by all browsers and clients, and is very unlikely to be completely removed, as many older websites still use it. This ensures a consistent appearance when a Markdown file with these attributes is viewed outside of a website generated by Material for MkDocs. \u21a9","title":"Images"},{"location":"reference/images/#images","text":"While images are first-class citizens of Markdown and part of the core syntax, it can be difficult to work with them. Material for MkDocs makes working with images more comfortable, providing styles for image alignment and image captions.","title":"Images"},{"location":"reference/images/#configuration","text":"This configuration adds the ability to align images, add captions to images (rendering them as figures), and mark large images for lazy-loading. Add the following lines to mkdocs.yml : markdown_extensions : - attr_list - md_in_html See additional configuration options: Attribute Lists Markdown in HTML","title":"Configuration"},{"location":"reference/images/#lightbox","text":"0.1.0 \u00b7 Plugin If you want to add image zoom functionality to your documentation, the glightbox plugin is an excellent choice, as it integrates perfectly with Material for MkDocs. Install it with pip : pip install mkdocs-glightbox Then, add the following lines to mkdocs.yml : plugins : - glightbox We recommend checking out the available configuration options .","title":"Lightbox"},{"location":"reference/images/#usage","text":"","title":"Usage"},{"location":"reference/images/#image-alignment","text":"When Attribute Lists is enabled, images can be aligned by adding the respective alignment directions via the align attribute, i.e. align=left or align=right : Left Right Image, aligned to left ![ Image title ]( https://dummyimage.com/600x400/eee/aaa ){ align=left } Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Image, aligned to right ![ Image title ]( https://dummyimage.com/600x400/eee/aaa ){ align=right } Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. If there's insufficient space to render the text next to the image, the image will stretch to the full width of the viewport, e.g. on mobile viewports. Why is there no centered alignment? The align attribute doesn't allow for centered alignment, which is why this option is not supported by Material for MkDocs. 1 Instead, the image captions syntax can be used, as captions are optional.","title":"Image alignment"},{"location":"reference/images/#image-captions","text":"Sadly, the Markdown syntax doesn't provide native support for image captions, but it's always possible to use the Markdown in HTML extension with literal figure and figcaption tags: Image with caption < figure markdown > ![Image title](https://dummyimage.com/600x400/){ width=\"300\" } < figcaption > Image caption </ figcaption > </ figure > Image caption","title":"Image captions"},{"location":"reference/images/#image-lazy-loading","text":"Modern browsers provide native support for lazy-loading images through the loading=lazy directive, which degrades to eager-loading in browsers without support: Image, lazy-loaded ![ Image title ]( https://dummyimage.com/600x400/ ){ loading=lazy }","title":"Image lazy-loading"},{"location":"reference/images/#light-and-dark-mode","text":"8.1.1 \u00b7 Experimental If you added a color palette toggle and want to show different images for light and dark color schemes, you can append a #only-light or #only-dark hash fragment to the image URL: Image, different for light and dark mode ![ Image title ]( https://dummyimage.com/600x400/f5f5f5/aaaaaa#only-light ) ![ Image title ]( https://dummyimage.com/600x400/21222c/d5d7e2#only-dark ) You might also realize that the align attribute has been deprecated as of HTML5, so why use it anyways? The main reason is portability \u2013 it's still supported by all browsers and clients, and is very unlikely to be completely removed, as many older websites still use it. This ensures a consistent appearance when a Markdown file with these attributes is viewed outside of a website generated by Material for MkDocs. \u21a9","title":"Light and dark mode"},{"location":"reference/lists/","text":"Lists \u00b6 Material for MkDocs supports several flavors of lists that cater to different use cases, including unordered lists and ordered lists , which are supported through standard Markdown, as well as definition lists and task lists , which are supported through extensions. Configuration \u00b6 This configuration enables the use of definition lists and tasks lists, which are both not part of the standard Markdown syntax. Add the following lines to mkdocs.yml : markdown_extensions : - def_list - pymdownx.tasklist : custom_checkbox : true See additional configuration options: Definition Lists Tasklist Usage \u00b6 Using unordered lists \u00b6 Unordered lists can be written by prefixing a line with a - , * or + list marker, all of which can be used interchangeably. Furthermore, all flavors of lists can be nested inside each other: List, unordered - Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. * Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. * Nam vulputate tincidunt fringilla. * Nullam dignissim ultrices urna non auctor. Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Using ordered lists \u00b6 Ordered lists must start with a number immediately followed by a dot. The numbers do not need to be consecutive and can be all set to 1. , as they will be re-numbered when rendered: List, ordered 1. Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. 1. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. 2. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. 1. Mauris dictum mi lacus 2. Ut sit amet placerat ante 3. Suspendisse ac eros arcu Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Using definition lists \u00b6 When Definition Lists is enabled, lists of arbitrary key-value pairs, e.g. the parameters of functions or modules, can be enumerated with a simple syntax: Definition list `Lorem ipsum dolor sit amet` : Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. `Cras arcu libero` : Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Using task lists \u00b6 When Tasklist is enabled, unordered list items can be prefixed with [ ] to render an unchecked checkbox or [x] to render a checked checkbox, allowing for the definition of task lists: Task list - [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit - [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [ ] Praesent sed risus massa - [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"Lists"},{"location":"reference/lists/#lists","text":"Material for MkDocs supports several flavors of lists that cater to different use cases, including unordered lists and ordered lists , which are supported through standard Markdown, as well as definition lists and task lists , which are supported through extensions.","title":"Lists"},{"location":"reference/lists/#configuration","text":"This configuration enables the use of definition lists and tasks lists, which are both not part of the standard Markdown syntax. Add the following lines to mkdocs.yml : markdown_extensions : - def_list - pymdownx.tasklist : custom_checkbox : true See additional configuration options: Definition Lists Tasklist","title":"Configuration"},{"location":"reference/lists/#usage","text":"","title":"Usage"},{"location":"reference/lists/#using-unordered-lists","text":"Unordered lists can be written by prefixing a line with a - , * or + list marker, all of which can be used interchangeably. Furthermore, all flavors of lists can be nested inside each other: List, unordered - Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. * Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. * Nam vulputate tincidunt fringilla. * Nullam dignissim ultrices urna non auctor. Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor.","title":"Using unordered lists"},{"location":"reference/lists/#using-ordered-lists","text":"Ordered lists must start with a number immediately followed by a dot. The numbers do not need to be consecutive and can be all set to 1. , as they will be re-numbered when rendered: List, ordered 1. Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. 1. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. 2. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. 1. Mauris dictum mi lacus 2. Ut sit amet placerat ante 3. Suspendisse ac eros arcu Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu","title":"Using ordered lists"},{"location":"reference/lists/#using-definition-lists","text":"When Definition Lists is enabled, lists of arbitrary key-value pairs, e.g. the parameters of functions or modules, can be enumerated with a simple syntax: Definition list `Lorem ipsum dolor sit amet` : Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. `Cras arcu libero` : Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor.","title":"Using definition lists"},{"location":"reference/lists/#using-task-lists","text":"When Tasklist is enabled, unordered list items can be prefixed with [ ] to render an unchecked checkbox or [x] to render a checked checkbox, allowing for the definition of task lists: Task list - [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit - [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [ ] Praesent sed risus massa - [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"Using task lists"},{"location":"reference/mathjax/","text":"MathJax \u00b6 MathJax is a beautiful and accessible way to display mathematical content in the browser, adds support for mathematical typesetting in different notations (e.g. LaTeX , MathML , AsciiMath ), and can be easily integrated with Material for MkDocs. Configuration \u00b6 This configuration enables support for rendering block and inline block equations through MathJax . Create a configuration file and add the following lines to mkdocs.yml : docs/javascripts/mathjax.js mkdocs.yml window . MathJax = { tex : { inlineMath : [[ \"\\\\(\" , \"\\\\)\" ]], displayMath : [[ \"\\\\[\" , \"\\\\]\" ]], processEscapes : true , processEnvironments : true }, options : { ignoreHtmlClass : \".*|\" , processHtmlClass : \"arithmatex\" } }; document $ . subscribe (() => { // (1)! MathJax . typesetPromise () }) This integrates MathJax with instant loading . markdown_extensions : - pymdownx.arithmatex : generic : true extra_javascript : - javascripts/mathjax.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js See additional configuration options: Arithmatex window.MathJax = { tex: { inlineMath: [[\"\\\\(\", \"\\\\)\"]], displayMath: [[\"\\\\[\", \"\\\\]\"]], processEscapes: true, processEnvironments: true }, options: { ignoreHtmlClass: \".*|\", processHtmlClass: \"arithmatex\" } }; Usage \u00b6 Using block syntax \u00b6 Blocks must be enclosed in $$ ... $$ or \\[ ... \\] on separate lines: MathJax, block syntax $$ \\operatorname {ker} f = \\{ g \\in G:f ( g )= e_{H} \\} { \\mbox {.}} $$ \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] Using inline block syntax \u00b6 Inline blocks must be enclosed in $ ... $ or \\( ... \\) : MathJax, inline syntax The homomorphism $ f $ is injective if and only if its kernel is only the singleton set $ e_G $ , because otherwise $ \\exists a,b \\in G $ with $ a \\neq b $ such that $ f ( a )= f ( b ) $ . The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) .","title":"MathJax"},{"location":"reference/mathjax/#mathjax","text":"MathJax is a beautiful and accessible way to display mathematical content in the browser, adds support for mathematical typesetting in different notations (e.g. LaTeX , MathML , AsciiMath ), and can be easily integrated with Material for MkDocs.","title":"MathJax"},{"location":"reference/mathjax/#configuration","text":"This configuration enables support for rendering block and inline block equations through MathJax . Create a configuration file and add the following lines to mkdocs.yml : docs/javascripts/mathjax.js mkdocs.yml window . MathJax = { tex : { inlineMath : [[ \"\\\\(\" , \"\\\\)\" ]], displayMath : [[ \"\\\\[\" , \"\\\\]\" ]], processEscapes : true , processEnvironments : true }, options : { ignoreHtmlClass : \".*|\" , processHtmlClass : \"arithmatex\" } }; document $ . subscribe (() => { // (1)! MathJax . typesetPromise () }) This integrates MathJax with instant loading . markdown_extensions : - pymdownx.arithmatex : generic : true extra_javascript : - javascripts/mathjax.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js See additional configuration options: Arithmatex window.MathJax = { tex: { inlineMath: [[\"\\\\(\", \"\\\\)\"]], displayMath: [[\"\\\\[\", \"\\\\]\"]], processEscapes: true, processEnvironments: true }, options: { ignoreHtmlClass: \".*|\", processHtmlClass: \"arithmatex\" } };","title":"Configuration"},{"location":"reference/mathjax/#usage","text":"","title":"Usage"},{"location":"reference/mathjax/#using-block-syntax","text":"Blocks must be enclosed in $$ ... $$ or \\[ ... \\] on separate lines: MathJax, block syntax $$ \\operatorname {ker} f = \\{ g \\in G:f ( g )= e_{H} \\} { \\mbox {.}} $$ \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\]","title":"Using block syntax"},{"location":"reference/mathjax/#using-inline-block-syntax","text":"Inline blocks must be enclosed in $ ... $ or \\( ... \\) : MathJax, inline syntax The homomorphism $ f $ is injective if and only if its kernel is only the singleton set $ e_G $ , because otherwise $ \\exists a,b \\in G $ with $ a \\neq b $ such that $ f ( a )= f ( b ) $ . The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) .","title":"Using inline block syntax"},{"location":"reference/tooltips/","text":"Abbreviations \u00b6 Technical documentation often incurs the usage of many acronyms, which may need additional explanation, especially for new user of your project. For these matters, Material for MkDocs uses a combination of Markdown extensions to enable site-wide glossaries. Configuration \u00b6 This configuration enables abbreviations and allows to build a simple project-wide glossary, sourcing definitions from a central location. Add the following line to mkdocs.yml : markdown_extensions : - abbr - attr_list - pymdownx.snippets See additional configuration options: Abbreviations Attribute Lists Snippets Improved tooltips \u00b6 Sponsors only \u00b7 insiders-4.15.0 \u00b7 Experimental When improved tooltips are enabled, Material for MkDocs replaces the browser's rendering logic for title attribute with beautiful little tooltips. Add the following lines to mkdocs.yml : theme : features : - content.tooltips Now, tooltips will be rendered for the following elements: Content \u2013 elements with a title , permalinks and copy-to-clipboard button Header \u2013 home button, header title, color palette switch and repository link Navigation \u2013 links that are shortened with ellipsis, i.e. ... Usage \u00b6 Adding tooltips \u00b6 The Markdown syntax allows to specify a title for each link, which will render as a beautiful tooltip when improved tooltips are enabled. Add a tooltip to a link with the following lines: Link with tooltip, inline syntax [ Hover me ]( https://example.com \"I'm a tooltip!\" ) Hover me Tooltips can also be added to link references: Link with tooltip, reference syntax [ Hover me ][ example ] [ example ]: https://example.com \"I'm a tooltip!\" Hover me For all other elements, a title can be added by using the Attribute Lists extension: Icon with tooltip :material-information-outline:{ title=\"Important information\" } Adding abbreviations \u00b6 Abbreviations can be defined by using a special syntax similar to URLs and footnotes , starting with a * and immediately followed by the term or acronym to be associated in square brackets: Text with abbreviations The HTML specification is maintained by the W3C. *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium The HTML specification is maintained by the W3C . Adding a glossary \u00b6 The Snippets extension can be used to implement a simple glossary by moving all abbreviations in a dedicated file 1 , and auto-append this file to all pages with the following configuration: includes/abbreviations.md mkdocs.yml *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium markdown_extensions : - pymdownx.snippets : auto_append : - includes/abbreviations.md It's highly recommended to put the Markdown file containing the abbreviations outside of the docs folder (here, a folder with the name includes is used), as MkDocs might otherwise complain about an unreferenced file. \u21a9","title":"Abbreviations"},{"location":"reference/tooltips/#abbreviations","text":"Technical documentation often incurs the usage of many acronyms, which may need additional explanation, especially for new user of your project. For these matters, Material for MkDocs uses a combination of Markdown extensions to enable site-wide glossaries.","title":"Abbreviations"},{"location":"reference/tooltips/#configuration","text":"This configuration enables abbreviations and allows to build a simple project-wide glossary, sourcing definitions from a central location. Add the following line to mkdocs.yml : markdown_extensions : - abbr - attr_list - pymdownx.snippets See additional configuration options: Abbreviations Attribute Lists Snippets","title":"Configuration"},{"location":"reference/tooltips/#improved-tooltips","text":"Sponsors only \u00b7 insiders-4.15.0 \u00b7 Experimental When improved tooltips are enabled, Material for MkDocs replaces the browser's rendering logic for title attribute with beautiful little tooltips. Add the following lines to mkdocs.yml : theme : features : - content.tooltips Now, tooltips will be rendered for the following elements: Content \u2013 elements with a title , permalinks and copy-to-clipboard button Header \u2013 home button, header title, color palette switch and repository link Navigation \u2013 links that are shortened with ellipsis, i.e. ...","title":"Improved tooltips"},{"location":"reference/tooltips/#usage","text":"","title":"Usage"},{"location":"reference/tooltips/#adding-tooltips","text":"The Markdown syntax allows to specify a title for each link, which will render as a beautiful tooltip when improved tooltips are enabled. Add a tooltip to a link with the following lines: Link with tooltip, inline syntax [ Hover me ]( https://example.com \"I'm a tooltip!\" ) Hover me Tooltips can also be added to link references: Link with tooltip, reference syntax [ Hover me ][ example ] [ example ]: https://example.com \"I'm a tooltip!\" Hover me For all other elements, a title can be added by using the Attribute Lists extension: Icon with tooltip :material-information-outline:{ title=\"Important information\" }","title":"Adding tooltips"},{"location":"reference/tooltips/#adding-abbreviations","text":"Abbreviations can be defined by using a special syntax similar to URLs and footnotes , starting with a * and immediately followed by the term or acronym to be associated in square brackets: Text with abbreviations The HTML specification is maintained by the W3C. *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium The HTML specification is maintained by the W3C .","title":"Adding abbreviations"},{"location":"reference/tooltips/#adding-a-glossary","text":"The Snippets extension can be used to implement a simple glossary by moving all abbreviations in a dedicated file 1 , and auto-append this file to all pages with the following configuration: includes/abbreviations.md mkdocs.yml *[HTML]: Hyper Text Markup Language *[W3C]: World Wide Web Consortium markdown_extensions : - pymdownx.snippets : auto_append : - includes/abbreviations.md It's highly recommended to put the Markdown file containing the abbreviations outside of the docs folder (here, a folder with the name includes is used), as MkDocs might otherwise complain about an unreferenced file. \u21a9","title":"Adding a glossary"},{"location":"setup/adding-a-comment-system/","text":"Adding a comment system \u00b6 Material for MkDocs allows to easily add the third-party comment system of your choice to the footer of any page by using theme extension . As an example, we'll be integrating Giscus , which is Open Source, free, and uses GitHub discussions as a backend. Customization \u00b6 Giscus integration \u00b6 Before you can use Giscus , you need to complete the following steps: Install the Giscus GitHub App and grant access to the repository that should host comments as GitHub discussions. Note that this can be a repository different from your documentation. Visit Giscus and generate the snippet through their configuration tool to load the comment system. Copy the snippet for the next step. The resulting snippet should look similar to this: < script src = \"https://giscus.app/client.js\" data-repo = \"<username>/<repository>\" data-repo-id = \"...\" data-category = \"...\" data-category-id = \"...\" data-mapping = \"pathname\" data-reactions-enabled = \"1\" data-emit-metadata = \"1\" data-theme = \"light\" data-lang = \"en\" crossorigin = \"anonymous\" async > </ script > The comments.html partial (empty by default) is the best place to add the snippet generated by Giscus . Follow the guide on theme extension and override the comments.html partial with: {% if page.meta.comments %} < h2 id = \"__comments\" > {{ lang.t(\"meta.comments\") }} </ h2 > <!-- Insert generated snippet here --> <!-- Synchronize Giscus theme with palette --> < script > var giscus = document . querySelector ( \"script[src*=giscus]\" ) /* Set palette on initial load */ var palette = __md_get ( \"__palette\" ) if ( palette && typeof palette . color === \"object\" ) { var theme = palette . color . scheme === \"slate\" ? \"dark\" : \"light\" giscus . setAttribute ( \"data-theme\" , theme ) // (1)! } /* Register event handlers after documented loaded */ document . addEventListener ( \"DOMContentLoaded\" , function () { var ref = document . querySelector ( \"[data-md-component=palette]\" ) ref . addEventListener ( \"change\" , function () { var palette = __md_get ( \"__palette\" ) if ( palette && typeof palette . color === \"object\" ) { var theme = palette . color . scheme === \"slate\" ? \"dark\" : \"light\" /* Instruct Giscus to change theme */ var frame = document . querySelector ( \".giscus-frame\" ) frame . contentWindow . postMessage ( { giscus : { setConfig : { theme } } }, \"https://giscus.app\" ) } }) }) </ script > {% endif %} This code block ensures that Giscus renders with a dark theme when the palette is set to slate . Note that multiple dark themes are available, so you can change it to your liking. Replace the highlighted line with the snippet you generated with the Giscus configuration tool in the previous step. If you copied the snippet from above, you can enable comments on a page by setting the comments front matter property to true : --- comments : true --- # Document title ... If you wish to enable comments for an entire folder, you can use the built-in meta plugin .","title":"Adding a comment system"},{"location":"setup/adding-a-comment-system/#adding-a-comment-system","text":"Material for MkDocs allows to easily add the third-party comment system of your choice to the footer of any page by using theme extension . As an example, we'll be integrating Giscus , which is Open Source, free, and uses GitHub discussions as a backend.","title":"Adding a comment system"},{"location":"setup/adding-a-comment-system/#customization","text":"","title":"Customization"},{"location":"setup/adding-a-comment-system/#giscus-integration","text":"Before you can use Giscus , you need to complete the following steps: Install the Giscus GitHub App and grant access to the repository that should host comments as GitHub discussions. Note that this can be a repository different from your documentation. Visit Giscus and generate the snippet through their configuration tool to load the comment system. Copy the snippet for the next step. The resulting snippet should look similar to this: < script src = \"https://giscus.app/client.js\" data-repo = \"<username>/<repository>\" data-repo-id = \"...\" data-category = \"...\" data-category-id = \"...\" data-mapping = \"pathname\" data-reactions-enabled = \"1\" data-emit-metadata = \"1\" data-theme = \"light\" data-lang = \"en\" crossorigin = \"anonymous\" async > </ script > The comments.html partial (empty by default) is the best place to add the snippet generated by Giscus . Follow the guide on theme extension and override the comments.html partial with: {% if page.meta.comments %} < h2 id = \"__comments\" > {{ lang.t(\"meta.comments\") }} </ h2 > <!-- Insert generated snippet here --> <!-- Synchronize Giscus theme with palette --> < script > var giscus = document . querySelector ( \"script[src*=giscus]\" ) /* Set palette on initial load */ var palette = __md_get ( \"__palette\" ) if ( palette && typeof palette . color === \"object\" ) { var theme = palette . color . scheme === \"slate\" ? \"dark\" : \"light\" giscus . setAttribute ( \"data-theme\" , theme ) // (1)! } /* Register event handlers after documented loaded */ document . addEventListener ( \"DOMContentLoaded\" , function () { var ref = document . querySelector ( \"[data-md-component=palette]\" ) ref . addEventListener ( \"change\" , function () { var palette = __md_get ( \"__palette\" ) if ( palette && typeof palette . color === \"object\" ) { var theme = palette . color . scheme === \"slate\" ? \"dark\" : \"light\" /* Instruct Giscus to change theme */ var frame = document . querySelector ( \".giscus-frame\" ) frame . contentWindow . postMessage ( { giscus : { setConfig : { theme } } }, \"https://giscus.app\" ) } }) }) </ script > {% endif %} This code block ensures that Giscus renders with a dark theme when the palette is set to slate . Note that multiple dark themes are available, so you can change it to your liking. Replace the highlighted line with the snippet you generated with the Giscus configuration tool in the previous step. If you copied the snippet from above, you can enable comments on a page by setting the comments front matter property to true : --- comments : true --- # Document title ... If you wish to enable comments for an entire folder, you can use the built-in meta plugin .","title":"Giscus integration"},{"location":"setup/adding-a-git-repository/","text":"Adding a git repository \u00b6 If your documentation is related to source code, Material for MkDocs provides the ability to display information to the project's repository as part of the static site, including stars and forks. Furthermore, the date of last update and creation , as well as contributors can be shown. Configuration \u00b6 Repository \u00b6 0.1.0 \u00b7 Default: none In order to display a link to the repository of your project as part of your documentation, set repo_url in mkdocs.yml to the public URL of your repository, e.g.: repo_url : https://github.com/squidfunk/mkdocs-material The link to the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Additionally, for public repositories hosted on GitHub or GitLab , the number of stars and forks is automatically requested and rendered. GitHub repositories also include the tag of the latest release. 1 Repository name \u00b6 0.1.0 \u00b7 Default: automatically set to GitHub , GitLab or Bitbucket MkDocs will infer the source provider by examining the URL and try to set the repository name automatically. If you wish to customize the name, set repo_name in mkdocs.yml : repo_name : squidfunk/mkdocs-material Repository icon \u00b6 5.0.0 \u00b7 Default: \u2013 fontawesome/brands/git-alt While the default repository icon is a generic git icon, it can be set to any icon bundled with the theme by referencing a valid icon path in mkdocs.yml : theme : icon : repo : fontawesome/brands/git-alt # (1)! Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: Some popular choices: \u2013 fontawesome/brands/git \u2013 fontawesome/brands/git-alt \u2013 fontawesome/brands/github \u2013 fontawesome/brands/github-alt \u2013 fontawesome/brands/gitlab \u2013 fontawesome/brands/gitkraken \u2013 fontawesome/brands/bitbucket \u2013 fontawesome/solid/trash Edit button \u00b6 0.1.0 \u00b7 Default: automatically set If the repository URL points to a GitHub , GitLab or Bitbucket repository, an edit button is displayed at the top of each document. This behavior can be changed by setting edit_uri in mkdocs.yml : Customize edit path Hide edit button edit_uri : edit/master/docs/ edit_uri : \"\" The icon of the edit button can be changed with the following lines: theme : icon : edit : material/pencil # (1)! Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: Revisioning \u00b6 The following plugins are fully integrated with Material for MkDocs, allowing for showing the date of last update and creation of a document, as well as links to all contributors or authors involved. Document dates \u00b6 4.6.0 \u00b7 Plugin The git-revision-date-localized plugin adds support for adding the date of last update and creation of a document at the bottom of each page. Install it with pip : pip install mkdocs-git-revision-date-localized-plugin Then, add the following lines to mkdocs.yml : plugins : - git-revision-date-localized : enable_creation_date : true The following configuration options are supported: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable : plugins : - git-revision-date-localized : enabled : !ENV [ CI , false ] type Default: date \u2013 The format of the date to be displayed. Valid values are date , datetime , iso_date , iso_datetime and timeago : plugins : - git-revision-date-localized : type : date enable_creation_date Default: false \u2013 Enables the display of the creation date of the file associated with the page next to the last updated date at the bottom of the page: plugins : - git-revision-date-localized : enable_creation_date : true fallback_to_build_date Default: false \u2013 Enables falling back to the time when mkdocs build was executed. Can be used as a fallback when the build is performed outside of a git repository: plugins : - git-revision-date-localized : fallback_to_build_date : true The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. Document contributors \u00b6 Sponsors only \u00b7 insiders-4.19.0 \u00b7 Plugin \u00b7 Experimental The git-committers 2 plugin renders the GitHub avatars of all contributors, linking to their GitHub profiles at the bottom of each page. As always, it can be installed with pip : pip install mkdocs-git-committers-plugin-2 Then, add the following lines to mkdocs.yml : plugins : - git-committers : repository : squidfunk/mkdocs-material branch : main The following configuration options are supported: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable : plugins : - git-committers : enabled : !ENV [ CI , false ] repository Default: none \u00b7 Required \u2013 This property must be set to the slug of the repository that contains your documentation. The slug must follow the pattern <username>/<repository> : plugins : - git-committers : repository : squidfunk/mkdocs-material branch Default: master \u2013 This property should be set to the branch of the repository from which to retrieve the contributors. To use the main branch: plugins : - git-committers : branch : main The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. Document authors \u00b6 Sponsors only \u00b7 insiders-4.19.0 \u00b7 Plugin \u00b7 Experimental The git-authors plugin extracts the authors of a document from git to display them at the bottom of each page. It's a lightweight alternative to the git-committers plugin. Install it with pip : pip install mkdocs-git-authors-plugin Then, add the following lines to mkdocs.yml : plugins : - git-authors Unfortunately, GitHub only provides an API endpoint to obtain the latest release - not the latest tag. Thus, make sure to create a release (not pre-release) for the latest tag you want to display next to the number of stars and forks. \u21a9 We currently recommend using a fork of the git-committers plugin, as it contains many improvements that have not yet been merged back into the original plugin. See byrnereese/mkdocs-git-committers-plugin#12 for more information. \u21a9","title":"Adding a git repository"},{"location":"setup/adding-a-git-repository/#adding-a-git-repository","text":"If your documentation is related to source code, Material for MkDocs provides the ability to display information to the project's repository as part of the static site, including stars and forks. Furthermore, the date of last update and creation , as well as contributors can be shown.","title":"Adding a git repository"},{"location":"setup/adding-a-git-repository/#configuration","text":"","title":"Configuration"},{"location":"setup/adding-a-git-repository/#repository","text":"0.1.0 \u00b7 Default: none In order to display a link to the repository of your project as part of your documentation, set repo_url in mkdocs.yml to the public URL of your repository, e.g.: repo_url : https://github.com/squidfunk/mkdocs-material The link to the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Additionally, for public repositories hosted on GitHub or GitLab , the number of stars and forks is automatically requested and rendered. GitHub repositories also include the tag of the latest release. 1","title":"Repository"},{"location":"setup/adding-a-git-repository/#repository-name","text":"0.1.0 \u00b7 Default: automatically set to GitHub , GitLab or Bitbucket MkDocs will infer the source provider by examining the URL and try to set the repository name automatically. If you wish to customize the name, set repo_name in mkdocs.yml : repo_name : squidfunk/mkdocs-material","title":"Repository name"},{"location":"setup/adding-a-git-repository/#repository-icon","text":"5.0.0 \u00b7 Default: \u2013 fontawesome/brands/git-alt While the default repository icon is a generic git icon, it can be set to any icon bundled with the theme by referencing a valid icon path in mkdocs.yml : theme : icon : repo : fontawesome/brands/git-alt # (1)! Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: Some popular choices: \u2013 fontawesome/brands/git \u2013 fontawesome/brands/git-alt \u2013 fontawesome/brands/github \u2013 fontawesome/brands/github-alt \u2013 fontawesome/brands/gitlab \u2013 fontawesome/brands/gitkraken \u2013 fontawesome/brands/bitbucket \u2013 fontawesome/solid/trash","title":"Repository icon"},{"location":"setup/adding-a-git-repository/#edit-button","text":"0.1.0 \u00b7 Default: automatically set If the repository URL points to a GitHub , GitLab or Bitbucket repository, an edit button is displayed at the top of each document. This behavior can be changed by setting edit_uri in mkdocs.yml : Customize edit path Hide edit button edit_uri : edit/master/docs/ edit_uri : \"\" The icon of the edit button can be changed with the following lines: theme : icon : edit : material/pencil # (1)! Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard:","title":"Edit button"},{"location":"setup/adding-a-git-repository/#revisioning","text":"The following plugins are fully integrated with Material for MkDocs, allowing for showing the date of last update and creation of a document, as well as links to all contributors or authors involved.","title":"Revisioning"},{"location":"setup/adding-a-git-repository/#document-dates","text":"4.6.0 \u00b7 Plugin The git-revision-date-localized plugin adds support for adding the date of last update and creation of a document at the bottom of each page. Install it with pip : pip install mkdocs-git-revision-date-localized-plugin Then, add the following lines to mkdocs.yml : plugins : - git-revision-date-localized : enable_creation_date : true The following configuration options are supported: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable : plugins : - git-revision-date-localized : enabled : !ENV [ CI , false ] type Default: date \u2013 The format of the date to be displayed. Valid values are date , datetime , iso_date , iso_datetime and timeago : plugins : - git-revision-date-localized : type : date enable_creation_date Default: false \u2013 Enables the display of the creation date of the file associated with the page next to the last updated date at the bottom of the page: plugins : - git-revision-date-localized : enable_creation_date : true fallback_to_build_date Default: false \u2013 Enables falling back to the time when mkdocs build was executed. Can be used as a fallback when the build is performed outside of a git repository: plugins : - git-revision-date-localized : fallback_to_build_date : true The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.","title":"Document dates"},{"location":"setup/adding-a-git-repository/#document-contributors","text":"Sponsors only \u00b7 insiders-4.19.0 \u00b7 Plugin \u00b7 Experimental The git-committers 2 plugin renders the GitHub avatars of all contributors, linking to their GitHub profiles at the bottom of each page. As always, it can be installed with pip : pip install mkdocs-git-committers-plugin-2 Then, add the following lines to mkdocs.yml : plugins : - git-committers : repository : squidfunk/mkdocs-material branch : main The following configuration options are supported: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable : plugins : - git-committers : enabled : !ENV [ CI , false ] repository Default: none \u00b7 Required \u2013 This property must be set to the slug of the repository that contains your documentation. The slug must follow the pattern <username>/<repository> : plugins : - git-committers : repository : squidfunk/mkdocs-material branch Default: master \u2013 This property should be set to the branch of the repository from which to retrieve the contributors. To use the main branch: plugins : - git-committers : branch : main The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.","title":"Document contributors"},{"location":"setup/adding-a-git-repository/#document-authors","text":"Sponsors only \u00b7 insiders-4.19.0 \u00b7 Plugin \u00b7 Experimental The git-authors plugin extracts the authors of a document from git to display them at the bottom of each page. It's a lightweight alternative to the git-committers plugin. Install it with pip : pip install mkdocs-git-authors-plugin Then, add the following lines to mkdocs.yml : plugins : - git-authors Unfortunately, GitHub only provides an API endpoint to obtain the latest release - not the latest tag. Thus, make sure to create a release (not pre-release) for the latest tag you want to display next to the number of stars and forks. \u21a9 We currently recommend using a fork of the git-committers plugin, as it contains many improvements that have not yet been merged back into the original plugin. See byrnereese/mkdocs-git-committers-plugin#12 for more information. \u21a9","title":"Document authors"},{"location":"setup/building-for-offline-usage/","text":"Building for offline usage \u00b6 If you want to ship your documentation together with your product, MkDocs has you covered \u2013 with support from themes, MkDocs allows for building offline-capable documentation. Luckily, Material for MkDocs offers offline support for many of its features. Configuration \u00b6 Built-in offline plugin \u00b6 Sponsors only \u00b7 insiders-4.10.0 \u00b7 Plugin The built-in offline plugin makes sure that the site search works when you distribute the contents of your site directory as a download. Simply add the following lines to mkdocs.yml : plugins : - offline If you need to be able to build your documentation with and without Insiders , please refer to the built-in plugins section to learn how shared configurations help to achieve this. The plugin will automatically disable use_directory_urls via mkdocs.yml , ensuring that users can open your documentation directly from the local file system. The following configuration options are available: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable : plugins : - offline : enabled : !ENV [ OFFLINE , false ] Now, after invoking mkdocs build , you can open site/index.html directly in your browser and the site search will work as if the documentation was hosted on a regular server. Automatically bundle all external assets The brand-new built-in privacy plugin makes it easy to use external assets while building documentation for offline usage, as it will automatically download all external assets to distribute them with your documentation. Limitations \u00b6 Material for MkDocs offers many interactive features, some of which will not work from the file system due to the restrictions of modern browsers: all features that use the fetch API will error. Thus, when building for offline usage, make sure to disable the following configuration settings: instant loading , site analytics , git repository , versioning and comment systems .","title":"Building for offline usage"},{"location":"setup/building-for-offline-usage/#building-for-offline-usage","text":"If you want to ship your documentation together with your product, MkDocs has you covered \u2013 with support from themes, MkDocs allows for building offline-capable documentation. Luckily, Material for MkDocs offers offline support for many of its features.","title":"Building for offline usage"},{"location":"setup/building-for-offline-usage/#configuration","text":"","title":"Configuration"},{"location":"setup/building-for-offline-usage/#built-in-offline-plugin","text":"Sponsors only \u00b7 insiders-4.10.0 \u00b7 Plugin The built-in offline plugin makes sure that the site search works when you distribute the contents of your site directory as a download. Simply add the following lines to mkdocs.yml : plugins : - offline If you need to be able to build your documentation with and without Insiders , please refer to the built-in plugins section to learn how shared configurations help to achieve this. The plugin will automatically disable use_directory_urls via mkdocs.yml , ensuring that users can open your documentation directly from the local file system. The following configuration options are available: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to switch the plugin off, e.g. for local builds, use an environment variable : plugins : - offline : enabled : !ENV [ OFFLINE , false ] Now, after invoking mkdocs build , you can open site/index.html directly in your browser and the site search will work as if the documentation was hosted on a regular server. Automatically bundle all external assets The brand-new built-in privacy plugin makes it easy to use external assets while building documentation for offline usage, as it will automatically download all external assets to distribute them with your documentation.","title":"Built-in offline plugin"},{"location":"setup/building-for-offline-usage/#limitations","text":"Material for MkDocs offers many interactive features, some of which will not work from the file system due to the restrictions of modern browsers: all features that use the fetch API will error. Thus, when building for offline usage, make sure to disable the following configuration settings: instant loading , site analytics , git repository , versioning and comment systems .","title":"Limitations"},{"location":"setup/changing-the-colors/","text":"Changing the colors \u00b6 As any proper Material Design implementation, Material for MkDocs supports Google's original color palette , which can be easily configured through mkdocs.yml . Furthermore, colors can be customized with a few lines of CSS to fit your brand's identity by using CSS variables . Configuration \u00b6 Color palette \u00b6 Color scheme \u00b6 5.2.0 \u00b7 Default: default Material for MkDocs supports two color schemes: a light mode , which is just called default , and a dark mode , which is called slate . The color scheme can be set via mkdocs.yml : theme : palette : scheme : default Click on a tile to change the color scheme: default slate var buttons = document.querySelectorAll(\"button[data-md-color-scheme]\") buttons.forEach(function(button) { button.addEventListener(\"click\", function() { var attr = this.getAttribute(\"data-md-color-scheme\") document.body.setAttribute(\"data-md-color-scheme\", attr) var name = document.querySelector(\"#__code_1 code span.l\") name.textContent = attr }) }) Primary color \u00b6 0.2.0 \u00b7 Default: indigo The primary color is used for the header, the sidebar, text links and several other components. In order to change the primary color, set the following value in mkdocs.yml to a valid color name: theme : palette : primary : indigo Click on a tile to change the primary color: red pink purple deep purple indigo blue light blue cyan teal green light green lime yellow amber orange deep orange brown grey blue grey black white var buttons = document.querySelectorAll(\"button[data-md-color-primary]\") buttons.forEach(function(button) { button.addEventListener(\"click\", function() { var attr = this.getAttribute(\"data-md-color-primary\") document.body.setAttribute(\"data-md-color-primary\", attr) var name = document.querySelector(\"#__code_2 code span.l\") name.textContent = attr.replace(\"-\", \" \") }) }) Accent color \u00b6 0.2.0 \u00b7 Default: indigo The accent color is used to denote elements that can be interacted with, e.g. hovered links, buttons and scrollbars. It can be changed in mkdocs.yml by choosing a valid color name: theme : palette : accent : indigo Click on a tile to change the accent color: .md-typeset button[data-md-color-accent] > code { background-color: var(--md-code-bg-color); color: var(--md-accent-fg-color); } red pink purple deep purple indigo blue light blue cyan teal green light green lime yellow amber orange deep orange var buttons = document.querySelectorAll(\"button[data-md-color-accent]\") buttons.forEach(function(button) { button.addEventListener(\"click\", function() { var attr = this.getAttribute(\"data-md-color-accent\") document.body.setAttribute(\"data-md-color-accent\", attr) var name = document.querySelector(\"#__code_3 code span.l\") name.textContent = attr.replace(\"-\", \" \") }) }) Color palette toggle \u00b6 7.1.0 \u00b7 Default: none Offering a light and dark color palette makes your documentation pleasant to read at different times of the day, so the user can choose accordingly. Add the following lines to mkdocs.yml : theme : palette : # (1)! # Palette toggle for light mode - scheme : default toggle : icon : material/brightness-7 # (2)! name : Switch to dark mode # Palette toggle for dark mode - scheme : slate toggle : icon : material/brightness-4 name : Switch to light mode Note that the theme.palette setting is now defined as a list. Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: This configuration will render a color palette toggle next to the search bar. Note that you can also define separate settings for primary and accent per color palette. The following properties must be set for each toggle: icon Default: none \u00b7 Required \u2013 This property must point to a valid icon path referencing any icon bundled with the theme, or the build will not succeed. Some popular combinations: + \u2013 material/brightness-7 + material/brightness-4 + \u2013 material/toggle-switch + material/toggle-switch-off-outline + \u2013 material/weather-night + material/weather-sunny + \u2013 material/eye + material/eye-outline + \u2013 material/lightbulb + material/lightbulb-outline name Default: none \u00b7 Required \u2013 This property is used as the toggle's title attribute and should be set to a discernable name to improve accessibility. It's rendered as a tooltip . System preference \u00b6 7.1.0 \u00b7 Default: none Each color palette can be linked to the user's system preference for light and dark appearance by using a media query. Simply add a media property next to the scheme definition in mkdocs.yml : theme : palette : # Palette toggle for light mode - media : \"(prefers-color-scheme: light)\" scheme : default toggle : icon : material/brightness-7 name : Switch to dark mode # Palette toggle for dark mode - media : \"(prefers-color-scheme: dark)\" scheme : slate toggle : icon : material/brightness-4 name : Switch to light mode When the user first visits your site, the media queries are evaluated in the order of their definition. The first media query that matches selects the default color palette. Automatic light / dark mode \u00b6 Sponsors only \u00b7 insiders-4.18.0 \u00b7 Experimental Newer operating system allow to automatically switch between light and dark appearance during day and night times. Insiders adds support for automatic light / dark mode, delegating color palette selection to the user's operating system. Add the following lines to mkdocs.yml : theme : palette : # Palette toggle for automatic mode - media : \"(prefers-color-scheme)\" toggle : icon : material/brightness-auto name : Switch to light mode # Palette toggle for light mode - media : \"(prefers-color-scheme: light)\" scheme : default # (1)! toggle : icon : material/brightness-7 name : Switch to dark mode # Palette toggle for dark mode - media : \"(prefers-color-scheme: dark)\" scheme : slate toggle : icon : material/brightness-4 name : Switch to system preference You can also define separate settings for primary and accent per color palette, i.e. different colors for light and dark mode. Material for MkDocs will now change the color palette each time the operating system switches between light and dark appearance, even when the user doesn't reload the site. Customization \u00b6 Custom colors \u00b6 Material for MkDocs implements colors using CSS variables (custom properties). If you want to customize the colors beyond the palette (e.g. to use your brand-specific colors), you can add an additional style sheet and tweak the values of the CSS variables. Let's say you're YouTube , and want to set the primary color to your brand's palette. Just add: docs/stylesheets/extra.css mkdocs.yml : root > * { --md-primary-fg-color : #EE0F0F ; --md-primary-fg-color--light : #ECB7B7 ; --md-primary-fg-color--dark : #90030C ; } extra_css : - stylesheets/extra.css See the file containing the color definitions for a list of all CSS variables. Custom color schemes \u00b6 Besides overriding specific colors, you can create your own, named color scheme by wrapping the definitions in a [data-md-color-scheme=\"...\"] attribute selector , which you can then set via mkdocs.yml as described in the color schemes section: docs/stylesheets/extra.css mkdocs.yml [ data-md-color-scheme = \"youtube\" ] { --md-primary-fg-color : #EE0F0F ; --md-primary-fg-color--light : #ECB7B7 ; --md-primary-fg-color--dark : #90030C ; } theme : palette : scheme : youtube extra_css : - stylesheets/extra.css Additionally, the slate color scheme defines all of it's colors via hsla color functions and deduces its colors from the --md-hue CSS variable. You can tune the slate theme with: [ data-md-color-scheme = \"slate\" ] { --md-hue : 210 ; /* (1)! */ } The hue value must be in the range of [0, 360]","title":"Changing the colors"},{"location":"setup/changing-the-colors/#changing-the-colors","text":"As any proper Material Design implementation, Material for MkDocs supports Google's original color palette , which can be easily configured through mkdocs.yml . Furthermore, colors can be customized with a few lines of CSS to fit your brand's identity by using CSS variables .","title":"Changing the colors"},{"location":"setup/changing-the-colors/#configuration","text":"","title":"Configuration"},{"location":"setup/changing-the-colors/#color-palette","text":"","title":"Color palette"},{"location":"setup/changing-the-colors/#color-scheme","text":"5.2.0 \u00b7 Default: default Material for MkDocs supports two color schemes: a light mode , which is just called default , and a dark mode , which is called slate . The color scheme can be set via mkdocs.yml : theme : palette : scheme : default Click on a tile to change the color scheme: default slate var buttons = document.querySelectorAll(\"button[data-md-color-scheme]\") buttons.forEach(function(button) { button.addEventListener(\"click\", function() { var attr = this.getAttribute(\"data-md-color-scheme\") document.body.setAttribute(\"data-md-color-scheme\", attr) var name = document.querySelector(\"#__code_1 code span.l\") name.textContent = attr }) })","title":"Color scheme"},{"location":"setup/changing-the-colors/#primary-color","text":"0.2.0 \u00b7 Default: indigo The primary color is used for the header, the sidebar, text links and several other components. In order to change the primary color, set the following value in mkdocs.yml to a valid color name: theme : palette : primary : indigo Click on a tile to change the primary color: red pink purple deep purple indigo blue light blue cyan teal green light green lime yellow amber orange deep orange brown grey blue grey black white var buttons = document.querySelectorAll(\"button[data-md-color-primary]\") buttons.forEach(function(button) { button.addEventListener(\"click\", function() { var attr = this.getAttribute(\"data-md-color-primary\") document.body.setAttribute(\"data-md-color-primary\", attr) var name = document.querySelector(\"#__code_2 code span.l\") name.textContent = attr.replace(\"-\", \" \") }) })","title":"Primary color"},{"location":"setup/changing-the-colors/#accent-color","text":"0.2.0 \u00b7 Default: indigo The accent color is used to denote elements that can be interacted with, e.g. hovered links, buttons and scrollbars. It can be changed in mkdocs.yml by choosing a valid color name: theme : palette : accent : indigo Click on a tile to change the accent color: .md-typeset button[data-md-color-accent] > code { background-color: var(--md-code-bg-color); color: var(--md-accent-fg-color); } red pink purple deep purple indigo blue light blue cyan teal green light green lime yellow amber orange deep orange var buttons = document.querySelectorAll(\"button[data-md-color-accent]\") buttons.forEach(function(button) { button.addEventListener(\"click\", function() { var attr = this.getAttribute(\"data-md-color-accent\") document.body.setAttribute(\"data-md-color-accent\", attr) var name = document.querySelector(\"#__code_3 code span.l\") name.textContent = attr.replace(\"-\", \" \") }) })","title":"Accent color"},{"location":"setup/changing-the-colors/#color-palette-toggle","text":"7.1.0 \u00b7 Default: none Offering a light and dark color palette makes your documentation pleasant to read at different times of the day, so the user can choose accordingly. Add the following lines to mkdocs.yml : theme : palette : # (1)! # Palette toggle for light mode - scheme : default toggle : icon : material/brightness-7 # (2)! name : Switch to dark mode # Palette toggle for dark mode - scheme : slate toggle : icon : material/brightness-4 name : Switch to light mode Note that the theme.palette setting is now defined as a list. Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: This configuration will render a color palette toggle next to the search bar. Note that you can also define separate settings for primary and accent per color palette. The following properties must be set for each toggle: icon Default: none \u00b7 Required \u2013 This property must point to a valid icon path referencing any icon bundled with the theme, or the build will not succeed. Some popular combinations: + \u2013 material/brightness-7 + material/brightness-4 + \u2013 material/toggle-switch + material/toggle-switch-off-outline + \u2013 material/weather-night + material/weather-sunny + \u2013 material/eye + material/eye-outline + \u2013 material/lightbulb + material/lightbulb-outline name Default: none \u00b7 Required \u2013 This property is used as the toggle's title attribute and should be set to a discernable name to improve accessibility. It's rendered as a tooltip .","title":"Color palette toggle"},{"location":"setup/changing-the-colors/#system-preference","text":"7.1.0 \u00b7 Default: none Each color palette can be linked to the user's system preference for light and dark appearance by using a media query. Simply add a media property next to the scheme definition in mkdocs.yml : theme : palette : # Palette toggle for light mode - media : \"(prefers-color-scheme: light)\" scheme : default toggle : icon : material/brightness-7 name : Switch to dark mode # Palette toggle for dark mode - media : \"(prefers-color-scheme: dark)\" scheme : slate toggle : icon : material/brightness-4 name : Switch to light mode When the user first visits your site, the media queries are evaluated in the order of their definition. The first media query that matches selects the default color palette.","title":"System preference"},{"location":"setup/changing-the-colors/#automatic-light-dark-mode","text":"Sponsors only \u00b7 insiders-4.18.0 \u00b7 Experimental Newer operating system allow to automatically switch between light and dark appearance during day and night times. Insiders adds support for automatic light / dark mode, delegating color palette selection to the user's operating system. Add the following lines to mkdocs.yml : theme : palette : # Palette toggle for automatic mode - media : \"(prefers-color-scheme)\" toggle : icon : material/brightness-auto name : Switch to light mode # Palette toggle for light mode - media : \"(prefers-color-scheme: light)\" scheme : default # (1)! toggle : icon : material/brightness-7 name : Switch to dark mode # Palette toggle for dark mode - media : \"(prefers-color-scheme: dark)\" scheme : slate toggle : icon : material/brightness-4 name : Switch to system preference You can also define separate settings for primary and accent per color palette, i.e. different colors for light and dark mode. Material for MkDocs will now change the color palette each time the operating system switches between light and dark appearance, even when the user doesn't reload the site.","title":"Automatic light / dark mode"},{"location":"setup/changing-the-colors/#customization","text":"","title":"Customization"},{"location":"setup/changing-the-colors/#custom-colors","text":"Material for MkDocs implements colors using CSS variables (custom properties). If you want to customize the colors beyond the palette (e.g. to use your brand-specific colors), you can add an additional style sheet and tweak the values of the CSS variables. Let's say you're YouTube , and want to set the primary color to your brand's palette. Just add: docs/stylesheets/extra.css mkdocs.yml : root > * { --md-primary-fg-color : #EE0F0F ; --md-primary-fg-color--light : #ECB7B7 ; --md-primary-fg-color--dark : #90030C ; } extra_css : - stylesheets/extra.css See the file containing the color definitions for a list of all CSS variables.","title":"Custom colors"},{"location":"setup/changing-the-colors/#custom-color-schemes","text":"Besides overriding specific colors, you can create your own, named color scheme by wrapping the definitions in a [data-md-color-scheme=\"...\"] attribute selector , which you can then set via mkdocs.yml as described in the color schemes section: docs/stylesheets/extra.css mkdocs.yml [ data-md-color-scheme = \"youtube\" ] { --md-primary-fg-color : #EE0F0F ; --md-primary-fg-color--light : #ECB7B7 ; --md-primary-fg-color--dark : #90030C ; } theme : palette : scheme : youtube extra_css : - stylesheets/extra.css Additionally, the slate color scheme defines all of it's colors via hsla color functions and deduces its colors from the --md-hue CSS variable. You can tune the slate theme with: [ data-md-color-scheme = \"slate\" ] { --md-hue : 210 ; /* (1)! */ } The hue value must be in the range of [0, 360]","title":"Custom color schemes"},{"location":"setup/changing-the-fonts/","text":"Changing the fonts \u00b6 Material for MkDocs makes it easy to change the typeface of your project documentation, as it directly integrates with Google Fonts . Alternatively, fonts can be custom-loaded if self-hosting is preferred for data privacy reasons or another destination should be used. Configuration \u00b6 Regular font \u00b6 0.1.2 \u00b7 Default: Roboto The regular font is used for all body copy, headlines, and essentially everything that does not need to be monospaced. It can be set to any valid Google Font via mkdocs.yml : theme : font : text : Roboto The typeface will be loaded in 300, 400, 400i and 700 . Monospaced font \u00b6 0.1.2 \u00b7 Default: Roboto Mono The monospaced font is used for code blocks and can be configured separately. Just like the regular font, it can be set to any valid Google Font via mkdocs.yml : theme : font : code : Roboto Mono The typeface will be loaded in 400. Autoloading \u00b6 1.0.0 \u00b7 Default: none If you want to prevent typefaces from being loaded from Google Fonts , e.g. to adhere to data privacy regulations, and fall back to system fonts, add the following lines to mkdocs.yml : theme : font : false Automatically bundle Google Fonts The brand-new built-in privacy plugin makes it easy to use Google Fonts while complying with the General Data Protection Regulation (GDPR), by automatically downloading and self-hosting the web font files. Customization \u00b6 Additional fonts \u00b6 If you want to load an (additional) font from another destination or override the system font, you can use an additional style sheet to add the corresponding @font-face definition: docs/stylesheets/extra.css mkdocs.yml @ font-face { font-family : \"<font>\" ; src : \"...\" ; } extra_css : - stylesheets/extra.css The font can then be applied to specific elements, e.g. only headlines, or globally to be used as the site-wide regular or monospaced font: Regular font Monospaced font : root { --md-text-font : \"<font>\" ; /* (1)! */ } Always define fonts through CSS variables and not font-family , as this would disable the system font fallback. : root { --md-code-font : \"<font>\" ; }","title":"Changing the fonts"},{"location":"setup/changing-the-fonts/#changing-the-fonts","text":"Material for MkDocs makes it easy to change the typeface of your project documentation, as it directly integrates with Google Fonts . Alternatively, fonts can be custom-loaded if self-hosting is preferred for data privacy reasons or another destination should be used.","title":"Changing the fonts"},{"location":"setup/changing-the-fonts/#configuration","text":"","title":"Configuration"},{"location":"setup/changing-the-fonts/#regular-font","text":"0.1.2 \u00b7 Default: Roboto The regular font is used for all body copy, headlines, and essentially everything that does not need to be monospaced. It can be set to any valid Google Font via mkdocs.yml : theme : font : text : Roboto The typeface will be loaded in 300, 400, 400i and 700 .","title":"Regular font"},{"location":"setup/changing-the-fonts/#monospaced-font","text":"0.1.2 \u00b7 Default: Roboto Mono The monospaced font is used for code blocks and can be configured separately. Just like the regular font, it can be set to any valid Google Font via mkdocs.yml : theme : font : code : Roboto Mono The typeface will be loaded in 400.","title":"Monospaced font"},{"location":"setup/changing-the-fonts/#autoloading","text":"1.0.0 \u00b7 Default: none If you want to prevent typefaces from being loaded from Google Fonts , e.g. to adhere to data privacy regulations, and fall back to system fonts, add the following lines to mkdocs.yml : theme : font : false Automatically bundle Google Fonts The brand-new built-in privacy plugin makes it easy to use Google Fonts while complying with the General Data Protection Regulation (GDPR), by automatically downloading and self-hosting the web font files.","title":"Autoloading"},{"location":"setup/changing-the-fonts/#customization","text":"","title":"Customization"},{"location":"setup/changing-the-fonts/#additional-fonts","text":"If you want to load an (additional) font from another destination or override the system font, you can use an additional style sheet to add the corresponding @font-face definition: docs/stylesheets/extra.css mkdocs.yml @ font-face { font-family : \"<font>\" ; src : \"...\" ; } extra_css : - stylesheets/extra.css The font can then be applied to specific elements, e.g. only headlines, or globally to be used as the site-wide regular or monospaced font: Regular font Monospaced font : root { --md-text-font : \"<font>\" ; /* (1)! */ } Always define fonts through CSS variables and not font-family , as this would disable the system font fallback. : root { --md-code-font : \"<font>\" ; }","title":"Additional fonts"},{"location":"setup/changing-the-language/","text":"Changing the language \u00b6 Material for MkDocs supports internationalization (i18n) and provides translations for template variables and labels in 50+ languages. Additionally, the site search can be configured to use a language-specific stemmer, if available. Configuration \u00b6 Site language \u00b6 1.12.0 \u00b7 Default: en You can set the site language in mkdocs.yml with: theme : language : en # (1)! HTML5 only allows to set a single language per document , which is why Material for MkDocs only supports setting a canonical language for the entire project, i.e. one per mkdocs.yml . The easiest way to build a multi-language documentation is to create one project in a subfolder per language, and then use the language selector to interlink those projects. The following languages are supported: af \u2013 Afrikaans ar \u2013 Arabic bg \u2013 Bulgarian bn \u2013 Bengali (Bangla) ca \u2013 Catalan cs \u2013 Czech da \u2013 Danish de \u2013 German el \u2013 Greek en \u2013 English eo \u2013 Esperanto es \u2013 Spanish et \u2013 Estonian fa \u2013 Persian (Farsi) fi \u2013 Finnish fr \u2013 French gl \u2013 Galician he \u2013 Hebrew hi \u2013 Hindi hr \u2013 Croatian hu \u2013 Hungarian hy \u2013 Armenian id \u2013 Indonesian is \u2013 Icelandic it \u2013 Italian ja \u2013 Japanese ka \u2013 Georgian kr \u2013 Korean lt \u2013 Lithuanian lv \u2013 Latvian mk \u2013 Macedonian mn \u2013 Mongolian ms \u2013 Bahasa Malaysia my \u2013 Burmese nl \u2013 Dutch nn \u2013 Norwegian (Nynorsk) no \u2013 Norwegian pl \u2013 Polish pt \u2013 Portuguese pt-BR \u2013 Portuguese (Brasilian) ro \u2013 Romanian ru \u2013 Russian sh \u2013 Serbo-Croatian si \u2013 Sinhalese sk \u2013 Slovak sl \u2013 Slovenian sr \u2013 Serbian sv \u2013 Swedish th \u2013 Thai tl \u2013 Tagalog tr \u2013 Turkish uk \u2013 Ukrainian ur \u2013 Urdu uz \u2013 Uzbek vi \u2013 Vietnamese zh \u2013 Chinese (Simplified) zh-Hant \u2013 Chinese (Traditional) zh-TW \u2013 Chinese (Taiwanese) Add language Note that some languages will produce unreadable anchor links due to the way the default slug function works. Consider using a Unicode-aware slug function . Site language selector \u00b6 7.0.0 \u00b7 Default: none \u00b7 Experimental If your documentation is available in multiple languages, a language selector pointing to those languages can be added to the header. Alternate languages can be defined via mkdocs.yml . extra : alternate : - name : English link : /en/ # (1)! lang : en - name : Deutsch link : /de/ lang : de Note that this must be an absolute link. If it includes a domain part, it's used as defined. Otherwise the domain part of the site_url as set in mkdocs.yml is prepended to the link. The following properties are available for each alternate language: name Default: none \u00b7 Required \u2013 This value of this property is used inside the language selector as the name of the language and must be set to a non-empty string. link Default: none \u00b7 Required \u2013 This property must be set to an absolute link, which might also point to another domain or subdomain not necessarily generated with MkDocs. lang Default: none \u00b7 Required \u2013 This property must contain an ISO 639-1 language code and is used for the hreflang attribute of the link, improving discoverability via search engines. Directionality \u00b6 2.5.0 \u00b7 Default: automatically set While many languages are read ltr (left-to-right), Material for MkDocs also supports rtl (right-to-left) directionality which is deduced from the selected language, but can also be set with: theme : direction : ltr Click on a tile to change the directionality: ltr rtl var buttons = document.querySelectorAll(\"button[data-md-dir]\") buttons.forEach(function(button) { button.addEventListener(\"click\", function() { var attr = this.getAttribute(\"data-md-dir\") document.body.dir = attr var name = document.querySelector(\"#__code_3 code span.l\") name.textContent = attr }) }) Customization \u00b6 Custom translations \u00b6 If you want to customize some of the translations for a language, just follow the guide on theme extension and create a new partial in the overrides folder. Then, import the translations of the language as a fallback and only adjust the ones you want to override: overrides/partials/languages/custom.html mkdocs.yml <!-- Import translations for language and fallback --> {% import \"partials/languages/de.html\" as language %} {% import \"partials/languages/en.html\" as fallback %} <!-- (1)! --> <!-- Define custom translations --> {% macro override(key) %}{{ { \"source.file.date.created\": \"Erstellt am\", <!-- (2)! --> \"source.file.date.updated\": \"Aktualisiert am\" }[key] }}{% endmacro %} <!-- Re-export translations --> {% macro t(key) %}{{ override(key) or language.t(key) or fallback.t(key) }}{% endmacro %} Note that en must always be used as a fallback language, as it's the default theme language. Check the list of available languages , pick the translation you want to override for your language and add them here. theme : language : custom","title":"Changing the language"},{"location":"setup/changing-the-language/#changing-the-language","text":"Material for MkDocs supports internationalization (i18n) and provides translations for template variables and labels in 50+ languages. Additionally, the site search can be configured to use a language-specific stemmer, if available.","title":"Changing the language"},{"location":"setup/changing-the-language/#configuration","text":"","title":"Configuration"},{"location":"setup/changing-the-language/#site-language","text":"1.12.0 \u00b7 Default: en You can set the site language in mkdocs.yml with: theme : language : en # (1)! HTML5 only allows to set a single language per document , which is why Material for MkDocs only supports setting a canonical language for the entire project, i.e. one per mkdocs.yml . The easiest way to build a multi-language documentation is to create one project in a subfolder per language, and then use the language selector to interlink those projects. The following languages are supported: af \u2013 Afrikaans ar \u2013 Arabic bg \u2013 Bulgarian bn \u2013 Bengali (Bangla) ca \u2013 Catalan cs \u2013 Czech da \u2013 Danish de \u2013 German el \u2013 Greek en \u2013 English eo \u2013 Esperanto es \u2013 Spanish et \u2013 Estonian fa \u2013 Persian (Farsi) fi \u2013 Finnish fr \u2013 French gl \u2013 Galician he \u2013 Hebrew hi \u2013 Hindi hr \u2013 Croatian hu \u2013 Hungarian hy \u2013 Armenian id \u2013 Indonesian is \u2013 Icelandic it \u2013 Italian ja \u2013 Japanese ka \u2013 Georgian kr \u2013 Korean lt \u2013 Lithuanian lv \u2013 Latvian mk \u2013 Macedonian mn \u2013 Mongolian ms \u2013 Bahasa Malaysia my \u2013 Burmese nl \u2013 Dutch nn \u2013 Norwegian (Nynorsk) no \u2013 Norwegian pl \u2013 Polish pt \u2013 Portuguese pt-BR \u2013 Portuguese (Brasilian) ro \u2013 Romanian ru \u2013 Russian sh \u2013 Serbo-Croatian si \u2013 Sinhalese sk \u2013 Slovak sl \u2013 Slovenian sr \u2013 Serbian sv \u2013 Swedish th \u2013 Thai tl \u2013 Tagalog tr \u2013 Turkish uk \u2013 Ukrainian ur \u2013 Urdu uz \u2013 Uzbek vi \u2013 Vietnamese zh \u2013 Chinese (Simplified) zh-Hant \u2013 Chinese (Traditional) zh-TW \u2013 Chinese (Taiwanese) Add language Note that some languages will produce unreadable anchor links due to the way the default slug function works. Consider using a Unicode-aware slug function .","title":"Site language"},{"location":"setup/changing-the-language/#site-language-selector","text":"7.0.0 \u00b7 Default: none \u00b7 Experimental If your documentation is available in multiple languages, a language selector pointing to those languages can be added to the header. Alternate languages can be defined via mkdocs.yml . extra : alternate : - name : English link : /en/ # (1)! lang : en - name : Deutsch link : /de/ lang : de Note that this must be an absolute link. If it includes a domain part, it's used as defined. Otherwise the domain part of the site_url as set in mkdocs.yml is prepended to the link. The following properties are available for each alternate language: name Default: none \u00b7 Required \u2013 This value of this property is used inside the language selector as the name of the language and must be set to a non-empty string. link Default: none \u00b7 Required \u2013 This property must be set to an absolute link, which might also point to another domain or subdomain not necessarily generated with MkDocs. lang Default: none \u00b7 Required \u2013 This property must contain an ISO 639-1 language code and is used for the hreflang attribute of the link, improving discoverability via search engines.","title":"Site language selector"},{"location":"setup/changing-the-language/#directionality","text":"2.5.0 \u00b7 Default: automatically set While many languages are read ltr (left-to-right), Material for MkDocs also supports rtl (right-to-left) directionality which is deduced from the selected language, but can also be set with: theme : direction : ltr Click on a tile to change the directionality: ltr rtl var buttons = document.querySelectorAll(\"button[data-md-dir]\") buttons.forEach(function(button) { button.addEventListener(\"click\", function() { var attr = this.getAttribute(\"data-md-dir\") document.body.dir = attr var name = document.querySelector(\"#__code_3 code span.l\") name.textContent = attr }) })","title":"Directionality"},{"location":"setup/changing-the-language/#customization","text":"","title":"Customization"},{"location":"setup/changing-the-language/#custom-translations","text":"If you want to customize some of the translations for a language, just follow the guide on theme extension and create a new partial in the overrides folder. Then, import the translations of the language as a fallback and only adjust the ones you want to override: overrides/partials/languages/custom.html mkdocs.yml <!-- Import translations for language and fallback --> {% import \"partials/languages/de.html\" as language %} {% import \"partials/languages/en.html\" as fallback %} <!-- (1)! --> <!-- Define custom translations --> {% macro override(key) %}{{ { \"source.file.date.created\": \"Erstellt am\", <!-- (2)! --> \"source.file.date.updated\": \"Aktualisiert am\" }[key] }}{% endmacro %} <!-- Re-export translations --> {% macro t(key) %}{{ override(key) or language.t(key) or fallback.t(key) }}{% endmacro %} Note that en must always be used as a fallback language, as it's the default theme language. Check the list of available languages , pick the translation you want to override for your language and add them here. theme : language : custom","title":"Custom translations"},{"location":"setup/changing-the-logo-and-icons/","text":"Changing the logo and icons \u00b6 When installing Material for MkDocs, you immediately get access to over 8,000 icons ready to be used for customization of specific parts of the theme and/or when writing your documentation in Markdown. Not enough? You can also add additional icons with minimal effort. Configuration \u00b6 Logo \u00b6 0.1.0 \u00b7 Default: \u2013 material/library The logo can be changed to a user-provided image (any type, incl. *.png and *.svg ) located in the docs folder, or to any icon bundled with the theme. Add the following lines to mkdocs.yml : Image Icon, bundled theme : logo : assets/logo.png theme : icon : logo : material/library # (1)! Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: Normally, the logo in the header and sidebar links to the homepage of the documentation, which is the same as site_url . This behavior can be changed with the following configuration: extra : homepage : https://example.com Favicon \u00b6 0.1.0 \u00b7 Default: assets/images/favicon.png The favicon can be changed to a path pointing to a user-provided image, which must be located in the docs folder. Add the following lines to mkdocs.yml : theme : favicon : images/favicon.png Customization \u00b6 Additional icons \u00b6 In order to use custom icons, extend the theme and create a new folder named .icons in the custom_dir you want to use for overrides. Next, add your *.svg icons into a subfolder of the .icons folder. Let's say you downloaded and unpacked the Bootstrap icon set, and want to add it to your project documentation. The structure of your project should look like this: . \u251c\u2500 overrides/ \u2502 \u2514\u2500 .icons/ \u2502 \u2514\u2500 bootstrap/ \u2502 \u2514\u2500 *.svg \u2514\u2500 mkdocs.yml Then, add the following lines to mkdocs.yml : markdown_extensions : - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator : !!python/name:materialx.emoji.to_svg options : custom_icons : - overrides/.icons You can now use all Bootstrap icons anywhere in Markdown files, as well as everywhere icons can be used in mkdocs.yml . However, note that the syntaxes are slightly different: Using icons in configuration : take the path of the *.svg icon file starting at the .icons folder and drop the file extension, e.g. for .icons/bootstrap/envelope-paper.svg , use: theme : icon : logo : bootstrap/envelope-paper Using icons in Markdown files : additionally to taking the path from the .icons folder as noted above, replace all / with - and enclose the icon shortcode in two colons: :bootstrap-envelope-paper: For further notes on icon usage, please consult the icon reference .","title":"Changing the logo and icons"},{"location":"setup/changing-the-logo-and-icons/#changing-the-logo-and-icons","text":"When installing Material for MkDocs, you immediately get access to over 8,000 icons ready to be used for customization of specific parts of the theme and/or when writing your documentation in Markdown. Not enough? You can also add additional icons with minimal effort.","title":"Changing the logo and icons"},{"location":"setup/changing-the-logo-and-icons/#configuration","text":"","title":"Configuration"},{"location":"setup/changing-the-logo-and-icons/#logo","text":"0.1.0 \u00b7 Default: \u2013 material/library The logo can be changed to a user-provided image (any type, incl. *.png and *.svg ) located in the docs folder, or to any icon bundled with the theme. Add the following lines to mkdocs.yml : Image Icon, bundled theme : logo : assets/logo.png theme : icon : logo : material/library # (1)! Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: Normally, the logo in the header and sidebar links to the homepage of the documentation, which is the same as site_url . This behavior can be changed with the following configuration: extra : homepage : https://example.com","title":"Logo"},{"location":"setup/changing-the-logo-and-icons/#favicon","text":"0.1.0 \u00b7 Default: assets/images/favicon.png The favicon can be changed to a path pointing to a user-provided image, which must be located in the docs folder. Add the following lines to mkdocs.yml : theme : favicon : images/favicon.png","title":"Favicon"},{"location":"setup/changing-the-logo-and-icons/#customization","text":"","title":"Customization"},{"location":"setup/changing-the-logo-and-icons/#additional-icons","text":"In order to use custom icons, extend the theme and create a new folder named .icons in the custom_dir you want to use for overrides. Next, add your *.svg icons into a subfolder of the .icons folder. Let's say you downloaded and unpacked the Bootstrap icon set, and want to add it to your project documentation. The structure of your project should look like this: . \u251c\u2500 overrides/ \u2502 \u2514\u2500 .icons/ \u2502 \u2514\u2500 bootstrap/ \u2502 \u2514\u2500 *.svg \u2514\u2500 mkdocs.yml Then, add the following lines to mkdocs.yml : markdown_extensions : - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator : !!python/name:materialx.emoji.to_svg options : custom_icons : - overrides/.icons You can now use all Bootstrap icons anywhere in Markdown files, as well as everywhere icons can be used in mkdocs.yml . However, note that the syntaxes are slightly different: Using icons in configuration : take the path of the *.svg icon file starting at the .icons folder and drop the file extension, e.g. for .icons/bootstrap/envelope-paper.svg , use: theme : icon : logo : bootstrap/envelope-paper Using icons in Markdown files : additionally to taking the path from the .icons folder as noted above, replace all / with - and enclose the icon shortcode in two colons: :bootstrap-envelope-paper: For further notes on icon usage, please consult the icon reference .","title":"Additional icons"},{"location":"setup/ensuring-data-privacy/","text":"Ensuring data privacy \u00b6 Material for MkDocs makes compliance with data privacy regulations very easy, as it offers a native cookie consent solution to seek explicit consent from users before setting up analytics . Additionally, external assets can be automatically downloaded for self-hosting . Configuration \u00b6 Cookie consent \u00b6 8.4.0 \u00b7 Default: none \u00b7 Experimental Material for MkDocs ships a native and extensible cookie consent form which asks the user for consent prior to sending requests to third parties. Add the following to mkdocs.yml : extra : consent : title : Cookie consent description : >- # (1)! We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better. You can add arbitrary HTML tags in the description , e.g. to link to your terms of service or other parts of the site. The following properties are available: title Default: none \u00b7 Required \u2013 This property sets the title of the cookie consent, which is rendered at the top of the form and must be set to a non-empty string. description Default: none \u00b7 Required \u2013 This property sets the description of the cookie consent, is rendered below the title, and may include raw HTML (e.g. a links to the terms of service). cookies Default: none \u2013 This property allows to add custom cookies or change the initial checked state and name of built-in cookies. Currently, the following cookies are built-in: Google Analytics \u2013 analytics (enabled by default) GitHub \u2013 github (enabled by default) Each cookie must receive a unique identifier which is used as a key in the cookies map, and can be either set to a string, or to a map defining name and checked state: Custom cookie name Custom initial state Custom cookie extra : consent : cookies : analytics : Custom name extra : consent : cookies : analytics : name : Google Analytics checked : false extra : consent : cookies : analytics : Google Analytics # (1)! custom : Custom cookie If you define a custom cookie as part of the cookies property, the analytics cookie must be added back explicitly, or analytics won't be triggered. If Google Analytics was configured via mkdocs.yml , the cookie consent will automatically include a setting for the user to disable it. Custom cookies can be used from JavaScript. actions Default: [accept, manage] \u2013 This property defines which buttons are shown and in which order, e.g. to allow the user to accept cookies and manage settings: extra : consent : actions : - accept - manage # (1)! If the manage settings button is omitted from the actions property, the settings are always shown. The cookie consent form includes three types of buttons: accept \u2013 Button to accept selected cookies reject \u2013 Button to reject all cookies manage \u2013 Button to manage settings When a user first visits your site, a cookie consent form is rendered: Change cookie settings \u00b6 In order to comply with GDPR, users must be able to change their cookie settings at any time. This can be done by adding a simple link to your copyright notice in mkdocs.yml : copyright : > Copyright &copy; 2016 - 2022 Martin Donath \u2013 <a href=\"#__consent\">Change cookie settings</a> Built-in privacy plugin \u00b6 Sponsors only \u00b7 insiders-4.9.0 \u00b7 Plugin \u00b7 Experimental The built-in privacy plugin automatically identifies external assets as part of the build process and downloads all assets for very simple self-hosting. Add the following lines to mkdocs.yml : plugins : - privacy If you need to be able to build your documentation with and without Insiders , please refer to the built-in plugins section to learn how shared configurations help to achieve this. The following configuration options are available: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable : plugins : - privacy : enabled : !ENV [ CI , false ] External assets \u00b6 The following configuration options are available for external assets: external_assets Default: bundle \u2013 This option specifies what the plugin should do when encountering external assets. There are two options: while report will issue warning messages during the build, bundle will automatically download all external files and adjust all references: plugins : - privacy : external_assets : bundle If you've removed all external assets from your project via customization , it's still a good idea to enable the plugin and set the mode to report , as the plugin will make sure that there are no hidden external links in any Markdown files that were unintentionally added. Using report in strict mode will make the build fail when external assets are detected. external_assets_dir Default: assets/external \u2013 This option specifies where the downloaded external assets will be stored. It's normally not necessary to change this option: plugins : - privacy : external_assets_dir : assets/external The path must be defined relative to docs_dir . external_assets_exclude Default: none \u2013 This option allows to exclude certain external assets from processing by the privacy plugin, so they will not be downloaded and bundled during the build: plugins : - privacy : external_assets_exclude : # (1)! - cdn.jsdelivr.net/npm/mathjax@3/* - giscus.app/* MathJax loads web fonts for typesetting of mathematical content through relative URLs, and thus cannot be automatically bundled by the privacy plugin. MathJax can be self-hosted . Giscus, which we recommend to use as a comment system , uses a technique called code-splitting to load only the code that is necessary, which is implemented via relative URLs. Giscus can be self-hosted as well. Excluding specific external assets can be necessary if they contain dynamically created or relative URLs, which can't be resolved by the privacy plugin due to technical limitations . Why can't Material for MkDocs bundle all assets by design? The primary reason why Material for MkDocs can't just bundle all of its own assets is the integration with Google Fonts , which offers over a thousand different fonts that can be used to render your documentation. Most of the fonts include several weights and are split up into different character sets to keep the download size small, so the browser only downloads what is really needed. For Roboto, our default regular font , this results in 42 *.woff2 files in total . If Material for MkDocs would bundle all font files, the download size would be in the hundreds of megabytes, slowing down automated builds. Furthermore, authors might add external assets like third-party scripts or style sheets that would need to be remembered to be defined as further local assets. This is the very reason the built-in privacy plugin exists \u2014 it automates the process of downloading all external assets manually to ensure compliance with GDPR with some some technical limitations . External links \u00b6 Sponsors only \u00b7 insiders-4.26.0 \u00b7 Experimental The following configuration options are available for external links: external_links Default: true \u2013 This option specifies whether the plugin should automatically annotate external links. By default, rel=\"noopener\" is added to all links with target=\"_blank\" : plugins : - privacy : external_links : true external_links_attr_map Default: None \u2013 This option specifies custom attributes that should be added to external links, like for example target=\"_blank\" so all external links open in a new window: plugins : - privacy : external_links_attr_map : target : _blank external_links_noopener Default: true \u2013 This option specifies whether the plugin should automatically add rel=\"noopener\" to all links with target=\"_blank\" for security reasons: plugins : - privacy : external_links_noopener : true How it works \u00b6 The built-in privacy plugin scans the resulting HTML for links to external resources, including external scripts, style sheets, images and web fonts, and downloads them to bundle them with your documentation site. Every URL refering to an external resource, no matter if part of a template or Markdown file, is then replaced with the URL to the local copy. An example: < script src = \"https://example.com/script.js\" ></ script > The external script is downloaded, and the link is replaced with: < script src = \"assets/external/example.com/script.js\" ></ script > Style sheets are scanned for external url(...) references, e.g. images and web fonts, which are then also downloaded and bundled with your documentation site. This means that Google Fonts can be configured in mkdocs.yml as usual, as the built-in privacy plugin automatically downloads and bundles all dependent resources. As a third measure, preconnect hints used for DNS pre-fetching which might also leak the visitors IP address to a third party are automatically removed during the build process. Expand to inspect example For the official documentation, the built-in privacy plugin downloads the following resources: . \u2514\u2500 assets/external/ \u251c\u2500 unpkg.com/tablesort@5.3.0/dist/tablesort.min.js \u251c\u2500 fonts.googleapis.com/css \u251c\u2500 fonts.gstatic.com/s/ \u2502 \u251c\u2500 roboto/v29/ \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc-CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc0CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc1CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc2CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc3CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc5CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc6CsQ.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic-CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic0CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic1CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic2CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic3CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic5CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic6CsQ.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xEIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xFIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xGIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xHIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xIIzI.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xLIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xMIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fABc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fBBc4.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fBxc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCBc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCRc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fChc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCxc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfABc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfBBc4.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfBxc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCBc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCRc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfChc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCxc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu4WxKOzY.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu4mxK.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu5mxKOzY.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu72xKOzY.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu7GxKOzY.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu7WxKOzY.woff2 \u2502 \u2502 \u2514\u2500 KFOmCnqEu92Fr1Mu7mxKOzY.woff2 \u2502 \u2514\u2500 robotomono/v13/ \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSV0mf0h.woff2 \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSZ0mf0h.woff2 \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSd0mf0h.woff2 \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSh0mQ.woff2 \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSt0mf0h.woff2 \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSx0mf0h.woff2 \u2502 \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtElOUlYIw.woff2 \u2502 \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEleUlYIw.woff2 \u2502 \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEluUlYIw.woff2 \u2502 \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEm-Ul.woff2 \u2502 \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEmOUlYIw.woff2 \u2502 \u2514\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEn-UlYIw.woff2 \u2514\u2500 polyfill.io/v3/polyfill.min.js Caching recommended \u00b6 All downloaded files are written to the .cache directory, significantly reducing the duration of subsequent builds as only replacements need to be carried out. You might want to: Ignore the .cache directory in your project, by adding it to .gitignore . When building your site for publishing, use a build cache to save the .cache directory in between builds. Taking the example from the publishing guide , add the following lines: name : ci on : push : branches : - master - main jobs : deploy : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - uses : actions/setup-python@v2 with : python-version : 3.x - uses : actions/cache@v2 with : key : ${{ github.ref }} path : .cache - run : pip install mkdocs-material - run : mkdocs gh-deploy --force Limitations \u00b6 Note that dynamically created URLs as part of scripts are not detected, and thus cannot be automatically downloaded. The built-in privacy plugin does not execute scripts \u2013 it can only detect fully qualified URLs to download and replace. In short, don't do this: const cdn = \"https://polyfill.io\" const url = ` ${ cdn } /v3/polyfill.min.js` Instead, always use fully qualified URLs: const url = \"https://polyfill.io/v3/polyfill.min.js\" Customization \u00b6 Custom cookies \u00b6 If you've customized the cookie consent and added a custom cookie, the user will be prompted to accept your custom cookie. Use additional JavaScript to check whether the user accepted it: docs/javascripts/consent.js mkdocs.yml var consent = __md_get ( \"__consent\" ) if ( consent && consent . custom ) { /* The user accepted the cookie */ } extra_javascript : - javascripts/consent.js","title":"Ensuring data privacy"},{"location":"setup/ensuring-data-privacy/#ensuring-data-privacy","text":"Material for MkDocs makes compliance with data privacy regulations very easy, as it offers a native cookie consent solution to seek explicit consent from users before setting up analytics . Additionally, external assets can be automatically downloaded for self-hosting .","title":"Ensuring data privacy"},{"location":"setup/ensuring-data-privacy/#configuration","text":"","title":"Configuration"},{"location":"setup/ensuring-data-privacy/#cookie-consent","text":"8.4.0 \u00b7 Default: none \u00b7 Experimental Material for MkDocs ships a native and extensible cookie consent form which asks the user for consent prior to sending requests to third parties. Add the following to mkdocs.yml : extra : consent : title : Cookie consent description : >- # (1)! We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better. You can add arbitrary HTML tags in the description , e.g. to link to your terms of service or other parts of the site. The following properties are available: title Default: none \u00b7 Required \u2013 This property sets the title of the cookie consent, which is rendered at the top of the form and must be set to a non-empty string. description Default: none \u00b7 Required \u2013 This property sets the description of the cookie consent, is rendered below the title, and may include raw HTML (e.g. a links to the terms of service). cookies Default: none \u2013 This property allows to add custom cookies or change the initial checked state and name of built-in cookies. Currently, the following cookies are built-in: Google Analytics \u2013 analytics (enabled by default) GitHub \u2013 github (enabled by default) Each cookie must receive a unique identifier which is used as a key in the cookies map, and can be either set to a string, or to a map defining name and checked state: Custom cookie name Custom initial state Custom cookie extra : consent : cookies : analytics : Custom name extra : consent : cookies : analytics : name : Google Analytics checked : false extra : consent : cookies : analytics : Google Analytics # (1)! custom : Custom cookie If you define a custom cookie as part of the cookies property, the analytics cookie must be added back explicitly, or analytics won't be triggered. If Google Analytics was configured via mkdocs.yml , the cookie consent will automatically include a setting for the user to disable it. Custom cookies can be used from JavaScript. actions Default: [accept, manage] \u2013 This property defines which buttons are shown and in which order, e.g. to allow the user to accept cookies and manage settings: extra : consent : actions : - accept - manage # (1)! If the manage settings button is omitted from the actions property, the settings are always shown. The cookie consent form includes three types of buttons: accept \u2013 Button to accept selected cookies reject \u2013 Button to reject all cookies manage \u2013 Button to manage settings When a user first visits your site, a cookie consent form is rendered:","title":"Cookie consent"},{"location":"setup/ensuring-data-privacy/#change-cookie-settings","text":"In order to comply with GDPR, users must be able to change their cookie settings at any time. This can be done by adding a simple link to your copyright notice in mkdocs.yml : copyright : > Copyright &copy; 2016 - 2022 Martin Donath \u2013 <a href=\"#__consent\">Change cookie settings</a>","title":"Change cookie settings"},{"location":"setup/ensuring-data-privacy/#built-in-privacy-plugin","text":"Sponsors only \u00b7 insiders-4.9.0 \u00b7 Plugin \u00b7 Experimental The built-in privacy plugin automatically identifies external assets as part of the build process and downloads all assets for very simple self-hosting. Add the following lines to mkdocs.yml : plugins : - privacy If you need to be able to build your documentation with and without Insiders , please refer to the built-in plugins section to learn how shared configurations help to achieve this. The following configuration options are available: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable : plugins : - privacy : enabled : !ENV [ CI , false ]","title":"Built-in privacy plugin"},{"location":"setup/ensuring-data-privacy/#external-assets","text":"The following configuration options are available for external assets: external_assets Default: bundle \u2013 This option specifies what the plugin should do when encountering external assets. There are two options: while report will issue warning messages during the build, bundle will automatically download all external files and adjust all references: plugins : - privacy : external_assets : bundle If you've removed all external assets from your project via customization , it's still a good idea to enable the plugin and set the mode to report , as the plugin will make sure that there are no hidden external links in any Markdown files that were unintentionally added. Using report in strict mode will make the build fail when external assets are detected. external_assets_dir Default: assets/external \u2013 This option specifies where the downloaded external assets will be stored. It's normally not necessary to change this option: plugins : - privacy : external_assets_dir : assets/external The path must be defined relative to docs_dir . external_assets_exclude Default: none \u2013 This option allows to exclude certain external assets from processing by the privacy plugin, so they will not be downloaded and bundled during the build: plugins : - privacy : external_assets_exclude : # (1)! - cdn.jsdelivr.net/npm/mathjax@3/* - giscus.app/* MathJax loads web fonts for typesetting of mathematical content through relative URLs, and thus cannot be automatically bundled by the privacy plugin. MathJax can be self-hosted . Giscus, which we recommend to use as a comment system , uses a technique called code-splitting to load only the code that is necessary, which is implemented via relative URLs. Giscus can be self-hosted as well. Excluding specific external assets can be necessary if they contain dynamically created or relative URLs, which can't be resolved by the privacy plugin due to technical limitations . Why can't Material for MkDocs bundle all assets by design? The primary reason why Material for MkDocs can't just bundle all of its own assets is the integration with Google Fonts , which offers over a thousand different fonts that can be used to render your documentation. Most of the fonts include several weights and are split up into different character sets to keep the download size small, so the browser only downloads what is really needed. For Roboto, our default regular font , this results in 42 *.woff2 files in total . If Material for MkDocs would bundle all font files, the download size would be in the hundreds of megabytes, slowing down automated builds. Furthermore, authors might add external assets like third-party scripts or style sheets that would need to be remembered to be defined as further local assets. This is the very reason the built-in privacy plugin exists \u2014 it automates the process of downloading all external assets manually to ensure compliance with GDPR with some some technical limitations .","title":"External assets"},{"location":"setup/ensuring-data-privacy/#external-links","text":"Sponsors only \u00b7 insiders-4.26.0 \u00b7 Experimental The following configuration options are available for external links: external_links Default: true \u2013 This option specifies whether the plugin should automatically annotate external links. By default, rel=\"noopener\" is added to all links with target=\"_blank\" : plugins : - privacy : external_links : true external_links_attr_map Default: None \u2013 This option specifies custom attributes that should be added to external links, like for example target=\"_blank\" so all external links open in a new window: plugins : - privacy : external_links_attr_map : target : _blank external_links_noopener Default: true \u2013 This option specifies whether the plugin should automatically add rel=\"noopener\" to all links with target=\"_blank\" for security reasons: plugins : - privacy : external_links_noopener : true","title":"External links "},{"location":"setup/ensuring-data-privacy/#how-it-works","text":"The built-in privacy plugin scans the resulting HTML for links to external resources, including external scripts, style sheets, images and web fonts, and downloads them to bundle them with your documentation site. Every URL refering to an external resource, no matter if part of a template or Markdown file, is then replaced with the URL to the local copy. An example: < script src = \"https://example.com/script.js\" ></ script > The external script is downloaded, and the link is replaced with: < script src = \"assets/external/example.com/script.js\" ></ script > Style sheets are scanned for external url(...) references, e.g. images and web fonts, which are then also downloaded and bundled with your documentation site. This means that Google Fonts can be configured in mkdocs.yml as usual, as the built-in privacy plugin automatically downloads and bundles all dependent resources. As a third measure, preconnect hints used for DNS pre-fetching which might also leak the visitors IP address to a third party are automatically removed during the build process. Expand to inspect example For the official documentation, the built-in privacy plugin downloads the following resources: . \u2514\u2500 assets/external/ \u251c\u2500 unpkg.com/tablesort@5.3.0/dist/tablesort.min.js \u251c\u2500 fonts.googleapis.com/css \u251c\u2500 fonts.gstatic.com/s/ \u2502 \u251c\u2500 roboto/v29/ \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc-CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc0CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc1CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc2CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc3CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc5CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TjASc6CsQ.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic-CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic0CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic1CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic2CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic3CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic5CsTKlA.woff2 \u2502 \u2502 \u251c\u2500 KFOjCnqEu92Fr1Mu51TzBic6CsQ.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xEIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xFIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xGIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xHIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xIIzI.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xLIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOkCnqEu92Fr1Mu51xMIzIFKw.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fABc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fBBc4.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fBxc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCBc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCRc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fChc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmSU5fCxc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfABc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfBBc4.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfBxc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCBc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCRc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfChc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOlCnqEu92Fr1MmWUlfCxc4EsA.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu4WxKOzY.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu4mxK.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu5mxKOzY.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu72xKOzY.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu7GxKOzY.woff2 \u2502 \u2502 \u251c\u2500 KFOmCnqEu92Fr1Mu7WxKOzY.woff2 \u2502 \u2502 \u2514\u2500 KFOmCnqEu92Fr1Mu7mxKOzY.woff2 \u2502 \u2514\u2500 robotomono/v13/ \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSV0mf0h.woff2 \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSZ0mf0h.woff2 \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSd0mf0h.woff2 \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSh0mQ.woff2 \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSt0mf0h.woff2 \u2502 \u251c\u2500 L0xTDF4xlVMF-BfR8bXMIhJHg45mwgGEFl0_3vrtSM1J-gEPT5Ese6hmHSx0mf0h.woff2 \u2502 \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtElOUlYIw.woff2 \u2502 \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEleUlYIw.woff2 \u2502 \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEluUlYIw.woff2 \u2502 \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEm-Ul.woff2 \u2502 \u251c\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEmOUlYIw.woff2 \u2502 \u2514\u2500 L0xdDF4xlVMF-BfR8bXMIjhOsXG-q2oeuFoqFrlnAIe2Imhk1T8rbociImtEn-UlYIw.woff2 \u2514\u2500 polyfill.io/v3/polyfill.min.js","title":"How it works"},{"location":"setup/ensuring-data-privacy/#caching","text":"All downloaded files are written to the .cache directory, significantly reducing the duration of subsequent builds as only replacements need to be carried out. You might want to: Ignore the .cache directory in your project, by adding it to .gitignore . When building your site for publishing, use a build cache to save the .cache directory in between builds. Taking the example from the publishing guide , add the following lines: name : ci on : push : branches : - master - main jobs : deploy : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - uses : actions/setup-python@v2 with : python-version : 3.x - uses : actions/cache@v2 with : key : ${{ github.ref }} path : .cache - run : pip install mkdocs-material - run : mkdocs gh-deploy --force","title":"Caching"},{"location":"setup/ensuring-data-privacy/#limitations","text":"Note that dynamically created URLs as part of scripts are not detected, and thus cannot be automatically downloaded. The built-in privacy plugin does not execute scripts \u2013 it can only detect fully qualified URLs to download and replace. In short, don't do this: const cdn = \"https://polyfill.io\" const url = ` ${ cdn } /v3/polyfill.min.js` Instead, always use fully qualified URLs: const url = \"https://polyfill.io/v3/polyfill.min.js\"","title":"Limitations"},{"location":"setup/ensuring-data-privacy/#customization","text":"","title":"Customization"},{"location":"setup/ensuring-data-privacy/#custom-cookies","text":"If you've customized the cookie consent and added a custom cookie, the user will be prompted to accept your custom cookie. Use additional JavaScript to check whether the user accepted it: docs/javascripts/consent.js mkdocs.yml var consent = __md_get ( \"__consent\" ) if ( consent && consent . custom ) { /* The user accepted the cookie */ } extra_javascript : - javascripts/consent.js","title":"Custom cookies"},{"location":"setup/setting-up-a-blog/","text":"Setting up a blog \u00b6 Material for MkDocs makes it very easy to build a blog, either as a sidecar to your documentation or standalone. Focus on your content while the engine does all the heavy lifting, automatically generating archive and category indexes, post slugs , configurable pagination and more. Check out our blog , which is created with the new built-in blog plugin ! Configuration \u00b6 Built-in blog plugin \u00b6 Sponsors only \u00b7 insiders-4.23.0 \u00b7 Plugin \u00b7 Experimental The built-in blog plugin adds support for building a blog from a folder of posts, which are annotated with dates and other structured data. First, add the following lines to mkdocs.yml : plugins : - blog If you need to be able to build your documentation with and without Insiders , please refer to the built-in plugins section to learn how shared configurations help to achieve this. By default, the built-in blog plugin assumes that your blog is hosted inside the blog subfolder of your documentation ( this is configurable ). Next, you need to create the following structure: . \u251c\u2500 docs/ \u2502 \u2514\u2500 blog/ \u2502 \u251c\u2500 posts/ \u2502 \u2514\u2500 index.md \u2514\u2500 mkdocs.yml Since the built-in blog plugin auto-generates archive and category indexes, it must know where to add those to the navigation. Thus, make sure to add a blog/index.md file in mkdocs.yml : nav : - Blog : - blog/index.md # (1)! Within this file, you can specify the title of your blog, which is then picked up and used by the built-in blog plugin: # Blog The following configuration options are available: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable : plugins : - blog : enabled : !ENV [ CI , false ] blog_dir Default: blog \u2013 This option specifies the folder where your posts and metadata live. The name of the folder will also be included in the generated URLs as a prefix to all blog-related pages. If you want to build a standalone blog, change it to . : Subdirectory Standalone plugins : - blog : blog_dir : path/to/folder plugins : - blog : blog_dir : . The path must be defined relative to docs_dir . The built-in blog plugin has dozens of options that allow for advanced configuration. It's a good idea to start writing your first post , and come back here later for fine-tuning the output. Posts \u00b6 The following configuration options are available for posts: post_date_format Default: long \u2013 This option specifies the date format that is used when posts are rendered. Under the hood, the built-in blog plugin leverages Babel to render dates locale-aware using the configured site language . The following formats are supported: Monday, January 31, 2022 January 31, 2022 Jan 31, 2022 1/31/22 plugins : - blog : post_date_format : full plugins : - blog : post_date_format : long plugins : - blog : post_date_format : medium plugins : - blog : post_date_format : short Note that depending on the site language , formats might look different for other languages. Additionally, Babel supports a pattern syntax which allows for custom formats. post_url_date_format Default: yyyy/MM/dd \u2013 This option specifies the date format that is used in the URL of the post. The format string must adhere to Babel 's pattern syntax . Some examples: blog/2022/01/31/ / blog/2022/01/ / blog/2022/ / plugins : - blog : post_url_date_format : yyyy/MM/dd plugins : - blog : post_url_date_format : yyyy/MM plugins : - blog : post_url_date_format : yyyy If you want to exclude the date altogether, e.g. when your blog features mostly evergreen content, you can remove the date placeholder from the format string (see below). post_url_format Default: {date}/{slug} \u2013 This option specifies the format string that is used for the URL of the post. The following placeholders are currently supported: date \u2013 Replaced with the post's date, as configured in post_url_date_format . slug \u2013 Replaced with a slug generated from the post's title. file \u2013 Replaced with the post's file name. blog/2022/ / blog/ / plugins : - blog : post_url_format : \"{date}/{slug}\" plugins : - blog : post_url_format : \"{slug}\" If you remove the date placeholder, make sure that post URLs don't collide with other the URLs of other pages added to the blog section, as this leads to undefined behavior. post_slugify Default: headerid.slugify \u2013 This option specifies which function to use for generating URL-compatible slugs from post titles. Python Markdown Extensions comes with several Unicode-aware slug functions which should be a good choice for non-ASCII languages: Unicode Unicode, case-sensitive plugins : - blog : post_slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower plugins : - blog : post_slugify : !!python/object/apply:pymdownx.slugs.slugify post_slugify_separator Default: - \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string, including the empty string: plugins : - blog : post_slugify_separator : \"-\" post_excerpt Default: optional \u2013 This option specifies whether post excerpts should be considered being optional or required by the built-in blog plugin when generating indexes. If excerpts are required, the plugin terminates with an error if a post doesn't define an excerpt: Optional Required plugins : - blog : post_excerpt : optional plugins : - blog : post_excerpt : required post_excerpt_max_authors Default: 1 \u2013 This option specifies the number of authors rendered in post excerpts. While each post may be written by multiple authors, this setting allows to limit the display to just a few or even a single author, or disable authors in excerpts altogether: Render up to 2 authors in excerpts Disable authors in excerpts plugins : - blog : post_excerpt_max_authors : 2 plugins : - blog : post_excerpt_max_authors : 0 post_excerpt_max_categories Default: 5 \u2013 This option specifies the number of categories rendered in post excerpts. While each post may be assigned to multiple categories, the built-in blog plugin can be instructed to only show the first n categories to keep it short and concise: Render up to 2 categories in excerpts Disable categories in excerpts plugins : - blog : post_excerpt_max_categories : 2 plugins : - blog : post_excerpt_max_categories : 0 post_excerpt_separator Default: <!-- more --> \u2013 This option specifies the separator the built-in blog plugin will look for in a post's content when generating post excerpts . All content after the separator is not considered to be part of the excerpt. post_readtime Default: true \u2013 This option specifies whether the built-in blog plugin should compute the reading time of a post automatically, which is then rendered in post excerpts, as well as in the posts themselves. If you want to disable reading time computation, add: plugins : - blog : post_readtime : false post_readtime_words_per_minute Default: 265 \u2013 This option specifies the number of words that a reader is expected to read per minute when computing the reading time of a post. If you feel that estimation is not quite right, you can fine-tune reading time computation with the following setting: plugins : - blog : post_readtime_words_per_minute : 265 Archive \u00b6 The following configuration options are available for archive index generation: archive Default: true \u2013 This option specifies whether the built-in blog plugin should generate archive indexes. An archive indexes shows all posts for a specific interval (e.g. year, month, etc.) in reverse chronological order. If you want to disable archive index generation, add: plugins : - blog : archive : false archive_name Default: automatically set \u2013 This option specifies the title of the archive section which the built-in blog plugin will generate and add to the navigation. If this setting is omitted, it's sourced from the translations, falling back to English. Change it with: plugins : - blog : archive_name : Archive archive_date_format Default: yyyy \u2013 This option specifies the date format that is used when archive indexes are rendered. The format string must adhere to Babel 's pattern syntax . Popular settings are: 2022 January 2022 plugins : - blog : archive_date_format : yyyy plugins : - blog : archive_date_format : MMMM yyyy archive_url_date_format Default: yyyy \u2013 This option specifies the date format that is used in the archive index URL. The format string must adhere to Babel 's pattern syntax . Some examples: blog/archive/2022/ blog/archive/2022/01/ plugins : - blog : archive_url_date_format : yyyy plugins : - blog : archive_url_date_format : yyyy/MM archive_url_format Default: archive/{date} \u2013 This option specifies the format string that is used for the URL of the archive index, and can be used to localize the URL: blog/archive/2022/ blog/2022/ plugins : - blog : archive_url_format : \"archive/{date}\" plugins : - blog : archive_url_format : \"{date}\" Categories \u00b6 The following configuration options are available for category index generation: categories Default: true \u2013 This option specifies whether the built-in blog plugin should generate category indexes. A category indexes shows all posts for a specific category in reverse chronological order. If you want to disable category index generation, add: plugins : - blog : categories : false categories_name Default: automatically set \u2013 This option specifies the title of the category section which the built-in blog plugin will generate and add to the navigation. If this setting is omitted, it's sourced from the translations, falling back to English. Change it with: plugins : - blog : categories_name : Categories categories_url_format Default: category/{slug} \u2013 This option specifies the format string that is used for the URL of the category index, and can be used to localize the URL: blog/category/ / blog/ / plugins : - blog : categories_url_format : \"category/{slug}\" plugins : - blog : categories_url_format : \"{slug}\" categories_slugify Default: headerid.slugify \u2013 This option specifies which function to use for generating URL-compatible slugs from categories. Python Markdown Extensions comes with several Unicode-aware slug functions which should be a good choice for non-ASCII languages: Unicode Unicode, case-sensitive plugins : - blog : categories_slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower plugins : - blog : categories_slugify : !!python/object/apply:pymdownx.slugs.slugify categories_slugify_separator Default: - \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string, including the empty string: plugins : - blog : categories_slugify_separator : \"-\" categories_allowed Default: none \u2013 This option specifies the categories that are allowed to be used in posts. If this setting is omitted, the built-in blog plugin will not check category names. Use this option to define a list of categories in order to catch typos: plugins : - blog : categories_allowed : - General - Search - Performance Pagination \u00b6 The following configuration options are available for index pagination: pagination Default: true \u2013 This option specifies whether the built-in blog plugin should paginate the index. The index shows all posts in reverse chronological order, which can be many. If you want to disable index pagination, add: plugins : - blog : pagination : false pagination_per_page Default: 10 \u2013 This option specifies the number of posts rendered on a single index page. If more posts are found, they are assigned to a 2 nd page, and so on. If you have large post excerpts , it might be a good idea to reduce the number of posts per page: plugins : - blog : pagination_per_page : 5 pagination_url_format Default: page/{page} \u2013 This option specifies the format string that is used for the URL of the paginated index, and can be used to localize the URL: blog/page/n/ blog/n/ plugins : - blog : pagination_url_format : \"page/{page}\" plugins : - blog : pagination_url_format : \"{page}\" pagination_template Default: ~2~ \u2013 This option specifies the format string that is provided to the paginate module, which allows to customize how pagination is constructed. Popular choices: 1 2 3 .. n 1 2 3 .. n 1 plugins : - blog : pagination_template : \"~2~\" plugins : - blog : pagination_template : \"$link_first $link_previous ~2~ $link_next $link_last\" plugins : - blog : pagination_template : \"$link_previous $page $link_next\" The paginate module exposes the following placeholders: $first_page \u2013 number of first reachable page $last_page \u2013 number of last reachable page $page \u2013 number of currently selected page $page_count \u2013 number of reachable pages $items_per_page \u2013 maximal number of items per page $first_item \u2013 index of first item on the current page $last_item \u2013 index of last item on the current page $item_count \u2013 total number of items $link_first \u2013 link to first page (unless this is first page) $link_last \u2013 link to last page (unless this is last page) $link_previous \u2013 link to previous page (unless this is first page) $link_next \u2013 link to next page (unless this is last page) pagination_keep_content Default: false \u2013 This option specifies whether paginated index pages should inherit the custom content from the index page, i.e. the content of blog/index.md : plugins : - blog : pagination_keep_content : true Authors \u00b6 The following configuration options are available for author info: authors Default: true \u2013 This option specifies whether the built-in blog plugin should generate author info. If it is enabled, the plugin will look up authors in a file called .authors.yml and include authors in indexes and in posts. If you want to disable this behavior, add: plugins : - blog : authors : false authors_file Default: .authors.yml \u2013 This option specifies the name of the file where the authors for your posts resides. The default settings assumes that the file is called .authors.yml (mind the . at the beginning): plugins : - blog : authors_file : .authors.yml The path must be defined relative to blog_dir . Also see the section on adding authors . Drafts \u00b6 The following configuration options are available for drafts: draft Default: false \u2013 This option specifies whether the built-in blog plugin should also include posts marked as drafts when the site is being built. Including draft posts might be desired in deploy previews, which is why it exists in the first place: Render drafts Don't render drafts plugins : - blog : draft : true plugins : - blog : draft : false draft_on_serve Default: true \u2013 This option specifies whether posts marked as drafts should be included when previewing your site with mkdocs serve . By default, drafts are rendered when previewing, but skipped when the site is being built: plugins : - blog : draft_on_serve : true draft_if_future_date Default: false \u2013 This option specifies whether the built-in blog plugin should mark posts with a future date as drafts. When the date passed today, the post is automatically unmarked and included when the site is being built: plugins : - blog : draft_if_future_date : true RSS \u00b6 Sponsors only \u00b7 insiders-4.23.0 \u00b7 Plugin The built-in blog plugin integrates seamlessly with the RSS plugin , which provides a simple way to add an RSS feed to your blog (or to your whole documentation). Install it with pip : pip install mkdocs-rss-plugin Then, add the following lines to mkdocs.yml : plugins : - rss : match_path : blog/posts/.* # (1)! date_from_meta : as_creation : date categories : - categories - tags # (2)! The RSS plugin allows to filter for URLs to be included in the feed. In this example, only blog posts will be part of the feed. If you want to include a post's categories as well as its tags in the feed, add both categories and tags here. The following configuration options are supported: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable : plugins : - rss : enabled : !ENV [ CI , false ] match_path Default: .* \u2013 This option specifies which pages should be included in the feed. For example, to only include blog posts in the feed, use the following regular expression: plugins : - rss : match_path : blog/posts/.* date_from_meta Default: none \u2013 This option specifies which front matter property should be used as a creation date of a page in the feed. It's recommended to use the date property: plugins : - rss : date_from_meta : as_creation : date categories Default: none \u2013 This option specifies which front matter properties are used as categories as part of the feed. If you use categories and tags , add both with the following lines: plugins : - rss : categories : - categories - tags comments_path Default: none \u2013 This option specifies the anchor at which comments for a post or page can be found. If you've integrated a comment system , add the following lines: plugins : - rss : comments_path : \"#__comments\" Material for MkDocs will automatically add the necessary metadata to your site which will make the RSS feed discoverable by browsers and feed readers. Note that the RSS plugin comes with several other configuration options. For further information, see the documentation . Usage \u00b6 Writing your first post \u00b6 After you've successfully set up the built-in blog plugin , it's time to write your first post. The plugin doesn't assume any specific directory structure, so you're completely free in how you organize your posts, as long as they are all located inside the posts directory: . \u251c\u2500 docs/ \u2502 \u2514\u2500 blog/ \u2502 \u251c\u2500 posts/ \u2502 \u2502 \u2514\u2500 hello-world.md # (1)! \u2502 \u2514\u2500 index.md \u2514\u2500 mkdocs.yml If you'd like to arrange posts differently, you're free to do so. The URLs are built from the format specified in post_url_format and the titles and dates of posts, no matter how they are organized inside the posts directory. Create a new file called hello-world.md and add the following lines: --- draft : true # (1)! date : 2022-01-31 categories : - Hello - World --- # Hello world! ... If you mark a post as a draft , a red marker appears next to the post date on index pages. When the site is built, drafts are not included in the output. This behavior can be changed , e.g. for rendering drafts when building deploy previews. When you spin up the live preview server , you should be greeted by your first post! You'll also realize, that archive and category indexes have been automatically generated for you. Adding an excerpt \u00b6 The blog index, as well as archive and category indexes can either list the entire content of each post, or excerpts of posts. An excerpt can be created by adding a <!-- more --> separator after the first few paragraphs of a post: # Hello world! Lorem ipsum dolor sit amet , consectetur adipiscing elit . Nulla et euismod nulla . Curabitur feugiat , tortor non consequat finibus , justo purus auctor massa , nec semper lorem quam in massa . < ! -- more --> ... When the built-in blog plugin generates all indexes, the content before the excerpt separator is automatically extracted, allowing the user to start reading a post before deciding to jump in. Adding authors \u00b6 In order to add a little more personality to your posts, you can associate each post with one or multiple authors . First, create the .authors.yml file in your blog directory, and add an author: squidfunk : name : Martin Donath description : Creator avatar : https://github.com/squidfunk.png The .authors.yml file associates each author with an identifier (in this example squidfunk ), which can then be used in posts. The following properties are available for each author: name Default: none \u00b7 Required \u2013 This property must define a name for the author. The name is displayed in the left sidebar of each post as part of the author info. description Default: none \u00b7 Required \u2013 This property can be used to add a short description for the author, e.g. the role or profession of the author, or any other title. avatar Default: none \u00b7 Required \u2013 This property must point to a valid image URL, internal or external, and is used as part of posts and excerpts as the author's avatar. Now, you can assign one or more authors to a post by referencing their identifiers in the front matter of the Markdown file under the authors property. For each author, a small profile is rendered in the left sidebar of each post, as well as in post excerpts on index pages: --- date : 2022-01-31 authors : - squidfunk ... --- # Hello world! ... Adding categories \u00b6 Categories are an excellent way for grouping your posts thematically on dedicated index pages. This way, a user interested in a specific topic can explore all of your posts on this topic. Make sure categories are enabled and add them to the front matter categories property: --- date : 2022-01-31 categories : - Hello - World --- # Hello world! ... If you want to save yourself from typos when typing out categories, you can define your desired categories in mkdocs.yml as part of the categories_allowed configuration option. The built-in blog plugin will stop the build if a category is not found within the list. Adding tags \u00b6 Besides categories , the built-in blog plugin also integrates with the built-in tags plugin . If you add tags in the front matter tags property as part of a post, the post is linked from the tags index : --- date : 2022-01-31 tags : - Foo - Bar --- # Hello world! ... As usual, the tags are rendered above the main headline and posts are linked on the tags index page, if configured. Note that posts are, as pages, only linked with their titles. Adding related links \u00b6 Related links offer the perfect way to prominently add a further reading section to your post that is included in the left sidebar, guiding the user to other destinations of your documentation. Use the front matter links property to add related links to a post: --- date : 2022-01-31 links : - setup/setting-up-site-search.md#built-in-search-plugin - insiders/index.md#how-to-become-a-sponsor --- # Hello world! ... You can use the exact same syntax as for the nav section in mkdocs.yml , which means you can set explicit titles for links, add external links and even use nesting: --- date : 2022-01-31 links : - setup/setting-up-site-search.md#built-in-search-plugin - insiders/index.md#how-to-become-a-sponsor - Nested section : - External link : https://example.com - setup/setting-up-site-search.md --- # Hello world! ... If you look closely, you'll realize that you can even use an anchor to link to a specific section of a document, extending the possiblities of the nav syntax in mkdocs.yml . The built-in blog plugin resolves the anchor and sets the title of the anchor as a subtitle of the related link. Note that all links must be relative to docs_dir , as is also the case for the nav setting. Linking from and to posts \u00b6 While post URLs are dynamically computed, the built-in blog plugin ensures that all links from and to posts and a post's assets are correct. If you want to link to a post, just use the path to the Markdown file as a link reference (links must be relative): [ Hello World! ]( blog/posts/hello-world.md ) Linking from a post to a page, e.g. the index, follows the same method: [ Blog ]( ../index.md ) All assets inside the posts directory are copied to the blog/assets folder when the site is being built. Of course, you can also reference assets from posts outside of the posts directory. The built-in blog plugin ensures that all links are correct. Setting the reading time \u00b6 When enabled , the readtime package is used to compute the expected reading time of each post, which is rendered as part of the post and post excerpt. Nowadays, many blogs show reading times, which is why the built-in blog plugin offers this capability as well. Sometimes, however, the computed reading time might not feel accurate, or result in odd and unpleasant numbers. For this reason, reading time can be overridden and explicitly set with the front matter readtime property for a post: --- date : 2022-01-31 readtime : 15 --- # Hello world! ... This will disable automatic reading time computation. Setting defaults \u00b6 If you have a lot of posts, it might feel redundant to define all of the above for each post. Luckily, the built-in meta plugin allows to set default front matter properties per folder. You can group your posts by categories, or authors, and add a .meta.yml file to set common properties: . \u251c\u2500 docs/ \u2502 \u2514\u2500 blog/ \u2502 \u251c\u2500 posts/ \u2502 \u251c\u2500 .meta.yml # (1)! \u2502 \u2514\u2500 index.md \u2514\u2500 mkdocs.yml As already noted, you can also place a .meta.yml file in nested folders of the posts directory. This file then can define all front matter properties that are valid in posts, e.g.: authors : - squidfunk categories : - Hello - World Note that order matters \u2013 the built-in meta plugin must be defined before the blog plugin in mkdocs.yml , so that all set defaults are correctly picked up by the built-in blog plugin : plugins : - meta - blog Lists and dictionaries in .meta.yml files are merged and deduplicated with the values defined for a post, which means you can define common properties in .meta.yml and then add specific properties or overrides for each post. Adding pages \u00b6 Besides posts, it's also possible to add static pages to your blog by listing the pages in the nav section of mkdocs.yml . All generated indexes are included after the last specified page. For example, to add a page on the authors of the blog, add the following to mkdocs.yml : nav : - Blog : - blog/index.md - blog/authors.md ... Customization \u00b6 Custom index pages \u00b6 insiders-4.24.0 \u00b7 Experimental If you want to add custom content to automatically generated archive and category indexes, e.g. to add a category description prior to the list of posts, you can manually create the category page in the same location where the built-in blog plugin would create it: . \u251c\u2500 docs/ \u2502 \u2514\u2500 blog/ \u2502 \u251c\u2500 category/ \u2502 \u2502 \u2514\u2500 hello.md #(1)! \u2502 \u251c\u2500 posts/ \u2502 \u2514\u2500 index.md \u2514\u2500 mkdocs.yml The easiest way is to first add the category to the blog post, then take the URL generated by the built-in blog plugin and create the file at the corresponding location in the blog_dir folder. Note that the shown directory listing is based on the default configuration. If you specify different values for the following options, be sure to adjust the path accordingly: blog_dir categories_url_format categories_slugify You can now add arbitrary content to the newly created file, or set specific front matter properties for this page, e.g. to change the page description : --- description : Nullam urna elit, malesuada eget finibus ut, ac tortor. --- # Hello ... All post excerpts belonging to the category are automatically appended. Overriding templates \u00b6 The built-in blog plugin is built on the same basis as Material for MkDocs, which means you can override all templates used for the blog by using theme extension as usual. The following templates are added by the built-in blog plugin : blog.html \u2013 Template for blog index blog-post.html \u2013 Template for blog post blog-archive.html \u2013 Template for blog archive index blog-category.html \u2013 Template for blog category index","title":"Setting up a blog"},{"location":"setup/setting-up-a-blog/#setting-up-a-blog","text":"Material for MkDocs makes it very easy to build a blog, either as a sidecar to your documentation or standalone. Focus on your content while the engine does all the heavy lifting, automatically generating archive and category indexes, post slugs , configurable pagination and more. Check out our blog , which is created with the new built-in blog plugin !","title":"Setting up a blog"},{"location":"setup/setting-up-a-blog/#configuration","text":"","title":"Configuration"},{"location":"setup/setting-up-a-blog/#built-in-blog-plugin","text":"Sponsors only \u00b7 insiders-4.23.0 \u00b7 Plugin \u00b7 Experimental The built-in blog plugin adds support for building a blog from a folder of posts, which are annotated with dates and other structured data. First, add the following lines to mkdocs.yml : plugins : - blog If you need to be able to build your documentation with and without Insiders , please refer to the built-in plugins section to learn how shared configurations help to achieve this. By default, the built-in blog plugin assumes that your blog is hosted inside the blog subfolder of your documentation ( this is configurable ). Next, you need to create the following structure: . \u251c\u2500 docs/ \u2502 \u2514\u2500 blog/ \u2502 \u251c\u2500 posts/ \u2502 \u2514\u2500 index.md \u2514\u2500 mkdocs.yml Since the built-in blog plugin auto-generates archive and category indexes, it must know where to add those to the navigation. Thus, make sure to add a blog/index.md file in mkdocs.yml : nav : - Blog : - blog/index.md # (1)! Within this file, you can specify the title of your blog, which is then picked up and used by the built-in blog plugin: # Blog The following configuration options are available: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable : plugins : - blog : enabled : !ENV [ CI , false ] blog_dir Default: blog \u2013 This option specifies the folder where your posts and metadata live. The name of the folder will also be included in the generated URLs as a prefix to all blog-related pages. If you want to build a standalone blog, change it to . : Subdirectory Standalone plugins : - blog : blog_dir : path/to/folder plugins : - blog : blog_dir : . The path must be defined relative to docs_dir . The built-in blog plugin has dozens of options that allow for advanced configuration. It's a good idea to start writing your first post , and come back here later for fine-tuning the output.","title":"Built-in blog plugin"},{"location":"setup/setting-up-a-blog/#posts","text":"The following configuration options are available for posts: post_date_format Default: long \u2013 This option specifies the date format that is used when posts are rendered. Under the hood, the built-in blog plugin leverages Babel to render dates locale-aware using the configured site language . The following formats are supported: Monday, January 31, 2022 January 31, 2022 Jan 31, 2022 1/31/22 plugins : - blog : post_date_format : full plugins : - blog : post_date_format : long plugins : - blog : post_date_format : medium plugins : - blog : post_date_format : short Note that depending on the site language , formats might look different for other languages. Additionally, Babel supports a pattern syntax which allows for custom formats. post_url_date_format Default: yyyy/MM/dd \u2013 This option specifies the date format that is used in the URL of the post. The format string must adhere to Babel 's pattern syntax . Some examples: blog/2022/01/31/ / blog/2022/01/ / blog/2022/ / plugins : - blog : post_url_date_format : yyyy/MM/dd plugins : - blog : post_url_date_format : yyyy/MM plugins : - blog : post_url_date_format : yyyy If you want to exclude the date altogether, e.g. when your blog features mostly evergreen content, you can remove the date placeholder from the format string (see below). post_url_format Default: {date}/{slug} \u2013 This option specifies the format string that is used for the URL of the post. The following placeholders are currently supported: date \u2013 Replaced with the post's date, as configured in post_url_date_format . slug \u2013 Replaced with a slug generated from the post's title. file \u2013 Replaced with the post's file name. blog/2022/ / blog/ / plugins : - blog : post_url_format : \"{date}/{slug}\" plugins : - blog : post_url_format : \"{slug}\" If you remove the date placeholder, make sure that post URLs don't collide with other the URLs of other pages added to the blog section, as this leads to undefined behavior. post_slugify Default: headerid.slugify \u2013 This option specifies which function to use for generating URL-compatible slugs from post titles. Python Markdown Extensions comes with several Unicode-aware slug functions which should be a good choice for non-ASCII languages: Unicode Unicode, case-sensitive plugins : - blog : post_slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower plugins : - blog : post_slugify : !!python/object/apply:pymdownx.slugs.slugify post_slugify_separator Default: - \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string, including the empty string: plugins : - blog : post_slugify_separator : \"-\" post_excerpt Default: optional \u2013 This option specifies whether post excerpts should be considered being optional or required by the built-in blog plugin when generating indexes. If excerpts are required, the plugin terminates with an error if a post doesn't define an excerpt: Optional Required plugins : - blog : post_excerpt : optional plugins : - blog : post_excerpt : required post_excerpt_max_authors Default: 1 \u2013 This option specifies the number of authors rendered in post excerpts. While each post may be written by multiple authors, this setting allows to limit the display to just a few or even a single author, or disable authors in excerpts altogether: Render up to 2 authors in excerpts Disable authors in excerpts plugins : - blog : post_excerpt_max_authors : 2 plugins : - blog : post_excerpt_max_authors : 0 post_excerpt_max_categories Default: 5 \u2013 This option specifies the number of categories rendered in post excerpts. While each post may be assigned to multiple categories, the built-in blog plugin can be instructed to only show the first n categories to keep it short and concise: Render up to 2 categories in excerpts Disable categories in excerpts plugins : - blog : post_excerpt_max_categories : 2 plugins : - blog : post_excerpt_max_categories : 0 post_excerpt_separator Default: <!-- more --> \u2013 This option specifies the separator the built-in blog plugin will look for in a post's content when generating post excerpts . All content after the separator is not considered to be part of the excerpt. post_readtime Default: true \u2013 This option specifies whether the built-in blog plugin should compute the reading time of a post automatically, which is then rendered in post excerpts, as well as in the posts themselves. If you want to disable reading time computation, add: plugins : - blog : post_readtime : false post_readtime_words_per_minute Default: 265 \u2013 This option specifies the number of words that a reader is expected to read per minute when computing the reading time of a post. If you feel that estimation is not quite right, you can fine-tune reading time computation with the following setting: plugins : - blog : post_readtime_words_per_minute : 265","title":"Posts"},{"location":"setup/setting-up-a-blog/#archive","text":"The following configuration options are available for archive index generation: archive Default: true \u2013 This option specifies whether the built-in blog plugin should generate archive indexes. An archive indexes shows all posts for a specific interval (e.g. year, month, etc.) in reverse chronological order. If you want to disable archive index generation, add: plugins : - blog : archive : false archive_name Default: automatically set \u2013 This option specifies the title of the archive section which the built-in blog plugin will generate and add to the navigation. If this setting is omitted, it's sourced from the translations, falling back to English. Change it with: plugins : - blog : archive_name : Archive archive_date_format Default: yyyy \u2013 This option specifies the date format that is used when archive indexes are rendered. The format string must adhere to Babel 's pattern syntax . Popular settings are: 2022 January 2022 plugins : - blog : archive_date_format : yyyy plugins : - blog : archive_date_format : MMMM yyyy archive_url_date_format Default: yyyy \u2013 This option specifies the date format that is used in the archive index URL. The format string must adhere to Babel 's pattern syntax . Some examples: blog/archive/2022/ blog/archive/2022/01/ plugins : - blog : archive_url_date_format : yyyy plugins : - blog : archive_url_date_format : yyyy/MM archive_url_format Default: archive/{date} \u2013 This option specifies the format string that is used for the URL of the archive index, and can be used to localize the URL: blog/archive/2022/ blog/2022/ plugins : - blog : archive_url_format : \"archive/{date}\" plugins : - blog : archive_url_format : \"{date}\"","title":"Archive"},{"location":"setup/setting-up-a-blog/#categories","text":"The following configuration options are available for category index generation: categories Default: true \u2013 This option specifies whether the built-in blog plugin should generate category indexes. A category indexes shows all posts for a specific category in reverse chronological order. If you want to disable category index generation, add: plugins : - blog : categories : false categories_name Default: automatically set \u2013 This option specifies the title of the category section which the built-in blog plugin will generate and add to the navigation. If this setting is omitted, it's sourced from the translations, falling back to English. Change it with: plugins : - blog : categories_name : Categories categories_url_format Default: category/{slug} \u2013 This option specifies the format string that is used for the URL of the category index, and can be used to localize the URL: blog/category/ / blog/ / plugins : - blog : categories_url_format : \"category/{slug}\" plugins : - blog : categories_url_format : \"{slug}\" categories_slugify Default: headerid.slugify \u2013 This option specifies which function to use for generating URL-compatible slugs from categories. Python Markdown Extensions comes with several Unicode-aware slug functions which should be a good choice for non-ASCII languages: Unicode Unicode, case-sensitive plugins : - blog : categories_slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower plugins : - blog : categories_slugify : !!python/object/apply:pymdownx.slugs.slugify categories_slugify_separator Default: - \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string, including the empty string: plugins : - blog : categories_slugify_separator : \"-\" categories_allowed Default: none \u2013 This option specifies the categories that are allowed to be used in posts. If this setting is omitted, the built-in blog plugin will not check category names. Use this option to define a list of categories in order to catch typos: plugins : - blog : categories_allowed : - General - Search - Performance","title":"Categories"},{"location":"setup/setting-up-a-blog/#pagination","text":"The following configuration options are available for index pagination: pagination Default: true \u2013 This option specifies whether the built-in blog plugin should paginate the index. The index shows all posts in reverse chronological order, which can be many. If you want to disable index pagination, add: plugins : - blog : pagination : false pagination_per_page Default: 10 \u2013 This option specifies the number of posts rendered on a single index page. If more posts are found, they are assigned to a 2 nd page, and so on. If you have large post excerpts , it might be a good idea to reduce the number of posts per page: plugins : - blog : pagination_per_page : 5 pagination_url_format Default: page/{page} \u2013 This option specifies the format string that is used for the URL of the paginated index, and can be used to localize the URL: blog/page/n/ blog/n/ plugins : - blog : pagination_url_format : \"page/{page}\" plugins : - blog : pagination_url_format : \"{page}\" pagination_template Default: ~2~ \u2013 This option specifies the format string that is provided to the paginate module, which allows to customize how pagination is constructed. Popular choices: 1 2 3 .. n 1 2 3 .. n 1 plugins : - blog : pagination_template : \"~2~\" plugins : - blog : pagination_template : \"$link_first $link_previous ~2~ $link_next $link_last\" plugins : - blog : pagination_template : \"$link_previous $page $link_next\" The paginate module exposes the following placeholders: $first_page \u2013 number of first reachable page $last_page \u2013 number of last reachable page $page \u2013 number of currently selected page $page_count \u2013 number of reachable pages $items_per_page \u2013 maximal number of items per page $first_item \u2013 index of first item on the current page $last_item \u2013 index of last item on the current page $item_count \u2013 total number of items $link_first \u2013 link to first page (unless this is first page) $link_last \u2013 link to last page (unless this is last page) $link_previous \u2013 link to previous page (unless this is first page) $link_next \u2013 link to next page (unless this is last page) pagination_keep_content Default: false \u2013 This option specifies whether paginated index pages should inherit the custom content from the index page, i.e. the content of blog/index.md : plugins : - blog : pagination_keep_content : true","title":"Pagination"},{"location":"setup/setting-up-a-blog/#authors","text":"The following configuration options are available for author info: authors Default: true \u2013 This option specifies whether the built-in blog plugin should generate author info. If it is enabled, the plugin will look up authors in a file called .authors.yml and include authors in indexes and in posts. If you want to disable this behavior, add: plugins : - blog : authors : false authors_file Default: .authors.yml \u2013 This option specifies the name of the file where the authors for your posts resides. The default settings assumes that the file is called .authors.yml (mind the . at the beginning): plugins : - blog : authors_file : .authors.yml The path must be defined relative to blog_dir . Also see the section on adding authors .","title":"Authors"},{"location":"setup/setting-up-a-blog/#drafts","text":"The following configuration options are available for drafts: draft Default: false \u2013 This option specifies whether the built-in blog plugin should also include posts marked as drafts when the site is being built. Including draft posts might be desired in deploy previews, which is why it exists in the first place: Render drafts Don't render drafts plugins : - blog : draft : true plugins : - blog : draft : false draft_on_serve Default: true \u2013 This option specifies whether posts marked as drafts should be included when previewing your site with mkdocs serve . By default, drafts are rendered when previewing, but skipped when the site is being built: plugins : - blog : draft_on_serve : true draft_if_future_date Default: false \u2013 This option specifies whether the built-in blog plugin should mark posts with a future date as drafts. When the date passed today, the post is automatically unmarked and included when the site is being built: plugins : - blog : draft_if_future_date : true","title":"Drafts"},{"location":"setup/setting-up-a-blog/#rss","text":"Sponsors only \u00b7 insiders-4.23.0 \u00b7 Plugin The built-in blog plugin integrates seamlessly with the RSS plugin , which provides a simple way to add an RSS feed to your blog (or to your whole documentation). Install it with pip : pip install mkdocs-rss-plugin Then, add the following lines to mkdocs.yml : plugins : - rss : match_path : blog/posts/.* # (1)! date_from_meta : as_creation : date categories : - categories - tags # (2)! The RSS plugin allows to filter for URLs to be included in the feed. In this example, only blog posts will be part of the feed. If you want to include a post's categories as well as its tags in the feed, add both categories and tags here. The following configuration options are supported: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable : plugins : - rss : enabled : !ENV [ CI , false ] match_path Default: .* \u2013 This option specifies which pages should be included in the feed. For example, to only include blog posts in the feed, use the following regular expression: plugins : - rss : match_path : blog/posts/.* date_from_meta Default: none \u2013 This option specifies which front matter property should be used as a creation date of a page in the feed. It's recommended to use the date property: plugins : - rss : date_from_meta : as_creation : date categories Default: none \u2013 This option specifies which front matter properties are used as categories as part of the feed. If you use categories and tags , add both with the following lines: plugins : - rss : categories : - categories - tags comments_path Default: none \u2013 This option specifies the anchor at which comments for a post or page can be found. If you've integrated a comment system , add the following lines: plugins : - rss : comments_path : \"#__comments\" Material for MkDocs will automatically add the necessary metadata to your site which will make the RSS feed discoverable by browsers and feed readers. Note that the RSS plugin comes with several other configuration options. For further information, see the documentation .","title":"RSS"},{"location":"setup/setting-up-a-blog/#usage","text":"","title":"Usage"},{"location":"setup/setting-up-a-blog/#writing-your-first-post","text":"After you've successfully set up the built-in blog plugin , it's time to write your first post. The plugin doesn't assume any specific directory structure, so you're completely free in how you organize your posts, as long as they are all located inside the posts directory: . \u251c\u2500 docs/ \u2502 \u2514\u2500 blog/ \u2502 \u251c\u2500 posts/ \u2502 \u2502 \u2514\u2500 hello-world.md # (1)! \u2502 \u2514\u2500 index.md \u2514\u2500 mkdocs.yml If you'd like to arrange posts differently, you're free to do so. The URLs are built from the format specified in post_url_format and the titles and dates of posts, no matter how they are organized inside the posts directory. Create a new file called hello-world.md and add the following lines: --- draft : true # (1)! date : 2022-01-31 categories : - Hello - World --- # Hello world! ... If you mark a post as a draft , a red marker appears next to the post date on index pages. When the site is built, drafts are not included in the output. This behavior can be changed , e.g. for rendering drafts when building deploy previews. When you spin up the live preview server , you should be greeted by your first post! You'll also realize, that archive and category indexes have been automatically generated for you.","title":"Writing your first post"},{"location":"setup/setting-up-a-blog/#adding-an-excerpt","text":"The blog index, as well as archive and category indexes can either list the entire content of each post, or excerpts of posts. An excerpt can be created by adding a <!-- more --> separator after the first few paragraphs of a post: # Hello world! Lorem ipsum dolor sit amet , consectetur adipiscing elit . Nulla et euismod nulla . Curabitur feugiat , tortor non consequat finibus , justo purus auctor massa , nec semper lorem quam in massa . < ! -- more --> ... When the built-in blog plugin generates all indexes, the content before the excerpt separator is automatically extracted, allowing the user to start reading a post before deciding to jump in.","title":"Adding an excerpt"},{"location":"setup/setting-up-a-blog/#adding-authors","text":"In order to add a little more personality to your posts, you can associate each post with one or multiple authors . First, create the .authors.yml file in your blog directory, and add an author: squidfunk : name : Martin Donath description : Creator avatar : https://github.com/squidfunk.png The .authors.yml file associates each author with an identifier (in this example squidfunk ), which can then be used in posts. The following properties are available for each author: name Default: none \u00b7 Required \u2013 This property must define a name for the author. The name is displayed in the left sidebar of each post as part of the author info. description Default: none \u00b7 Required \u2013 This property can be used to add a short description for the author, e.g. the role or profession of the author, or any other title. avatar Default: none \u00b7 Required \u2013 This property must point to a valid image URL, internal or external, and is used as part of posts and excerpts as the author's avatar. Now, you can assign one or more authors to a post by referencing their identifiers in the front matter of the Markdown file under the authors property. For each author, a small profile is rendered in the left sidebar of each post, as well as in post excerpts on index pages: --- date : 2022-01-31 authors : - squidfunk ... --- # Hello world! ...","title":"Adding authors"},{"location":"setup/setting-up-a-blog/#adding-categories","text":"Categories are an excellent way for grouping your posts thematically on dedicated index pages. This way, a user interested in a specific topic can explore all of your posts on this topic. Make sure categories are enabled and add them to the front matter categories property: --- date : 2022-01-31 categories : - Hello - World --- # Hello world! ... If you want to save yourself from typos when typing out categories, you can define your desired categories in mkdocs.yml as part of the categories_allowed configuration option. The built-in blog plugin will stop the build if a category is not found within the list.","title":"Adding categories"},{"location":"setup/setting-up-a-blog/#adding-tags","text":"Besides categories , the built-in blog plugin also integrates with the built-in tags plugin . If you add tags in the front matter tags property as part of a post, the post is linked from the tags index : --- date : 2022-01-31 tags : - Foo - Bar --- # Hello world! ... As usual, the tags are rendered above the main headline and posts are linked on the tags index page, if configured. Note that posts are, as pages, only linked with their titles.","title":"Adding tags"},{"location":"setup/setting-up-a-blog/#adding-related-links","text":"Related links offer the perfect way to prominently add a further reading section to your post that is included in the left sidebar, guiding the user to other destinations of your documentation. Use the front matter links property to add related links to a post: --- date : 2022-01-31 links : - setup/setting-up-site-search.md#built-in-search-plugin - insiders/index.md#how-to-become-a-sponsor --- # Hello world! ... You can use the exact same syntax as for the nav section in mkdocs.yml , which means you can set explicit titles for links, add external links and even use nesting: --- date : 2022-01-31 links : - setup/setting-up-site-search.md#built-in-search-plugin - insiders/index.md#how-to-become-a-sponsor - Nested section : - External link : https://example.com - setup/setting-up-site-search.md --- # Hello world! ... If you look closely, you'll realize that you can even use an anchor to link to a specific section of a document, extending the possiblities of the nav syntax in mkdocs.yml . The built-in blog plugin resolves the anchor and sets the title of the anchor as a subtitle of the related link. Note that all links must be relative to docs_dir , as is also the case for the nav setting.","title":"Adding related links"},{"location":"setup/setting-up-a-blog/#linking-from-and-to-posts","text":"While post URLs are dynamically computed, the built-in blog plugin ensures that all links from and to posts and a post's assets are correct. If you want to link to a post, just use the path to the Markdown file as a link reference (links must be relative): [ Hello World! ]( blog/posts/hello-world.md ) Linking from a post to a page, e.g. the index, follows the same method: [ Blog ]( ../index.md ) All assets inside the posts directory are copied to the blog/assets folder when the site is being built. Of course, you can also reference assets from posts outside of the posts directory. The built-in blog plugin ensures that all links are correct.","title":"Linking from and to posts"},{"location":"setup/setting-up-a-blog/#setting-the-reading-time","text":"When enabled , the readtime package is used to compute the expected reading time of each post, which is rendered as part of the post and post excerpt. Nowadays, many blogs show reading times, which is why the built-in blog plugin offers this capability as well. Sometimes, however, the computed reading time might not feel accurate, or result in odd and unpleasant numbers. For this reason, reading time can be overridden and explicitly set with the front matter readtime property for a post: --- date : 2022-01-31 readtime : 15 --- # Hello world! ... This will disable automatic reading time computation.","title":"Setting the reading time"},{"location":"setup/setting-up-a-blog/#setting-defaults","text":"If you have a lot of posts, it might feel redundant to define all of the above for each post. Luckily, the built-in meta plugin allows to set default front matter properties per folder. You can group your posts by categories, or authors, and add a .meta.yml file to set common properties: . \u251c\u2500 docs/ \u2502 \u2514\u2500 blog/ \u2502 \u251c\u2500 posts/ \u2502 \u251c\u2500 .meta.yml # (1)! \u2502 \u2514\u2500 index.md \u2514\u2500 mkdocs.yml As already noted, you can also place a .meta.yml file in nested folders of the posts directory. This file then can define all front matter properties that are valid in posts, e.g.: authors : - squidfunk categories : - Hello - World Note that order matters \u2013 the built-in meta plugin must be defined before the blog plugin in mkdocs.yml , so that all set defaults are correctly picked up by the built-in blog plugin : plugins : - meta - blog Lists and dictionaries in .meta.yml files are merged and deduplicated with the values defined for a post, which means you can define common properties in .meta.yml and then add specific properties or overrides for each post.","title":"Setting defaults"},{"location":"setup/setting-up-a-blog/#adding-pages","text":"Besides posts, it's also possible to add static pages to your blog by listing the pages in the nav section of mkdocs.yml . All generated indexes are included after the last specified page. For example, to add a page on the authors of the blog, add the following to mkdocs.yml : nav : - Blog : - blog/index.md - blog/authors.md ...","title":"Adding pages"},{"location":"setup/setting-up-a-blog/#customization","text":"","title":"Customization"},{"location":"setup/setting-up-a-blog/#custom-index-pages","text":"insiders-4.24.0 \u00b7 Experimental If you want to add custom content to automatically generated archive and category indexes, e.g. to add a category description prior to the list of posts, you can manually create the category page in the same location where the built-in blog plugin would create it: . \u251c\u2500 docs/ \u2502 \u2514\u2500 blog/ \u2502 \u251c\u2500 category/ \u2502 \u2502 \u2514\u2500 hello.md #(1)! \u2502 \u251c\u2500 posts/ \u2502 \u2514\u2500 index.md \u2514\u2500 mkdocs.yml The easiest way is to first add the category to the blog post, then take the URL generated by the built-in blog plugin and create the file at the corresponding location in the blog_dir folder. Note that the shown directory listing is based on the default configuration. If you specify different values for the following options, be sure to adjust the path accordingly: blog_dir categories_url_format categories_slugify You can now add arbitrary content to the newly created file, or set specific front matter properties for this page, e.g. to change the page description : --- description : Nullam urna elit, malesuada eget finibus ut, ac tortor. --- # Hello ... All post excerpts belonging to the category are automatically appended.","title":"Custom index pages"},{"location":"setup/setting-up-a-blog/#overriding-templates","text":"The built-in blog plugin is built on the same basis as Material for MkDocs, which means you can override all templates used for the blog by using theme extension as usual. The following templates are added by the built-in blog plugin : blog.html \u2013 Template for blog index blog-post.html \u2013 Template for blog post blog-archive.html \u2013 Template for blog archive index blog-category.html \u2013 Template for blog category index","title":"Overriding templates"},{"location":"setup/setting-up-navigation/","text":"Setting up navigation \u00b6 A clear and concise navigation structure is an important aspect of good project documentation. Material for MkDocs provides a multitude of options to configure the behavior of navigational elements, including tabs and sections , and one of its flag-ship feature: instant loading . Configuration \u00b6 Instant loading \u00b6 5.0.0 \u00b7 Feature flag When instant loading is enabled, clicks on all internal links will be intercepted and dispatched via XHR without fully reloading the page. Add the following lines to mkdocs.yml : theme : features : - navigation.instant The resulting page is parsed and injected and all event handlers and components are rebound automatically, i.e., Material for MkDocs now behaves like a Single Page Application . Now, the search index survives navigation, which is especially useful for large documentation sites. Anchor tracking \u00b6 8.0.0 \u00b7 Feature flag \u00b7 Experimental When anchor tracking is enabled, the URL in the address bar is automatically updated with the active anchor as highlighted in the table of contents. Add the following lines to mkdocs.yml : theme : features : - navigation.tracking Navigation tabs \u00b6 1.1.0 \u00b7 Feature flag When tabs are enabled, top-level sections are rendered in a menu layer below the header for viewports above 1220px , but remain as-is on mobile. 1 Add the following lines to mkdocs.yml : theme : features : - navigation.tabs With tabs Without Sticky navigation tabs \u00b6 7.3.0 \u00b7 Feature flag When sticky tabs are enabled, navigation tabs will lock below the header and always remain visible when scrolling down. Just add the following two feature flags to mkdocs.yml : theme : features : - navigation.tabs - navigation.tabs.sticky With sticky tabs Without Navigation sections \u00b6 6.2.0 \u00b7 Feature flag When sections are enabled, top-level sections are rendered as groups in the sidebar for viewports above 1220px , but remain as-is on mobile. Add the following lines to mkdocs.yml : theme : features : - navigation.sections With sections Without Both feature flags, navigation.tabs and navigation.sections , can be combined with each other. If both feature flags are enabled, sections are rendered for level 2 navigation items. Navigation expansion \u00b6 6.2.0 \u00b7 Feature flag When expansion is enabled, the left sidebar will expand all collapsible subsections by default, so the user doesn't have to open subsections manually. Add the following lines to mkdocs.yml : theme : features : - navigation.expand With expansion Without Navigation pruning \u00b6 Sponsors only \u00b7 insiders-4.16.0 \u00b7 Experimental When pruning is enabled, only the visible navigation items are included in the rendered HTML, reducing the size of the built site by 33% or more . Add the following lines to mkdocs.yml : theme : features : - navigation.prune # (1)! This feature flag is not compatible with navigation.expand , as navigation expansion requires the complete navigation structure. This feature flag is especially useful for documentation sites with 100+ or even 1,000+ of pages, as the navigation makes up a significant fraction of the HTML. Navigation pruning will replace all expandable sections with links to the first page in that section (or the section index page). Section index pages \u00b6 7.3.0 \u00b7 Feature flag When section index pages are enabled, documents can be directly attached to sections, which is particularly useful for providing overview pages. Add the following lines to mkdocs.yml : theme : features : - navigation.indexes # (1)! This feature flag is not compatible with toc.integrate , as sections cannot host the table of contents due to missing space. With section index pages Without In order to link a page to a section, create a new document with the name index.md in the respective folder, and add it to the beginning of your navigation section: nav : - Section : - section/index.md - Page 1 : section/page-1.md ... - Page n : section/page-n.md Table of contents \u00b6 Anchor following \u00b6 8.5.0 \u00b7 Experimental When anchor following for the table of contents is enabled, the sidebar is automatically scrolled so that the active anchor is always visible. Add the following lines to mkdocs.yml : theme : features : - toc.follow Navigation integration \u00b6 6.2.0 \u00b7 Feature flag When navigation integration for the table of contents is enabled, it is always rendered as part of the navigation sidebar on the left. Add the following lines to mkdocs.yml : theme : features : - toc.integrate # (1)! This feature flag is not compatible with navigation.indexes , as sections cannot host the table of contents due to missing space. With navigation integration Without Back-to-top button \u00b6 7.1.0 \u00b7 Feature flag A back-to-top button can be shown when the user, after scrolling down, starts to scroll up again. It's rendered centered and just below the header. Add the following lines to mkdocs.yml : theme : features : - navigation.top Usage \u00b6 Hiding the sidebars \u00b6 The navigation and/or table of contents sidebars can be hidden for a document with the front matter hide property. Add the following lines at the top of a Markdown file: --- hide : - navigation - toc --- # Document title ... Hide navigation Hide table of contents Hide both Customization \u00b6 Keyboard shortcuts \u00b6 Material for MkDocs includes several keyboard shortcuts that make it possible to navigate your project documentation via keyboard. There are two modes: search This mode is active when the search is focused . It provides several key bindings to make search accessible and navigable via keyboard: Down , Up : select next / previous result Esc , Tab : close search dialog Enter : follow selected result global This mode is active when search is not focussed and when there's no other focussed element that is susceptible to keyboard input. The following keys are bound: F , S , / : open search dialog P , , : go to previous page N , . : go to next page Let's say you want to bind some action to the X key. By using additional JavaScript , you can subscribe to the keyboard$ observable and attach your custom event listener: docs/javascripts/shortcuts.js mkdocs.yml keyboard$ . subscribe ( function ( key ) { if ( key . mode === \"global\" && key . type === \"x\" ) { /* Add custom keyboard handler here */ key . claim () // (1)! } }) The call to key.claim() will execute preventDefault() on the underlying event, so the keypress will not propagate further and touch other event listeners. extra_javascript : - javascripts/shortcuts.js Content area width \u00b6 The width of the content area is set so the length of each line doesn't exceed 80-100 characters, depending on the width of the characters. While this is a reasonable default, as longer lines tend to be harder to read, it may be desirable to increase the overall width of the content area, or even make it stretch to the entire available space. This can easily be achieved with an additional style sheet and a few lines of CSS: docs/stylesheets/extra.css mkdocs.yml . md-grid { max-width : 1440 px ; /* (1)! */ } If you want the content area to always stretch to the available screen space, reset max-width with the following CSS: . md-grid { max-width : initial ; } extra_css : - stylesheets/extra.css Prior to 6.2.0, navigation tabs had a slightly different behavior. All top-level pages (i.e. all top-level entries directly refefring to a *.md file) defined inside the nav entry of mkdocs.yml were grouped under the first tab which received the title of the first page. This made it impossible to include a top-level page (or external link) as a tab item, as was reported in #1884 and #2072 . From 6.2.0 on, navigation tabs include all top-level pages and sections. \u21a9","title":"Setting up navigation"},{"location":"setup/setting-up-navigation/#setting-up-navigation","text":"A clear and concise navigation structure is an important aspect of good project documentation. Material for MkDocs provides a multitude of options to configure the behavior of navigational elements, including tabs and sections , and one of its flag-ship feature: instant loading .","title":"Setting up navigation"},{"location":"setup/setting-up-navigation/#configuration","text":"","title":"Configuration"},{"location":"setup/setting-up-navigation/#instant-loading","text":"5.0.0 \u00b7 Feature flag When instant loading is enabled, clicks on all internal links will be intercepted and dispatched via XHR without fully reloading the page. Add the following lines to mkdocs.yml : theme : features : - navigation.instant The resulting page is parsed and injected and all event handlers and components are rebound automatically, i.e., Material for MkDocs now behaves like a Single Page Application . Now, the search index survives navigation, which is especially useful for large documentation sites.","title":"Instant loading"},{"location":"setup/setting-up-navigation/#anchor-tracking","text":"8.0.0 \u00b7 Feature flag \u00b7 Experimental When anchor tracking is enabled, the URL in the address bar is automatically updated with the active anchor as highlighted in the table of contents. Add the following lines to mkdocs.yml : theme : features : - navigation.tracking","title":"Anchor tracking"},{"location":"setup/setting-up-navigation/#navigation-tabs","text":"1.1.0 \u00b7 Feature flag When tabs are enabled, top-level sections are rendered in a menu layer below the header for viewports above 1220px , but remain as-is on mobile. 1 Add the following lines to mkdocs.yml : theme : features : - navigation.tabs With tabs Without","title":"Navigation tabs"},{"location":"setup/setting-up-navigation/#sticky-navigation-tabs","text":"7.3.0 \u00b7 Feature flag When sticky tabs are enabled, navigation tabs will lock below the header and always remain visible when scrolling down. Just add the following two feature flags to mkdocs.yml : theme : features : - navigation.tabs - navigation.tabs.sticky With sticky tabs Without","title":"Sticky navigation tabs"},{"location":"setup/setting-up-navigation/#navigation-sections","text":"6.2.0 \u00b7 Feature flag When sections are enabled, top-level sections are rendered as groups in the sidebar for viewports above 1220px , but remain as-is on mobile. Add the following lines to mkdocs.yml : theme : features : - navigation.sections With sections Without Both feature flags, navigation.tabs and navigation.sections , can be combined with each other. If both feature flags are enabled, sections are rendered for level 2 navigation items.","title":"Navigation sections"},{"location":"setup/setting-up-navigation/#navigation-expansion","text":"6.2.0 \u00b7 Feature flag When expansion is enabled, the left sidebar will expand all collapsible subsections by default, so the user doesn't have to open subsections manually. Add the following lines to mkdocs.yml : theme : features : - navigation.expand With expansion Without","title":"Navigation expansion"},{"location":"setup/setting-up-navigation/#navigation-pruning","text":"Sponsors only \u00b7 insiders-4.16.0 \u00b7 Experimental When pruning is enabled, only the visible navigation items are included in the rendered HTML, reducing the size of the built site by 33% or more . Add the following lines to mkdocs.yml : theme : features : - navigation.prune # (1)! This feature flag is not compatible with navigation.expand , as navigation expansion requires the complete navigation structure. This feature flag is especially useful for documentation sites with 100+ or even 1,000+ of pages, as the navigation makes up a significant fraction of the HTML. Navigation pruning will replace all expandable sections with links to the first page in that section (or the section index page).","title":"Navigation pruning"},{"location":"setup/setting-up-navigation/#section-index-pages","text":"7.3.0 \u00b7 Feature flag When section index pages are enabled, documents can be directly attached to sections, which is particularly useful for providing overview pages. Add the following lines to mkdocs.yml : theme : features : - navigation.indexes # (1)! This feature flag is not compatible with toc.integrate , as sections cannot host the table of contents due to missing space. With section index pages Without In order to link a page to a section, create a new document with the name index.md in the respective folder, and add it to the beginning of your navigation section: nav : - Section : - section/index.md - Page 1 : section/page-1.md ... - Page n : section/page-n.md","title":"Section index pages"},{"location":"setup/setting-up-navigation/#table-of-contents","text":"","title":"Table of contents"},{"location":"setup/setting-up-navigation/#anchor-following","text":"8.5.0 \u00b7 Experimental When anchor following for the table of contents is enabled, the sidebar is automatically scrolled so that the active anchor is always visible. Add the following lines to mkdocs.yml : theme : features : - toc.follow","title":"Anchor following"},{"location":"setup/setting-up-navigation/#navigation-integration","text":"6.2.0 \u00b7 Feature flag When navigation integration for the table of contents is enabled, it is always rendered as part of the navigation sidebar on the left. Add the following lines to mkdocs.yml : theme : features : - toc.integrate # (1)! This feature flag is not compatible with navigation.indexes , as sections cannot host the table of contents due to missing space. With navigation integration Without","title":"Navigation integration"},{"location":"setup/setting-up-navigation/#back-to-top-button","text":"7.1.0 \u00b7 Feature flag A back-to-top button can be shown when the user, after scrolling down, starts to scroll up again. It's rendered centered and just below the header. Add the following lines to mkdocs.yml : theme : features : - navigation.top","title":"Back-to-top button"},{"location":"setup/setting-up-navigation/#usage","text":"","title":"Usage"},{"location":"setup/setting-up-navigation/#hiding-the-sidebars","text":"The navigation and/or table of contents sidebars can be hidden for a document with the front matter hide property. Add the following lines at the top of a Markdown file: --- hide : - navigation - toc --- # Document title ... Hide navigation Hide table of contents Hide both","title":"Hiding the sidebars"},{"location":"setup/setting-up-navigation/#customization","text":"","title":"Customization"},{"location":"setup/setting-up-navigation/#keyboard-shortcuts","text":"Material for MkDocs includes several keyboard shortcuts that make it possible to navigate your project documentation via keyboard. There are two modes: search This mode is active when the search is focused . It provides several key bindings to make search accessible and navigable via keyboard: Down , Up : select next / previous result Esc , Tab : close search dialog Enter : follow selected result global This mode is active when search is not focussed and when there's no other focussed element that is susceptible to keyboard input. The following keys are bound: F , S , / : open search dialog P , , : go to previous page N , . : go to next page Let's say you want to bind some action to the X key. By using additional JavaScript , you can subscribe to the keyboard$ observable and attach your custom event listener: docs/javascripts/shortcuts.js mkdocs.yml keyboard$ . subscribe ( function ( key ) { if ( key . mode === \"global\" && key . type === \"x\" ) { /* Add custom keyboard handler here */ key . claim () // (1)! } }) The call to key.claim() will execute preventDefault() on the underlying event, so the keypress will not propagate further and touch other event listeners. extra_javascript : - javascripts/shortcuts.js","title":"Keyboard shortcuts"},{"location":"setup/setting-up-navigation/#content-area-width","text":"The width of the content area is set so the length of each line doesn't exceed 80-100 characters, depending on the width of the characters. While this is a reasonable default, as longer lines tend to be harder to read, it may be desirable to increase the overall width of the content area, or even make it stretch to the entire available space. This can easily be achieved with an additional style sheet and a few lines of CSS: docs/stylesheets/extra.css mkdocs.yml . md-grid { max-width : 1440 px ; /* (1)! */ } If you want the content area to always stretch to the available screen space, reset max-width with the following CSS: . md-grid { max-width : initial ; } extra_css : - stylesheets/extra.css Prior to 6.2.0, navigation tabs had a slightly different behavior. All top-level pages (i.e. all top-level entries directly refefring to a *.md file) defined inside the nav entry of mkdocs.yml were grouped under the first tab which received the title of the first page. This made it impossible to include a top-level page (or external link) as a tab item, as was reported in #1884 and #2072 . From 6.2.0 on, navigation tabs include all top-level pages and sections. \u21a9","title":"Content area width"},{"location":"setup/setting-up-site-analytics/","text":"Setting up site analytics \u00b6 As with any other service offered on the web, understanding how your project documentation is actually used can be an essential success factor. Material for MkDocs natively integrates with Google Analytics and offers a customizable cookie consent and a feedback widget . Configuration \u00b6 Google Analytics \u00b6 7.1.8 \u00b7 Default: none Material for MkDocs integrates with both, Google Analytics 4 and the now phasing out Universal Analytics. Depending on the given property prefix, add the following lines to mkdocs.yml : Google Analytics 4 Universal Analytics extra : analytics : provider : google property : G-XXXXXXXXXX extra : analytics : provider : google property : UA-XXXXXXXX-X How to measure site search usage? Besides page views and events, site search can be tracked to better understand how people use your documentation and what they expect to find. In order to enable site search tracking, the following steps are required: Google Analytics 4 Universal Analytics Go to your Google Analytics admin settings Select the property for the respective tracking code Select the data streams tab and click the corresponding URL Click the gear icon within the enhanced measurement section Ensure that site search is enabled Go to your Google Analytics admin settings Select the property for the respective tracking code Go to the view settings tab Scroll down and enable site search settings Set the query parameter to q Was this page helpful? \u00b6 8.4.0 \u00b7 Default: none \u00b7 Experimental A simple feedback widget can be included at the bottom of each page, encouraging users to give instant feedback whether a page was helpful or not. Add the following lines to mkdocs.yml : extra : analytics : # (1)! feedback : title : Was this page helpful? ratings : - icon : material/emoticon-happy-outline name : This page was helpful data : 1 note : >- Thanks for your feedback! - icon : material/emoticon-sad-outline name : This page could be improved data : 0 note : >- # (2)! Thanks for your feedback! Help us improve this page by using our <a href=\"...\" target=\"_blank\" rel=\"noopener\">feedback form</a>. This feature is natively integrated with Google Analytics , which is why provider and property are also required. However, it's also possible to provide a custom feedback integration . You can add arbitrary HTML tags to the note which is shown after the user submitted the feedback, e.g. to link to a feedback form. Both properties, title and ratings , are required. Note that it's allowed to define more than two ratings, e.g. to implement a 1-5 star rating. Since the feedback widget sends data to a third-party service, it is, of course, natively integrated with the cookie consent feature 1 . How to visualize the collected feedback ratings? To visualize feedback ratings you'll need to create a custom report with Google Analytics that will quickly show you the worst- and best-rated pages of your project documentation. Google Analytics 4 Universal Analytics Go to your Google Analytics dashboard Go to the configure page on the left hand menu, then select custom definitions Click the custom metrics tab and then create custom metrics , enter the following values: Metric name: Page helpful Description: Was this page helpful? Event parameter: data Unit of measurement: Standard Go to the explore page on the left hand menu, create a new blank exploration Configure the report as follows: Dimensions: Add Event name and Page location Metrics: Add Event count and Page helpful (the custom metric created in step 3) Rows: Page location Values: Drag in both Event count and Page helpful Filters: Add a new filter for Event name / exactly matches / feedback Delay in data availability The report may take 24 hours or longer to begin displaying data Go to your Google Analytics dashboard Open the customization panel on the left and go to custom reports Create a new custom report and set a custom title and name Add Avg. Value and Total Events to metric group Add Event Label to dimension drilldown Add Event Category to filters and filter for the value feedback Now, after you've saved the report and collected some feedback ratings, you'll have a list of all pages with the total number of ratings, and an average rating per page. This should help you identify pages that need to be improved: The following properties are available for each rating: icon Default: none \u00b7 Required \u2013 This property must point to a valid icon path referencing any icon bundled with the theme , or the build will not succeed. Some popular combinations: + \u2013 material/emoticon-happy-outline + material/emoticon-sad-outline + \u2013 material/thumb-up-outline + material/thumb-down-outline + \u2013 material/heart + material/heart-broken name Default: none \u00b7 Required \u2013 The value of this property is shown on user interaction (i.e. keyboard focus or mouse hover), explaining the meaning of the rating behind the icon. data Default: none \u00b7 Required \u2013 The value of this property is sent as a data value with the custom event that is transmitted to Google Analytics 2 (or any custom integration). note Default: none \u00b7 Required \u2013 The value of this property is shown after the user selected the rating. It may contain arbitrary HTML tags, which is especially useful to ask the user to provide more detailed feedback for the current page through a form. It's also possible to pre-fill forms with the URL and title of the current page by using the following placeholders: {url} \u2013 Page URL {title} \u2013 Page title https://github.com/.../issues/new/?title=[Feedback]+{title}+-+{url} In this example, when clicking the link, the user is redirected to the \"new issue\" form of your repository, with a pre-filled title including the path of the current document, e.g.: [Feedback] Setting up site analytics \u2013 /setup/setting-up-site-analytics/ An alternative to GitHub issues is Google Forms . Usage \u00b6 Hiding the feedback widget \u00b6 The feedback widget can be hidden for a document with the front matter hide property. Add the following lines at the top of a Markdown file: --- hide : - feedback --- # Document title ... Customization \u00b6 Custom site analytics \u00b6 In order to integrate another analytics service provider offering a JavaScript-based tracking solution, just follow the guide on theme extension and create a new partial in the overrides folder. The name of the partial is used to configure the custom integration via mkdocs.yml : overrides/partials/integrations/analytics/custom.html mkdocs.yml < script > /* Add custom analytics integration here, e.g. */ var property = \"{{ config.extra.analytics.property }}\" // (1)! /* Wait for page to load and application to mount */ document . addEventListener ( \"DOMContentLoaded\" , function () { location$ . subscribe ( function ( url ) { /* Add custom page event tracking here */ // (2)! }) }) </ script > As an example, this variable receives the value set in mkdocs.yml , which is \"foobar\" for property . If you're using instant loading , you can use the location$ observable to listen for navigation events, which always emits the current URL . extra : analytics : provider : custom property : foobar # (1)! You can add arbitrary key-value combinations to configure your custom integration. This is especially useful if you're sharing the custom integration across multiple repositories. Custom site feedback \u00b6 A custom feedback widget integration just needs to process the events that are generated by users interacting with the feedback widget with the help of some additional JavaScript : docs/javascripts/feedback.js mkdocs.yml var feedback = document . forms . feedback feedback . addEventListener ( \"submit\" , function ( ev ) { ev . preventDefault () /* Retrieve page and feedback value */ var page = document . location . pathname var data = ev . submitter . getAttribute ( \"data-md-value\" ) /* Send feedback value */ console . log ( page , data ) }) extra_javascript : - javascripts/feedback.js If the user doesn't accept the analytics cookie, the feedback widget is not shown. \u21a9 Note that for Google Analytics, the data value must be an integer. \u21a9","title":"Setting up site analytics"},{"location":"setup/setting-up-site-analytics/#setting-up-site-analytics","text":"As with any other service offered on the web, understanding how your project documentation is actually used can be an essential success factor. Material for MkDocs natively integrates with Google Analytics and offers a customizable cookie consent and a feedback widget .","title":"Setting up site analytics"},{"location":"setup/setting-up-site-analytics/#configuration","text":"","title":"Configuration"},{"location":"setup/setting-up-site-analytics/#google-analytics","text":"7.1.8 \u00b7 Default: none Material for MkDocs integrates with both, Google Analytics 4 and the now phasing out Universal Analytics. Depending on the given property prefix, add the following lines to mkdocs.yml : Google Analytics 4 Universal Analytics extra : analytics : provider : google property : G-XXXXXXXXXX extra : analytics : provider : google property : UA-XXXXXXXX-X How to measure site search usage? Besides page views and events, site search can be tracked to better understand how people use your documentation and what they expect to find. In order to enable site search tracking, the following steps are required: Google Analytics 4 Universal Analytics Go to your Google Analytics admin settings Select the property for the respective tracking code Select the data streams tab and click the corresponding URL Click the gear icon within the enhanced measurement section Ensure that site search is enabled Go to your Google Analytics admin settings Select the property for the respective tracking code Go to the view settings tab Scroll down and enable site search settings Set the query parameter to q","title":"Google Analytics"},{"location":"setup/setting-up-site-analytics/#was-this-page-helpful","text":"8.4.0 \u00b7 Default: none \u00b7 Experimental A simple feedback widget can be included at the bottom of each page, encouraging users to give instant feedback whether a page was helpful or not. Add the following lines to mkdocs.yml : extra : analytics : # (1)! feedback : title : Was this page helpful? ratings : - icon : material/emoticon-happy-outline name : This page was helpful data : 1 note : >- Thanks for your feedback! - icon : material/emoticon-sad-outline name : This page could be improved data : 0 note : >- # (2)! Thanks for your feedback! Help us improve this page by using our <a href=\"...\" target=\"_blank\" rel=\"noopener\">feedback form</a>. This feature is natively integrated with Google Analytics , which is why provider and property are also required. However, it's also possible to provide a custom feedback integration . You can add arbitrary HTML tags to the note which is shown after the user submitted the feedback, e.g. to link to a feedback form. Both properties, title and ratings , are required. Note that it's allowed to define more than two ratings, e.g. to implement a 1-5 star rating. Since the feedback widget sends data to a third-party service, it is, of course, natively integrated with the cookie consent feature 1 . How to visualize the collected feedback ratings? To visualize feedback ratings you'll need to create a custom report with Google Analytics that will quickly show you the worst- and best-rated pages of your project documentation. Google Analytics 4 Universal Analytics Go to your Google Analytics dashboard Go to the configure page on the left hand menu, then select custom definitions Click the custom metrics tab and then create custom metrics , enter the following values: Metric name: Page helpful Description: Was this page helpful? Event parameter: data Unit of measurement: Standard Go to the explore page on the left hand menu, create a new blank exploration Configure the report as follows: Dimensions: Add Event name and Page location Metrics: Add Event count and Page helpful (the custom metric created in step 3) Rows: Page location Values: Drag in both Event count and Page helpful Filters: Add a new filter for Event name / exactly matches / feedback Delay in data availability The report may take 24 hours or longer to begin displaying data Go to your Google Analytics dashboard Open the customization panel on the left and go to custom reports Create a new custom report and set a custom title and name Add Avg. Value and Total Events to metric group Add Event Label to dimension drilldown Add Event Category to filters and filter for the value feedback Now, after you've saved the report and collected some feedback ratings, you'll have a list of all pages with the total number of ratings, and an average rating per page. This should help you identify pages that need to be improved: The following properties are available for each rating: icon Default: none \u00b7 Required \u2013 This property must point to a valid icon path referencing any icon bundled with the theme , or the build will not succeed. Some popular combinations: + \u2013 material/emoticon-happy-outline + material/emoticon-sad-outline + \u2013 material/thumb-up-outline + material/thumb-down-outline + \u2013 material/heart + material/heart-broken name Default: none \u00b7 Required \u2013 The value of this property is shown on user interaction (i.e. keyboard focus or mouse hover), explaining the meaning of the rating behind the icon. data Default: none \u00b7 Required \u2013 The value of this property is sent as a data value with the custom event that is transmitted to Google Analytics 2 (or any custom integration). note Default: none \u00b7 Required \u2013 The value of this property is shown after the user selected the rating. It may contain arbitrary HTML tags, which is especially useful to ask the user to provide more detailed feedback for the current page through a form. It's also possible to pre-fill forms with the URL and title of the current page by using the following placeholders: {url} \u2013 Page URL {title} \u2013 Page title https://github.com/.../issues/new/?title=[Feedback]+{title}+-+{url} In this example, when clicking the link, the user is redirected to the \"new issue\" form of your repository, with a pre-filled title including the path of the current document, e.g.: [Feedback] Setting up site analytics \u2013 /setup/setting-up-site-analytics/ An alternative to GitHub issues is Google Forms .","title":"Was this page helpful?"},{"location":"setup/setting-up-site-analytics/#usage","text":"","title":"Usage"},{"location":"setup/setting-up-site-analytics/#hiding-the-feedback-widget","text":"The feedback widget can be hidden for a document with the front matter hide property. Add the following lines at the top of a Markdown file: --- hide : - feedback --- # Document title ...","title":"Hiding the feedback widget"},{"location":"setup/setting-up-site-analytics/#customization","text":"","title":"Customization"},{"location":"setup/setting-up-site-analytics/#custom-site-analytics","text":"In order to integrate another analytics service provider offering a JavaScript-based tracking solution, just follow the guide on theme extension and create a new partial in the overrides folder. The name of the partial is used to configure the custom integration via mkdocs.yml : overrides/partials/integrations/analytics/custom.html mkdocs.yml < script > /* Add custom analytics integration here, e.g. */ var property = \"{{ config.extra.analytics.property }}\" // (1)! /* Wait for page to load and application to mount */ document . addEventListener ( \"DOMContentLoaded\" , function () { location$ . subscribe ( function ( url ) { /* Add custom page event tracking here */ // (2)! }) }) </ script > As an example, this variable receives the value set in mkdocs.yml , which is \"foobar\" for property . If you're using instant loading , you can use the location$ observable to listen for navigation events, which always emits the current URL . extra : analytics : provider : custom property : foobar # (1)! You can add arbitrary key-value combinations to configure your custom integration. This is especially useful if you're sharing the custom integration across multiple repositories.","title":"Custom site analytics"},{"location":"setup/setting-up-site-analytics/#custom-site-feedback","text":"A custom feedback widget integration just needs to process the events that are generated by users interacting with the feedback widget with the help of some additional JavaScript : docs/javascripts/feedback.js mkdocs.yml var feedback = document . forms . feedback feedback . addEventListener ( \"submit\" , function ( ev ) { ev . preventDefault () /* Retrieve page and feedback value */ var page = document . location . pathname var data = ev . submitter . getAttribute ( \"data-md-value\" ) /* Send feedback value */ console . log ( page , data ) }) extra_javascript : - javascripts/feedback.js If the user doesn't accept the analytics cookie, the feedback widget is not shown. \u21a9 Note that for Google Analytics, the data value must be an integer. \u21a9","title":"Custom site feedback"},{"location":"setup/setting-up-site-search/","text":"Setting up site search \u00b6 Material for MkDocs provides an excellent client-side search implementation, omitting the need for the integration of third-party services, which might not be compliant with privacy regulations. Moreover, search even works offline , allowing users to download your documentation. Configuration \u00b6 Built-in search plugin \u00b6 0.1.0 \u00b7 Plugin The built-in search plugin integrates seamlessly with Material for MkDocs, adding multilingual client-side search with lunr and lunr-languages . It's enabled by default, but must be re-added to mkdocs.yml when other plugins are used: plugins : - search The following configuration options are supported: lang Default: automatically set \u2013 This option allows to include the language-specific stemmers provided by lunr-languages . Note that Material for MkDocs will set this automatically based on the site language , but it may be overridden, e.g. to support multiple languages: A single language Multiple languages plugins : - search : lang : ru plugins : - search : lang : # (1)! - en - ru Be aware that including support for other languages increases the general JavaScript payload by around 20kb (before gzip ) and by another 15-30kb per language. The following languages are supported: ar \u2013 Arabic da \u2013 Danish de \u2013 German du \u2013 Dutch en \u2013 English es \u2013 Spanish fi \u2013 Finnish fr \u2013 French hu \u2013 Hungarian it \u2013 Italian ja \u2013 Japanese no \u2013 Norwegian pt \u2013 Portuguese ro \u2013 Romanian ru \u2013 Russian sv \u2013 Swedish th \u2013 Thai tr \u2013 Turkish vi \u2013 Vietnamese Material for MkDocs goes to great lengths to support languages that are not part of this list by automatically falling back to the stemmer yielding the best result. separator Default: automatically set \u2013 The separator for indexing and query tokenization can be customized, making it possible to index parts of words separated by other characters than whitespace and - , e.g. by including . : plugins : - search : separator : '[\\s\\-\\.]' # (1)! Tokenization itself is carried out by lunr's default tokenizer , which doesn't allow for lookahead or multi-character separators. For more finegrained control over the tokenization process, see the section on tokenizer lookahead . prebuild_index 5.0.0 \u00b7 Deprecated \u00b7 8.0.0 \u00b7 Default: false \u2013 MkDocs can generate a prebuilt index of all pages during build time, which provides performance improvements at the cost of more bandwidth, as it reduces the build time of the search index: plugins : - search : prebuild_index : true Note that this configuration option was removed, as the new search plugin generates up to 50% smaller search indexes, doubling search performance. Read more on the new search plugin Chinese language support \u00b6 Sponsors only \u00b7 insiders-4.14.0 \u00b7 Experimental Insiders adds search support for the Chinese language (see our blog article from May 2022) by integrating with the text segmentation library jieba , which can be installed with pip . pip install jieba If jieba is installed, the built-in search plugin automatically detects Chinese characters and runs them through the segmenter. The following configuration options are available: jieba_dict insiders-4.17.2 \u00b7 Default: none \u2013 This option allows for specifying a custom dictionary to be used by jieba for segmenting text, replacing the default dictionary: plugins : - search : jieba_dict : dict.txt # (1)! The following alternative dictionaries are provided by jieba : dict.txt.small \u2013 \u5360\u7528\u5185\u5b58\u8f83\u5c0f\u7684\u8bcd\u5178\u6587\u4ef6 dict.txt.big \u2013 \u652f\u6301\u7e41\u4f53\u5206\u8bcd\u66f4\u597d\u7684\u8bcd\u5178\u6587\u4ef6 jieba_dict_user insiders-4.17.2 \u00b7 Default: none \u2013 This option allows for specifying an additional user dictionary to be used by jieba for segmenting text, augmenting the default dictionary: plugins : - search : jieba_dict_user : user_dict.txt User dictionaries can be used for tuning the segmenter to preserve technical terms. Rich search previews \u00b6 Sponsors only \u00b7 insiders-3.0.0 \u00b7 Experimental Insiders ships rich search previews as part of the new search plugin , which will render code blocks directly in the search result, and highlight all occurrences inside those blocks: Insiders Material for MkDocs Tokenizer lookahead \u00b6 Sponsors only \u00b7 insiders-3.0.0 \u00b7 Experimental Insiders allows for more complex configurations of the separator setting as part of the new search plugin , yielding more influence on the way documents are tokenized: plugins : - search : separator : '[\\s\\-,:!=\\[\\]()\"/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])' The following section explains what can be achieved with tokenizer lookahead: Case changes Version numbers HTML/XML tags (?!\\b)(?=[A-Z][a-z]) PascalCase and camelCase are used as naming conventions in many programming languages. By adding this match group to the separator , words are split at case changes , tokenizing the word PascalCase into Pascal and Case , so both terms can be searched individually. Read more on tokenizing case changes \\.(?!\\d) When . is added to the separator , version numbers would be split into parts, rendering them undiscoverable via search. By adding this match group, a small lookahead is introduced, so version numbers will remain as they are, and can be found through search. Read more on tokenizing version numbers &[lg]t; If your documentation includes HTML/XML code examples, you may want to allow users to find specific tag names. Unfortunately, the < and > control characters are encoded in code blocks as &lt; and &gt; . Adding this expression to the separator allows for just that. Read more on tokenizing HTML/XML tags Search suggestions \u00b6 7.2.0 \u00b7 Feature flag \u00b7 Experimental When search suggestions are enabled, the search will display the likeliest completion for the last word which can be accepted with the Right key. Add the following lines to mkdocs.yml : theme : features : - search.suggest Searching for search su yields search suggestions as a suggestion. Search highlighting \u00b6 7.2.0 \u00b7 Feature flag \u00b7 Experimental When search highlighting is enabled and a user clicks on a search result, Material for MkDocs will highlight all occurrences after following the link. Add the following lines to mkdocs.yml : theme : features : - search.highlight Searching for code blocks highlights all occurrences of both terms. Search sharing \u00b6 7.2.0 \u00b7 Feature flag \u00b7 Experimental When search sharing is activated, a share button is rendered next to the reset button, which allows to deep link to the current search query and result. Add the following lines to mkdocs.yml : theme : features : - search.share When a user clicks the share button, the URL is automatically copied to the clipboard. Usage \u00b6 Search boosting \u00b6 8.3.0 \u00b7 Experimental Pages can be boosted in search with the front matter search.boost property, which will make them rank higher. Add the following lines at the top of a Markdown file: --- search : boost : 2 # (1)! --- # Document title ... When boosting pages, be gentle and start with low values . Search exclusion \u00b6 Sponsors only \u00b7 insiders-3.1.0 \u00b7 Experimental Pages can be excluded from search with the front matter search.exclude property, removing them from the index. Add the following lines at the top of a Markdown file: --- search : exclude : true --- # Document title ... Excluding sections \u00b6 When Attribute Lists is enabled, specific sections of pages can be excluded from search by adding the { data-search-exclude } pragma after a Markdown heading: docs/page.md search_index.json # Document title ## Section 1 The content of this section is included ## Section 2 { data-search-exclude } The content of this section is excluded { ... \"docs\" : [ { \"location\" : \"page/\" , \"text\" : \"\" , \"title\" : \"Document title\" }, { \"location\" : \"page/#section-1\" , \"text\" : \"<p>The content of this section is included</p>\" , \"title\" : \"Section 1\" } ] } Excluding blocks \u00b6 When Attribute Lists is enabled, specific sections of pages can be excluded from search by adding the { data-search-exclude } pragma after a Markdown inline- or block-level element: docs/page.md search_index.json # Document title The content of this block is included The content of this block is excluded { data-search-exclude } { ... \"docs\" : [ { \"location\" : \"page/\" , \"text\" : \"<p>The content of this block is included</p>\" , \"title\" : \"Document title\" } ] } Customization \u00b6 The search implementation of Material for MkDocs is probably its most sophisticated feature, as it tries to balance a great typeahead experience, good performance, accessibility, and a result list that is easy to scan. This is where Material for MkDocs deviates from other themes. The following section explains how search can be customized to tailor it to your needs. Query transformation \u00b6 When a user enters a query into the search box, the query is pre-processed before it is submitted to the search index. Material for MkDocs will apply the following transformations, which can be customized by extending the theme : export function defaultTransform ( query : string ) : string { return query . split ( /\"([^\"]+)\"/g ) /* (1)! */ . map (( terms , index ) => index & 1 ? terms . replace ( /^\\b|^(?![^\\x00-\\x7F]|$)|\\s+/g , \" +\" ) : terms ) . join ( \"\" ) . replace ( /\"|(?:^|\\s+)[*+\\-:^~]+(?=\\s+|$)/g , \"\" ) /* (2)! */ . trim () /* (3)! */ } Search for terms in quotation marks and prepend a + modifier to denote that the resulting document must contain all terms, converting the query to an AND query (as opposed to the default OR behavior). While users may expect terms enclosed in quotation marks to map to span queries, i.e. for which order is important, lunr doesn't support them, so the best we can do is to convert the terms to an AND query. Replace control characters which are not located at the beginning of the query or preceded by white space, or are not followed by a non-whitespace character or are at the end of the query string. Furthermore, filter unmatched quotation marks. Trim excess whitespace from left and right. If you want to switch to the default behavior of the mkdocs and readthedocs themes, both of which don't transform the query prior to submission, or customize the transform function, you can do this by overriding the config block : {% extends \"base.html\" %} {% block config %} {{ super() }} < script > var __search = { transform : function ( query ) { return query } } </ script > {% endblock %} The transform function will receive the query string as entered by the user and must return the processed query string to be submitted to the search index. Custom search \u00b6 Material for MkDocs implements search as part of a web worker . If you want to switch the web worker with your own implementation, e.g. to submit search to an external service, you can add a custom JavaScript file to the docs directory and override the config block : {% extends \"base.html\" %} {% block config %} {{ super() }} < script > var __search = { worker : \"<url>\" } </ script > {% endblock %} Communication with the search worker is implemented using a designated message format using discriminated unions, i.e. through the type property of the message. See the following interface definitions to learn about the message formats: SearchMessage SearchIndex and SearchResult The sequence and direction of messages is rather intuitive: SearchSetupMessage SearchReadyMessage SearchQueryMessage SearchResultMessage","title":"Setting up site search"},{"location":"setup/setting-up-site-search/#setting-up-site-search","text":"Material for MkDocs provides an excellent client-side search implementation, omitting the need for the integration of third-party services, which might not be compliant with privacy regulations. Moreover, search even works offline , allowing users to download your documentation.","title":"Setting up site search"},{"location":"setup/setting-up-site-search/#configuration","text":"","title":"Configuration"},{"location":"setup/setting-up-site-search/#built-in-search-plugin","text":"0.1.0 \u00b7 Plugin The built-in search plugin integrates seamlessly with Material for MkDocs, adding multilingual client-side search with lunr and lunr-languages . It's enabled by default, but must be re-added to mkdocs.yml when other plugins are used: plugins : - search The following configuration options are supported: lang Default: automatically set \u2013 This option allows to include the language-specific stemmers provided by lunr-languages . Note that Material for MkDocs will set this automatically based on the site language , but it may be overridden, e.g. to support multiple languages: A single language Multiple languages plugins : - search : lang : ru plugins : - search : lang : # (1)! - en - ru Be aware that including support for other languages increases the general JavaScript payload by around 20kb (before gzip ) and by another 15-30kb per language. The following languages are supported: ar \u2013 Arabic da \u2013 Danish de \u2013 German du \u2013 Dutch en \u2013 English es \u2013 Spanish fi \u2013 Finnish fr \u2013 French hu \u2013 Hungarian it \u2013 Italian ja \u2013 Japanese no \u2013 Norwegian pt \u2013 Portuguese ro \u2013 Romanian ru \u2013 Russian sv \u2013 Swedish th \u2013 Thai tr \u2013 Turkish vi \u2013 Vietnamese Material for MkDocs goes to great lengths to support languages that are not part of this list by automatically falling back to the stemmer yielding the best result. separator Default: automatically set \u2013 The separator for indexing and query tokenization can be customized, making it possible to index parts of words separated by other characters than whitespace and - , e.g. by including . : plugins : - search : separator : '[\\s\\-\\.]' # (1)! Tokenization itself is carried out by lunr's default tokenizer , which doesn't allow for lookahead or multi-character separators. For more finegrained control over the tokenization process, see the section on tokenizer lookahead . prebuild_index 5.0.0 \u00b7 Deprecated \u00b7 8.0.0 \u00b7 Default: false \u2013 MkDocs can generate a prebuilt index of all pages during build time, which provides performance improvements at the cost of more bandwidth, as it reduces the build time of the search index: plugins : - search : prebuild_index : true Note that this configuration option was removed, as the new search plugin generates up to 50% smaller search indexes, doubling search performance. Read more on the new search plugin","title":"Built-in search plugin"},{"location":"setup/setting-up-site-search/#chinese-language-support","text":"Sponsors only \u00b7 insiders-4.14.0 \u00b7 Experimental Insiders adds search support for the Chinese language (see our blog article from May 2022) by integrating with the text segmentation library jieba , which can be installed with pip . pip install jieba If jieba is installed, the built-in search plugin automatically detects Chinese characters and runs them through the segmenter. The following configuration options are available: jieba_dict insiders-4.17.2 \u00b7 Default: none \u2013 This option allows for specifying a custom dictionary to be used by jieba for segmenting text, replacing the default dictionary: plugins : - search : jieba_dict : dict.txt # (1)! The following alternative dictionaries are provided by jieba : dict.txt.small \u2013 \u5360\u7528\u5185\u5b58\u8f83\u5c0f\u7684\u8bcd\u5178\u6587\u4ef6 dict.txt.big \u2013 \u652f\u6301\u7e41\u4f53\u5206\u8bcd\u66f4\u597d\u7684\u8bcd\u5178\u6587\u4ef6 jieba_dict_user insiders-4.17.2 \u00b7 Default: none \u2013 This option allows for specifying an additional user dictionary to be used by jieba for segmenting text, augmenting the default dictionary: plugins : - search : jieba_dict_user : user_dict.txt User dictionaries can be used for tuning the segmenter to preserve technical terms.","title":"Chinese language support"},{"location":"setup/setting-up-site-search/#rich-search-previews","text":"Sponsors only \u00b7 insiders-3.0.0 \u00b7 Experimental Insiders ships rich search previews as part of the new search plugin , which will render code blocks directly in the search result, and highlight all occurrences inside those blocks: Insiders Material for MkDocs","title":"Rich search previews"},{"location":"setup/setting-up-site-search/#tokenizer-lookahead","text":"Sponsors only \u00b7 insiders-3.0.0 \u00b7 Experimental Insiders allows for more complex configurations of the separator setting as part of the new search plugin , yielding more influence on the way documents are tokenized: plugins : - search : separator : '[\\s\\-,:!=\\[\\]()\"/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])' The following section explains what can be achieved with tokenizer lookahead: Case changes Version numbers HTML/XML tags (?!\\b)(?=[A-Z][a-z]) PascalCase and camelCase are used as naming conventions in many programming languages. By adding this match group to the separator , words are split at case changes , tokenizing the word PascalCase into Pascal and Case , so both terms can be searched individually. Read more on tokenizing case changes \\.(?!\\d) When . is added to the separator , version numbers would be split into parts, rendering them undiscoverable via search. By adding this match group, a small lookahead is introduced, so version numbers will remain as they are, and can be found through search. Read more on tokenizing version numbers &[lg]t; If your documentation includes HTML/XML code examples, you may want to allow users to find specific tag names. Unfortunately, the < and > control characters are encoded in code blocks as &lt; and &gt; . Adding this expression to the separator allows for just that. Read more on tokenizing HTML/XML tags","title":"Tokenizer lookahead"},{"location":"setup/setting-up-site-search/#search-suggestions","text":"7.2.0 \u00b7 Feature flag \u00b7 Experimental When search suggestions are enabled, the search will display the likeliest completion for the last word which can be accepted with the Right key. Add the following lines to mkdocs.yml : theme : features : - search.suggest Searching for search su yields search suggestions as a suggestion.","title":"Search suggestions"},{"location":"setup/setting-up-site-search/#search-highlighting","text":"7.2.0 \u00b7 Feature flag \u00b7 Experimental When search highlighting is enabled and a user clicks on a search result, Material for MkDocs will highlight all occurrences after following the link. Add the following lines to mkdocs.yml : theme : features : - search.highlight Searching for code blocks highlights all occurrences of both terms.","title":"Search highlighting"},{"location":"setup/setting-up-site-search/#search-sharing","text":"7.2.0 \u00b7 Feature flag \u00b7 Experimental When search sharing is activated, a share button is rendered next to the reset button, which allows to deep link to the current search query and result. Add the following lines to mkdocs.yml : theme : features : - search.share When a user clicks the share button, the URL is automatically copied to the clipboard.","title":"Search sharing"},{"location":"setup/setting-up-site-search/#usage","text":"","title":"Usage"},{"location":"setup/setting-up-site-search/#search-boosting","text":"8.3.0 \u00b7 Experimental Pages can be boosted in search with the front matter search.boost property, which will make them rank higher. Add the following lines at the top of a Markdown file: --- search : boost : 2 # (1)! --- # Document title ... When boosting pages, be gentle and start with low values .","title":"Search boosting"},{"location":"setup/setting-up-site-search/#search-exclusion","text":"Sponsors only \u00b7 insiders-3.1.0 \u00b7 Experimental Pages can be excluded from search with the front matter search.exclude property, removing them from the index. Add the following lines at the top of a Markdown file: --- search : exclude : true --- # Document title ...","title":"Search exclusion"},{"location":"setup/setting-up-site-search/#excluding-sections","text":"When Attribute Lists is enabled, specific sections of pages can be excluded from search by adding the { data-search-exclude } pragma after a Markdown heading: docs/page.md search_index.json # Document title ## Section 1 The content of this section is included ## Section 2 { data-search-exclude } The content of this section is excluded { ... \"docs\" : [ { \"location\" : \"page/\" , \"text\" : \"\" , \"title\" : \"Document title\" }, { \"location\" : \"page/#section-1\" , \"text\" : \"<p>The content of this section is included</p>\" , \"title\" : \"Section 1\" } ] }","title":"Excluding sections"},{"location":"setup/setting-up-site-search/#excluding-blocks","text":"When Attribute Lists is enabled, specific sections of pages can be excluded from search by adding the { data-search-exclude } pragma after a Markdown inline- or block-level element: docs/page.md search_index.json # Document title The content of this block is included The content of this block is excluded { data-search-exclude } { ... \"docs\" : [ { \"location\" : \"page/\" , \"text\" : \"<p>The content of this block is included</p>\" , \"title\" : \"Document title\" } ] }","title":"Excluding blocks"},{"location":"setup/setting-up-site-search/#customization","text":"The search implementation of Material for MkDocs is probably its most sophisticated feature, as it tries to balance a great typeahead experience, good performance, accessibility, and a result list that is easy to scan. This is where Material for MkDocs deviates from other themes. The following section explains how search can be customized to tailor it to your needs.","title":"Customization"},{"location":"setup/setting-up-site-search/#query-transformation","text":"When a user enters a query into the search box, the query is pre-processed before it is submitted to the search index. Material for MkDocs will apply the following transformations, which can be customized by extending the theme : export function defaultTransform ( query : string ) : string { return query . split ( /\"([^\"]+)\"/g ) /* (1)! */ . map (( terms , index ) => index & 1 ? terms . replace ( /^\\b|^(?![^\\x00-\\x7F]|$)|\\s+/g , \" +\" ) : terms ) . join ( \"\" ) . replace ( /\"|(?:^|\\s+)[*+\\-:^~]+(?=\\s+|$)/g , \"\" ) /* (2)! */ . trim () /* (3)! */ } Search for terms in quotation marks and prepend a + modifier to denote that the resulting document must contain all terms, converting the query to an AND query (as opposed to the default OR behavior). While users may expect terms enclosed in quotation marks to map to span queries, i.e. for which order is important, lunr doesn't support them, so the best we can do is to convert the terms to an AND query. Replace control characters which are not located at the beginning of the query or preceded by white space, or are not followed by a non-whitespace character or are at the end of the query string. Furthermore, filter unmatched quotation marks. Trim excess whitespace from left and right. If you want to switch to the default behavior of the mkdocs and readthedocs themes, both of which don't transform the query prior to submission, or customize the transform function, you can do this by overriding the config block : {% extends \"base.html\" %} {% block config %} {{ super() }} < script > var __search = { transform : function ( query ) { return query } } </ script > {% endblock %} The transform function will receive the query string as entered by the user and must return the processed query string to be submitted to the search index.","title":"Query transformation"},{"location":"setup/setting-up-site-search/#custom-search","text":"Material for MkDocs implements search as part of a web worker . If you want to switch the web worker with your own implementation, e.g. to submit search to an external service, you can add a custom JavaScript file to the docs directory and override the config block : {% extends \"base.html\" %} {% block config %} {{ super() }} < script > var __search = { worker : \"<url>\" } </ script > {% endblock %} Communication with the search worker is implemented using a designated message format using discriminated unions, i.e. through the type property of the message. See the following interface definitions to learn about the message formats: SearchMessage SearchIndex and SearchResult The sequence and direction of messages is rather intuitive: SearchSetupMessage SearchReadyMessage SearchQueryMessage SearchResultMessage","title":"Custom search"},{"location":"setup/setting-up-social-cards/","text":"Setting up social cards \u00b6 Social cards, also known as social previews, are images that are displayed when a link to your project documentation is shared on social media. Material for MkDocs can generate beautiful social cards automatically, using the colors , fonts and logo 1 defined in mkdocs.yml , e.g.: The social preview image for the page on setting up site analytics . Twitter's Card validator shows how it will look when shared. Configuration \u00b6 Built-in social plugin \u00b6 8.5.0 \u00b7 Plugin \u00b7 Experimental First, ensure you've installed all dependencies and have a valid site_url , as social preview images must be referenced via absolute URLs. Then, add the following lines to mkdocs.yml : plugins : - social The following configuration options are available: cards Default: true \u2013 This option specifies whether to generate social card images. If you want to switch the plugin off, e.g. for local builds, you can use an environment variable : plugins : - social : cards : !ENV [ CARDS , false ] cards_color Default: theme.palette.primary \u2013 This option specifies the colors for the background fill and foreground text when generating the social card: plugins : - social : cards_color : fill : \"#0FF1CE\" # (1)! text : \"#FFFFFF\" Colors can either be defined as HEX colors, or as CSS color keywords . Note that HEX colors must be enclosed in quotes. cards_font Default: theme.font.text \u2013 This option specifies which font to use for rendering the social card, which can be any font hosted on Google Fonts : plugins : - social : cards_font : Roboto Why do social cards render boxes for CJK languages? Some fonts do not contain CJK characters, like for example the default font, Roboto . In case your site_name , site_description , or page title contain CJK characters, choose another font from Google Fonts which comes with CJK characters, e.g. one from the Noto Sans font family: Chinese (Simplified) Chinese (Traditional) Japanese Korean plugins : - social : cards_font : Noto Sans SC plugins : - social : cards_font : Noto Sans TC plugins : - social : cards_font : Noto Sans JP plugins : - social : cards_font : Noto Sans KR cards_dir Default: assets/images/social \u2013 This option specifies where the generated social card images will be written to. It's normally not necessary to change this option: plugins : - social : cards_dir : path/to/folder Dependencies \u00b6 Two Python libraries must be installed alongside Material for MkDocs to generate the social preview images, both of which are based on Cairo Graphics \u2013 Pillow and CairoSVG : pip install pillow cairosvg Both libraries are built with native extensions which need to be installed as well. The Docker image comes with all dependencies pre-installed. If you don't want to use Docker, see the following section which explains how to install all dependencies on your system: macOS Windows Linux Make sure Homebrew is installed, which is a modern package manager for macOS. Next, use the following command to install all necessary dependencies: brew install cairo freetype libffi libjpeg libpng zlib As stated in the installation guide , the easiest way to get up and running with the Cairo Graphics library on Windows is by installing GTK+ , since it has Cairo as a dependency. You can also download and install a precompiled GTK runtime . There are several package managers for Linux with varying availability per distribution. The installation guide explains how to install the Cairo Graphics library for your distribution: Ubuntu Fedora openSUSE apt-get install libcairo2-dev libfreetype6-dev libffi-dev libjpeg-dev libpng-dev libz-dev yum install cairo-devel freetype-devel libffi-devel libjpeg-devel libpng-devel zlib-devel zypper install cairo-devel freetype-devel libffi-devel libjpeg-devel libpng-devel zlib-devel Caching recommended \u00b6 The built-in social plugin automatically fetches the fonts you define in mkdocs.yml from Google Fonts, and uses them to render the text that is displayed on the social card. The font files and generated cards are both written to the .cache directory, which is used in subsequent builds to detect whether the social cards need to be regenerated. You might want to: Ignore the .cache directory in your project, by adding it to .gitignore . When building your site for publishing, use a build cache to save the .cache directory in between builds. Taking the example from the publishing guide , add the following lines: name : ci on : push : branches : - master - main jobs : deploy : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - uses : actions/setup-python@v2 with : python-version : 3.x - uses : actions/cache@v2 with : key : ${{ github.ref }} path : .cache - run : pip install mkdocs-material - run : mkdocs gh-deploy --force Meta tags \u00b6 The built-in social plugin automatically sets all necessary meta tags, equivalent to the following two customizations, which you can set manually when you don't want to use it: Open Graph Twitter Cards {% extends \"base.html\" %} {% block extrahead %} {% set title = config.site_name %} {% if page and page.meta and page.meta.title %} {% set title = title ~ \" - \" ~ page.meta.title %} {% elif page and page.title and not page.is_homepage %} {% set title = title ~ \" - \" ~ page.title %} {% endif %} < meta property = \"og:type\" content = \"website\" /> < meta property = \"og:title\" content = \"{{ title }}\" /> < meta property = \"og:description\" content = \"{{ config.site_description }}\" /> < meta property = \"og:url\" content = \"{{ page.canonical_url }}\" /> < meta property = \"og:image\" content = \"<url>\" /> < meta property = \"og:image:type\" content = \"image/png\" /> < meta property = \"og:image:width\" content = \"1200\" /> < meta property = \"og:image:height\" content = \"630\" /> {% endblock %} {% extends \"base.html\" %} {% block extrahead %} {% set title = config.site_name %} {% if page and page.meta and page.meta.title %} {% set title = title ~ \" - \" ~ page.meta.title %} {% elif page and page.title and not page.is_homepage %} {% set title = title ~ \" - \" ~ page.title %} {% endif %} < meta name = \"twitter:card\" content = \"summary_large_image\" /> < meta name = \"twitter:title\" content = \"{{ title }}\" /> < meta name = \"twitter:description\" content = \"{{ config.site_description }}\" /> < meta name = \"twitter:image\" content = \"<url>\" /> {% endblock %} Usage \u00b6 If you want to adjust the title or set a custom description for the social card, you can set the front matter title and description properties, which take precedence over the default values. Changing the title Changing the description Both types of logos, images ( theme.logo ) and icons ( theme.icon.logo ) are supported. While an image logo is used as-is, icons are filled with the color used in the header (white or black), which depends on the primary color. \u21a9","title":"Setting up social cards"},{"location":"setup/setting-up-social-cards/#setting-up-social-cards","text":"Social cards, also known as social previews, are images that are displayed when a link to your project documentation is shared on social media. Material for MkDocs can generate beautiful social cards automatically, using the colors , fonts and logo 1 defined in mkdocs.yml , e.g.: The social preview image for the page on setting up site analytics . Twitter's Card validator shows how it will look when shared.","title":"Setting up social cards"},{"location":"setup/setting-up-social-cards/#configuration","text":"","title":"Configuration"},{"location":"setup/setting-up-social-cards/#built-in-social-plugin","text":"8.5.0 \u00b7 Plugin \u00b7 Experimental First, ensure you've installed all dependencies and have a valid site_url , as social preview images must be referenced via absolute URLs. Then, add the following lines to mkdocs.yml : plugins : - social The following configuration options are available: cards Default: true \u2013 This option specifies whether to generate social card images. If you want to switch the plugin off, e.g. for local builds, you can use an environment variable : plugins : - social : cards : !ENV [ CARDS , false ] cards_color Default: theme.palette.primary \u2013 This option specifies the colors for the background fill and foreground text when generating the social card: plugins : - social : cards_color : fill : \"#0FF1CE\" # (1)! text : \"#FFFFFF\" Colors can either be defined as HEX colors, or as CSS color keywords . Note that HEX colors must be enclosed in quotes. cards_font Default: theme.font.text \u2013 This option specifies which font to use for rendering the social card, which can be any font hosted on Google Fonts : plugins : - social : cards_font : Roboto Why do social cards render boxes for CJK languages? Some fonts do not contain CJK characters, like for example the default font, Roboto . In case your site_name , site_description , or page title contain CJK characters, choose another font from Google Fonts which comes with CJK characters, e.g. one from the Noto Sans font family: Chinese (Simplified) Chinese (Traditional) Japanese Korean plugins : - social : cards_font : Noto Sans SC plugins : - social : cards_font : Noto Sans TC plugins : - social : cards_font : Noto Sans JP plugins : - social : cards_font : Noto Sans KR cards_dir Default: assets/images/social \u2013 This option specifies where the generated social card images will be written to. It's normally not necessary to change this option: plugins : - social : cards_dir : path/to/folder","title":"Built-in social plugin"},{"location":"setup/setting-up-social-cards/#dependencies","text":"Two Python libraries must be installed alongside Material for MkDocs to generate the social preview images, both of which are based on Cairo Graphics \u2013 Pillow and CairoSVG : pip install pillow cairosvg Both libraries are built with native extensions which need to be installed as well. The Docker image comes with all dependencies pre-installed. If you don't want to use Docker, see the following section which explains how to install all dependencies on your system: macOS Windows Linux Make sure Homebrew is installed, which is a modern package manager for macOS. Next, use the following command to install all necessary dependencies: brew install cairo freetype libffi libjpeg libpng zlib As stated in the installation guide , the easiest way to get up and running with the Cairo Graphics library on Windows is by installing GTK+ , since it has Cairo as a dependency. You can also download and install a precompiled GTK runtime . There are several package managers for Linux with varying availability per distribution. The installation guide explains how to install the Cairo Graphics library for your distribution: Ubuntu Fedora openSUSE apt-get install libcairo2-dev libfreetype6-dev libffi-dev libjpeg-dev libpng-dev libz-dev yum install cairo-devel freetype-devel libffi-devel libjpeg-devel libpng-devel zlib-devel zypper install cairo-devel freetype-devel libffi-devel libjpeg-devel libpng-devel zlib-devel","title":"Dependencies"},{"location":"setup/setting-up-social-cards/#caching","text":"The built-in social plugin automatically fetches the fonts you define in mkdocs.yml from Google Fonts, and uses them to render the text that is displayed on the social card. The font files and generated cards are both written to the .cache directory, which is used in subsequent builds to detect whether the social cards need to be regenerated. You might want to: Ignore the .cache directory in your project, by adding it to .gitignore . When building your site for publishing, use a build cache to save the .cache directory in between builds. Taking the example from the publishing guide , add the following lines: name : ci on : push : branches : - master - main jobs : deploy : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - uses : actions/setup-python@v2 with : python-version : 3.x - uses : actions/cache@v2 with : key : ${{ github.ref }} path : .cache - run : pip install mkdocs-material - run : mkdocs gh-deploy --force","title":"Caching"},{"location":"setup/setting-up-social-cards/#meta-tags","text":"The built-in social plugin automatically sets all necessary meta tags, equivalent to the following two customizations, which you can set manually when you don't want to use it: Open Graph Twitter Cards {% extends \"base.html\" %} {% block extrahead %} {% set title = config.site_name %} {% if page and page.meta and page.meta.title %} {% set title = title ~ \" - \" ~ page.meta.title %} {% elif page and page.title and not page.is_homepage %} {% set title = title ~ \" - \" ~ page.title %} {% endif %} < meta property = \"og:type\" content = \"website\" /> < meta property = \"og:title\" content = \"{{ title }}\" /> < meta property = \"og:description\" content = \"{{ config.site_description }}\" /> < meta property = \"og:url\" content = \"{{ page.canonical_url }}\" /> < meta property = \"og:image\" content = \"<url>\" /> < meta property = \"og:image:type\" content = \"image/png\" /> < meta property = \"og:image:width\" content = \"1200\" /> < meta property = \"og:image:height\" content = \"630\" /> {% endblock %} {% extends \"base.html\" %} {% block extrahead %} {% set title = config.site_name %} {% if page and page.meta and page.meta.title %} {% set title = title ~ \" - \" ~ page.meta.title %} {% elif page and page.title and not page.is_homepage %} {% set title = title ~ \" - \" ~ page.title %} {% endif %} < meta name = \"twitter:card\" content = \"summary_large_image\" /> < meta name = \"twitter:title\" content = \"{{ title }}\" /> < meta name = \"twitter:description\" content = \"{{ config.site_description }}\" /> < meta name = \"twitter:image\" content = \"<url>\" /> {% endblock %}","title":"Meta tags"},{"location":"setup/setting-up-social-cards/#usage","text":"If you want to adjust the title or set a custom description for the social card, you can set the front matter title and description properties, which take precedence over the default values. Changing the title Changing the description Both types of logos, images ( theme.logo ) and icons ( theme.icon.logo ) are supported. While an image logo is used as-is, icons are filled with the color used in the header (white or black), which depends on the primary color. \u21a9","title":"Usage"},{"location":"setup/setting-up-tags/","text":"Setting up tags \u00b6 Material for MkDocs adds first-class support for categorizing pages with tags, which adds the possibility to group related pages and make them discoverable via search and a dedicated tags index . If your documentation is large, tags can help to discover relevant information faster. Configuration \u00b6 Built-in tags plugin \u00b6 8.2.0 \u00b7 Plugin \u00b7 Experimental The built-in tags plugin adds the ability to categorize any page with tags as part of the front matter of the page. In order to add support for tags, add the following lines to mkdocs.yml : plugins : - tags The following configuration options are available: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable : plugins : - tags : enabled : !ENV [ CI , false ] tags_file Default: none \u2013 This option specifies which page should be used to render the tags index. See the section on adding a tags index for more information. If this option is specified, tags become clickable, pointing to the corresponding section in the tags index: plugins : - tags : tags_file : tags.md The page holding the tags index can be linked anywhere in the nav section of mkdocs.yml . Note, however, that this options is not required \u2013 only use it if you want a tags index page. tags_extra_files insiders-4.20.0 \u00b7 Default: none \u2013 This option specifies additional pages, i.e. to render subsets of the tags index , in order to provide scoped tags indexes for specific sections: plugins : - tags : tags_extra_files : compatibility.md : - compat # (1)! web.md : - html - js - css Each page can be assigned a list of tag identifiers , which must be defined as part of extra.tags in mkdocs.yml : extra : tags : Compatibility : compat HTML5 : html JavaScript : js CSS : css In this example, all pages with the tag Compatibility will be included in the additional tags index on compatibility.md , all pages defining at least one of the tags HTML5 , JavaScript or CSS will be included in the additional tags index on web.md . Note that the values listed under each tags extra file must be alphanumeric tag identifiers , not tags themselves. See #3864 for more information. tags_slugify insiders-4.25.0 \u00b7 Default: headerid.slugify \u2013 This option specifies which function to use for generating URL-compatible slugs from tags. Python Markdown Extensions includes several Unicode-aware slug functions which are a good choice for non-ASCII languages: Unicode Unicode, case-sensitive plugins : - tags : tags_slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower plugins : - tags : tags_slugify : !!python/object/apply:pymdownx.slugs.slugify tags_slugify_separator insiders-4.25.0 \u00b7 Default: - \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string: plugins : - tags : tags_slugify_separator : \"-\" tags_compare insiders-4.26.2 \u00b7 Default: None \u2013 This option specifies which function to use when comparing tag values for sorting. If you wish to compare tags irregardless of casing, use: plugins : - tags : tags_compare : !!python/name:material.plugins.tags.plugin.casefold You can also define your own comparison function which must return a tag value (as a string) that is used for sorting, and reference it accordingly. tags_compare_reverse insiders-4.26.2 \u00b7 Default: false \u2013 This option specifies whether tags are sorted in reverse order. It is mainly provided for completeness. To change direction, use: plugins : - tags : tags_compare_reverse : true tags_allowed insiders-4.25.0 \u00b7 Default: none \u2013 This option allows the author to define explicitly which tags are allowed to be used on pages. If this setting is omitted, the built-in tags plugin won't check tag names. Use this option to define a list of tags in order to catch typos: plugins : - tags : tags_allowed : - HTML5 - JavaScript - CSS Tag icons and identifiers \u00b6 8.5.0 \u00b7 Experimental Each tag can be associated with an icon, which is then rendered inside the tag. Before assigning icons to tags, associate each tag with a unique identifier, by adding the following to mkdocs.yml : extra : tags : <tag> : <identifier> # (1)! The identifier can only include alphanumeric characters, as well as dashes and underscores. For example, if you have a tag Compatibility , you can set compat as an identifier: extra : tags : Compatibility : compat Identifiers can be reused between tags. Tags which are not explicitly associated will use the default tag icon which is Next, each identifier can be associated with an icon, even a custom icon , by adding the following lines to mkdocs.yml under the theme.icon configuration setting: Tag icon Tag default icon theme : icon : tag : <identifier> : <icon> # (1)! Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: theme : icon : tag : default : <icon> Expand to inspect example theme : icon : tag : html : fontawesome/brands/html5 js : fontawesome/brands/js css : fontawesome/brands/css3 extra : tags : HTML5 : html JavaScript : js CSS : css Usage \u00b6 Adding tags \u00b6 When the built-in tags plugin is enabled, tags can be added for a document with the front matter tags property. Add the following lines at the top of a Markdown file: --- tags: - HTML5 - JavaScript - CSS --- ... The page will now render with those tags above the main headline and within the search preview, which now allows to find pages by tags . How to set tags for an entire folder? With the help of the built-in meta plugin , you can ensure that tags are set for an entire section and all nested pages, by creating a .meta.yml file in the corresponding folder with the following content: tags : - HTML5 - JavaScript - CSS The tags set in .meta.yml are merged and deduplicated with the tags defined for a page, which means you can define common tags in .meta.yml and then add specific tags for each page. The tags in .meta.yml are appended. Adding a tags index \u00b6 The built-in tags plugin allows to define a file to render a tags index , which can be any page that is part of the nav section. To add a tags index, create a page, e.g. tags.md : # Tags Following is a list of relevant tags: [TAGS] The [TAGS] marker specifies the position of the tags index, i.e. it is replaced with the actual tags index when the page is rendered. You can include arbitrary content before and after the marker: Hiding tags on a page \u00b6 While the tags are rendered above the main headline, sometimes, it might be desirable to hide them for a specific page, which can be achieved with the front matter hide property: --- hide : - tags --- # Document title ...","title":"Setting up tags"},{"location":"setup/setting-up-tags/#setting-up-tags","text":"Material for MkDocs adds first-class support for categorizing pages with tags, which adds the possibility to group related pages and make them discoverable via search and a dedicated tags index . If your documentation is large, tags can help to discover relevant information faster.","title":"Setting up tags"},{"location":"setup/setting-up-tags/#configuration","text":"","title":"Configuration"},{"location":"setup/setting-up-tags/#built-in-tags-plugin","text":"8.2.0 \u00b7 Plugin \u00b7 Experimental The built-in tags plugin adds the ability to categorize any page with tags as part of the front matter of the page. In order to add support for tags, add the following lines to mkdocs.yml : plugins : - tags The following configuration options are available: enabled Default: true \u2013 This option specifies whether the plugin is enabled when building your project. If you want to speed up local builds, you can use an environment variable : plugins : - tags : enabled : !ENV [ CI , false ] tags_file Default: none \u2013 This option specifies which page should be used to render the tags index. See the section on adding a tags index for more information. If this option is specified, tags become clickable, pointing to the corresponding section in the tags index: plugins : - tags : tags_file : tags.md The page holding the tags index can be linked anywhere in the nav section of mkdocs.yml . Note, however, that this options is not required \u2013 only use it if you want a tags index page. tags_extra_files insiders-4.20.0 \u00b7 Default: none \u2013 This option specifies additional pages, i.e. to render subsets of the tags index , in order to provide scoped tags indexes for specific sections: plugins : - tags : tags_extra_files : compatibility.md : - compat # (1)! web.md : - html - js - css Each page can be assigned a list of tag identifiers , which must be defined as part of extra.tags in mkdocs.yml : extra : tags : Compatibility : compat HTML5 : html JavaScript : js CSS : css In this example, all pages with the tag Compatibility will be included in the additional tags index on compatibility.md , all pages defining at least one of the tags HTML5 , JavaScript or CSS will be included in the additional tags index on web.md . Note that the values listed under each tags extra file must be alphanumeric tag identifiers , not tags themselves. See #3864 for more information. tags_slugify insiders-4.25.0 \u00b7 Default: headerid.slugify \u2013 This option specifies which function to use for generating URL-compatible slugs from tags. Python Markdown Extensions includes several Unicode-aware slug functions which are a good choice for non-ASCII languages: Unicode Unicode, case-sensitive plugins : - tags : tags_slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower plugins : - tags : tags_slugify : !!python/object/apply:pymdownx.slugs.slugify tags_slugify_separator insiders-4.25.0 \u00b7 Default: - \u2013 This option specifies the separator which is used by the slug function. By default, a hyphen is used, but it can be changed to any string: plugins : - tags : tags_slugify_separator : \"-\" tags_compare insiders-4.26.2 \u00b7 Default: None \u2013 This option specifies which function to use when comparing tag values for sorting. If you wish to compare tags irregardless of casing, use: plugins : - tags : tags_compare : !!python/name:material.plugins.tags.plugin.casefold You can also define your own comparison function which must return a tag value (as a string) that is used for sorting, and reference it accordingly. tags_compare_reverse insiders-4.26.2 \u00b7 Default: false \u2013 This option specifies whether tags are sorted in reverse order. It is mainly provided for completeness. To change direction, use: plugins : - tags : tags_compare_reverse : true tags_allowed insiders-4.25.0 \u00b7 Default: none \u2013 This option allows the author to define explicitly which tags are allowed to be used on pages. If this setting is omitted, the built-in tags plugin won't check tag names. Use this option to define a list of tags in order to catch typos: plugins : - tags : tags_allowed : - HTML5 - JavaScript - CSS","title":"Built-in tags plugin"},{"location":"setup/setting-up-tags/#tag-icons-and-identifiers","text":"8.5.0 \u00b7 Experimental Each tag can be associated with an icon, which is then rendered inside the tag. Before assigning icons to tags, associate each tag with a unique identifier, by adding the following to mkdocs.yml : extra : tags : <tag> : <identifier> # (1)! The identifier can only include alphanumeric characters, as well as dashes and underscores. For example, if you have a tag Compatibility , you can set compat as an identifier: extra : tags : Compatibility : compat Identifiers can be reused between tags. Tags which are not explicitly associated will use the default tag icon which is Next, each identifier can be associated with an icon, even a custom icon , by adding the following lines to mkdocs.yml under the theme.icon configuration setting: Tag icon Tag default icon theme : icon : tag : <identifier> : <icon> # (1)! Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: theme : icon : tag : default : <icon> Expand to inspect example theme : icon : tag : html : fontawesome/brands/html5 js : fontawesome/brands/js css : fontawesome/brands/css3 extra : tags : HTML5 : html JavaScript : js CSS : css","title":"Tag icons and identifiers"},{"location":"setup/setting-up-tags/#usage","text":"","title":"Usage"},{"location":"setup/setting-up-tags/#adding-tags","text":"When the built-in tags plugin is enabled, tags can be added for a document with the front matter tags property. Add the following lines at the top of a Markdown file: --- tags: - HTML5 - JavaScript - CSS --- ... The page will now render with those tags above the main headline and within the search preview, which now allows to find pages by tags . How to set tags for an entire folder? With the help of the built-in meta plugin , you can ensure that tags are set for an entire section and all nested pages, by creating a .meta.yml file in the corresponding folder with the following content: tags : - HTML5 - JavaScript - CSS The tags set in .meta.yml are merged and deduplicated with the tags defined for a page, which means you can define common tags in .meta.yml and then add specific tags for each page. The tags in .meta.yml are appended.","title":"Adding tags"},{"location":"setup/setting-up-tags/#adding-a-tags-index","text":"The built-in tags plugin allows to define a file to render a tags index , which can be any page that is part of the nav section. To add a tags index, create a page, e.g. tags.md : # Tags Following is a list of relevant tags: [TAGS] The [TAGS] marker specifies the position of the tags index, i.e. it is replaced with the actual tags index when the page is rendered. You can include arbitrary content before and after the marker:","title":"Adding a tags index"},{"location":"setup/setting-up-tags/#hiding-tags-on-a-page","text":"While the tags are rendered above the main headline, sometimes, it might be desirable to hide them for a specific page, which can be achieved with the front matter hide property: --- hide : - tags --- # Document title ...","title":"Hiding tags on a page"},{"location":"setup/setting-up-the-footer/","text":"Setting up the footer \u00b6 The footer of your project documentation is a great place to add links to websites or platforms you or your company are using as additional marketing channels, e.g. or , which you can easily configure via mkdocs.yml . Configuration \u00b6 Social links \u00b6 1.0.0 \u00b7 Default: none Social links are rendered next to the copyright notice as part of the footer of your project documentation. Add a list of social links in mkdocs.yml with: extra : social : - icon : fontawesome/brands/twitter # (1)! link : https://twitter.com/squidfunk Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: The following properties are available for each link: icon Default: none \u00b7 Required \u2013 This property must contain a valid path to any icon bundled with the theme, or the build will not succeed. Some popular choices: \u2013 fontawesome/brands/docker \u2013 fontawesome/brands/facebook \u2013 fontawesome/brands/github \u2013 fontawesome/brands/instagram \u2013 fontawesome/brands/linkedin \u2013 fontawesome/brands/medium \u2013 fontawesome/brands/pied-piper-alt \u2013 fontawesome/brands/product-hunt \u2013 fontawesome/brands/slack \u2013 fontawesome/brands/twitter link Default: none \u00b7 Required \u2013 This property must be set to a relative or absolute URL including the URI scheme. All URI schemes are supported, including mailto and bitcoin : Twitter Email extra : social : - icon : fontawesome/brands/twitter link : https://twitter.com/squidfunk extra : social : - icon : fontawesome/solid/paper-plane link : mailto:<email-address> name Default: domain name from link , if available \u2013 This property is used as the link's title attribute and can be set to a discernable name to improve accessibility: extra : social : - icon : fontawesome/brands/twitter link : https://twitter.com/squidfunk name : squidfunk on Twitter Copyright notice \u00b6 0.1.0 \u00b7 Default: none A custom copyright banner can be rendered as part of the footer, which is displayed next to the social links. It can be defined as part of mkdocs.yml : copyright : Copyright &copy; 2016 - 2020 Martin Donath Generator notice \u00b6 7.3.0 \u00b7 Default: true The footer displays a Made with Material for MkDocs notice to denote how the site was generated. The notice can be removed with the following option via mkdocs.yml : extra : generator : false Please read this before removing the generator notice The subtle Made with Material for MkDocs hint in the footer is one of the reasons why this project is so popular, as it tells the user how the site is generated, helping new users to discover this project. Before removing please consider that you're enjoying the benefits of @squidfunk 's work for free, as this project is Open Source and has a permissive license. Thousands of hours went into this project, most of them without any financial return. Thus, if you remove this notice, please consider sponsoring the project. Thank you Usage \u00b6 Hiding prev/next links \u00b6 The footer navigation showing links to the previous and next page can be hidden with the front matter hide property. Add the following lines at the top of a Markdown file: --- hide : - footer --- # Document title ... Customization \u00b6 Custom copyright \u00b6 8.0.0 \u00b7 Customization In order to customize and override the copyright notice , extend the theme and override the copyright.html partial , which normally includes the copyright property set in mkdocs.yml .","title":"Setting up the footer"},{"location":"setup/setting-up-the-footer/#setting-up-the-footer","text":"The footer of your project documentation is a great place to add links to websites or platforms you or your company are using as additional marketing channels, e.g. or , which you can easily configure via mkdocs.yml .","title":"Setting up the footer"},{"location":"setup/setting-up-the-footer/#configuration","text":"","title":"Configuration"},{"location":"setup/setting-up-the-footer/#social-links","text":"1.0.0 \u00b7 Default: none Social links are rendered next to the copyright notice as part of the footer of your project documentation. Add a list of social links in mkdocs.yml with: extra : social : - icon : fontawesome/brands/twitter # (1)! link : https://twitter.com/squidfunk Enter a few keywords to find the perfect icon using our icon search and click on the shortcode to copy it to your clipboard: The following properties are available for each link: icon Default: none \u00b7 Required \u2013 This property must contain a valid path to any icon bundled with the theme, or the build will not succeed. Some popular choices: \u2013 fontawesome/brands/docker \u2013 fontawesome/brands/facebook \u2013 fontawesome/brands/github \u2013 fontawesome/brands/instagram \u2013 fontawesome/brands/linkedin \u2013 fontawesome/brands/medium \u2013 fontawesome/brands/pied-piper-alt \u2013 fontawesome/brands/product-hunt \u2013 fontawesome/brands/slack \u2013 fontawesome/brands/twitter link Default: none \u00b7 Required \u2013 This property must be set to a relative or absolute URL including the URI scheme. All URI schemes are supported, including mailto and bitcoin : Twitter Email extra : social : - icon : fontawesome/brands/twitter link : https://twitter.com/squidfunk extra : social : - icon : fontawesome/solid/paper-plane link : mailto:<email-address> name Default: domain name from link , if available \u2013 This property is used as the link's title attribute and can be set to a discernable name to improve accessibility: extra : social : - icon : fontawesome/brands/twitter link : https://twitter.com/squidfunk name : squidfunk on Twitter","title":"Social links"},{"location":"setup/setting-up-the-footer/#copyright-notice","text":"0.1.0 \u00b7 Default: none A custom copyright banner can be rendered as part of the footer, which is displayed next to the social links. It can be defined as part of mkdocs.yml : copyright : Copyright &copy; 2016 - 2020 Martin Donath","title":"Copyright notice"},{"location":"setup/setting-up-the-footer/#generator-notice","text":"7.3.0 \u00b7 Default: true The footer displays a Made with Material for MkDocs notice to denote how the site was generated. The notice can be removed with the following option via mkdocs.yml : extra : generator : false Please read this before removing the generator notice The subtle Made with Material for MkDocs hint in the footer is one of the reasons why this project is so popular, as it tells the user how the site is generated, helping new users to discover this project. Before removing please consider that you're enjoying the benefits of @squidfunk 's work for free, as this project is Open Source and has a permissive license. Thousands of hours went into this project, most of them without any financial return. Thus, if you remove this notice, please consider sponsoring the project. Thank you","title":"Generator notice"},{"location":"setup/setting-up-the-footer/#usage","text":"","title":"Usage"},{"location":"setup/setting-up-the-footer/#hiding-prevnext-links","text":"The footer navigation showing links to the previous and next page can be hidden with the front matter hide property. Add the following lines at the top of a Markdown file: --- hide : - footer --- # Document title ...","title":"Hiding prev/next links"},{"location":"setup/setting-up-the-footer/#customization","text":"","title":"Customization"},{"location":"setup/setting-up-the-footer/#custom-copyright","text":"8.0.0 \u00b7 Customization In order to customize and override the copyright notice , extend the theme and override the copyright.html partial , which normally includes the copyright property set in mkdocs.yml .","title":"Custom copyright"},{"location":"setup/setting-up-the-header/","text":"Setting up the header \u00b6 Material for MkDocs' header can be customized to show an announcement bar that disappears upon scrolling, and provides some options for further configuration. It also includes the search bar and a place to display your project's git repository , as explained in those dedicated guides. Configuration \u00b6 Automatic hiding \u00b6 6.2.0 \u00b7 Feature flag When autohiding is enabled, the header is automatically hidden when the user scrolls past a certain threshold, leaving more space for content. Add the following lines to mkdocs.yml : theme : features : - header.autohide Announcement bar \u00b6 5.0.0 \u00b7 Customization Material for MkDocs includes an announcement bar, which is the perfect place to display project news or other important information to the user. When the user scrolls past the header, the bar will automatically disappear. In order to add an announcement bar, extend the theme and override the announce block , which is empty by default: {% extends \"base.html\" %} {% block announce %} <!-- Add announcement here, including arbitrary HTML --> {% endblock %} Mark as read \u00b6 8.4.0 \u00b7 Feature flag \u00b7 Experimental In order to render temporary announcements that can be marked as read by the user, a button to dismiss the current announcement can be included. Add the following lines to mkdocs.yml : theme : features : - announce.dismiss When the user clicks the button, the current announcement is dismissed and not displayed again until the content of the announcement changes. This is handled automatically. Scroll to the top of this page to see it in action.","title":"Setting up the header"},{"location":"setup/setting-up-the-header/#setting-up-the-header","text":"Material for MkDocs' header can be customized to show an announcement bar that disappears upon scrolling, and provides some options for further configuration. It also includes the search bar and a place to display your project's git repository , as explained in those dedicated guides.","title":"Setting up the header"},{"location":"setup/setting-up-the-header/#configuration","text":"","title":"Configuration"},{"location":"setup/setting-up-the-header/#automatic-hiding","text":"6.2.0 \u00b7 Feature flag When autohiding is enabled, the header is automatically hidden when the user scrolls past a certain threshold, leaving more space for content. Add the following lines to mkdocs.yml : theme : features : - header.autohide","title":"Automatic hiding"},{"location":"setup/setting-up-the-header/#announcement-bar","text":"5.0.0 \u00b7 Customization Material for MkDocs includes an announcement bar, which is the perfect place to display project news or other important information to the user. When the user scrolls past the header, the bar will automatically disappear. In order to add an announcement bar, extend the theme and override the announce block , which is empty by default: {% extends \"base.html\" %} {% block announce %} <!-- Add announcement here, including arbitrary HTML --> {% endblock %}","title":"Announcement bar"},{"location":"setup/setting-up-the-header/#mark-as-read","text":"8.4.0 \u00b7 Feature flag \u00b7 Experimental In order to render temporary announcements that can be marked as read by the user, a button to dismiss the current announcement can be included. Add the following lines to mkdocs.yml : theme : features : - announce.dismiss When the user clicks the button, the current announcement is dismissed and not displayed again until the content of the announcement changes. This is handled automatically. Scroll to the top of this page to see it in action.","title":"Mark as read"},{"location":"setup/setting-up-versioning/","text":"Setting up versioning \u00b6 Material for MkDocs makes it easy to deploy multiple versions of your project documentation by integrating with external utilities that add those capabilities to MkDocs, i.e. mike . When deploying a new version, older versions of your documentation remain untouched. Configuration \u00b6 Versioning \u00b6 7.0.0 \u00b7 Utility mike makes it easy to deploy multiple versions of your project documentation. It integrates natively with Material for MkDocs and can be enabled via mkdocs.yml : extra : version : provider : mike This renders a version selector in the header: Check out the versioning example to see it in action \u2013 squidfunk.github.io/mkdocs-material-example-versioning Why use mike? mike is built around the idea that once you've generated your docs for a particular version, you should never need to touch that version again. This means you never have to worry about breaking changes in MkDocs, since your old docs (built with an old version of MkDocs) are already generated and sitting in your gh-pages branch. While mike is flexible, it's optimized around putting your docs in a <major>.<minor> directory, with optional aliases (e.g. latest or dev ) to particularly notable versions. This makes it easy to make permalinks to whatever version of the documentation you want to direct people to. Version warning \u00b6 8.0.0 \u00b7 Customization If you're using versioning, you might want to display a warning when the user visits any other version than the latest version. Using theme extension , you can override the outdated block : {% extends \"base.html\" %} {% block outdated %} You're not viewing the latest version. < a href = \"{{ '../' ~ base_url }}\" > <!-- (1)! --> < strong > Click here to go to latest. </ strong > </ a > {% endblock %} Given this value for the href attribute, the link will always redirect to the root of your site, which will then redirect to the latest version. This ensures that older versions of your site do not depend on a specific alias, e.g. latest , to allow for changing the alias later on without breaking earlier versions. This will render a version warning above the header: The default version is identified by the latest alias. If you wish to set another alias as the latest version, e.g. stable , add the following lines to mkdocs.yml : extra : version : default : stable Make sure that this matches the default version . Usage \u00b6 While this section outlines the basic workflow for publishing new versions, it's best to check out mike's documentation to make yourself familar with its mechanics. Publishing a new version \u00b6 If you want to publish a new version of your project documentation, choose a version identifier and update the alias set as the default version with: mike deploy --push --update-aliases 0.1 latest Note that every version will be deployed as a subdirectory of your site_url , e.g.: docs.example.com/0.1/ docs.example.com/0.2/ ... Setting a default version \u00b6 When starting with mike , a good idea is to set an alias as a default version, e.g. latest , and when publishing a new version, always update the alias to point to the latest version: mike set-default --push latest When publishing a new version, mike will create a redirect in the root of your project documentation to the version associated with the alias: docs.example.com docs.example.com/0.1","title":"Setting up versioning"},{"location":"setup/setting-up-versioning/#setting-up-versioning","text":"Material for MkDocs makes it easy to deploy multiple versions of your project documentation by integrating with external utilities that add those capabilities to MkDocs, i.e. mike . When deploying a new version, older versions of your documentation remain untouched.","title":"Setting up versioning"},{"location":"setup/setting-up-versioning/#configuration","text":"","title":"Configuration"},{"location":"setup/setting-up-versioning/#versioning","text":"7.0.0 \u00b7 Utility mike makes it easy to deploy multiple versions of your project documentation. It integrates natively with Material for MkDocs and can be enabled via mkdocs.yml : extra : version : provider : mike This renders a version selector in the header: Check out the versioning example to see it in action \u2013 squidfunk.github.io/mkdocs-material-example-versioning Why use mike? mike is built around the idea that once you've generated your docs for a particular version, you should never need to touch that version again. This means you never have to worry about breaking changes in MkDocs, since your old docs (built with an old version of MkDocs) are already generated and sitting in your gh-pages branch. While mike is flexible, it's optimized around putting your docs in a <major>.<minor> directory, with optional aliases (e.g. latest or dev ) to particularly notable versions. This makes it easy to make permalinks to whatever version of the documentation you want to direct people to.","title":"Versioning"},{"location":"setup/setting-up-versioning/#version-warning","text":"8.0.0 \u00b7 Customization If you're using versioning, you might want to display a warning when the user visits any other version than the latest version. Using theme extension , you can override the outdated block : {% extends \"base.html\" %} {% block outdated %} You're not viewing the latest version. < a href = \"{{ '../' ~ base_url }}\" > <!-- (1)! --> < strong > Click here to go to latest. </ strong > </ a > {% endblock %} Given this value for the href attribute, the link will always redirect to the root of your site, which will then redirect to the latest version. This ensures that older versions of your site do not depend on a specific alias, e.g. latest , to allow for changing the alias later on without breaking earlier versions. This will render a version warning above the header: The default version is identified by the latest alias. If you wish to set another alias as the latest version, e.g. stable , add the following lines to mkdocs.yml : extra : version : default : stable Make sure that this matches the default version .","title":"Version warning"},{"location":"setup/setting-up-versioning/#usage","text":"While this section outlines the basic workflow for publishing new versions, it's best to check out mike's documentation to make yourself familar with its mechanics.","title":"Usage"},{"location":"setup/setting-up-versioning/#publishing-a-new-version","text":"If you want to publish a new version of your project documentation, choose a version identifier and update the alias set as the default version with: mike deploy --push --update-aliases 0.1 latest Note that every version will be deployed as a subdirectory of your site_url , e.g.: docs.example.com/0.1/ docs.example.com/0.2/ ...","title":"Publishing a new version"},{"location":"setup/setting-up-versioning/#setting-a-default-version","text":"When starting with mike , a good idea is to set an alias as a default version, e.g. latest , and when publishing a new version, always update the alias to point to the latest version: mike set-default --push latest When publishing a new version, mike will create a redirect in the root of your project documentation to the version associated with the alias: docs.example.com docs.example.com/0.1","title":"Setting a default version"},{"location":"setup/extensions/","text":"Extensions \u00b6 Markdown is a very small language with a kind-of reference implementation called John Gruber's Markdown . Python Markdown and Python Markdown Extensions are two packages that enhance the Markdown writing experience, adding useful syntax extensions for technical writing. Supported extensions \u00b6 The following extensions are all supported by Material for MkDocs and therefore strongly recommended. Click on each extension to learn about its purpose and configuration: Abbreviations Admonition Arithmatex Attribute Lists BetterEm Caret, Mark & Tilde Critic Definition Lists Details Emoji Footnotes Highlight Keys Markdown in HTML SmartSymbols Snippets SuperFences Tabbed Table of Contents Tables Tasklist Configuration \u00b6 Extensions are configured as part of mkdocs.yml \u2013 the MkDocs configuration file. The following sections contain two example configurations to bootstrap your documentation project. Minimal configuration \u00b6 This configuration is a good starting point for when you're using Material for MkDocs for the first time. The best idea is to explore the reference , and gradually add what you want to use: markdown_extensions : # Python Markdown - toc : permalink : true # Python Markdown Extensions - pymdownx.highlight - pymdownx.superfences Recommended configuration \u00b6 This configuration enables all Markdown-related features of Material for MkDocs and is great for experienced users bootstrapping a new documentation project: markdown_extensions : # Python Markdown - abbr - admonition - attr_list - def_list - footnotes - md_in_html - toc : permalink : true # Python Markdown Extensions - pymdownx.arithmatex : generic : true - pymdownx.betterem : smart_enable : all - pymdownx.caret - pymdownx.details - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator : !!python/name:materialx.emoji.to_svg - pymdownx.highlight - pymdownx.inlinehilite - pymdownx.keys - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tabbed : alternate_style : true - pymdownx.tasklist : custom_checkbox : true - pymdownx.tilde","title":"Extensions"},{"location":"setup/extensions/#extensions","text":"Markdown is a very small language with a kind-of reference implementation called John Gruber's Markdown . Python Markdown and Python Markdown Extensions are two packages that enhance the Markdown writing experience, adding useful syntax extensions for technical writing.","title":"Extensions"},{"location":"setup/extensions/#supported-extensions","text":"The following extensions are all supported by Material for MkDocs and therefore strongly recommended. Click on each extension to learn about its purpose and configuration: Abbreviations Admonition Arithmatex Attribute Lists BetterEm Caret, Mark & Tilde Critic Definition Lists Details Emoji Footnotes Highlight Keys Markdown in HTML SmartSymbols Snippets SuperFences Tabbed Table of Contents Tables Tasklist","title":"Supported extensions"},{"location":"setup/extensions/#configuration","text":"Extensions are configured as part of mkdocs.yml \u2013 the MkDocs configuration file. The following sections contain two example configurations to bootstrap your documentation project.","title":"Configuration"},{"location":"setup/extensions/#minimal-configuration","text":"This configuration is a good starting point for when you're using Material for MkDocs for the first time. The best idea is to explore the reference , and gradually add what you want to use: markdown_extensions : # Python Markdown - toc : permalink : true # Python Markdown Extensions - pymdownx.highlight - pymdownx.superfences","title":"Minimal configuration"},{"location":"setup/extensions/#recommended-configuration","text":"This configuration enables all Markdown-related features of Material for MkDocs and is great for experienced users bootstrapping a new documentation project: markdown_extensions : # Python Markdown - abbr - admonition - attr_list - def_list - footnotes - md_in_html - toc : permalink : true # Python Markdown Extensions - pymdownx.arithmatex : generic : true - pymdownx.betterem : smart_enable : all - pymdownx.caret - pymdownx.details - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator : !!python/name:materialx.emoji.to_svg - pymdownx.highlight - pymdownx.inlinehilite - pymdownx.keys - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tabbed : alternate_style : true - pymdownx.tasklist : custom_checkbox : true - pymdownx.tilde","title":"Recommended configuration"},{"location":"setup/extensions/python-markdown-extensions/","text":"Python Markdown Extensions \u00b6 The Python Markdown Extensions package is an excellent collection of additional extensions perfectly suited for advanced technical writing. Material for MkDocs lists this package as an explicit dependency, so it's automatically installed with a supported version. Supported extensions \u00b6 In general, all extensions that are part of Python Markdown Extensions should work with Material for MkDocs. The following list includes all extensions that are natively supported, meaning they work without any further adjustments. Arithmatex \u00b6 1.0.0 \u00b7 Extension The Arithmatex extension allows for rendering of block and inline block equations and integrates seamlessly with MathJax 1 \u2013 a library for mathematical typesetting. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.arithmatex : generic : true Besides enabling the extension in mkdocs.yml , a MathJax configuration and the JavaScript runtime need to be included, which can be done with a few lines of additional JavaScript : docs/javascripts/mathjax.js mkdocs.yml window . MathJax = { tex : { inlineMath : [[ \"\\\\(\" , \"\\\\)\" ]], displayMath : [[ \"\\\\[\" , \"\\\\]\" ]], processEscapes : true , processEnvironments : true }, options : { ignoreHtmlClass : \".*|\" , processHtmlClass : \"arithmatex\" } }; document $ . subscribe (() => { MathJax . typesetPromise () }) extra_javascript : - javascripts/mathjax.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Using block syntax Using inline block syntax BetterEm \u00b6 0.1.0 \u00b7 Extension The BetterEm extension improves the detection of Markup to emphasize text in Markdown using special characters, i.e. for **bold** and _italic_ formatting. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.betterem The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the BetterEm documentation for more information. Caret, Mark & Tilde \u00b6 1.0.0 \u00b7 Extension The Caret , Mark and Tilde extensions add the ability to highlight text and define sub- and superscript using a simple syntax. Enable them together via mkdocs.yml : markdown_extensions : - pymdownx.caret - pymdownx.mark - pymdownx.tilde The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the Caret , Mark and Tilde documentation for guidance. See reference for usage: Highlighting text Sub- and superscripts Critic \u00b6 1.0.0 \u00b7 Extension The Critic extension allows for the usage of Critic Markup to highlight added, deleted or updated sections in a document, i.e. for tracking changes in Markdown syntax. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.critic The following configuration options are supported: mode Default: view \u2013 This option defines how the markup should be parsed, i.e. whether to just view all suggested changes, or alternatively accept or reject them: View changes Accept changes Reject changes markdown_extensions : - pymdownx.critic : mode : view markdown_extensions : - pymdownx.critic : mode : accept markdown_extensions : - pymdownx.critic : mode : reject See reference for usage: Highlighting changes Details \u00b6 1.9.0 \u00b7 Extension The Details extension supercharges the Admonition extension, making the resulting call-outs collapsible, allowing them to be opened and closed by the user. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.details No configuration options are available. See reference for usage: Collapsible blocks Emoji \u00b6 1.0.0 \u00b7 Extension The Emoji extension automatically inlines bundled and custom icons and emojis in *.svg file format into the resulting HTML page. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji # (1)! emoji_generator : !!python/name:materialx.emoji.to_svg Python Markdown Extensions uses the pymdownx namespace, but in order to support the inlining of icons, the materialx namespace must be used, as it extends the functionality of pymdownx . The following configuration options are supported: emoji_index Default: emojione \u2013 This option defines which set of emojis is used for rendering. Note that the use of emojione is not recommended due to restrictions in licensing : markdown_extensions : - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator Default: to_png \u2013 This option defines how the resolved emoji or icon shortcode is render. Note that icons can only be used together with the to_svg configuration: markdown_extensions : - pymdownx.emoji : emoji_generator : !!python/name:materialx.emoji.to_svg options.custom_icons Default: none \u2013 This option allows to list folders with additional icon sets to be used in Markdown or mkdocs.yml , which is explained in more detail in the icon customization guide : markdown_extensions : - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator : !!python/name:materialx.emoji.to_svg options : custom_icons : - overrides/.icons The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Using emojis Using icons Using icons in templates Highlight \u00b6 5.0.0 \u00b7 Extension \u00b7 Supersedes CodeHilite The Highlight extension adds support for syntax highlighting of code blocks (with the help of SuperFences ) and inline code blocks (with the help of InlineHilite ). Enable it via mkdocs.yml : markdown_extensions : - pymdownx.highlight : anchor_linenums : true - pymdownx.superfences # (1)! Highlight is used by the SuperFences extension to perform syntax highlighting on code blocks, not the other way round, which is why this extension also needs to be enabled. The following configuration options are supported: use_pygments Default: true \u2013 This option allows to control whether highlighting should be carried out during build time using Pygments or in the browser with a JavaScript syntax highlighter: Pygments JavaScript markdown_extensions : - pymdownx.highlight : use_pygments : true - pymdownx.superfences markdown_extensions : - pymdownx.highlight : use_pygments : false As an example, Highlight.js , a JavaScript syntax highlighter, can be integrated with some additional JavaScript and an additional style sheet in mkdocs.yml : docs/javascripts/highlight.js mkdocs.yml document $ . subscribe (() => { hljs . highlightAll () }) extra_javascript : - https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js - javascripts/highlight.js extra_css : - https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/styles/default.min.css Note that Highlight.js has no affiliation with the Highlight extension. All following configuration options are only compatible with build-time syntax highlighting using Pygments , so they don't apply if use_pygments is set to false . auto_title Default: false \u2013 This option will automatically add a title to all code blocks that shows the name of the language being used, e.g. Python is printed for a py block: markdown_extensions : - pymdownx.highlight : auto_title : true linenums Default: false \u2013 This option will add line numbers to all code blocks. If you wish to add line numbers to some , but not all code blocks, consult the section on adding line numbers in the code block reference, which also contains some tips on working with line numbers: markdown_extensions : - pymdownx.highlight : linenums : true linenums_style Default: table \u2013 The Highlight extension provides three ways to add line numbers, two of which are supported by Material for MkDocs. While table wraps a code block in a <table> element, pymdownx-inline renders line numbers as part of the line itself: markdown_extensions : - pymdownx.highlight : linenums_style : pymdownx-inline Note that inline will put line numbers next to the actual code, which means that they will be included when selecting text with the cursor or copying a code block to the clipboard. Thus, the usage of either table or pymdownx-inline is recommended. anchor_linenums 8.1.0 \u00b7 Default: false \u2013 If a code blocks contains line numbers, enabling this setting will wrap them with anchor links, so they can be hyperlinked and shared more easily: markdown_extensions : - pymdownx.highlight : anchor_linenums : true The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Using code blocks Adding a title Adding line numbers Highlighting specific lines Custom syntax theme InlineHilite \u00b6 5.0.0 \u00b7 Extension The InlineHilite extension add support for syntax highlighting of inline code blocks. It's built on top of the Highlight extension, from which it sources its configuration. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.highlight - pymdownx.inlinehilite The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. The only exception is the css_class option, which must not be changed. See the InlineHilite documentation for guidance. See reference for usage: Highlighting inline code blocks Keys \u00b6 1.0.0 \u00b7 Extension The Keys extension adds a simple syntax to allow for the rendering of keyboard keys and combinations, e.g. Ctrl + Alt + Del . Enable it via mkdocs.yml : markdown_extensions : - pymdownx.keys The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. The only exception is the class option, which must not be changed. See the Keys documentation for more information. See reference for usage: Adding keyboard keys SmartSymbols \u00b6 0.1.0 \u00b7 Extension The SmartSymbols extension converts some sequences of characters into their corresponding symbols, e.h. copyright symbols or fractions. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.smartsymbols The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the SmartSymbols documentation for guidance. Snippets \u00b6 0.1.0 \u00b7 Extension The Snippets extension adds the ability to embed content from arbitrary files into a document, including other documents or source files, by using a simple syntax. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.snippets The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the Snippets documentation for more information. See reference for usage: Adding a glossary Embedding external files SuperFences \u00b6 0.1.0 \u00b7 Extension \u00b7 Supersedes Fenced Code Blocks The SuperFences extension allows for arbitrary nesting of code and content blocks inside each other, including admonitions, tabs, lists and all other elements. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.superfences The following configuration options are supported: custom_fences Default: none \u2013 This option allows to define a handler for custom fences, e.g. to preserve the definitions of Mermaid.js diagrams to be interpreted in the browser: markdown_extensions : - pymdownx.superfences : custom_fences : - name : mermaid class : mermaid format : !!python/name:pymdownx.superfences.fence_code_format Note that this will primarily prevent syntax highlighting from being applied. See the reference on diagrams to learn how Mermaid.js is integrated with Material for MkDocs. The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Using annotations Using code blocks Using content tabs Using flowcharts Using sequence diagrams Using state diagrams Using class diagrams Using entity-relationship diagrams Tabbed \u00b6 5.0.0 \u00b7 Extension The Tabbed extension allows the usage of content tabs, a simple way to group related content and code blocks under accessible tabs. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.tabbed : alternate_style : true The following configuration options are supported: alternate_style 7.3.1 \u00b7 Default: false \u00b7 Required \u2013 This option enables the content tabs alternate style , which has better behavior on mobile viewports , and is the only supported style: markdown_extensions : - pymdownx.tabbed : alternate_style : true slugify Default: headerid.slugify \u2013 This option allows for customization of the slug function. For some languages, the default may not produce good and readable identifiers \u2013 consider using another slug function like for example those from Python Markdown Extensions : Unicode Unicode, case-sensitive markdown_extensions : - pymdownx.tabbed : slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower markdown_extensions : - pymdownx.tabbed : slugify : !!python/object/apply:pymdownx.slugs.slugify The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Grouping code blocks Grouping other content Embedded content Tasklist \u00b6 1.0.0 \u00b7 Extension The Tasklist extension allows for the usage of GitHub Flavored Markdown inspired task lists , following the same syntactical conventions. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.tasklist : custom_checkbox : true The following configuration options are supported: custom_checkbox Default: false \u00b7 This option toggles the rendering style of checkboxes, replacing native checkbox styles with beautiful icons, and is therefore recommended: markdown_extensions : - pymdownx.tasklist : custom_checkbox : true clickable_checkbox Default: false \u00b7 This option toggles whether checkboxes are clickable. As the state is not persisted, the use of this option is rather discouraged from a user experience perspective: markdown_extensions : - pymdownx.tasklist : clickable_checkbox : true The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Using task lists Other libraries like KaTeX are also supported and can be integrated with some additional effort. See the Arithmatex documentation on KaTeX for further guidance, as this is beyond the scope of Material for MkDocs. \u21a9","title":"Python Markdown Extensions"},{"location":"setup/extensions/python-markdown-extensions/#python-markdown-extensions","text":"The Python Markdown Extensions package is an excellent collection of additional extensions perfectly suited for advanced technical writing. Material for MkDocs lists this package as an explicit dependency, so it's automatically installed with a supported version.","title":"Python Markdown Extensions"},{"location":"setup/extensions/python-markdown-extensions/#supported-extensions","text":"In general, all extensions that are part of Python Markdown Extensions should work with Material for MkDocs. The following list includes all extensions that are natively supported, meaning they work without any further adjustments.","title":"Supported extensions"},{"location":"setup/extensions/python-markdown-extensions/#arithmatex","text":"1.0.0 \u00b7 Extension The Arithmatex extension allows for rendering of block and inline block equations and integrates seamlessly with MathJax 1 \u2013 a library for mathematical typesetting. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.arithmatex : generic : true Besides enabling the extension in mkdocs.yml , a MathJax configuration and the JavaScript runtime need to be included, which can be done with a few lines of additional JavaScript : docs/javascripts/mathjax.js mkdocs.yml window . MathJax = { tex : { inlineMath : [[ \"\\\\(\" , \"\\\\)\" ]], displayMath : [[ \"\\\\[\" , \"\\\\]\" ]], processEscapes : true , processEnvironments : true }, options : { ignoreHtmlClass : \".*|\" , processHtmlClass : \"arithmatex\" } }; document $ . subscribe (() => { MathJax . typesetPromise () }) extra_javascript : - javascripts/mathjax.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Using block syntax Using inline block syntax","title":"Arithmatex"},{"location":"setup/extensions/python-markdown-extensions/#betterem","text":"0.1.0 \u00b7 Extension The BetterEm extension improves the detection of Markup to emphasize text in Markdown using special characters, i.e. for **bold** and _italic_ formatting. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.betterem The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the BetterEm documentation for more information.","title":"BetterEm"},{"location":"setup/extensions/python-markdown-extensions/#caret-mark-tilde","text":"1.0.0 \u00b7 Extension The Caret , Mark and Tilde extensions add the ability to highlight text and define sub- and superscript using a simple syntax. Enable them together via mkdocs.yml : markdown_extensions : - pymdownx.caret - pymdownx.mark - pymdownx.tilde The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the Caret , Mark and Tilde documentation for guidance. See reference for usage: Highlighting text Sub- and superscripts","title":"Caret, Mark &amp; Tilde"},{"location":"setup/extensions/python-markdown-extensions/#critic","text":"1.0.0 \u00b7 Extension The Critic extension allows for the usage of Critic Markup to highlight added, deleted or updated sections in a document, i.e. for tracking changes in Markdown syntax. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.critic The following configuration options are supported: mode Default: view \u2013 This option defines how the markup should be parsed, i.e. whether to just view all suggested changes, or alternatively accept or reject them: View changes Accept changes Reject changes markdown_extensions : - pymdownx.critic : mode : view markdown_extensions : - pymdownx.critic : mode : accept markdown_extensions : - pymdownx.critic : mode : reject See reference for usage: Highlighting changes","title":"Critic"},{"location":"setup/extensions/python-markdown-extensions/#details","text":"1.9.0 \u00b7 Extension The Details extension supercharges the Admonition extension, making the resulting call-outs collapsible, allowing them to be opened and closed by the user. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.details No configuration options are available. See reference for usage: Collapsible blocks","title":"Details"},{"location":"setup/extensions/python-markdown-extensions/#emoji","text":"1.0.0 \u00b7 Extension The Emoji extension automatically inlines bundled and custom icons and emojis in *.svg file format into the resulting HTML page. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji # (1)! emoji_generator : !!python/name:materialx.emoji.to_svg Python Markdown Extensions uses the pymdownx namespace, but in order to support the inlining of icons, the materialx namespace must be used, as it extends the functionality of pymdownx . The following configuration options are supported: emoji_index Default: emojione \u2013 This option defines which set of emojis is used for rendering. Note that the use of emojione is not recommended due to restrictions in licensing : markdown_extensions : - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator Default: to_png \u2013 This option defines how the resolved emoji or icon shortcode is render. Note that icons can only be used together with the to_svg configuration: markdown_extensions : - pymdownx.emoji : emoji_generator : !!python/name:materialx.emoji.to_svg options.custom_icons Default: none \u2013 This option allows to list folders with additional icon sets to be used in Markdown or mkdocs.yml , which is explained in more detail in the icon customization guide : markdown_extensions : - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator : !!python/name:materialx.emoji.to_svg options : custom_icons : - overrides/.icons The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Using emojis Using icons Using icons in templates","title":"Emoji"},{"location":"setup/extensions/python-markdown-extensions/#highlight","text":"5.0.0 \u00b7 Extension \u00b7 Supersedes CodeHilite The Highlight extension adds support for syntax highlighting of code blocks (with the help of SuperFences ) and inline code blocks (with the help of InlineHilite ). Enable it via mkdocs.yml : markdown_extensions : - pymdownx.highlight : anchor_linenums : true - pymdownx.superfences # (1)! Highlight is used by the SuperFences extension to perform syntax highlighting on code blocks, not the other way round, which is why this extension also needs to be enabled. The following configuration options are supported: use_pygments Default: true \u2013 This option allows to control whether highlighting should be carried out during build time using Pygments or in the browser with a JavaScript syntax highlighter: Pygments JavaScript markdown_extensions : - pymdownx.highlight : use_pygments : true - pymdownx.superfences markdown_extensions : - pymdownx.highlight : use_pygments : false As an example, Highlight.js , a JavaScript syntax highlighter, can be integrated with some additional JavaScript and an additional style sheet in mkdocs.yml : docs/javascripts/highlight.js mkdocs.yml document $ . subscribe (() => { hljs . highlightAll () }) extra_javascript : - https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js - javascripts/highlight.js extra_css : - https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/styles/default.min.css Note that Highlight.js has no affiliation with the Highlight extension. All following configuration options are only compatible with build-time syntax highlighting using Pygments , so they don't apply if use_pygments is set to false . auto_title Default: false \u2013 This option will automatically add a title to all code blocks that shows the name of the language being used, e.g. Python is printed for a py block: markdown_extensions : - pymdownx.highlight : auto_title : true linenums Default: false \u2013 This option will add line numbers to all code blocks. If you wish to add line numbers to some , but not all code blocks, consult the section on adding line numbers in the code block reference, which also contains some tips on working with line numbers: markdown_extensions : - pymdownx.highlight : linenums : true linenums_style Default: table \u2013 The Highlight extension provides three ways to add line numbers, two of which are supported by Material for MkDocs. While table wraps a code block in a <table> element, pymdownx-inline renders line numbers as part of the line itself: markdown_extensions : - pymdownx.highlight : linenums_style : pymdownx-inline Note that inline will put line numbers next to the actual code, which means that they will be included when selecting text with the cursor or copying a code block to the clipboard. Thus, the usage of either table or pymdownx-inline is recommended. anchor_linenums 8.1.0 \u00b7 Default: false \u2013 If a code blocks contains line numbers, enabling this setting will wrap them with anchor links, so they can be hyperlinked and shared more easily: markdown_extensions : - pymdownx.highlight : anchor_linenums : true The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Using code blocks Adding a title Adding line numbers Highlighting specific lines Custom syntax theme","title":"Highlight"},{"location":"setup/extensions/python-markdown-extensions/#inlinehilite","text":"5.0.0 \u00b7 Extension The InlineHilite extension add support for syntax highlighting of inline code blocks. It's built on top of the Highlight extension, from which it sources its configuration. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.highlight - pymdownx.inlinehilite The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. The only exception is the css_class option, which must not be changed. See the InlineHilite documentation for guidance. See reference for usage: Highlighting inline code blocks","title":"InlineHilite"},{"location":"setup/extensions/python-markdown-extensions/#keys","text":"1.0.0 \u00b7 Extension The Keys extension adds a simple syntax to allow for the rendering of keyboard keys and combinations, e.g. Ctrl + Alt + Del . Enable it via mkdocs.yml : markdown_extensions : - pymdownx.keys The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. The only exception is the class option, which must not be changed. See the Keys documentation for more information. See reference for usage: Adding keyboard keys","title":"Keys"},{"location":"setup/extensions/python-markdown-extensions/#smartsymbols","text":"0.1.0 \u00b7 Extension The SmartSymbols extension converts some sequences of characters into their corresponding symbols, e.h. copyright symbols or fractions. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.smartsymbols The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the SmartSymbols documentation for guidance.","title":"SmartSymbols"},{"location":"setup/extensions/python-markdown-extensions/#snippets","text":"0.1.0 \u00b7 Extension The Snippets extension adds the ability to embed content from arbitrary files into a document, including other documents or source files, by using a simple syntax. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.snippets The configuration options of this extension are not specific to Material for MkDocs, as they only impact the Markdown parsing stage. See the Snippets documentation for more information. See reference for usage: Adding a glossary Embedding external files","title":"Snippets"},{"location":"setup/extensions/python-markdown-extensions/#superfences","text":"0.1.0 \u00b7 Extension \u00b7 Supersedes Fenced Code Blocks The SuperFences extension allows for arbitrary nesting of code and content blocks inside each other, including admonitions, tabs, lists and all other elements. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.superfences The following configuration options are supported: custom_fences Default: none \u2013 This option allows to define a handler for custom fences, e.g. to preserve the definitions of Mermaid.js diagrams to be interpreted in the browser: markdown_extensions : - pymdownx.superfences : custom_fences : - name : mermaid class : mermaid format : !!python/name:pymdownx.superfences.fence_code_format Note that this will primarily prevent syntax highlighting from being applied. See the reference on diagrams to learn how Mermaid.js is integrated with Material for MkDocs. The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Using annotations Using code blocks Using content tabs Using flowcharts Using sequence diagrams Using state diagrams Using class diagrams Using entity-relationship diagrams","title":"SuperFences"},{"location":"setup/extensions/python-markdown-extensions/#tabbed","text":"5.0.0 \u00b7 Extension The Tabbed extension allows the usage of content tabs, a simple way to group related content and code blocks under accessible tabs. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.tabbed : alternate_style : true The following configuration options are supported: alternate_style 7.3.1 \u00b7 Default: false \u00b7 Required \u2013 This option enables the content tabs alternate style , which has better behavior on mobile viewports , and is the only supported style: markdown_extensions : - pymdownx.tabbed : alternate_style : true slugify Default: headerid.slugify \u2013 This option allows for customization of the slug function. For some languages, the default may not produce good and readable identifiers \u2013 consider using another slug function like for example those from Python Markdown Extensions : Unicode Unicode, case-sensitive markdown_extensions : - pymdownx.tabbed : slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower markdown_extensions : - pymdownx.tabbed : slugify : !!python/object/apply:pymdownx.slugs.slugify The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Grouping code blocks Grouping other content Embedded content","title":"Tabbed"},{"location":"setup/extensions/python-markdown-extensions/#tasklist","text":"1.0.0 \u00b7 Extension The Tasklist extension allows for the usage of GitHub Flavored Markdown inspired task lists , following the same syntactical conventions. Enable it via mkdocs.yml : markdown_extensions : - pymdownx.tasklist : custom_checkbox : true The following configuration options are supported: custom_checkbox Default: false \u00b7 This option toggles the rendering style of checkboxes, replacing native checkbox styles with beautiful icons, and is therefore recommended: markdown_extensions : - pymdownx.tasklist : custom_checkbox : true clickable_checkbox Default: false \u00b7 This option toggles whether checkboxes are clickable. As the state is not persisted, the use of this option is rather discouraged from a user experience perspective: markdown_extensions : - pymdownx.tasklist : clickable_checkbox : true The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. See reference for usage: Using task lists Other libraries like KaTeX are also supported and can be integrated with some additional effort. See the Arithmatex documentation on KaTeX for further guidance, as this is beyond the scope of Material for MkDocs. \u21a9","title":"Tasklist"},{"location":"setup/extensions/python-markdown/","text":"Python Markdown \u00b6 Material for MkDocs supports a large number of Python Markdown extensions, which is part of what makes it so attractive for technical writing. Following is a list of all supported extensions, linking to the relevant sections of the reference for which features they need to be enabled. Supported extensions \u00b6 Abbreviations \u00b6 1.0.0 \u00b7 Extension The Abbreviations extension adds the ability to add a small tooltip to an element, by wrapping it with an abbr tag. Only plain text (no markup) is supported. Enable it via mkdocs.yml : markdown_extensions : - abbr No configuration options are available. See reference for usage: Adding abbreviations Adding a glossary Admonition \u00b6 0.1.0 \u00b7 Extension The Admonition extension adds support for admonitions, more commonly known as call-outs , which can be defined in Markdown by using a simple syntax. Enable it via mkdocs.yml : markdown_extensions : - admonition No configuration options are available. See reference for usage: Adding admonitions Changing the title Removing the title Supported types Attribute Lists \u00b6 0.1.0 \u00b7 Extension The Attribute Lists extension allows to add HTML attributes and CSS classes to almost every Markdown inline- and block-level element with a special syntax. Enable it via mkdocs.yml : markdown_extensions : - attr_list No configuration options are available. See reference for usage: Using annotations Using grids Adding buttons Adding tooltips Using icons with colors Using icons with animations Image alignment Image lazy-loading Definition Lists \u00b6 1.1.0 \u00b7 Extension The Definition Lists extension adds the ability to add definition lists (more commonly known as description lists \u2013 dl in HTML) via Markdown to a document. Enable it via mkdocs.yml : markdown_extensions : - def_list No configuration options are available. See reference for usage: Using definition lists Footnotes \u00b6 1.0.0 \u00b7 Extension The Footnotes extension allows to define inline footnotes, which are then rendered below all Markdown content of a document. Enable it via mkdocs.yml : markdown_extensions : - footnotes No configuration options are supported. See reference for usage: Adding footnote references Adding footnote content Markdown in HTML \u00b6 0.1.0 \u00b7 Extension The Markdown in HTML extension allows for writing Markdown inside of HTML, which is useful for wrapping Markdown content with custom elements. Enable it via mkdocs.yml : markdown_extensions : - md_in_html By default, Markdown ignores any content within a raw HTML block-level element. With the md_in_html extension enabled, the content of a raw HTML block-level element can be parsed as Markdown by including a markdown attribute on the opening tag. The markdown attribute will be stripped from the output, while all other attributes will be preserved. No configuration options are available. See reference for usage: Using annotations Using grids Image captions Table of Contents \u00b6 0.1.0 \u00b7 Extension The Table of Contents extension automatically generates a table of contents from a document, which Material for MkDocs will render as part of the resulting page. Enable it via mkdocs.yml : markdown_extensions : - toc : permalink : true The following configuration options are supported: title 7.3.5 \u00b7 Default: automatically set \u2013 This option sets the title of the table of contents in the right navigation sidebar, which is normally automatically sourced from the translations for the site language as set in mkdocs.yml : markdown_extensions : - toc : title : On this page permalink Default: false \u2013 This option adds an anchor link containing the paragraph symbol \u00b6 or another custom symbol at the end of each headline, exactly like on the page you're currently viewing, which Material for MkDocs will make appear on hover: \u00b6 \u2693\ufe0e markdown_extensions : - toc : permalink : true markdown_extensions : - toc : permalink : \u2693\ufe0e permalink_title Default: Permanent link \u2013 This option sets the title of the anchor link which is shown on hover and read by screen readers. For accessibility reasons, it might be beneficial to change it to a more discernable name, stating that the anchor links to the section itself: markdown_extensions : - toc : permalink_title : Anchor link to this section for reference slugify Default: headerid.slugify \u2013 This option allows for customization of the slug function. For some languages, the default may not produce good and readable identifiers \u2013 consider using another slug function like for example those from Python Markdown Extensions : Unicode Unicode, case-sensitive markdown_extensions : - toc : slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower markdown_extensions : - toc : slugify : !!python/object/apply:pymdownx.slugs.slugify toc_depth Default: 6 \u2013 Define the range of levels to be included in the table of contents. This may be useful for project documentation with deeply structured headings to decrease the length of the table of contents, or to remove the table of contents altogether: Hide levels 4-6 Hide table of contents markdown_extensions : - toc : toc_depth : 3 markdown_extensions : - toc : toc_depth : 0 The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk. Tables \u00b6 0.1.0 \u00b7 Extension The Tables extension adds the ability to create tables in Markdown by using a simple syntax. Enable it via mkdocs.yml (albeit it should be enabled by default): markdown_extensions : - tables No configuration options are available. See reference for usage: Using data tables Column alignment Superseded extensions \u00b6 The following Python Markdown extensions are not (or might not be) supported anymore, and are therefore not recommended for use. Instead, the alternatives should be considered. Fenced Code Blocks \u00b6 0.1.0 \u00b7 Extension Superseded by SuperFences . This extension might still work, but the SuperFences extension is superior in many ways, as it allows for arbitrary nesting, and is therefore recommended. CodeHilite \u00b6 0.1.0 ... 5.5.14 \u00b7 Extension Superseded by Highlight . Support for CodeHilite was dropped in 6.0.0, as Highlight has a better integration with other essential extensions like SuperFences and InlineHilite .","title":"Python Markdown"},{"location":"setup/extensions/python-markdown/#python-markdown","text":"Material for MkDocs supports a large number of Python Markdown extensions, which is part of what makes it so attractive for technical writing. Following is a list of all supported extensions, linking to the relevant sections of the reference for which features they need to be enabled.","title":"Python Markdown"},{"location":"setup/extensions/python-markdown/#supported-extensions","text":"","title":"Supported extensions"},{"location":"setup/extensions/python-markdown/#abbreviations","text":"1.0.0 \u00b7 Extension The Abbreviations extension adds the ability to add a small tooltip to an element, by wrapping it with an abbr tag. Only plain text (no markup) is supported. Enable it via mkdocs.yml : markdown_extensions : - abbr No configuration options are available. See reference for usage: Adding abbreviations Adding a glossary","title":"Abbreviations"},{"location":"setup/extensions/python-markdown/#admonition","text":"0.1.0 \u00b7 Extension The Admonition extension adds support for admonitions, more commonly known as call-outs , which can be defined in Markdown by using a simple syntax. Enable it via mkdocs.yml : markdown_extensions : - admonition No configuration options are available. See reference for usage: Adding admonitions Changing the title Removing the title Supported types","title":"Admonition"},{"location":"setup/extensions/python-markdown/#attribute-lists","text":"0.1.0 \u00b7 Extension The Attribute Lists extension allows to add HTML attributes and CSS classes to almost every Markdown inline- and block-level element with a special syntax. Enable it via mkdocs.yml : markdown_extensions : - attr_list No configuration options are available. See reference for usage: Using annotations Using grids Adding buttons Adding tooltips Using icons with colors Using icons with animations Image alignment Image lazy-loading","title":"Attribute Lists"},{"location":"setup/extensions/python-markdown/#definition-lists","text":"1.1.0 \u00b7 Extension The Definition Lists extension adds the ability to add definition lists (more commonly known as description lists \u2013 dl in HTML) via Markdown to a document. Enable it via mkdocs.yml : markdown_extensions : - def_list No configuration options are available. See reference for usage: Using definition lists","title":"Definition Lists"},{"location":"setup/extensions/python-markdown/#footnotes","text":"1.0.0 \u00b7 Extension The Footnotes extension allows to define inline footnotes, which are then rendered below all Markdown content of a document. Enable it via mkdocs.yml : markdown_extensions : - footnotes No configuration options are supported. See reference for usage: Adding footnote references Adding footnote content","title":"Footnotes"},{"location":"setup/extensions/python-markdown/#markdown-in-html","text":"0.1.0 \u00b7 Extension The Markdown in HTML extension allows for writing Markdown inside of HTML, which is useful for wrapping Markdown content with custom elements. Enable it via mkdocs.yml : markdown_extensions : - md_in_html By default, Markdown ignores any content within a raw HTML block-level element. With the md_in_html extension enabled, the content of a raw HTML block-level element can be parsed as Markdown by including a markdown attribute on the opening tag. The markdown attribute will be stripped from the output, while all other attributes will be preserved. No configuration options are available. See reference for usage: Using annotations Using grids Image captions","title":"Markdown in HTML"},{"location":"setup/extensions/python-markdown/#table-of-contents","text":"0.1.0 \u00b7 Extension The Table of Contents extension automatically generates a table of contents from a document, which Material for MkDocs will render as part of the resulting page. Enable it via mkdocs.yml : markdown_extensions : - toc : permalink : true The following configuration options are supported: title 7.3.5 \u00b7 Default: automatically set \u2013 This option sets the title of the table of contents in the right navigation sidebar, which is normally automatically sourced from the translations for the site language as set in mkdocs.yml : markdown_extensions : - toc : title : On this page permalink Default: false \u2013 This option adds an anchor link containing the paragraph symbol \u00b6 or another custom symbol at the end of each headline, exactly like on the page you're currently viewing, which Material for MkDocs will make appear on hover: \u00b6 \u2693\ufe0e markdown_extensions : - toc : permalink : true markdown_extensions : - toc : permalink : \u2693\ufe0e permalink_title Default: Permanent link \u2013 This option sets the title of the anchor link which is shown on hover and read by screen readers. For accessibility reasons, it might be beneficial to change it to a more discernable name, stating that the anchor links to the section itself: markdown_extensions : - toc : permalink_title : Anchor link to this section for reference slugify Default: headerid.slugify \u2013 This option allows for customization of the slug function. For some languages, the default may not produce good and readable identifiers \u2013 consider using another slug function like for example those from Python Markdown Extensions : Unicode Unicode, case-sensitive markdown_extensions : - toc : slugify : !!python/object/apply:pymdownx.slugs.slugify kwds : case : lower markdown_extensions : - toc : slugify : !!python/object/apply:pymdownx.slugs.slugify toc_depth Default: 6 \u2013 Define the range of levels to be included in the table of contents. This may be useful for project documentation with deeply structured headings to decrease the length of the table of contents, or to remove the table of contents altogether: Hide levels 4-6 Hide table of contents markdown_extensions : - toc : toc_depth : 3 markdown_extensions : - toc : toc_depth : 0 The other configuration options of this extension are not officially supported by Material for MkDocs, which is why they may yield unexpected results. Use them at your own risk.","title":"Table of Contents"},{"location":"setup/extensions/python-markdown/#tables","text":"0.1.0 \u00b7 Extension The Tables extension adds the ability to create tables in Markdown by using a simple syntax. Enable it via mkdocs.yml (albeit it should be enabled by default): markdown_extensions : - tables No configuration options are available. See reference for usage: Using data tables Column alignment","title":"Tables"},{"location":"setup/extensions/python-markdown/#superseded-extensions","text":"The following Python Markdown extensions are not (or might not be) supported anymore, and are therefore not recommended for use. Instead, the alternatives should be considered.","title":"Superseded extensions"},{"location":"setup/extensions/python-markdown/#fenced-code-blocks","text":"0.1.0 \u00b7 Extension Superseded by SuperFences . This extension might still work, but the SuperFences extension is superior in many ways, as it allows for arbitrary nesting, and is therefore recommended.","title":"Fenced Code Blocks"},{"location":"setup/extensions/python-markdown/#codehilite","text":"0.1.0 ... 5.5.14 \u00b7 Extension Superseded by Highlight . Support for CodeHilite was dropped in 6.0.0, as Highlight has a better integration with other essential extensions like SuperFences and InlineHilite .","title":"CodeHilite"},{"location":"tags/","text":"Tags \u00b6 If you want to get Updated-graph image, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ Graph) If you want to get Updated-mind-mapping image, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ MindMapping) If you want to get Commands(Ubuntu, Devops, Blockchain CLIs) in a compact, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ Commands) Following is a list of relevant tags: about \u00b6 About Me Reach Me api \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api armanriazi \u00b6 About Me Reach Me Master Thesis--Arman Riazi build \u00b6 Ocw runtime caas \u00b6 Rancher Master Thesis--Arman Riazi career \u00b6 About Me Reach Me cicd \u00b6 CICD Kubernetes armanriazi-movies-reactjs armanriazi-vidly-api cloud \u00b6 Cloud Virualization armanriazi-movies-reactjs armanriazi-vidly-api Master Thesis--Arman Riazi codebase \u00b6 Programming compile \u00b6 Libc rust connect \u00b6 Reach Me contact \u00b6 Reach Me container \u00b6 Docker Rancher Master Thesis--Arman Riazi corda \u00b6 Corda-R3 couchdb \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api crowdloan \u00b6 Crowdloan research intro cryprocurrency \u00b6 Cryptocurrency Balance Sheets (Archived) devops \u00b6 Hyperledger CICD Cloud DevOps Docker Elastic-Search Kubernetes Rancher Virualization armanriazi-movies-reactjs armanriazi-vidly-api Master Thesis--Arman Riazi docker \u00b6 Docker elastic \u00b6 Elastic-Search esxi \u00b6 Virualization ethereum_ecosystem \u00b6 Solidity Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract ewasm \u00b6 ParaState WASM experience \u00b6 About Me expressjs \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api faucet \u00b6 Arman Riazi github \u00b6 Substrate Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract armanriazi-movies-reactjs armanriazi-vidly-api Programming Master Thesis--Arman Riazi hyperledger \u00b6 Hyperledger i \u00b6 About Me Reach Me ibm \u00b6 Hyperledger armanriazi-movies-reactjs armanriazi-vidly-api iot \u00b6 Secondstate research intro java \u00b6 Corda-R3 Master Thesis--Arman Riazi kovan \u00b6 Arman Riazi kubernetes \u00b6 Kubernetes Rancher kusama \u00b6 Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro libc \u00b6 Libc rust llvm \u00b6 Ewasm research intro magazine \u00b6 Magazine master \u00b6 Master Thesis--Arman Riazi me \u00b6 About Me Reach Me music \u00b6 Music Videos node \u00b6 Substrate setup research intro nodejs \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api ocw \u00b6 Ocw runtime parastate \u00b6 Parastate research intro polkadot \u00b6 Polka research intro Substrate framework research intro polkadot_ecosystem \u00b6 ParaState Polkadot Substrate Parastate research intro Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro Ewasm research intro pos \u00b6 Parastate research intro programming \u00b6 Programming project \u00b6 ParaState Polkadot Substrate rancher \u00b6 Rancher reactjs \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api recuit \u00b6 About Me Reach Me research \u00b6 ParaState Polkadot restapi \u00b6 armanriazi-movies-reactjs armanriazi-vidly-api riazi \u00b6 About Me Reach Me rpc \u00b6 Substrate setup research intro runtime \u00b6 Ocw runtime rust \u00b6 Substrate setup research intro Programming sample \u00b6 ParaState Polkadot Substrate Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract armanriazi-movies-reactjs armanriazi-vidly-api science \u00b6 Master Thesis--Arman Riazi search \u00b6 Elastic-Search secondstate \u00b6 Secondstate research intro simulation \u00b6 Corda-R3 skills \u00b6 About Me smartcontract \u00b6 Solidity Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract social \u00b6 Reach Me substrate \u00b6 ParaState Polkadot Substrate Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro Ewasm research intro trade \u00b6 Cryptocurrency Balance Sheets (Archived) university \u00b6 Master Thesis--Arman Riazi virtualization \u00b6 Virualization Master Thesis--Arman Riazi vsphere \u00b6 Virualization wasm \u00b6 SecondState WASM Ewasm research intro webassembly \u00b6 Ewasm research intro whitepapaer \u00b6 Polka research intro","title":"Tags"},{"location":"tags/#tags","text":"If you want to get Updated-graph image, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ Graph) If you want to get Updated-mind-mapping image, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ MindMapping) If you want to get Commands(Ubuntu, Devops, Blockchain CLIs) in a compact, send me an Email to armanriazi.blockchain@gmail.com (Title: armanriazi_github_io _ Commands) Following is a list of relevant tags:","title":"Tags"},{"location":"tags/#about","text":"About Me Reach Me","title":"about"},{"location":"tags/#api","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"api"},{"location":"tags/#armanriazi","text":"About Me Reach Me Master Thesis--Arman Riazi","title":"armanriazi"},{"location":"tags/#build","text":"Ocw runtime","title":"build"},{"location":"tags/#caas","text":"Rancher Master Thesis--Arman Riazi","title":"caas"},{"location":"tags/#career","text":"About Me Reach Me","title":"career"},{"location":"tags/#cicd","text":"CICD Kubernetes armanriazi-movies-reactjs armanriazi-vidly-api","title":"cicd"},{"location":"tags/#cloud","text":"Cloud Virualization armanriazi-movies-reactjs armanriazi-vidly-api Master Thesis--Arman Riazi","title":"cloud"},{"location":"tags/#codebase","text":"Programming","title":"codebase"},{"location":"tags/#compile","text":"Libc rust","title":"compile"},{"location":"tags/#connect","text":"Reach Me","title":"connect"},{"location":"tags/#contact","text":"Reach Me","title":"contact"},{"location":"tags/#container","text":"Docker Rancher Master Thesis--Arman Riazi","title":"container"},{"location":"tags/#corda","text":"Corda-R3","title":"corda"},{"location":"tags/#couchdb","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"couchdb"},{"location":"tags/#crowdloan","text":"Crowdloan research intro","title":"crowdloan"},{"location":"tags/#cryprocurrency","text":"Cryptocurrency Balance Sheets (Archived)","title":"cryprocurrency"},{"location":"tags/#devops","text":"Hyperledger CICD Cloud DevOps Docker Elastic-Search Kubernetes Rancher Virualization armanriazi-movies-reactjs armanriazi-vidly-api Master Thesis--Arman Riazi","title":"devops"},{"location":"tags/#docker","text":"Docker","title":"docker"},{"location":"tags/#elastic","text":"Elastic-Search","title":"elastic"},{"location":"tags/#esxi","text":"Virualization","title":"esxi"},{"location":"tags/#ethereum_ecosystem","text":"Solidity Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract","title":"ethereum_ecosystem"},{"location":"tags/#ewasm","text":"ParaState WASM","title":"ewasm"},{"location":"tags/#experience","text":"About Me","title":"experience"},{"location":"tags/#expressjs","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"expressjs"},{"location":"tags/#faucet","text":"Arman Riazi","title":"faucet"},{"location":"tags/#github","text":"Substrate Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract armanriazi-movies-reactjs armanriazi-vidly-api Programming Master Thesis--Arman Riazi","title":"github"},{"location":"tags/#hyperledger","text":"Hyperledger","title":"hyperledger"},{"location":"tags/#i","text":"About Me Reach Me","title":"i"},{"location":"tags/#ibm","text":"Hyperledger armanriazi-movies-reactjs armanriazi-vidly-api","title":"ibm"},{"location":"tags/#iot","text":"Secondstate research intro","title":"iot"},{"location":"tags/#java","text":"Corda-R3 Master Thesis--Arman Riazi","title":"java"},{"location":"tags/#kovan","text":"Arman Riazi","title":"kovan"},{"location":"tags/#kubernetes","text":"Kubernetes Rancher","title":"kubernetes"},{"location":"tags/#kusama","text":"Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro","title":"kusama"},{"location":"tags/#libc","text":"Libc rust","title":"libc"},{"location":"tags/#llvm","text":"Ewasm research intro","title":"llvm"},{"location":"tags/#magazine","text":"Magazine","title":"magazine"},{"location":"tags/#master","text":"Master Thesis--Arman Riazi","title":"master"},{"location":"tags/#me","text":"About Me Reach Me","title":"me"},{"location":"tags/#music","text":"Music Videos","title":"music"},{"location":"tags/#node","text":"Substrate setup research intro","title":"node"},{"location":"tags/#nodejs","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"nodejs"},{"location":"tags/#ocw","text":"Ocw runtime","title":"ocw"},{"location":"tags/#parastate","text":"Parastate research intro","title":"parastate"},{"location":"tags/#polkadot","text":"Polka research intro Substrate framework research intro","title":"polkadot"},{"location":"tags/#polkadot_ecosystem","text":"ParaState Polkadot Substrate Parastate research intro Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro Ewasm research intro","title":"polkadot_ecosystem"},{"location":"tags/#pos","text":"Parastate research intro","title":"pos"},{"location":"tags/#programming","text":"Programming","title":"programming"},{"location":"tags/#project","text":"ParaState Polkadot Substrate","title":"project"},{"location":"tags/#rancher","text":"Rancher","title":"rancher"},{"location":"tags/#reactjs","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"reactjs"},{"location":"tags/#recuit","text":"About Me Reach Me","title":"recuit"},{"location":"tags/#research","text":"ParaState Polkadot","title":"research"},{"location":"tags/#restapi","text":"armanriazi-movies-reactjs armanriazi-vidly-api","title":"restapi"},{"location":"tags/#riazi","text":"About Me Reach Me","title":"riazi"},{"location":"tags/#rpc","text":"Substrate setup research intro","title":"rpc"},{"location":"tags/#runtime","text":"Ocw runtime","title":"runtime"},{"location":"tags/#rust","text":"Substrate setup research intro Programming","title":"rust"},{"location":"tags/#sample","text":"ParaState Polkadot Substrate Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract armanriazi-movies-reactjs armanriazi-vidly-api","title":"sample"},{"location":"tags/#science","text":"Master Thesis--Arman Riazi","title":"science"},{"location":"tags/#search","text":"Elastic-Search","title":"search"},{"location":"tags/#secondstate","text":"Secondstate research intro","title":"secondstate"},{"location":"tags/#simulation","text":"Corda-R3","title":"simulation"},{"location":"tags/#skills","text":"About Me","title":"skills"},{"location":"tags/#smartcontract","text":"Solidity Arman Riazi Arman Riazi Arman Riazi Arman Riazi SmartContract","title":"smartcontract"},{"location":"tags/#social","text":"Reach Me","title":"social"},{"location":"tags/#substrate","text":"ParaState Polkadot Substrate Polka research intro Substrate framework research intro Substrate setup research intro Crowdloan research intro Ewasm research intro","title":"substrate"},{"location":"tags/#trade","text":"Cryptocurrency Balance Sheets (Archived)","title":"trade"},{"location":"tags/#university","text":"Master Thesis--Arman Riazi","title":"university"},{"location":"tags/#virtualization","text":"Virualization Master Thesis--Arman Riazi","title":"virtualization"},{"location":"tags/#vsphere","text":"Virualization","title":"vsphere"},{"location":"tags/#wasm","text":"SecondState WASM Ewasm research intro","title":"wasm"},{"location":"tags/#webassembly","text":"Ewasm research intro","title":"webassembly"},{"location":"tags/#whitepapaer","text":"Polka research intro","title":"whitepapaer"}]}